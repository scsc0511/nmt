{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"attention_self_made.ipynb","provenance":[{"file_id":"13xkF0QrZdrNAzW96WwduGGJ71wbgauGE","timestamp":1622214334557}],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyP2k+DPcVQ6+N7j/0CsKYxz"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"cfkJMursRHk_","executionInfo":{"status":"ok","timestamp":1622351601438,"user_tz":-540,"elapsed":13413,"user":{"displayName":"최석웅","photoUrl":"","userId":"05234760535644650462"}}},"source":["from google.colab import auth \n","auth.authenticate_user()  "],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5m_slCmZRQQq","executionInfo":{"status":"ok","timestamp":1622351616835,"user_tz":-540,"elapsed":15405,"user":{"displayName":"최석웅","photoUrl":"","userId":"05234760535644650462"}},"outputId":"9c92f995-4667-4815-c950-4a50c1030c21"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I20AXsjyR2pB","executionInfo":{"status":"ok","timestamp":1622351780615,"user_tz":-540,"elapsed":162739,"user":{"displayName":"최석웅","photoUrl":"","userId":"05234760535644650462"}},"outputId":"58506fe2-d648-4e0e-e70f-2644485333f6"},"source":["## torch와 torchtext 버전이 맞지 않아 생기는 충돌을 막기 위해 \n","## 버전을 맞춰 설치 \n","\n","\n","%cd  /usr/local/lib/python3.7/dist-packages/\n","%rm -rf torch\n","!pip install torch==1.7.0\n","!pip install torchtext==0.8.1\n","%cd /content/gdrive/MyDrive/nlg/machine_translation/nmt"],"execution_count":3,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages\n","Collecting torch==1.7.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d9/74/d52c014fbfb50aefc084d2bf5ffaa0a8456f69c586782b59f93ef45e2da9/torch-1.7.0-cp37-cp37m-manylinux1_x86_64.whl (776.7MB)\n","\u001b[K     |████████████████████████████████| 776.8MB 23kB/s \n","\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch==1.7.0) (0.16.0)\n","Collecting dataclasses\n","  Downloading https://files.pythonhosted.org/packages/26/2f/1095cdc2868052dd1e64520f7c0d5c8c550ad297e944e641dbf1ffbb9a5d/dataclasses-0.6-py3-none-any.whl\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.7.0) (1.19.5)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.7.0) (3.7.4.3)\n","\u001b[31mERROR: torchvision 0.9.1+cu101 has requirement torch==1.8.1, but you'll have torch 1.7.0 which is incompatible.\u001b[0m\n","\u001b[31mERROR: torchtext 0.9.1 has requirement torch==1.8.1, but you'll have torch 1.7.0 which is incompatible.\u001b[0m\n","Installing collected packages: dataclasses, torch\n","  Found existing installation: torch 1.8.1+cu101\n","    Uninstalling torch-1.8.1+cu101:\n","      Successfully uninstalled torch-1.8.1+cu101\n","Successfully installed dataclasses-0.6 torch-1.7.0\n","Collecting torchtext==0.8.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/13/80/046f0691b296e755ae884df3ca98033cb9afcaf287603b2b7999e94640b8/torchtext-0.8.1-cp37-cp37m-manylinux1_x86_64.whl (7.0MB)\n","\u001b[K     |████████████████████████████████| 7.0MB 7.1MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.8.1) (2.23.0)\n","Collecting torch==1.7.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/90/5d/095ddddc91c8a769a68c791c019c5793f9c4456a688ddd235d6670924ecb/torch-1.7.1-cp37-cp37m-manylinux1_x86_64.whl (776.8MB)\n","\u001b[K     |████████████████████████████████| 776.8MB 21kB/s \n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.8.1) (4.41.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext==0.8.1) (1.19.5)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.8.1) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.8.1) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.8.1) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.8.1) (2020.12.5)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.7.1->torchtext==0.8.1) (3.7.4.3)\n","\u001b[31mERROR: torchvision 0.9.1+cu101 has requirement torch==1.8.1, but you'll have torch 1.7.1 which is incompatible.\u001b[0m\n","Installing collected packages: torch, torchtext\n","  Found existing installation: torch 1.7.0\n","    Uninstalling torch-1.7.0:\n","      Successfully uninstalled torch-1.7.0\n","  Found existing installation: torchtext 0.9.1\n","    Uninstalling torchtext-0.9.1:\n","      Successfully uninstalled torchtext-0.9.1\n","Successfully installed torch-1.7.1 torchtext-0.8.1\n","/content/gdrive/MyDrive/nlg/machine_translation/nmt\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j_6IywyVJrpR","executionInfo":{"status":"ok","timestamp":1622351780617,"user_tz":-540,"elapsed":18,"user":{"displayName":"최석웅","photoUrl":"","userId":"05234760535644650462"}},"outputId":"8a38d4f5-ca5a-4ae1-ea3d-45664d38f066"},"source":["%cd /content/gdrive/MyDrive/nlg/machine_translation/nmt"],"execution_count":4,"outputs":[{"output_type":"stream","text":["/content/gdrive/MyDrive/nlg/machine_translation/nmt\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ZiJWSjURwUZh","executionInfo":{"status":"ok","timestamp":1622351780618,"user_tz":-540,"elapsed":11,"user":{"displayName":"최석웅","photoUrl":"","userId":"05234760535644650462"}}},"source":["import os\n","## this is to prevent RuntimeError: CUDA error: device-side assert triggered\n","os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\" "],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"pUV9DUA8LeUm","executionInfo":{"status":"ok","timestamp":1622351781446,"user_tz":-540,"elapsed":838,"user":{"displayName":"최석웅","photoUrl":"","userId":"05234760535644650462"}}},"source":["import torch\n","import torch.nn as nn\n","from torch.nn.utils.rnn import pack_padded_sequence \n","from torch.nn.utils.rnn import pad_packed_sequence as unpack_padded_sequence\n","import torchtext\n","from torchtext.data import Field, Dataset, Example, interleave_keys, BucketIterator\n","import torch.optim as optim \n","import torch \n","import torch.nn as nn \n","from torch.cuda.amp import GradScaler, autocast\n","import numpy as np\n","from torch.nn import utils as tc_utils\n","import random\n","\n","#random.seed(1)\n","#np.random.seed(1)\n","#np.random.RandomState(1)\n","#torch.manual_seed(1)\n","#torch.cuda.manual_seed(1)\n","#torch.backends.cudnn.enabled=False\n","#torch.backends.cudnn.benchmark = False\n","#torch.backends.cudnn.deterministic=True"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"VMUNgriErD3d","executionInfo":{"status":"ok","timestamp":1622294611781,"user_tz":-540,"elapsed":7,"user":{"displayName":"최석웅","photoUrl":"","userId":"05234760535644650462"}}},"source":["## Hyper Parameter for Data \n","train_src_fn = '../data/corpus.shuf.train.tok.bpe.en'\n","train_tgt_fn = '../data/corpus.shuf.train.tok.bpe.ko'\n","valid_src_fn = '../data/corpus.shuf.valid.tok.bpe.en'\n","valid_tgt_fn = '../data/corpus.shuf.valid.tok.bpe.ko'\n","max_len = 100\n","init_token = '<BOS>'\n","eos_token= '<EOS>'\n","batch_size= 48\n","device = 0\n","max_vocab = 999999999999"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8AwUUk8aaj_s","executionInfo":{"status":"ok","timestamp":1622220750376,"user_tz":-540,"elapsed":23,"user":{"displayName":"최석웅","photoUrl":"","userId":"05234760535644650462"}},"outputId":"4b310556-fd56-4788-f1d9-45d2dbd2c389"},"source":["## this is why pad_id = 1, init_token_id=2, eos_token_id = 3\n"," \n","unk_token = '<unk>'\n","pad_token = '<pad>'\n","init_token = '<BOS>'\n","eos_token =  '<EOS>'\n","\n","## this code from pytorch document\n","from collections import OrderedDict\n","list(OrderedDict.fromkeys(\n","            tok for tok in [unk_token, pad_token, init_token,\n","                            eos_token]\n","            if tok is not None))"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['<unk>', '<pad>', '<BOS>', '<EOS>']"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"KN7XEWncHGfh","executionInfo":{"status":"ok","timestamp":1622351781447,"user_tz":-540,"elapsed":24,"user":{"displayName":"최석웅","photoUrl":"","userId":"05234760535644650462"}}},"source":["## Neural Machine Translation Dataset \n","\n","\n","\n","class TranslationDataset(Dataset) : \n","  def __init__(self, src_fn, tgt_fn, fields, max_len) :\n","    src_field = ('src', fields[0])\n","    tgt_field = ('tgt', fields[1]) \n","\n","    examples = list()\n","\n","    with open(src_fn, encoding='utf-8') as src, open(tgt_fn, encoding='utf-8') as tgt : \n","      for cur_src, cur_tgt in zip(src, tgt) : \n","        cur_src, cur_tgt = cur_src.strip(), cur_tgt.strip()\n","        if max_len and (max_len < max(len(cur_src.split()), len(cur_src.split()))) : continue\n","        examples.append(Example.fromlist([cur_src, cur_tgt], [src_field, tgt_field]))\n","\n","    super().__init__(examples, [src_field, tgt_field])\n","\n","  @staticmethod\n","  def sort_key(ex) : \n","    return interleave_keys(len(ex.src), len(ex.tgt))\n","\n","\n","\n","class DataLoader(object) : \n","  PAD_ID = 1\n","  INIT_TOKEN_ID = 2\n","  EOS_TOKEN_ID = 3\n","\n","  def __init__(self, src_fn=None, tgt_fn=None, max_len=255, init_token='<BOS>', eos_token='<EOS>', batch_size = 32, device=-1, shuffle=None, max_vocab =99999999999) : \n","    super(DataLoader, self).__init__()\n","    self.src = Field(sequential=True,use_vocab=True, batch_first=True,\n","                    include_lengths=True,fix_length=None,\n","                    init_token=None,eos_token=None)\n","    self.tgt = Field(sequential=True,use_vocab=True, batch_first=True,\n","                    include_lengths=True,fix_length=None,\n","                    init_token=init_token, eos_token=eos_token)\n","    \n","    if src_fn != None and tgt_fn != None :\n","      transl_dataset = TranslationDataset(src_fn, tgt_fn, (self.src, self.tgt), max_len)\n","\n","      self.data_iter = BucketIterator(transl_dataset, batch_size=batch_size, \n","                                      device = 'cuda:%d' % device if device >= 0 else 'cpu',\n","                                      sort_key = lambda x: len(x.tgt) +(max_len*len(x.src)),\n","                                      shuffle = shuffle,\n","                                       sort_within_batch=True,\n","                       )\n","      \n","      self.src.build_vocab(transl_dataset, max_size=max_vocab)\n","      self.tgt.build_vocab(transl_dataset, max_size=max_vocab)\n","\n","      \n","  def set_vocab_for_reproduction(self, src_vocab, tgt_vocab) : \n","    self.src.vocab = src_vocab \n","    self.tgt.vocab = tgt_vocab "],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"83SSQZR6rK_e","executionInfo":{"status":"ok","timestamp":1622220827963,"user_tz":-540,"elapsed":77605,"user":{"displayName":"최석웅","photoUrl":"","userId":"05234760535644650462"}},"outputId":"683c0e41-ba53-4ede-f96c-5818b5c82b28"},"source":["train_dl =  DataLoader(train_src_fn, train_tgt_fn, max_len, init_token, eos_token, batch_size,  -1, True, max_vocab)   ## device = -1 because gpu memory leakage -> batchwise loading \n","valid_dl =  DataLoader(valid_src_fn, valid_tgt_fn, max_len, init_token, eos_token, batch_size,  -1, False,max_vocab)   ## device = -1 because gpu memory leakage -> batchwise loading "],"execution_count":10,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torchtext/data/field.py:150: UserWarning: Field class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n","  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n","/usr/local/lib/python3.7/dist-packages/torchtext/data/example.py:78: UserWarning: Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n","  warnings.warn('Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.', UserWarning)\n","/usr/local/lib/python3.7/dist-packages/torchtext/data/iterator.py:48: UserWarning: BucketIterator class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n","  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"fbOPxiTVMjLl","executionInfo":{"status":"ok","timestamp":1622220827965,"user_tz":-540,"elapsed":43,"user":{"displayName":"최석웅","photoUrl":"","userId":"05234760535644650462"}}},"source":["valid_dl.set_vocab_for_reproduction(train_dl.src.vocab, train_dl.tgt.vocab)"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"2busNybwpU43","executionInfo":{"status":"ok","timestamp":1622220827966,"user_tz":-540,"elapsed":41,"user":{"displayName":"최석웅","photoUrl":"","userId":"05234760535644650462"}}},"source":["num_epochs = 30\n","\n","input_size = len(train_dl.src.vocab)\n","output_size = len(train_dl.tgt.vocab)\n","\n","embed_size = 512\n","hidden_size = 768\n","num_layer = 4\n","enc_bidirectional = True\n","drop_out = 0.2\n","max_clip_norm = 1e+8\n","\n","\n","beam_size = 5\n","lp_alpha = 0.6\n","lp_length = 5\n","cp_beta = 0.4\n","cp_min_val = 0.4"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"hL7pIOq0_97M","executionInfo":{"status":"ok","timestamp":1622220827967,"user_tz":-540,"elapsed":40,"user":{"displayName":"최석웅","photoUrl":"","userId":"05234760535644650462"}}},"source":["learning_rate =0.001\n","grad_update_period = 4"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"-d1UlxEBuD8g","executionInfo":{"status":"ok","timestamp":1622220827968,"user_tz":-540,"elapsed":40,"user":{"displayName":"최석웅","photoUrl":"","userId":"05234760535644650462"}}},"source":["## Attention 기반 Neural Machine Translator의 구성 \n","## Encoder + Decoder + Generator\n","## 그 외: 예측을 위해 BeamSearch를 사용, masking"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"rklrOcNRLfpW","executionInfo":{"status":"ok","timestamp":1622351781450,"user_tz":-540,"elapsed":23,"user":{"displayName":"최석웅","photoUrl":"","userId":"05234760535644650462"}}},"source":["class Attention(nn.Module) : \n","  def __init__(self, hidden_size) :\n","    super(Attention,self).__init__()\n","\n","    self.make_query = nn.Linear(hidden_size, hidden_size, bias=False)\n","    self.softmax = nn.Softmax(dim=-1) \n","\n","  def forward(self, enc_hs, cur_dec_h, mask=None) :\n","    ## |enc_hs| = (batch_size, enc_length, hidden_size)\n","    ## |cur_dec_h| = (batch_size, 1, hidden_size)\n","    ## |mask| = (batch_size, length)\n","\n","    query = self.make_query(cur_dec_h)\n","    ## |query| = (batch_size, 1, hidden_size)\n","    \n","    attn_weight = torch.bmm(query, enc_hs.transpose(1,2))\n","    ## |attn_weights| = (batch_size, 1, enc_length)\n","\n","    if mask is not None :\n","      attn_weight.masked_fill_(mask.unsqueeze(1), -float('inf'))\n","\n","    ## normalize and masking \n","    attn_weight = self.softmax(attn_weight)\n","    ## |attn_weights| = (batch_size, 1, enc_length)\n","\n","    context_vector = torch.bmm(attn_weight, enc_hs)\n","    ## |attn_weights} = (batch_size, 1, hidden_size)\n","\n","    return context_vector, attn_weight "],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"Eb7f0ETzQd8m","executionInfo":{"status":"ok","timestamp":1622351781450,"user_tz":-540,"elapsed":20,"user":{"displayName":"최석웅","photoUrl":"","userId":"05234760535644650462"}}},"source":["class LSTMEncoder(nn.Module) : \n","\n","  def __init__(self, embed_size, hidden_size, batch_first=True, num_layer=4, bidirectional=False, dropout=0.2) :\n","    super(LSTMEncoder,self).__init__() \n","\n","    ## hidden size를 hidden_size//2로 하는 이유 -> LSTM을 bidirectional로 하고 이를 concat하여\n","    ## LSTMEncoder의 최종 hidden size가 hidden_size가 되게 하기 위함 -> 이를 위해서는 hidden \n","    ## size가 짝수가 되어야 함 \n","    self.encoder = nn.LSTM(input_size=embed_size, hidden_size=int(hidden_size/2), \n","                           num_layers=num_layer, batch_first=batch_first, \n","                           bidirectional=bidirectional, dropout=dropout)\n","\n","  def forward(self, emb_vec) : \n","    ## 1. emb_vec = (emb_vec_data, emb_vec_length)의 튜플인 경우 \n","    ##   |emb_vec_data| = (batch_size, enc_length, embed_size)\n","    ##   |emb_vec_length| = (batch_size, )\n","    ## 2. emb_vec = emb_vec_data \n","    ##   |emb_vec_data| = (batch_size, enc_length, embed_size)\n","\n","    if isinstance(emb_vec, tuple) :\n","      ## emb_vec_data와 emb_vec_length는 mini batch 내에서 pad를 제외한 토큰의 개수를 기준으로\n","      ## 내림차순으로 정렬되어 있음. 이는 효율성 뿐만 아니라 pad를 계산하지 않아 정확도를 높이\n","      ## 기 위한 목적도 존재 \n","      ## 출처 : https://simonjisu.github.io/nlp/2018/07/05/packedsequence.html\n","      inp, emb_vec_length = emb_vec\n","      inp = pack_padded_sequence(inp, emb_vec_length.tolist(), batch_first=True)\n","    else : \n","      inp = emb_vec\n","    \n","    h_enc, hc_per_layer  = self.encoder(inp)\n","    ## |h_enc| = (batch_size, hidden_size)\n","    ## |hc_per_layer[0]| = (2*layer_num, batch_size, (hidden_size//2)) ([0] for hidden state, [1] for cell state)\n","\n","    if isinstance(emb_vec, tuple) : \n","      h_enc, _ = unpack_padded_sequence(h_enc, batch_first=True)\n","\n","    return h_enc, hc_per_layer\n"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"YCawrio3frG2","executionInfo":{"status":"ok","timestamp":1622351781451,"user_tz":-540,"elapsed":19,"user":{"displayName":"최석웅","photoUrl":"","userId":"05234760535644650462"}}},"source":["class LSTMDecoder(nn.Module) : \n","  def __init__(self, embed_size, hidden_size, batch_first=True, num_layer=4, dropout=0.2) :\n","    super(LSTMDecoder,self).__init__()\n","\n","    self.embed_size = embed_size \n","    self.hidden_size = hidden_size\n","\n","    ## Decoder는 Autoregressive한 속성을 가지기 때문에 하나의 Decoder가  \n","    ## 양 방향을 모두 고려할 수 없다. \n","    self.decoder = nn.LSTM(\n","        input_size=embed_size+hidden_size,\n","        hidden_size=hidden_size,\n","        num_layers=num_layer,\n","        batch_first = batch_first, \n","        dropout = dropout,\n","        bidirectional=False\n","    )\n","\n","   \n","  def forward(self, embed_vec, prev_dec_out, prev_hc) :\n","   ## |emb_vec| = (batch_size, 1, embed_size) -> 학습 과정에서는 실제 단어, 예측 과정에서는 이전 timestep에서의 예측값 \n","   ## |prev_hc| \n","   ##   |prev_h| = (num_layers, batch_size, hidden_size) -> 이전 타임 스텝의 hidden state\n","   ##   |prev_c| = (num_layers, batch_size, hidden_size) -> 이전 타임 스텝의 cell state(LSTM 기반이기 때문)\n","   ## |prev_dec_out| = (batch_size, 1, hidden_size) -> input feeding을 위한 것 \n","\n","    ## 맨 처음에는 이전 timestep이 없으므로 이전 timestep의 예측값도 없다. 이 경우 이전 time \n","    ## step의 output을 null vector로 해준다. 이 때 기존의 tensor와 같은 device에 있으면서 \n","    ## 같은 디바이스의 tensor로 만들기 위해 new_zeros()를 사용한다. \n","    ## 또한 beam search 과정에서는 input feeding을 사용하지 않기 때문에 이러한 경우에도 사용한다.\n","    batch_size = embed_vec.size(0)\n","    if prev_dec_out is None : \n","      prev_dec_out = embed_vec.new(batch_size, 1, self.hidden_size).zero_()\n","    \n","    ## input feeding -> Teacher Forcing을 사용하는 경우 학습 과정과 예측 과정에서 발생하는 \n","    ##                  모델에게 주어지는 정보의 차이를 최소화하기 위한 방법  \n","    input_vec = torch.cat([embed_vec, prev_dec_out], dim=-1)\n","    ## |input_vec| = (batch_size, 1, embed_size + hidden_size)\n","\n","\n","    h_dec, hc_per_layer = self.decoder(input_vec, prev_hc)\n","    ## |h_dec| = (batch_size, 1, 2*(hidden_size//2))\n","    ## |hc_per_layer[0]| = |hc_per_layer[1]| = (num_layers, batch_size, hidden_size)\n","\n","    return h_dec, hc_per_layer\n","\n"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"KyEJqemGuCL9","executionInfo":{"status":"ok","timestamp":1622351781452,"user_tz":-540,"elapsed":18,"user":{"displayName":"최석웅","photoUrl":"","userId":"05234760535644650462"}}},"source":["## Generator는 Decoder의 Output인 Hidden State와 Attention의 Output인 Context Vector를\n","## 입력 받아 조건부 확률의 결과인 Softmax Layer의 Output을 리턴\n","\n","class Generator(nn.Module) :\n","  def __init__(self,hidden_size, output_size) :\n","    super(Generator, self).__init__()\n","\n","    self.transform = nn.Linear(hidden_size, output_size)\n","    self.softmax = nn.LogSoftmax(dim=-1)\n","\n","  def forward(self, h_context) :\n","    # |dec_output| = (batch_size, length, hidden_size)\n","    \n","    transformed_vec = self.transform(h_context)\n","    # |transformed_vec| = (batch_size, length, out_size)\n","    \n","    output = self.softmax(transformed_vec)\n","    # |output| = (batch_size, length, out_size)\n","    \n","    return output"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"aLXp8pCoogmM","executionInfo":{"status":"ok","timestamp":1622351781453,"user_tz":-540,"elapsed":17,"user":{"displayName":"최석웅","photoUrl":"","userId":"05234760535644650462"}}},"source":["class LengthPenalty(object) :\n","  def __init__(self, alpha, beta) :\n","    super(LengthPenalty,self).__init__()\n","    self.alpha = alpha \n","    self.beta = beta \n","\n","  def __call__(self, length) :\n","    ## |length| = (batch_size, 1, 1) \n","    return ((1+self.beta) / (1+length))**self.alpha  "],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"TPo35YK3qSWP","executionInfo":{"status":"ok","timestamp":1622351781453,"user_tz":-540,"elapsed":15,"user":{"displayName":"최석웅","photoUrl":"","userId":"05234760535644650462"}}},"source":["class ConvergencePenalty() : \n","  def __init__(self, beta, min_val=1) :\n","    super(ConvergencePenalty,self).__init__()\n","    self.beta = beta \n","    self.min_val = min_val \n","\n","  def __call__(self, attn_weights) : \n","    ## |attn_weights| = (batch_size, enc_length, dec_length)\n","    \n","    log_attn_w = torch.log(attn_weights)\n","    ## |log_attn_w| = (batch_size, enc_length, dec_length)\n","\n","    sum_attn_w = torch.sum(log_attn_w, dim=-1)\n","    ## |sum_attn_w| = (batch_size, enc_length, 1)\n","\n","    clipped_attn_w = torch.clip(sum_attn_w, max=self.min_val)\n","    ## |clipped_attn_w| = (batch_size, enc_length, 1)\n","\n","    coverage_penalty = self.beta * torch.sum(clipped_attn_w, dim=-1)\n","    ## |covergae_penalty| = (batch_size, 1)\n","\n","    return coverage_penalty\n","\n"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZO-5LTDcjjon","executionInfo":{"status":"ok","timestamp":1622351781810,"user_tz":-540,"elapsed":371,"user":{"displayName":"최석웅","photoUrl":"","userId":"05234760535644650462"}}},"source":["## Beam Size 어떻게 테스트할지 생각해야 함 -> 일단 decoder 코드 부터 작성하는게 맞을 듯 -> 어차피 테스트 코드나 decoder 코드나 같을 거기 때문 \n","\n","\n","\n","class BeamSearch(nn.Module) : \n","  def __init__(self, beam_size, lp_alpha, lp_length, cp_beta, cp_min_val) : \n","    super(BeamSearch, self).__init__()\n","    self.beam_size = beam_size\n","    \n","    self.path_probs =  None #torch.Tensor.new_zeros(batch_size, 1, 1).to(device)\n","    self.path = []\n","\n","    self.length_penalty = LengthPenalty(lp_alpha, lp_length)\n","    self.convergence_penalty = ConvergencePenalty(cp_beta, cp_min_val)\n","\n","  def forward(self, cur_probs, prev_hc, ctx_refl_dec, mask=None) :\n","    ## |cur_probs| = (batch_size, 1, output_size) or (beam_size*batch_size, 1, ,output_size)\n","    ## |prev_hc| \n","    ##    |prev_h| = (num_layers, batch_size, hidden_size) or (num_layers, beam_size*batch_size, hidden_size)\n","    ##    |prev_c| = (num_layers, batch_size, hidden_size) or (num_layers, beam_size*batch_size, hidden_size)\n","    ## |ctx_refl_dec| = (batch_size,1, hidden_size) or (beam_size*batch_size, 1, hidden_size)\n","    ## |mask| = (batch_size, 1, hidden_size) or (beam_size*batch_size,)\n","\n","    cur_path_probs = self.calc_cur_path_probs(cur_probs, mask, self.path_probs==None)\n","    ## |cur_path_probs| = (batch_size, 1, beam_size*output_size)\n","\n","    prev_path_id, next_inp = self.select_path(path_probs)\n","    ## |prev_path_id| = |next_inp| = (beam_size*batch_size, 1, 1)\n","\n","    next_inp = self.construct_path(prev_path_id,next_inp)\n","    ## |next_inp| = (beam_size*batch_size, 1, 1)\n","\n","    \n","    next_hc = self.prepare_next_step(prev_hc, ctx_refl_dec, prev_path_id)\n","    ## |next_hc|\n","    ##    |next_h| = |next_c| = (num_layers, beam_size*batch_size, hidden_size)\n","\n","    return next_inp, next_hc\n","\n","    \n","  def calc_cur_path_probs(self, cur_probs, mask=None, swollen=False) :\n","    ## |cur_probs| = (batch_size, 1, output_size) or (beam_size*batch_size,1, output_size)\n","    ## |mask| = (batch_size,) or (beam_size*batch_size,)\n","\n","    output_size = cur_probs.size(-1)\n","\n","    ## 끝난 instance의 현재 확률값을 1로 만들어 주기 \n","    if mask != None :\n","      mask = torch.tile(mask, cur_probs.size())\n","      ## |mask| = (batch_size, 1, output_size) or (beam_size*batch_size, 1, output_size) \n","      \n","      cur_probs.masked_fill_(mask,1.0)\n","      ## |cur_probs| = (beam_size*batch_size, 1, output_size)\n","    \n","\n","    ##  현재 확률과 path에 대한 cumulative log prob 구하기\n","    cur_path_probs = torch.tile(self.path_probs, (1,1,output_size))\n","    ## |cur_path_probs| = (batch_size, 1, output_size) or (beam_size*batch_size, 1, output_size)\n","\n","    cur_path_probs = cur_path_probs +  torch.log(cur_probs)\n","    ## |cur_path_probs| = (batch_size, 1, output_size) or (beam_size*batch_size, 1, output_size)\n","\n","    if swollen == True : \n","      cur_path_probs = torch.tile(cur_path_probs, (self.beam_size, 1, 1)).to(device)\n","      ## |cur_path_probs| = (beam_size*batch_size, 1, output_size)\n","\n","    cur_path_probs = self.merge_equal_instance(cur_path_probs)\n","    ## |cur_path_probs| = (batch_size, 1, beam_size*output_size)\n","    \n","    return cur_path_probs \n","\n","  def merge_equal_instance(self, tensor) : \n","    ## |tensor| = (beam_size*batch_size, 1, output_size) or (beam_size*batch_size, 1, 1)\n","    batch_size = tensor.size(0) // self.beam_size\n","\n","    split = torch.split(tensor,batch_size, dim=0)\n","    merged = torch.cat(split, dim=-1)\n","    ## |merged| = (batch_size, 1, output_size*beam_size) or (batch_size, 1, beam_size)\n","\n","    return merged \n","\n","  def split_equal_instance(self, tensor) :\n","    ## |tensor| = (batch_size, 1, output_size*beam_size) or (batch_size, 1, beam_size)\n","    \n","    split_size = tensor.size(-1) // self.beam_size\n","\n","    split = torch.split(tensor, split_size, dim=-1)\n","    split = torch.cat(split, dim=0)\n","    ## |split| = (beam_size*batch_size, 1, output_size) or (beam_size*batch_size, 1, 1)\n","\n","    return split \n","  \n","  def select_path(self, path_probs) :\n","    ## |path_probs| = (batch_size , 1, beam_size*output_size)\n","\n","    selected_path_probs, selected_token_id = torch.topk(path_probs, self.beam_size, dim=-1)\n","    ## |selected_path_probs| = |selected_path_id| = (batch_size, 1, beam_size)\n","\n","    ## for next time step\n","    self.path_probs = self.split_equal_instance(selected_path_probs)\n","    ## |selected_path_probs| = (beam_size*batch_size, 1, 1)\n","\n","    ## this is for selecting next hidden/cell states and input feeding  \n","    prev_path_id = torch.round(selected_token_id/output_size).type(torch.long)\n","    prev_path_id = self.split_equal_instance(prev_path)\n","    ## |prev_path_id| = (beam_size*batch_size, 1, 1)\n","\n","    next_inp = selected_token_id.type(torch.long) % output_size\n","    ## |next_inp| = (batch_size, 1, beam_size)\n","\n","    next_inp = self.split_equal_instance(next_inp)\n","    ## |next_inp| = (beam_size * batch_size, 1, 1)\n","\n","    return prev_path_id, next_inp\n","\n","  ## must call this method after select_path \n","  def prepare_next_step(self, prev_hc, ctx_refl_dec, prev_path_id) : \n","    ## |ctx_refl_dec| = (beam_size*batch_size,1,hidden_size) or (batch_size, 1, hidden_size)\n","    ## |prev_path_id| = (beam_size*batch_size,1,1)\n","\n","    batch_size = prev_path_id.size(0) // self.beam_size    \n","    \n","    prev_h, prev_c = prev_hc\n","    ## |prev_hc| \n","    ##    |prev_h| = (num_layers, beam_size*batch_size, hidden_size) or (num_layers, batch_size, hidden_size)\n","    ##    |prev_c| = (num_layers, beam_size*batch_size, hidden_size) or (num_layers, batch_size, hidden_size)  \n","\n","    if prev_h.size(1) == batch_size :\n","      prev_h = torch.tile(prev_h,(1,self.beam_size,1))\n","      prev_c = torch.tile(prev_c,(1,self.beam_size,1))\n","      ctx_refl_dec = torch.tile(ctx_refl_dec,(1,self.beam_size,1))\n","      ## |prev_h| = |prev_c| = |ctx_refl_dec| = (beam_size*batch_size, 1, hidden_size)\n","\n","    prev_path_id = torch.cat([ i%batch_size+batch_size*path_id for i, path_id in enumerate(prev_path_id)], dim=0)\n","    ## |prev_path_id| = (beam_size*batch_size, )\n","\n","\n","    prev_h = prev_h.transpose(0,1)\n","    prev_c = prev_c.transpose(0,1)\n","    ## |prev_h| = (beam_size*batch_size, num_layers, hidden_size)\n","\n","    next_h = prev_h[prev_path_id].transpose(0,1).contiguous()\n","    next_c = prev_c[prev_path_id].transpose(0,1).contiguous()\n","    ## |next_h|=|next_c|=(num_layers, beam_size*batch_size, hidden_size)\n","\n","    return (next_h, next_c)\n","\n","  ## must call this method after select_path\n","  def construct_path(self, prev_path_id, next_inp) :\n","    ## |next_inp| = (beam_size*batch_size, 1, 1) \n","    ## |prev_path_id| = (beam_size*batch_size, 1, 1)\n","\n","    batch_size = prev_path_id.size(0) // self.beam_size\n","    prev_path_id = torch.cat([i%batch_size + path_id*batch_size for i, path_id in enumerate(prev_path_id)], dim=0)\n","    ## |prev_path_id| = (beam_size*batch_size)\n","\n","    if len(self.path) > 0 :\n","      self.path[-1] = self.path[-1][prev_path_id]\n","      ## |path[-1]| = (beam_size*batch_size, 1, 1)\n","\n","    self.path.append(next_inp)\n","    ## |path| = (cur_length,)\n","    ##    |path[i]| = (beam_size*batch_size, 1, 1)\n","\n","    return next_inp\n","\n","  ## after all time steps\n","  def make_mask(self, length) :\n","     \n","    min_len = torch.min(length)\n","\n","    ## this is for calc path probability\n","    ## In this case, the type of length element is boolean type\n","    if min_len == 0 :\n","      mask = (length == True)\n","      ## |length| = (batch_size,) or (beam_size*batch_size,)\n","      ## |mask| = (batch_size) or (beam_size*batch_size)\n","\n","    ## this is for cutting off selected path for each instance\n","    ## In this case, the type of length elements is integer \n","    else :\n","      max_len = torch.max(length)\n","      idx = torch.arange(max_len).unsqueeze(0).expand((length.size(0),max_len))\n","      ## |length| = (beam_size*batch_size,)\n","      ## |idx| = (beam_size*batch_size, max_len,)\n","      \n","      expanded_length = length.unsqueeze(1).expand(idx.size())\n","      ## |expanded_length| = (beam_size*batch_size, max_len)\n","      \n","      mask = idx >= expanded_length\n","      ## |mask| = (beam_size*batch_size, max_len)\n","\n","    return mask\n","\n","\n","  ## after all time steps\n","  ## not in forward  \n","  def calc_path_score(self, length, attn_weights) :\n","    ## |length| = (beam_size * bathc_size, 1, 1)\n","    ## |attn_weights| = (beam_size *  batch_size, enc_length, dec_length)\n","\n","    length_pen = self.length_penalty(length)\n","    ## |length_pen| = (beam_size * batch_size, 1, 1)\n","\n","    conver_pen = self.convergence_penalty(attn_weights)\n","    ## |conver_pen| = (beam_size * batch_size, 1, 1)\n","\n","    path_score = (torch.bmm(self.path_probs, length_pen) + conver_pen).contiguous() \n","    ## |path_score| = (beam_size * batch_size, 1, 1)\n","\n","    return path_score \n","\n","  ## after calc_path_score\n","  ## not in forward()\n","  def get_best_path(self, path_score, mask) :\n","    ## |path_score| = (beam_size * batch_size, 1, 1)\n","    ## |instance_len| = (beam_size*batch_size, 1, 1)\n","\n","    path_score = self.merge_eqaul_instance(path_score)\n","    ## |path_score| = |instance_len| = (batch_size, 1, beam_size)\n","\n","    path = torch.cat(self.path, dim=1)\n","    ## |path| = (beam_size*batch_size, length, 1)\n","\n","    max_path_id = torch.argmax(path_score, dim=-1).squeeze()\n","    ## |max_path_id| = (batch_size,)\n","    \n","    max_path_id = torch.cat([ i%self.batch_size + path_id*self.batch_size for i, path_id in enumerate(max_path_id)]).squeeze()\n","    ## |max_path_id| = (batch_size,)\n","\n","    best_path = path[max_path_id].contiguous()\n","    ## |best_path| = (batch_size, length, )\n","\n","    best_path = best_path.masked_fill_(mask, -1)\n","    ## |best_path| = (batch_size, length)\n","\n","    return best_path"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"o_MIIjQpD2Nz","executionInfo":{"status":"ok","timestamp":1622351782102,"user_tz":-540,"elapsed":295,"user":{"displayName":"최석웅","photoUrl":"","userId":"05234760535644650462"}}},"source":["class TranslationModel(nn.Module) :\n","  def __init__(self, input_size, output_size, emb_size, hidden_size, beam_size, num_layer, bidirectional, drop_out, lp_alpha, lp_length, cp_beta, cp_min_val, max_len) :\n","    super(TranslationModel, self).__init__()\n","    \n","    self.num_layer = num_layer\n","    self.num_direction = 2 if bidirectional else 1\n","    self.hidden_size = hidden_size\n","    self.output_size = output_size\n","    self.max_len = max_len\n","\n","\n","    self.src_emb = nn.Embedding(input_size, emb_size)\n","    self.tgt_emb = nn.Embedding(output_size, emb_size)\n","    self.enc = LSTMEncoder(emb_size, hidden_size, num_layer=num_layer, bidirectional=bidirectional, dropout=drop_out)\n","    self.dec = LSTMDecoder(emb_size, hidden_size, num_layer = num_layer, dropout=drop_out)\n","    self.attn = Attention(hidden_size)\n","    self.concat = nn.Linear(2*hidden_size, hidden_size)\n","    self.tanh = nn.Tanh()\n","    \n","    self.gen = Generator(hidden_size, output_size)\n","    \n","    self.beam_search = BeamSearch(beam_size, lp_alpha, lp_length, cp_beta, cp_min_val)\n","\n","\n","  def forward(self, src, tgt) :\n","        ## 1. src = (src_data, src_length)의 튜플인 경우 \n","        ##   |src_data| = (batch_size, src_length,)\n","        ##   |src_length| = (batch_size, )\n","        ## 2. src = src_data \n","        ##   |src_data| = (batch_size, src_length, )\n","\n","        ## |tgt| = (batch_size, tgt_length, )\n","\n","    batch_size = src[0].size(0)\n","    mask = None\n","    src_length = None\n","    if isinstance(src, tuple) :\n","      src_data, src_length = src\n","      mask = self.make_mask(src_data, src_length)\n","      ## |mask| = (batch_size, length)\n","    else :\n","      src_data = src\n","\n","    if isinstance(tgt, tuple) : \n","      tgt = tgt[0]\n","\n","    src_emb = self.src_emb(src_data)\n","    ## |src_emb| = (batch_size, length, emb_size)\n","\n","    enc_hs, init_dec_hc = self.enc((src_emb,src_length))\n","    init_dec_h, init_dec_c = init_dec_hc \n","    ## |enc_hs| = (batch_size, length, hidden_size) -> 후에 attention을 위해 사용 \n","    ## |init_dec_h| = (2*num_layer,batch_size,hidden_size//2) -> decoder의 각 layer의 hidden state의 초기 값으로 사용 \n","    ## |init_dec_c| = (2*num_layer,batch_size,hidden_size//2) -> decoder의 각 layer의 cell state의 초기 값으로 사용 \n","\n","    init_dec_h = init_dec_h.transpose(0,1).contiguous().view(batch_size, -1, self.hidden_size).transpose(0,1).contiguous()\n","    init_dec_c = init_dec_c.transpose(0,1).contiguous().view(batch_size, -1, self.hidden_size).transpose(0,1).contiguous()\n","    ## |init_dec_h| = (num_layer, batch_size, hidden_size)\n","    ## |init_dec_c| = (num_layer, batch_size, hidden_size) \n","\n","\n","    tgt_emb = self.tgt_emb(tgt)\n","    outputs = list()\n","    \n","    inp_feed = None\n","    dec_hc = (init_dec_h,init_dec_c)\n","    \n","    for i in range(tgt.size(1)) :\n","      ## Embedding \n","      cur_emb = tgt_emb[:,i,:].unsqueeze(1)\n","      ## |cur_emb| = (batch_size, emb_size)\n","\n","\n","      ## Decoder \n","      dec_out, dec_hc = self.dec(cur_emb, inp_feed, dec_hc)\n","      ## |dec_out| = (batch_size, 1, hidden_size)\n","      ## |dec_hc|\n","      ##   |dec_hc[0]| = (num_layer, batch_size, hidden_size)\n","      ##   |dec_hc[1]| = (num_layer, batch_size, hidden_size)\n","      \n","      ## Attention \n","      context_vector, _ = self.attn(enc_hs, dec_out, mask)\n","      ## |context_vector| = (batch_size, 1, hidden_size)\n","\n","      inp_feed = self.tanh(self.concat(torch.cat([dec_out, context_vector], dim=-1))) \n","      ## |inp_feed| = (batch_size, 1, hidden_size)\n","\n","      outputs.append(inp_feed)\n","    \n","    y_hat = torch.cat(outputs, dim=1)\n","    y_hat = self.gen(y_hat)\n","    ## |y_hat| = (batch_size, length, output_size)\n","\n","    return y_hat\n","\n","  def beam_search(self, src, bos_id, eos_id) :\n","    ## 1. src = (src_data, src_length)의 튜플인 경우 \n","    ##   |src_data| = (batch_size, src_length, input_size)\n","    ##   |src_length| = (batch_size, )\n","    ## 2. src = src_data \n","    ##   |src_data| = (batch_size, src_length, input_size)\n","\n","    ## 3. bos_id = (1,)\n","\n","    batch_size = src.size(0)\n","    if isinstance(src, tuple) :\n","      ## emb_vec_data와 emb_vec_length는 mini batch 내에서 pad를 제외한 토큰의 개수를 기준으로\n","      ## 내림차순으로 정렬되어 있음. 이는 효율성 뿐만 아니라 pad를 계산하지 않아 정확도를 높이\n","      ## 기 위한 목적도 존재 \n","      ## 출처 : https://simonjisu.github.io/nlp/2018/07/05/packedsequence.html\n","      src_data, src_length = src\n","      #src_data = pack_padded_sequence(src_data, src_length)\n","    else :\n","      src_data = src\n","\n","    src_emb = self.src_emb(src_data)\n","    ## |src_emb| = (batch_size, length, emb_size)\n","\n","    enc_hs, init_dec_hc = self.enc((src_emb,src_length)) \n","    ## |enc_hs| = (batch_size, length, hidden_size) -> 후에 attention을 위해 사용 \n","    ## |init_dec_hc[0]| = (2*num_layer,batch_size,hidden_size//2) -> decoder의 각 layer의 hidden state의 초기 값으로 사용 \n","    ## |init_dec_hc[1]| = (2*num_layer,batch_size,hidden_size//2) -> decoder의 각 layer의 cell state의 초기 값으로 사용 \n","\n","    init_dec_h = init_dec_hc[0].transpose(0,1).contiguous().view(batch_size, -1, self.hidden_size).transpose(0,1).contiguous()\n","    init_dec_c = init_dec_hc[1].transpose(0,1).contiguous().view(batch_size, -1, self.hidden_size).transpose(0,1).contiguous()\n","    ## |init_dec_h| = (num_layer, batch_size, hidden_size)\n","    ## |init_dec_c| = (num_layer, batch_size, hidden_size) \n","\n","    inp = torch.tensor([ bos_id for i in range(batch_size)])\n","    dec_hc = (init_dec_h,init_dec_c)\n","    mask = None \n","    end_flag = torch.tensor([False for i in range(batch_size)])\n","    attn_weights = []\n","    for i in range(self.max_len) :\n","      ## Embedding \n","      tgt_emb = self.tgt_emb(inp).unsqueeze(1)\n","      ## |tgt_emb| = (batch_size, 1, emb_size) or (beam_size*batch_size, 1, emb_size)\n","\n","      ## Decoder \n","      dec_out, dec_hc = self.dec(tgt_emb, dec_hc)\n","      ## |dec_out| = (batch_size, 1, hidden_size) or (beam_size * batch_size, 1 hidden_size)\n","      ## |dec_hc| = (num_layer, batch_size, hidden_size) or (num_layer, beam_size * batch_size, hidden_size)\n","      \n","      ## Attention \n","      context_vector, attn_weight = self.attn(enc_hs, dec_out)\n","      ## |context_vector| = (batch_size, 1, hidden_size) or (beam_size * batch_size, 1, hidden_size)\n","\n","      ctx_refl_dec = self.tanh(self.concat(torch.cat([dec_out, context_vector], dim=-1))) \n","      ## |ctx_refl_dec| = (batch_size, 1, hidden_size) or (beam_size * batch_size, 1, hidden_size)\n","\n","      y_hat = self.gen(ctx_refl_dec)\n","      ## |y_hat| = (batch_size, 1, output_size) or (beam_size * batch_size, 1, output_size)\n","\n","\n","      ## BeamSearch \n","      inp, dec_hc = self.beam_search(y_hat, dec_hc, ctx_refl_dec, mask)\n","      ## |inp| = (beam_size*batch_size, 1, 1)\n","      ## |dec_hc| \n","      ##  |dec_h| = (num_layers, beam_size*batch_size, hidden_size)\n","      ##  |dec_c| = (num_layers, beam_size*batch_size, hidden_size)\n","\n","      ## 종료된 부분을 나타내는 end flag 계산 \n","      end_flag = (end_flag) | (inp == eos_id)\n","      ## |end_flag| = (batch_size, ) or (beam_size * batch_size, ) \n","      if end_flag.size(0) == batch_size :\n","        end_flag = end_flag.exapnd(self.beam_size*batch_size, )\n","        ## |end_flag| = (beam_size * batchs_size, )\n","        \n","      ## 종료된 부분의 길이 저장 \n","      length[(inp == eos_id)] = i\n","\n","      ## 현재 timestep의 attention weight 저장 \n","      attn_weights.append(attn_weight)\n","\n","      ## 모든 Instance에 대하여 추론이 끝난 경우 종료 \n","      if torch.sum(end_flag) == self.beam_size*batch_size : \n","        break\n","\n","      ## 종료된 부분을 표시하는 mask 구하기\n","      mask = self.beam_search.make_mask(end_flag, mask)\n","      ## |mask| = (bathc_size, ) or (beam_size*batch_size, )\n","\n","    ## 최종 path 선택 \n","    attn_weights = torch.cat(attn_weights, dim=1).transpose(0,1).contiguous()\n","    ## |attn_weights| = (batch_size*beam_size, enc_length, dec_length)\n","    path_score = beam_search.calc_path_score(length)\n","    ## |path_score| = (batch_size*beam_size,)\n","    transl_result = get_best_path(path_score, mask)\n","    ## |tranl_result| = (batch_size, )\n","    \n","    return transl_result \n","  \n","  def make_mask(self, src, src_length) : \n","    mask = list()\n","\n","    max_length = max(src_length)\n","\n","    for cur_length in src_length : \n","      if max_length - cur_length > 0 : \n","        mask.append(torch.cat([src.new_ones(1,cur_length).zero_(), src.new_ones(1,max_length-cur_length)], dim=-1))\n","      else : \n","        mask.append(src.new_ones(1, cur_length).zero_())\n","    \n","    mask = torch.cat(mask, dim=0).bool()\n","\n","    return mask\n"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VsA3elKbLd6v","executionInfo":{"status":"ok","timestamp":1622220833340,"user_tz":-540,"elapsed":4866,"user":{"displayName":"최석웅","photoUrl":"","userId":"05234760535644650462"}},"outputId":"3f5eb760-a28e-4dec-ba18-9a4900b8166c"},"source":["tl_model = TranslationModel(input_size, output_size, embed_size, hidden_size, beam_size, num_layer, enc_bidirectional, drop_out, lp_alpha, lp_length, cp_beta, cp_min_val, max_len)\n","tl_model.to(device)"],"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/plain":["TranslationModel(\n","  (src_emb): Embedding(24393, 512)\n","  (tgt_emb): Embedding(44380, 512)\n","  (enc): LSTMEncoder(\n","    (encoder): LSTM(512, 384, num_layers=4, batch_first=True, dropout=0.2, bidirectional=True)\n","  )\n","  (dec): LSTMDecoder(\n","    (decoder): LSTM(1280, 768, num_layers=4, batch_first=True, dropout=0.2)\n","  )\n","  (attn): Attention(\n","    (make_query): Linear(in_features=768, out_features=768, bias=False)\n","    (softmax): Softmax(dim=-1)\n","  )\n","  (concat): Linear(in_features=1536, out_features=768, bias=True)\n","  (tanh): Tanh()\n","  (gen): Generator(\n","    (transform): Linear(in_features=768, out_features=44380, bias=True)\n","    (softmax): LogSoftmax(dim=-1)\n","  )\n","  (beam_search): BeamSearch()\n",")"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"code","metadata":{"id":"lua5F9jhLd-K","executionInfo":{"status":"ok","timestamp":1622220833341,"user_tz":-540,"elapsed":26,"user":{"displayName":"최석웅","photoUrl":"","userId":"05234760535644650462"}}},"source":["## LogSoftmax + NLLLoss \n","loss_weight = torch.ones(tl_model.output_size)\n","loss_weight[train_dl.PAD_ID] = 0.\n","crit = nn.NLLLoss(loss_weight, reduction='sum').to(device)\n","optimizer = optim.Adam(tl_model.parameters(), lr = learning_rate, )"],"execution_count":24,"outputs":[]},{"cell_type":"code","metadata":{"id":"p6gcQ8o0_reW","executionInfo":{"status":"ok","timestamp":1622220833343,"user_tz":-540,"elapsed":26,"user":{"displayName":"최석웅","photoUrl":"","userId":"05234760535644650462"}}},"source":["## for amp \n","scaler = GradScaler()"],"execution_count":25,"outputs":[]},{"cell_type":"code","metadata":{"id":"mi-pQi4iqOdZ","executionInfo":{"status":"ok","timestamp":1622220833344,"user_tz":-540,"elapsed":26,"user":{"displayName":"최석웅","photoUrl":"","userId":"05234760535644650462"}}},"source":["## to save \n","## Hyper Parameters \n","hyper_params = {'train_src_fn' : train_src_fn, 'train_tgt_fn' : train_tgt_fn, 'valid_src_fn' : valid_src_fn,\n","                'valid_tgt_fn' : valid_tgt_fn, 'max_len' : max_len, 'init_token' : init_token,\n","                'eos_token' : eos_token, 'batch_size' : batch_size, 'device' : device, 'max_vocab' : max_vocab,\n","                'num_epochs' : num_epochs, 'train_src_vocab' : train_dl.src.vocab, 'train_tgt_vocab':train_dl.tgt.vocab , 'valid_src_vocab' : valid_dl.src.vocab, 'valid_tgt_vocab' : valid_dl.tgt.vocab,\n","                'input_size' : input_size, 'output_size' : output_size, 'embed_size' : embed_size, 'hidden_size' : hidden_size,\n","                'num_layer' : num_layer, 'enc_bidirectional' : enc_bidirectional, 'drop_out' : drop_out, 'max_clip_norm': max_clip_norm, 'beam_size' : beam_size,\n","                'lp_alpha' : lp_alpha, 'lp_length' : lp_length, 'cp_beta' : cp_beta, 'cp_min_val' : cp_min_val, 'learning_rate' : learning_rate,\n","                'grad_update_period' : grad_update_period\n","                }\n","\n"],"execution_count":26,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_FWKEQAYLeBP","outputId":"f4f6aab9-b02c-4795-d844-9c3f75082afc"},"source":["#loss/ ppl \n","train_loss_sum = 0\n","train_ppl_sum = 0\n","\n","valid_loss_sum = 0\n","valid_ppl_sum = 0\n","\n","train_loss_list = list()\n","train_ppl_list = list() \n","\n","valid_loss_list = list()\n","valid_ppl_list = list()\n","\n","train_loss_sum_list = list() \n","train_ppl_sum_list = list()\n","valid_loss_sum_list = list()\n","valid_ppl_sum_list = list()\n","\n","for cur_epoch in range(num_epochs) :\n","  tl_model.train()\n","\n","  train_loss_sum = 0.; train_ppl_sum = 0.; valid_loss_sum = 0.; valid_ppl_sum =0.\n","  for i, train_batch in enumerate(train_dl.data_iter) :\n","    src = train_batch.src; tgt = train_batch.tgt\n","    ## |src|\n","    ##  |src[0]| = (batch_size, length, )\n","    ##  |src[1]| = (batch_size) \n","    ## |tgt|\n","    ##  |tgt[0]| = (batch_size, length, ) \n","    ##  |tgt[1]| = (batch_size)\n","\n","    ## this is for gpu memory leakage \n","    src = (src[0].to(device), src[1]);\n","    tgt = (tgt[0].to(device), tgt[1]);\n","\n","    \n","    with autocast() :\n","      ## FeedForward \n","      log_probs = tl_model(src, tgt[0][:,:-1])  ## extract <EOS> from target \n","      ## |log_probs| = (batch_size, length, output_size)\n","\n","      log_probs = log_probs.view(-1, log_probs.size(-1))\n","      ## |log_probs| = (batch_size * length, output_size)\n","\n","      loss = crit(log_probs, tgt[0][:,1:].contiguous().view(-1))\n","      loss_for_gradient = loss / (src[0].size(0) * grad_update_period)\n","    \n","    ## Scale loss. Calls backward() on scaled loss to create scaled gradients. \n","    ## Backward passes under autocast are not recommended. \n","    ## Backward ops run in the same dtype autocast chose for corresponding forward ops.\n","    ## Accumulates scaled gradients \n","    scaler.scale(loss_for_gradient).backward()\n","\n","    ## update for every periods\n","    if (i+1) % grad_update_period == 0 :\n","      ## Gradient Clipping because Gradient Explood or Vanish in RNN based Models \n","      tc_utils.clip_grad_norm_(tl_model.parameters(), max_clip_norm)\n","\n","      ## scaler.step() first unscale the gradients of the optimizer's assigned params. \n","      ## If these gradients do not contain infs or NaNs, optimizer.step() is then called, \n","      ## otherwise optimizer.step() is skipped \n","      scaler.step(optimizer)\n","\n","      ## Gradient Descent\n","\n","      ## Updates the scale for next iteration. \n","      scaler.update()  \n","\n","      ## Clear Gradient for next period \n","      optimizer.zero_grad()\n","\n","    ## Calculate loss and perplexity \n","\n","    all_words_num = int(train_batch.tgt[1].sum())\n","    ## tgt[1] is length of each instance \n","\n","    ## loss mean for each word in mini batch \n","    loss = float(loss / all_words_num)\n","    ppl = np.exp(loss)\n","    \n","    train_loss_list.append(loss)\n","    train_ppl_list.append(ppl)\n","    print_st = max(0, len(train_loss_list) - 100)\n","    print(f'Train Epoch #{cur_epoch+1}, Batch {i+1}/{len(train_dl.data_iter)} loss = {sum(train_loss_list[print_st:])/len(train_loss_list[print_st:])}, ppl = {sum(train_ppl_list[print_st:])/len(train_ppl_list[print_st:])}')  \n","    \n","  train_loss_sum_list.append(train_loss_sum)\n","  train_ppl_sum_list.append(train_ppl_sum)\n","\n","  tl_model.eval()\n","  for i, valid_batch in enumerate(valid_dl.data_iter) :\n","    src = valid_batch.src;  tgt = valid_batch.tgt\n","    ## |src| \n","    ##   |src[0]| = (batch_size, length, )\n","    ##   |src[1]| = (batch_size, )\n","    ## |tgt| \n","    ##   |tgt[0]| = (batch_size, length, )\n","    ##   |tgt[1]| = (batch_size,)\n","\n","    with torch.no_grad() :\n","      src = (src[0].to(device), src[1])\n","      tgt = (tgt[0].to(device), tgt[1])\n","      ## |src[0]| = (length, batch_size)\n","      ## |tgt[0]| = (length, batch_size)\n","      \n","      with autocast() : \n","      ## FeedForward \n","       log_probs = tl_model(src, tgt[0][:,:-1]) ## extract <EOS> from target \n","       ## |log_probs| = (batch_size * length, output_size)\n","       \n","       log_probs = log_probs.view(-1, log_probs.size(-1))\n","       ## |log_probs| = (batch_size * length, output_size)\n","       \n","       loss = crit(log_probs, tgt[0][:,1:].contiguous().view(-1)) \n","       loss_for_gradient = loss / (src[0].size(0) * grad_update_period)\n","    \n","    \n","    ## Calculate loss and perplexity \n","    ## loss mean for each word in mini batch  \n","    all_words_num = int(tgt[1].sum())\n","    loss = float(loss/all_words_num)\n","    ppl = np.exp(loss) \n","    \n","    valid_loss_list.append(float(loss))\n","    valid_ppl_list.append(float(ppl))\n","    \n","    print_st = max(0, len(valid_loss_list) - 100)\n","    print(f'Valid Epoch #{cur_epoch+1}, Batch {i+1}/{len(valid_dl.data_iter)} loss = {sum(valid_loss_list[print_st:])/len(valid_loss_list[print_st:])}, ppl = {sum(valid_ppl_list[print_st:])/len(valid_ppl_list[print_st:])}')\n","\n","    valid_loss_sum += loss\n","    valid_ppl_sum += ppl\n","    \n","  valid_loss_sum_list.append(valid_loss_sum)\n","  valid_ppl_sum_list.append(valid_ppl_sum)\n","\n","  ## Save Model for each iteration \n","  SAVE_PATH = f'./model_checkpoints/cur_epoch_{cur_epoch+1}_train_loss_{int(train_loss_sum/len(train_dl.data_iter))}_train_ppl_{int(train_ppl_sum/len(train_dl.data_iter))}_valid_loss_{int(valid_loss_sum/len(valid_dl.data_iter))}_valid_ppl_{int(valid_ppl_sum/len(valid_dl.data_iter))}.pt'\n","  torch.save({'hyper_params' : hyper_params, 'train_loss_sum' : train_loss_sum, 'train_ppl_sum' : train_ppl_sum, 'valid_loss_sum' : valid_loss_sum, 'valid_ppl_sum' : valid_ppl_sum,\n","              'model_state_dict' : tl_model.state_dict(), 'optim_state_dict' : optimizer.state_dict(), 'grad_scaler_state_dict' : scaler.state_dict()}, SAVE_PATH)\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torchtext/data/batch.py:23: UserWarning: Batch class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n","  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\u001b[1;30;43m스트리밍 출력 내용이 길어서 마지막 5000줄이 삭제되었습니다.\u001b[0m\n","Valid Epoch #7, Batch 342/4160 loss = 1.57185626745224, ppl = 4.860639045796545\n","Valid Epoch #7, Batch 343/4160 loss = 1.5709064674377442, ppl = 4.855587284433728\n","Valid Epoch #7, Batch 344/4160 loss = 1.5721943867206574, ppl = 4.86247705281879\n","Valid Epoch #7, Batch 345/4160 loss = 1.573664404153824, ppl = 4.871388917215114\n","Valid Epoch #7, Batch 346/4160 loss = 1.5747041153907775, ppl = 4.877385068528685\n","Valid Epoch #7, Batch 347/4160 loss = 1.574900517463684, ppl = 4.878384243009688\n","Valid Epoch #7, Batch 348/4160 loss = 1.5767981803417206, ppl = 4.887215936574237\n","Valid Epoch #7, Batch 349/4160 loss = 1.5771223533153533, ppl = 4.888794966848448\n","Valid Epoch #7, Batch 350/4160 loss = 1.5778649163246155, ppl = 4.892972524273978\n","Valid Epoch #7, Batch 351/4160 loss = 1.5789142739772797, ppl = 4.897959272907871\n","Valid Epoch #7, Batch 352/4160 loss = 1.5789950501918792, ppl = 4.898376369099401\n","Valid Epoch #7, Batch 353/4160 loss = 1.577855154275894, ppl = 4.893015095958959\n","Valid Epoch #7, Batch 354/4160 loss = 1.5794519484043121, ppl = 4.900840181893412\n","Valid Epoch #7, Batch 355/4160 loss = 1.5788269114494324, ppl = 4.897648270430205\n","Valid Epoch #7, Batch 356/4160 loss = 1.5776979410648346, ppl = 4.8922880919764715\n","Valid Epoch #7, Batch 357/4160 loss = 1.5801263761520385, ppl = 4.903933062299441\n","Valid Epoch #7, Batch 358/4160 loss = 1.5770878779888153, ppl = 4.888765370730817\n","Valid Epoch #7, Batch 359/4160 loss = 1.5772641587257386, ppl = 4.889639521116613\n","Valid Epoch #7, Batch 360/4160 loss = 1.576231210231781, ppl = 4.884114754149554\n","Valid Epoch #7, Batch 361/4160 loss = 1.5757118558883667, ppl = 4.881714930743711\n","Valid Epoch #7, Batch 362/4160 loss = 1.5757339096069336, ppl = 4.881822591537675\n","Valid Epoch #7, Batch 363/4160 loss = 1.5769202351570129, ppl = 4.887608670373878\n","Valid Epoch #7, Batch 364/4160 loss = 1.5792382097244262, ppl = 4.899436549197383\n","Valid Epoch #7, Batch 365/4160 loss = 1.5779024267196655, ppl = 4.892333430496312\n","Valid Epoch #7, Batch 366/4160 loss = 1.5787704861164094, ppl = 4.896633628474296\n","Valid Epoch #7, Batch 367/4160 loss = 1.5780928015708924, ppl = 4.893860424288547\n","Valid Epoch #7, Batch 368/4160 loss = 1.5815429174900055, ppl = 4.911533697784563\n","Valid Epoch #7, Batch 369/4160 loss = 1.582249232530594, ppl = 4.914505802034967\n","Valid Epoch #7, Batch 370/4160 loss = 1.5852883756160736, ppl = 4.930643079094578\n","Valid Epoch #7, Batch 371/4160 loss = 1.5854444241523742, ppl = 4.9313979583320915\n","Valid Epoch #7, Batch 372/4160 loss = 1.5841545248031617, ppl = 4.9253436296825175\n","Valid Epoch #7, Batch 373/4160 loss = 1.5852964961528777, ppl = 4.9305507275702265\n","Valid Epoch #7, Batch 374/4160 loss = 1.5862298846244811, ppl = 4.9355500070306455\n","Valid Epoch #7, Batch 375/4160 loss = 1.58864444732666, ppl = 4.947599918967682\n","Valid Epoch #7, Batch 376/4160 loss = 1.5862562656402588, ppl = 4.93659595294507\n","Valid Epoch #7, Batch 377/4160 loss = 1.585997017621994, ppl = 4.935454757783532\n","Valid Epoch #7, Batch 378/4160 loss = 1.5852752423286438, ppl = 4.932076267315424\n","Valid Epoch #7, Batch 379/4160 loss = 1.5835421931743623, ppl = 4.922895822715435\n","Valid Epoch #7, Batch 380/4160 loss = 1.5849358642101288, ppl = 4.93072014727427\n","Valid Epoch #7, Batch 381/4160 loss = 1.583437204360962, ppl = 4.923168101159808\n","Valid Epoch #7, Batch 382/4160 loss = 1.5831037509441375, ppl = 4.92154213520067\n","Valid Epoch #7, Batch 383/4160 loss = 1.5850282645225524, ppl = 4.931454641010364\n","Valid Epoch #7, Batch 384/4160 loss = 1.5865094804763793, ppl = 4.937795764767679\n","Valid Epoch #7, Batch 385/4160 loss = 1.5878265595436096, ppl = 4.944192273632526\n","Valid Epoch #7, Batch 386/4160 loss = 1.586673092842102, ppl = 4.938845113503538\n","Valid Epoch #7, Batch 387/4160 loss = 1.5877172327041627, ppl = 4.94379912521122\n","Valid Epoch #7, Batch 388/4160 loss = 1.5879470658302308, ppl = 4.944846610312874\n","Valid Epoch #7, Batch 389/4160 loss = 1.5889152884483337, ppl = 4.949818988198292\n","Valid Epoch #7, Batch 390/4160 loss = 1.5897637951374053, ppl = 4.953631789257508\n","Valid Epoch #7, Batch 391/4160 loss = 1.5896104204654693, ppl = 4.952982680506463\n","Valid Epoch #7, Batch 392/4160 loss = 1.5910401165485382, ppl = 4.959759543850523\n","Valid Epoch #7, Batch 393/4160 loss = 1.5929575455188751, ppl = 4.96943748981781\n","Valid Epoch #7, Batch 394/4160 loss = 1.5937012147903442, ppl = 4.973183117308524\n","Valid Epoch #7, Batch 395/4160 loss = 1.5923521769046785, ppl = 4.965742468070946\n","Valid Epoch #7, Batch 396/4160 loss = 1.5924245703220368, ppl = 4.966083022208797\n","Valid Epoch #7, Batch 397/4160 loss = 1.5934390866756438, ppl = 4.970848025484395\n","Valid Epoch #7, Batch 398/4160 loss = 1.5911749792099, ppl = 4.961538937394629\n","Valid Epoch #7, Batch 399/4160 loss = 1.5889401626586914, ppl = 4.950649518779951\n","Valid Epoch #7, Batch 400/4160 loss = 1.5889387440681457, ppl = 4.950642389223902\n","Valid Epoch #7, Batch 401/4160 loss = 1.5874040019512177, ppl = 4.944808264966826\n","Valid Epoch #7, Batch 402/4160 loss = 1.5872347128391266, ppl = 4.944261959491999\n","Valid Epoch #7, Batch 403/4160 loss = 1.5873568773269653, ppl = 4.944652852043605\n","Valid Epoch #7, Batch 404/4160 loss = 1.586897245645523, ppl = 4.942973871490958\n","Valid Epoch #7, Batch 405/4160 loss = 1.585200617313385, ppl = 4.936673998095307\n","Valid Epoch #7, Batch 406/4160 loss = 1.5823316550254822, ppl = 4.925628423062003\n","Valid Epoch #7, Batch 407/4160 loss = 1.581608464717865, ppl = 4.922883208333597\n","Valid Epoch #7, Batch 408/4160 loss = 1.5800665736198425, ppl = 4.916142622962743\n","Valid Epoch #7, Batch 409/4160 loss = 1.5805840575695038, ppl = 4.91812619046606\n","Valid Epoch #7, Batch 410/4160 loss = 1.5793413996696473, ppl = 4.913453557968307\n","Valid Epoch #7, Batch 411/4160 loss = 1.579694141149521, ppl = 4.91521371018541\n","Valid Epoch #7, Batch 412/4160 loss = 1.5779441726207732, ppl = 4.9078713328268115\n","Valid Epoch #7, Batch 413/4160 loss = 1.5743585276603698, ppl = 4.892041805214483\n","Valid Epoch #7, Batch 414/4160 loss = 1.576020783185959, ppl = 4.899358548258745\n","Valid Epoch #7, Batch 415/4160 loss = 1.5774888432025909, ppl = 4.905338873262424\n","Valid Epoch #7, Batch 416/4160 loss = 1.5736967098712922, ppl = 4.884092846364206\n","Valid Epoch #7, Batch 417/4160 loss = 1.5729036521911621, ppl = 4.880535922568219\n","Valid Epoch #7, Batch 418/4160 loss = 1.5739835798740387, ppl = 4.886327868156784\n","Valid Epoch #7, Batch 419/4160 loss = 1.5753568637371063, ppl = 4.893591346025243\n","Valid Epoch #7, Batch 420/4160 loss = 1.5730816614627838, ppl = 4.882619986425642\n","Valid Epoch #7, Batch 421/4160 loss = 1.5712642657756806, ppl = 4.873741014624377\n","Valid Epoch #7, Batch 422/4160 loss = 1.5707629597187043, ppl = 4.871409271738867\n","Valid Epoch #7, Batch 423/4160 loss = 1.5707285857200624, ppl = 4.871228385381186\n","Valid Epoch #7, Batch 424/4160 loss = 1.5740661251544952, ppl = 4.887127665622249\n","Valid Epoch #7, Batch 425/4160 loss = 1.5729815506935119, ppl = 4.881869827204724\n","Valid Epoch #7, Batch 426/4160 loss = 1.5706338918209075, ppl = 4.866923446257448\n","Valid Epoch #7, Batch 427/4160 loss = 1.5723949420452117, ppl = 4.876890806938711\n","Valid Epoch #7, Batch 428/4160 loss = 1.5716484153270722, ppl = 4.873496437286483\n","Valid Epoch #7, Batch 429/4160 loss = 1.574255449771881, ppl = 4.887429537894359\n","Valid Epoch #7, Batch 430/4160 loss = 1.5717518651485443, ppl = 4.873532198031587\n","Valid Epoch #7, Batch 431/4160 loss = 1.5734071981906892, ppl = 4.881856664597255\n","Valid Epoch #7, Batch 432/4160 loss = 1.5723118352890015, ppl = 4.876724971695542\n","Valid Epoch #7, Batch 433/4160 loss = 1.5706632614135743, ppl = 4.868029223451347\n","Valid Epoch #7, Batch 434/4160 loss = 1.5676024436950684, ppl = 4.853005932351944\n","Valid Epoch #7, Batch 435/4160 loss = 1.5680301642417909, ppl = 4.855605388346979\n","Valid Epoch #7, Batch 436/4160 loss = 1.567102588415146, ppl = 4.850816968454173\n","Valid Epoch #7, Batch 437/4160 loss = 1.566435010433197, ppl = 4.8466486067933\n","Valid Epoch #7, Batch 438/4160 loss = 1.567234342098236, ppl = 4.850735903058544\n","Valid Epoch #7, Batch 439/4160 loss = 1.5698768281936646, ppl = 4.865187106070888\n","Valid Epoch #7, Batch 440/4160 loss = 1.5698400557041168, ppl = 4.8649933746665495\n","Valid Epoch #7, Batch 441/4160 loss = 1.5711123502254487, ppl = 4.871260815269405\n","Valid Epoch #7, Batch 442/4160 loss = 1.5716734170913695, ppl = 4.874271450238463\n","Valid Epoch #7, Batch 443/4160 loss = 1.5717053043842315, ppl = 4.874433382371375\n","Valid Epoch #7, Batch 444/4160 loss = 1.5712640976905823, ppl = 4.871972565431283\n","Valid Epoch #7, Batch 445/4160 loss = 1.5716304421424865, ppl = 4.874405022106042\n","Valid Epoch #7, Batch 446/4160 loss = 1.5702551436424255, ppl = 4.866602837004901\n","Valid Epoch #7, Batch 447/4160 loss = 1.5711108887195586, ppl = 4.871192832789921\n","Valid Epoch #7, Batch 448/4160 loss = 1.5727508294582366, ppl = 4.880298384734564\n","Valid Epoch #7, Batch 449/4160 loss = 1.5717427587509156, ppl = 4.875551388870015\n","Valid Epoch #7, Batch 450/4160 loss = 1.5687375366687775, ppl = 4.860399528916003\n","Valid Epoch #7, Batch 451/4160 loss = 1.5692310428619385, ppl = 4.862931940212312\n","Valid Epoch #7, Batch 452/4160 loss = 1.5682196497917176, ppl = 4.857944835132541\n","Valid Epoch #7, Batch 453/4160 loss = 1.5690913546085357, ppl = 4.861989205114526\n","Valid Epoch #7, Batch 454/4160 loss = 1.56856094956398, ppl = 4.85925019401988\n","Valid Epoch #7, Batch 455/4160 loss = 1.5703905677795411, ppl = 4.86918587540175\n","Valid Epoch #7, Batch 456/4160 loss = 1.573578917980194, ppl = 4.886027691860712\n","Valid Epoch #7, Batch 457/4160 loss = 1.5715491795539855, ppl = 4.876105944258848\n","Valid Epoch #7, Batch 458/4160 loss = 1.5742757725715637, ppl = 4.889496017654122\n","Valid Epoch #7, Batch 459/4160 loss = 1.5726913630962371, ppl = 4.882165744717002\n","Valid Epoch #7, Batch 460/4160 loss = 1.5717221450805665, ppl = 4.877475913680528\n","Valid Epoch #7, Batch 461/4160 loss = 1.5733299481868743, ppl = 4.885328317270341\n","Valid Epoch #7, Batch 462/4160 loss = 1.5733913338184358, ppl = 4.885629239959984\n","Valid Epoch #7, Batch 463/4160 loss = 1.5735167694091796, ppl = 4.886282120882783\n","Valid Epoch #7, Batch 464/4160 loss = 1.5688888943195343, ppl = 4.865102517847494\n","Valid Epoch #7, Batch 465/4160 loss = 1.5692303276062012, ppl = 4.866828853531996\n","Valid Epoch #7, Batch 466/4160 loss = 1.5689349269866943, ppl = 4.865323408229933\n","Valid Epoch #7, Batch 467/4160 loss = 1.5716451871395112, ppl = 4.87763593998104\n","Valid Epoch #7, Batch 468/4160 loss = 1.5696940958499908, ppl = 4.866899789167846\n","Valid Epoch #7, Batch 469/4160 loss = 1.569046654701233, ppl = 4.864167479672397\n","Valid Epoch #7, Batch 470/4160 loss = 1.5670072162151336, ppl = 4.852807427565748\n","Valid Epoch #7, Batch 471/4160 loss = 1.5669748401641845, ppl = 4.852649839634971\n","Valid Epoch #7, Batch 472/4160 loss = 1.5685248565673828, ppl = 4.860022571875248\n","Valid Epoch #7, Batch 473/4160 loss = 1.5688514554500579, ppl = 4.861624445197859\n","Valid Epoch #7, Batch 474/4160 loss = 1.5697481763362884, ppl = 4.866887409759033\n","Valid Epoch #7, Batch 475/4160 loss = 1.569330085515976, ppl = 4.864587313550432\n","Valid Epoch #7, Batch 476/4160 loss = 1.56840674161911, ppl = 4.860989329908123\n","Valid Epoch #7, Batch 477/4160 loss = 1.5681037878990174, ppl = 4.859692696650256\n","Valid Epoch #7, Batch 478/4160 loss = 1.5691421139240265, ppl = 4.864631583148099\n","Valid Epoch #7, Batch 479/4160 loss = 1.5693367207050324, ppl = 4.865584966240575\n","Valid Epoch #7, Batch 480/4160 loss = 1.5680195713043212, ppl = 4.858162542536749\n","Valid Epoch #7, Batch 481/4160 loss = 1.567272982597351, ppl = 4.854802207842554\n","Valid Epoch #7, Batch 482/4160 loss = 1.567780123949051, ppl = 4.857296821556837\n","Valid Epoch #7, Batch 483/4160 loss = 1.5663701796531677, ppl = 4.849850739443399\n","Valid Epoch #7, Batch 484/4160 loss = 1.5670067262649536, ppl = 4.852877939083288\n","Valid Epoch #7, Batch 485/4160 loss = 1.5651093935966491, ppl = 4.843919920462908\n","Valid Epoch #7, Batch 486/4160 loss = 1.5659474551677703, ppl = 4.847743159689349\n","Valid Epoch #7, Batch 487/4160 loss = 1.5660241115093232, ppl = 4.848127652319083\n","Valid Epoch #7, Batch 488/4160 loss = 1.5680155515670777, ppl = 4.858286504696314\n","Valid Epoch #7, Batch 489/4160 loss = 1.567189838886261, ppl = 4.854016128211477\n","Valid Epoch #7, Batch 490/4160 loss = 1.5685281801223754, ppl = 4.860727886880295\n","Valid Epoch #7, Batch 491/4160 loss = 1.5702773857116699, ppl = 4.868755879763273\n","Valid Epoch #7, Batch 492/4160 loss = 1.5719334709644317, ppl = 4.877918104584084\n","Valid Epoch #7, Batch 493/4160 loss = 1.5695452451705934, ppl = 4.866134379623977\n","Valid Epoch #7, Batch 494/4160 loss = 1.568774197101593, ppl = 4.86225609943609\n","Valid Epoch #7, Batch 495/4160 loss = 1.568220945596695, ppl = 4.859483240894291\n","Valid Epoch #7, Batch 496/4160 loss = 1.569631301164627, ppl = 4.86663432882202\n","Valid Epoch #7, Batch 497/4160 loss = 1.569857326745987, ppl = 4.867763403805437\n","Valid Epoch #7, Batch 498/4160 loss = 1.572670944929123, ppl = 4.879667929755986\n","Valid Epoch #7, Batch 499/4160 loss = 1.5748626470565796, ppl = 4.890323424494498\n","Valid Epoch #7, Batch 500/4160 loss = 1.5756926572322845, ppl = 4.894672592024238\n","Valid Epoch #7, Batch 501/4160 loss = 1.576630036830902, ppl = 4.8981289366833\n","Valid Epoch #7, Batch 502/4160 loss = 1.5762967038154603, ppl = 4.897079912558359\n","Valid Epoch #7, Batch 503/4160 loss = 1.578807808160782, ppl = 4.9062694918029255\n","Valid Epoch #7, Batch 504/4160 loss = 1.5792630088329316, ppl = 4.907931915239141\n","Valid Epoch #7, Batch 505/4160 loss = 1.5811148023605346, ppl = 4.914863086318988\n","Valid Epoch #7, Batch 506/4160 loss = 1.5827071559429169, ppl = 4.920600974871948\n","Valid Epoch #7, Batch 507/4160 loss = 1.5839969539642333, ppl = 4.925640104333737\n","Valid Epoch #7, Batch 508/4160 loss = 1.5827427458763124, ppl = 4.9208741324524725\n","Valid Epoch #7, Batch 509/4160 loss = 1.5832985818386078, ppl = 4.923122208698251\n","Valid Epoch #7, Batch 510/4160 loss = 1.5850332081317902, ppl = 4.929811249949077\n","Valid Epoch #7, Batch 511/4160 loss = 1.5849215149879456, ppl = 4.929247178328998\n","Valid Epoch #7, Batch 512/4160 loss = 1.5849144852161408, ppl = 4.929220198390879\n","Valid Epoch #7, Batch 513/4160 loss = 1.588077654838562, ppl = 4.942876536252362\n","Valid Epoch #7, Batch 514/4160 loss = 1.588305449485779, ppl = 4.943977352820202\n","Valid Epoch #7, Batch 515/4160 loss = 1.5889167439937593, ppl = 4.946738323349808\n","Valid Epoch #7, Batch 516/4160 loss = 1.5898426020145415, ppl = 4.951207774186348\n","Valid Epoch #7, Batch 517/4160 loss = 1.5880993378162385, ppl = 4.94431342234583\n","Valid Epoch #7, Batch 518/4160 loss = 1.5870809817314149, ppl = 4.938835156570794\n","Valid Epoch #7, Batch 519/4160 loss = 1.5841472911834718, ppl = 4.924442867320635\n","Valid Epoch #7, Batch 520/4160 loss = 1.5846784734725952, ppl = 4.9267856275511\n","Valid Epoch #7, Batch 521/4160 loss = 1.5858247935771943, ppl = 4.932196746873939\n","Valid Epoch #7, Batch 522/4160 loss = 1.5874541091918946, ppl = 4.940222986874258\n","Valid Epoch #7, Batch 523/4160 loss = 1.587414755821228, ppl = 4.940016659528404\n","Valid Epoch #7, Batch 524/4160 loss = 1.5858313715457917, ppl = 4.931811857047052\n","Valid Epoch #7, Batch 525/4160 loss = 1.5886011123657227, ppl = 4.94645904954248\n","Valid Epoch #7, Batch 526/4160 loss = 1.587138307094574, ppl = 4.938772442967462\n","Valid Epoch #7, Batch 527/4160 loss = 1.5864293241500855, ppl = 4.934547513414277\n","Valid Epoch #7, Batch 528/4160 loss = 1.5893153524398804, ppl = 4.949198888096006\n","Valid Epoch #7, Batch 529/4160 loss = 1.585597686767578, ppl = 4.93034837328428\n","Valid Epoch #7, Batch 530/4160 loss = 1.584975014925003, ppl = 4.927399342116308\n","Valid Epoch #7, Batch 531/4160 loss = 1.5868256211280822, ppl = 4.938492095760479\n","Valid Epoch #7, Batch 532/4160 loss = 1.589341413974762, ppl = 4.951172974981422\n","Valid Epoch #7, Batch 533/4160 loss = 1.589431059360504, ppl = 4.951609877498354\n","Valid Epoch #7, Batch 534/4160 loss = 1.5928369677066803, ppl = 4.968633706138784\n","Valid Epoch #7, Batch 535/4160 loss = 1.5893545508384705, ppl = 4.950376664605522\n","Valid Epoch #7, Batch 536/4160 loss = 1.5921102929115296, ppl = 4.966008038313308\n","Valid Epoch #7, Batch 537/4160 loss = 1.590986386537552, ppl = 4.959589445203801\n","Valid Epoch #7, Batch 538/4160 loss = 1.589650444984436, ppl = 4.952935924346528\n","Valid Epoch #7, Batch 539/4160 loss = 1.5865398061275482, ppl = 4.936299431517506\n","Valid Epoch #7, Batch 540/4160 loss = 1.5875846588611602, ppl = 4.942091311463682\n","Valid Epoch #7, Batch 541/4160 loss = 1.5865508246421813, ppl = 4.936938644382836\n","Valid Epoch #7, Batch 542/4160 loss = 1.5869228589534758, ppl = 4.939030138235346\n","Valid Epoch #7, Batch 543/4160 loss = 1.588980470895767, ppl = 4.950650440598074\n","Valid Epoch #7, Batch 544/4160 loss = 1.5879087579250335, ppl = 4.945106281753956\n","Valid Epoch #7, Batch 545/4160 loss = 1.5866892504692078, ppl = 4.937342763934543\n","Valid Epoch #7, Batch 546/4160 loss = 1.5870390117168427, ppl = 4.939226420107093\n","Valid Epoch #7, Batch 547/4160 loss = 1.5863827204704284, ppl = 4.935671408637898\n","Valid Epoch #7, Batch 548/4160 loss = 1.584139941930771, ppl = 4.92357664628237\n","Valid Epoch #7, Batch 549/4160 loss = 1.5835883438587188, ppl = 4.921174751361351\n","Valid Epoch #7, Batch 550/4160 loss = 1.5833524310588836, ppl = 4.920167036759406\n","Valid Epoch #7, Batch 551/4160 loss = 1.5838651168346405, ppl = 4.922933631686477\n","Valid Epoch #7, Batch 552/4160 loss = 1.584978768825531, ppl = 4.928453616496485\n","Valid Epoch #7, Batch 553/4160 loss = 1.5845825564861298, ppl = 4.926571590881817\n","Valid Epoch #7, Batch 554/4160 loss = 1.5855094230175018, ppl = 4.931454930573286\n","Valid Epoch #7, Batch 555/4160 loss = 1.5834274923801421, ppl = 4.920286220446006\n","Valid Epoch #7, Batch 556/4160 loss = 1.580322984457016, ppl = 4.903822007262132\n","Valid Epoch #7, Batch 557/4160 loss = 1.5809985733032226, ppl = 4.90690351258769\n","Valid Epoch #7, Batch 558/4160 loss = 1.5807395160198212, ppl = 4.905468657647677\n","Valid Epoch #7, Batch 559/4160 loss = 1.5834851312637328, ppl = 4.9189588067525465\n","Valid Epoch #7, Batch 560/4160 loss = 1.5851361763477325, ppl = 4.9272310544212585\n","Valid Epoch #7, Batch 561/4160 loss = 1.5848557734489441, ppl = 4.925769136704276\n","Valid Epoch #7, Batch 562/4160 loss = 1.5835546517372132, ppl = 4.9197699659682534\n","Valid Epoch #7, Batch 563/4160 loss = 1.581367791891098, ppl = 4.909481915286926\n","Valid Epoch #7, Batch 564/4160 loss = 1.5840436708927155, ppl = 4.920523765510921\n","Valid Epoch #7, Batch 565/4160 loss = 1.5823087072372437, ppl = 4.912332083088518\n","Valid Epoch #7, Batch 566/4160 loss = 1.5849288725852966, ppl = 4.927373533402255\n","Valid Epoch #7, Batch 567/4160 loss = 1.5838498854637146, ppl = 4.922068873591951\n","Valid Epoch #7, Batch 568/4160 loss = 1.585139763355255, ppl = 4.928929660630576\n","Valid Epoch #7, Batch 569/4160 loss = 1.5864020955562592, ppl = 4.934425928686365\n","Valid Epoch #7, Batch 570/4160 loss = 1.5859888172149659, ppl = 4.932392959459915\n","Valid Epoch #7, Batch 571/4160 loss = 1.585289434194565, ppl = 4.929110400502555\n","Valid Epoch #7, Batch 572/4160 loss = 1.5845029282569885, ppl = 4.925226654178027\n","Valid Epoch #7, Batch 573/4160 loss = 1.5833347821235657, ppl = 4.919730432003039\n","Valid Epoch #7, Batch 574/4160 loss = 1.580856362581253, ppl = 4.906260441107241\n","Valid Epoch #7, Batch 575/4160 loss = 1.5811378383636474, ppl = 4.907798356887556\n","Valid Epoch #7, Batch 576/4160 loss = 1.585837607383728, ppl = 4.930114111357334\n","Valid Epoch #7, Batch 577/4160 loss = 1.5858378469944001, ppl = 4.930115121440335\n","Valid Epoch #7, Batch 578/4160 loss = 1.586027179956436, ppl = 4.931072296167954\n","Valid Epoch #7, Batch 579/4160 loss = 1.5865657711029053, ppl = 4.933809678847179\n","Valid Epoch #7, Batch 580/4160 loss = 1.5850142240524292, ppl = 4.926232555846128\n","Valid Epoch #7, Batch 581/4160 loss = 1.5855838453769684, ppl = 4.928773542679135\n","Valid Epoch #7, Batch 582/4160 loss = 1.5846309316158296, ppl = 4.924188263114591\n","Valid Epoch #7, Batch 583/4160 loss = 1.5849430906772612, ppl = 4.925747534363915\n","Valid Epoch #7, Batch 584/4160 loss = 1.5848483073711395, ppl = 4.925284476512376\n","Valid Epoch #7, Batch 585/4160 loss = 1.586808670759201, ppl = 4.934570242331677\n","Valid Epoch #7, Batch 586/4160 loss = 1.5883431661128997, ppl = 4.942457744037029\n","Valid Epoch #7, Batch 587/4160 loss = 1.5864659023284913, ppl = 4.933839833149379\n","Valid Epoch #7, Batch 588/4160 loss = 1.5857609570026399, ppl = 4.93001034048712\n","Valid Epoch #7, Batch 589/4160 loss = 1.5842825615406035, ppl = 4.92319218619497\n","Valid Epoch #7, Batch 590/4160 loss = 1.5834355974197387, ppl = 4.918840973298423\n","Valid Epoch #7, Batch 591/4160 loss = 1.5820479094982147, ppl = 4.912359062346891\n","Valid Epoch #7, Batch 592/4160 loss = 1.581916605234146, ppl = 4.911575967758805\n","Valid Epoch #7, Batch 593/4160 loss = 1.5833879685401917, ppl = 4.91850029821382\n","Valid Epoch #7, Batch 594/4160 loss = 1.5839885354042054, ppl = 4.921495146533867\n","Valid Epoch #7, Batch 595/4160 loss = 1.5833858239650727, ppl = 4.918643974163744\n","Valid Epoch #7, Batch 596/4160 loss = 1.5831203544139862, ppl = 4.917219770914906\n","Valid Epoch #7, Batch 597/4160 loss = 1.581659346818924, ppl = 4.910352608560476\n","Valid Epoch #7, Batch 598/4160 loss = 1.5813682913780212, ppl = 4.9089601471621185\n","Valid Epoch #7, Batch 599/4160 loss = 1.5805078315734864, ppl = 4.904496443838507\n","Valid Epoch #7, Batch 600/4160 loss = 1.5776549315452575, ppl = 4.8909436156569805\n","Valid Epoch #7, Batch 601/4160 loss = 1.5775045466423034, ppl = 4.8903670612982095\n","Valid Epoch #7, Batch 602/4160 loss = 1.5768956851959228, ppl = 4.888538905931545\n","Valid Epoch #7, Batch 603/4160 loss = 1.574620134830475, ppl = 4.8801166492354575\n","Valid Epoch #7, Batch 604/4160 loss = 1.5750083684921266, ppl = 4.881595541949973\n","Valid Epoch #7, Batch 605/4160 loss = 1.5743905568122865, ppl = 4.879139054965156\n","Valid Epoch #7, Batch 606/4160 loss = 1.5752188766002655, ppl = 4.882505257992057\n","Valid Epoch #7, Batch 607/4160 loss = 1.5737460350990295, ppl = 4.876802216105013\n","Valid Epoch #7, Batch 608/4160 loss = 1.5749886012077332, ppl = 4.881521143786053\n","Valid Epoch #7, Batch 609/4160 loss = 1.5739316928386688, ppl = 4.877350843805872\n","Valid Epoch #7, Batch 610/4160 loss = 1.572254583835602, ppl = 4.8708655042570115\n","Valid Epoch #7, Batch 611/4160 loss = 1.5747852432727814, ppl = 4.8853273802823995\n","Valid Epoch #7, Batch 612/4160 loss = 1.5743831717967987, ppl = 4.883815391011281\n","Valid Epoch #7, Batch 613/4160 loss = 1.5711096835136413, ppl = 4.869756363019163\n","Valid Epoch #7, Batch 614/4160 loss = 1.5716186726093293, ppl = 4.872308573372177\n","Valid Epoch #7, Batch 615/4160 loss = 1.5702331256866455, ppl = 4.866284370998455\n","Valid Epoch #7, Batch 616/4160 loss = 1.569772641658783, ppl = 4.864009728895461\n","Valid Epoch #7, Batch 617/4160 loss = 1.5699641120433807, ppl = 4.864709557871614\n","Valid Epoch #7, Batch 618/4160 loss = 1.570132803916931, ppl = 4.865578928329647\n","Valid Epoch #7, Batch 619/4160 loss = 1.5711712121963501, ppl = 4.870198130851915\n","Valid Epoch #7, Batch 620/4160 loss = 1.5735469543933869, ppl = 4.882342541345781\n","Valid Epoch #7, Batch 621/4160 loss = 1.5721839320659639, ppl = 4.87597639061952\n","Valid Epoch #7, Batch 622/4160 loss = 1.5702836143970489, ppl = 4.866737466616058\n","Valid Epoch #7, Batch 623/4160 loss = 1.5705975663661957, ppl = 4.8684063210434765\n","Valid Epoch #7, Batch 624/4160 loss = 1.5751790952682496, ppl = 4.896199245979437\n","Valid Epoch #7, Batch 625/4160 loss = 1.5724195086956023, ppl = 4.8815986820478345\n","Valid Epoch #7, Batch 626/4160 loss = 1.5727282667160034, ppl = 4.88312884145534\n","Valid Epoch #7, Batch 627/4160 loss = 1.5703119099140168, ppl = 4.870785181454501\n","Valid Epoch #7, Batch 628/4160 loss = 1.568467766046524, ppl = 4.860942670914259\n","Valid Epoch #7, Batch 629/4160 loss = 1.571847426891327, ppl = 4.877775345676927\n","Valid Epoch #7, Batch 630/4160 loss = 1.5726557576656341, ppl = 4.881639806003609\n","Valid Epoch #7, Batch 631/4160 loss = 1.569318138360977, ppl = 4.863007506735939\n","Valid Epoch #7, Batch 632/4160 loss = 1.5696485030651093, ppl = 4.8649224093817995\n","Valid Epoch #7, Batch 633/4160 loss = 1.571133474111557, ppl = 4.872759673075738\n","Valid Epoch #7, Batch 634/4160 loss = 1.5683180177211762, ppl = 4.858287593543805\n","Valid Epoch #7, Batch 635/4160 loss = 1.5698070597648621, ppl = 4.865324469416542\n","Valid Epoch #7, Batch 636/4160 loss = 1.5656705451011659, ppl = 4.8433393610561755\n","Valid Epoch #7, Batch 637/4160 loss = 1.5668218731880188, ppl = 4.849923751156885\n","Valid Epoch #7, Batch 638/4160 loss = 1.5677517139911652, ppl = 4.8544599055836315\n","Valid Epoch #7, Batch 639/4160 loss = 1.56734095454216, ppl = 4.852624996497725\n","Valid Epoch #7, Batch 640/4160 loss = 1.567312400341034, ppl = 4.852458538089589\n","Valid Epoch #7, Batch 641/4160 loss = 1.5689865601062776, ppl = 4.861080304443045\n","Valid Epoch #7, Batch 642/4160 loss = 1.5667716574668884, ppl = 4.84970211434551\n","Valid Epoch #7, Batch 643/4160 loss = 1.5641494131088256, ppl = 4.835289459204367\n","Valid Epoch #7, Batch 644/4160 loss = 1.5664430487155914, ppl = 4.847923987784907\n","Valid Epoch #7, Batch 645/4160 loss = 1.5658241057395934, ppl = 4.844331431960578\n","Valid Epoch #7, Batch 646/4160 loss = 1.5644195067882538, ppl = 4.837149991135223\n","Valid Epoch #7, Batch 647/4160 loss = 1.5649000322818756, ppl = 4.839729921403193\n","Valid Epoch #7, Batch 648/4160 loss = 1.5660460329055785, ppl = 4.845571192477262\n","Valid Epoch #7, Batch 649/4160 loss = 1.5671181499958038, ppl = 4.850364434200674\n","Valid Epoch #7, Batch 650/4160 loss = 1.5693743360042571, ppl = 4.86104861666686\n","Valid Epoch #7, Batch 651/4160 loss = 1.5701014685630799, ppl = 4.865223826638211\n","Valid Epoch #7, Batch 652/4160 loss = 1.570215882062912, ppl = 4.865826539869065\n","Valid Epoch #7, Batch 653/4160 loss = 1.571720575094223, ppl = 4.873387849347555\n","Valid Epoch #7, Batch 654/4160 loss = 1.5703358101844787, ppl = 4.86625399654012\n","Valid Epoch #7, Batch 655/4160 loss = 1.5702576887607576, ppl = 4.865878488687523\n","Valid Epoch #7, Batch 656/4160 loss = 1.5695874392986298, ppl = 4.862946545803243\n","Valid Epoch #7, Batch 657/4160 loss = 1.5706316924095154, ppl = 4.868138691161921\n","Valid Epoch #7, Batch 658/4160 loss = 1.570687665939331, ppl = 4.868445574564582\n","Valid Epoch #7, Batch 659/4160 loss = 1.5678113508224487, ppl = 4.8544010121135095\n","Valid Epoch #7, Batch 660/4160 loss = 1.5670045590400696, ppl = 4.850188090245214\n","Valid Epoch #7, Batch 661/4160 loss = 1.5652248990535735, ppl = 4.841806961495325\n","Valid Epoch #7, Batch 662/4160 loss = 1.5667225778102876, ppl = 4.848782209691838\n","Valid Epoch #7, Batch 663/4160 loss = 1.565772635936737, ppl = 4.8449681048949635\n","Valid Epoch #7, Batch 664/4160 loss = 1.5658274745941163, ppl = 4.845226726371034\n","Valid Epoch #7, Batch 665/4160 loss = 1.5666017520427704, ppl = 4.848707551613626\n","Valid Epoch #7, Batch 666/4160 loss = 1.564730213880539, ppl = 4.837569532088317\n","Valid Epoch #7, Batch 667/4160 loss = 1.5664092230796813, ppl = 4.84608136369763\n","Valid Epoch #7, Batch 668/4160 loss = 1.564556791782379, ppl = 4.836494611514724\n","Valid Epoch #7, Batch 669/4160 loss = 1.5655952835083007, ppl = 4.841566455282741\n","Valid Epoch #7, Batch 670/4160 loss = 1.566073832511902, ppl = 4.843928251609131\n","Valid Epoch #7, Batch 671/4160 loss = 1.5686781871318818, ppl = 4.857408617027696\n","Valid Epoch #7, Batch 672/4160 loss = 1.567946684360504, ppl = 4.854060608329046\n","Valid Epoch #7, Batch 673/4160 loss = 1.5692226421833038, ppl = 4.860097205484288\n","Valid Epoch #7, Batch 674/4160 loss = 1.5693254625797273, ppl = 4.860592173594204\n","Valid Epoch #7, Batch 675/4160 loss = 1.567293142080307, ppl = 4.850401628393455\n","Valid Epoch #7, Batch 676/4160 loss = 1.5655933690071107, ppl = 4.841099053127688\n","Valid Epoch #7, Batch 677/4160 loss = 1.566144427061081, ppl = 4.84348727397454\n","Valid Epoch #7, Batch 678/4160 loss = 1.5654626429080962, ppl = 4.8401237379878\n","Valid Epoch #7, Batch 679/4160 loss = 1.5660795271396637, ppl = 4.84344564271391\n","Valid Epoch #7, Batch 680/4160 loss = 1.5664239776134492, ppl = 4.845027766086262\n","Valid Epoch #7, Batch 681/4160 loss = 1.5669429218769073, ppl = 4.847472124071154\n","Valid Epoch #7, Batch 682/4160 loss = 1.5675091445446014, ppl = 4.850143876992459\n","Valid Epoch #7, Batch 683/4160 loss = 1.5659135282039642, ppl = 4.842661367757735\n","Valid Epoch #7, Batch 684/4160 loss = 1.565522871017456, ppl = 4.840798491528329\n","Valid Epoch #7, Batch 685/4160 loss = 1.5643891537189483, ppl = 4.83520769517095\n","Valid Epoch #7, Batch 686/4160 loss = 1.5632016062736511, ppl = 4.8289991778990755\n","Valid Epoch #7, Batch 687/4160 loss = 1.5670364820957183, ppl = 4.848504692809691\n","Valid Epoch #7, Batch 688/4160 loss = 1.5674801588058471, ppl = 4.850883311137441\n","Valid Epoch #7, Batch 689/4160 loss = 1.5682724106311798, ppl = 4.854411551558856\n","Valid Epoch #7, Batch 690/4160 loss = 1.569171267747879, ppl = 4.859041532625595\n","Valid Epoch #7, Batch 691/4160 loss = 1.5700642442703248, ppl = 4.863108818050682\n","Valid Epoch #7, Batch 692/4160 loss = 1.5676041996479035, ppl = 4.850187720864247\n","Valid Epoch #7, Batch 693/4160 loss = 1.5669109833240509, ppl = 4.8467983494323015\n","Valid Epoch #7, Batch 694/4160 loss = 1.5663322949409484, ppl = 4.843909475128099\n","Valid Epoch #7, Batch 695/4160 loss = 1.5667905700206757, ppl = 4.8460616430611845\n","Valid Epoch #7, Batch 696/4160 loss = 1.565299025774002, ppl = 4.838726137097441\n","Valid Epoch #7, Batch 697/4160 loss = 1.5664993369579314, ppl = 4.844293278269708\n","Valid Epoch #7, Batch 698/4160 loss = 1.5669519865512849, ppl = 4.846476512318326\n","Valid Epoch #7, Batch 699/4160 loss = 1.5664339900016784, ppl = 4.843968824992522\n","Valid Epoch #7, Batch 700/4160 loss = 1.5688819146156312, ppl = 4.855354518444667\n","Valid Epoch #7, Batch 701/4160 loss = 1.5674243819713594, ppl = 4.850193693985614\n","Valid Epoch #7, Batch 702/4160 loss = 1.5700730502605438, ppl = 4.859024853034736\n","Valid Epoch #7, Batch 703/4160 loss = 1.5702020418643952, ppl = 4.859452768452223\n","Valid Epoch #7, Batch 704/4160 loss = 1.5714909648895263, ppl = 4.864795492808848\n","Valid Epoch #7, Batch 705/4160 loss = 1.5693487274646758, ppl = 4.857362678110388\n","Valid Epoch #7, Batch 706/4160 loss = 1.5687940144538879, ppl = 4.855077692611006\n","Valid Epoch #7, Batch 707/4160 loss = 1.5671940076351165, ppl = 4.849763748152956\n","Valid Epoch #7, Batch 708/4160 loss = 1.5673653507232665, ppl = 4.8504616896386645\n","Valid Epoch #7, Batch 709/4160 loss = 1.5674666488170623, ppl = 4.850842562612093\n","Valid Epoch #7, Batch 710/4160 loss = 1.5669957721233367, ppl = 4.849208882680041\n","Valid Epoch #7, Batch 711/4160 loss = 1.5635688996315003, ppl = 4.830441981716868\n","Valid Epoch #7, Batch 712/4160 loss = 1.56618191242218, ppl = 4.841447298401467\n","Valid Epoch #7, Batch 713/4160 loss = 1.5693264532089233, ppl = 4.854861109221788\n","Valid Epoch #7, Batch 714/4160 loss = 1.5679288733005523, ppl = 4.8481530692178705\n","Valid Epoch #7, Batch 715/4160 loss = 1.5672982406616212, ppl = 4.8456756551094005\n","Valid Epoch #7, Batch 716/4160 loss = 1.5657527899742127, ppl = 4.838763888289786\n","Valid Epoch #7, Batch 717/4160 loss = 1.566895512342453, ppl = 4.843231056459126\n","Valid Epoch #7, Batch 718/4160 loss = 1.5664964509010315, ppl = 4.841197895604479\n","Valid Epoch #7, Batch 719/4160 loss = 1.567068817615509, ppl = 4.843956662082603\n","Valid Epoch #7, Batch 720/4160 loss = 1.566748548746109, ppl = 4.842146474475088\n","Valid Epoch #7, Batch 721/4160 loss = 1.5675840485095978, ppl = 4.845945353367304\n","Valid Epoch #7, Batch 722/4160 loss = 1.568242348432541, ppl = 4.848949174461628\n","Valid Epoch #7, Batch 723/4160 loss = 1.5674247694015504, ppl = 4.8447102860863165\n","Valid Epoch #7, Batch 724/4160 loss = 1.5652989292144774, ppl = 4.830229078177291\n","Valid Epoch #7, Batch 725/4160 loss = 1.5664500737190246, ppl = 4.835834278987959\n","Valid Epoch #7, Batch 726/4160 loss = 1.5664530813694, ppl = 4.835849418031415\n","Valid Epoch #7, Batch 727/4160 loss = 1.567492038011551, ppl = 4.840793773772948\n","Valid Epoch #7, Batch 728/4160 loss = 1.5669425904750824, ppl = 4.838195406495654\n","Valid Epoch #7, Batch 729/4160 loss = 1.5660382604599, ppl = 4.83312034713791\n","Valid Epoch #7, Batch 730/4160 loss = 1.567731145620346, ppl = 4.842300305104794\n","Valid Epoch #7, Batch 731/4160 loss = 1.5680521523952484, ppl = 4.843834369746461\n","Valid Epoch #7, Batch 732/4160 loss = 1.5649317371845246, ppl = 4.828039317845173\n","Valid Epoch #7, Batch 733/4160 loss = 1.5623061728477479, ppl = 4.814924893559926\n","Valid Epoch #7, Batch 734/4160 loss = 1.5654430043697358, ppl = 4.831323145106137\n","Valid Epoch #7, Batch 735/4160 loss = 1.5635459125041962, ppl = 4.8225339215623375\n","Valid Epoch #7, Batch 736/4160 loss = 1.5625936484336853, ppl = 4.818636097760558\n","Valid Epoch #7, Batch 737/4160 loss = 1.560875904560089, ppl = 4.80908024907349\n","Valid Epoch #7, Batch 738/4160 loss = 1.5599326705932617, ppl = 4.804481789498928\n","Valid Epoch #7, Batch 739/4160 loss = 1.5633862543106078, ppl = 4.822532599709184\n","Valid Epoch #7, Batch 740/4160 loss = 1.5613362538814544, ppl = 4.811742772523263\n","Valid Epoch #7, Batch 741/4160 loss = 1.5622562444210053, ppl = 4.817132416136866\n","Valid Epoch #7, Batch 742/4160 loss = 1.5652812278270722, ppl = 4.833343028958413\n","Valid Epoch #7, Batch 743/4160 loss = 1.567060537338257, ppl = 4.842704571431086\n","Valid Epoch #7, Batch 744/4160 loss = 1.5669537043571473, ppl = 4.842049518644717\n","Valid Epoch #7, Batch 745/4160 loss = 1.5656004166603088, ppl = 4.834927901787558\n","Valid Epoch #7, Batch 746/4160 loss = 1.566571626663208, ppl = 4.839784981105444\n","Valid Epoch #7, Batch 747/4160 loss = 1.566332004070282, ppl = 4.8384829569393215\n","Valid Epoch #7, Batch 748/4160 loss = 1.5667746102809905, ppl = 4.8409243291213855\n","Valid Epoch #7, Batch 749/4160 loss = 1.5677940165996551, ppl = 4.84598410570679\n","Valid Epoch #7, Batch 750/4160 loss = 1.567596881389618, ppl = 4.844951514070024\n","Valid Epoch #7, Batch 751/4160 loss = 1.5674792516231537, ppl = 4.844255330159687\n","Valid Epoch #7, Batch 752/4160 loss = 1.566239037513733, ppl = 4.838075741001797\n","Valid Epoch #7, Batch 753/4160 loss = 1.56703431725502, ppl = 4.842556144375145\n","Valid Epoch #7, Batch 754/4160 loss = 1.566994504928589, ppl = 4.842365297657578\n","Valid Epoch #7, Batch 755/4160 loss = 1.5657359886169433, ppl = 4.836703315838141\n","Valid Epoch #7, Batch 756/4160 loss = 1.567779334783554, ppl = 4.846291831521688\n","Valid Epoch #7, Batch 757/4160 loss = 1.567070026397705, ppl = 4.842706386053429\n","Valid Epoch #7, Batch 758/4160 loss = 1.5671827375888825, ppl = 4.843329578842086\n","Valid Epoch #7, Batch 759/4160 loss = 1.5665083265304565, ppl = 4.840581180727168\n","Valid Epoch #7, Batch 760/4160 loss = 1.5669200444221496, ppl = 4.842688622828958\n","Valid Epoch #7, Batch 761/4160 loss = 1.5696977758407593, ppl = 4.856465504387749\n","Valid Epoch #7, Batch 762/4160 loss = 1.5691462528705598, ppl = 4.853774593364056\n","Valid Epoch #7, Batch 763/4160 loss = 1.5706575298309327, ppl = 4.86001882240252\n","Valid Epoch #7, Batch 764/4160 loss = 1.5716616702079773, ppl = 4.86501398395912\n","Valid Epoch #7, Batch 765/4160 loss = 1.5749876189231873, ppl = 4.883448334461382\n","Valid Epoch #7, Batch 766/4160 loss = 1.5738428449630737, ppl = 4.877594585133383\n","Valid Epoch #7, Batch 767/4160 loss = 1.5733846616744995, ppl = 4.8751282785053585\n","Valid Epoch #7, Batch 768/4160 loss = 1.5736836528778075, ppl = 4.876557997484047\n","Valid Epoch #7, Batch 769/4160 loss = 1.5720148944854737, ppl = 4.868655235781392\n","Valid Epoch #7, Batch 770/4160 loss = 1.5719144141674042, ppl = 4.868149915101292\n","Valid Epoch #7, Batch 771/4160 loss = 1.5700630390644073, ppl = 4.858213262594738\n","Valid Epoch #7, Batch 772/4160 loss = 1.5705588901042937, ppl = 4.8604558655169745\n","Valid Epoch #7, Batch 773/4160 loss = 1.5712207186222076, ppl = 4.863903843932585\n","Valid Epoch #7, Batch 774/4160 loss = 1.570299048423767, ppl = 4.8596435046524045\n","Valid Epoch #7, Batch 775/4160 loss = 1.5717940747737884, ppl = 4.866935461747537\n","Valid Epoch #7, Batch 776/4160 loss = 1.5694099032878877, ppl = 4.856284877623615\n","Valid Epoch #7, Batch 777/4160 loss = 1.5694176411628724, ppl = 4.856319358476637\n","Valid Epoch #7, Batch 778/4160 loss = 1.5684112668037415, ppl = 4.851755312746307\n","Valid Epoch #7, Batch 779/4160 loss = 1.5680543994903564, ppl = 4.849808650278474\n","Valid Epoch #7, Batch 780/4160 loss = 1.5692138195037841, ppl = 4.855552885816679\n","Valid Epoch #7, Batch 781/4160 loss = 1.571230617761612, ppl = 4.866353701511696\n","Valid Epoch #7, Batch 782/4160 loss = 1.5717883348464965, ppl = 4.869137432742749\n","Valid Epoch #7, Batch 783/4160 loss = 1.5726945686340332, ppl = 4.873240203688755\n","Valid Epoch #7, Batch 784/4160 loss = 1.573879704475403, ppl = 4.879123689574431\n","Valid Epoch #7, Batch 785/4160 loss = 1.5734930884838105, ppl = 4.877357531451503\n","Valid Epoch #7, Batch 786/4160 loss = 1.5724989509582519, ppl = 4.872698106047367\n","Valid Epoch #7, Batch 787/4160 loss = 1.5681698358058929, ppl = 4.851180145571654\n","Valid Epoch #7, Batch 788/4160 loss = 1.5669861555099487, ppl = 4.845061694931574\n","Valid Epoch #7, Batch 789/4160 loss = 1.569196137189865, ppl = 4.856518041109437\n","Valid Epoch #7, Batch 790/4160 loss = 1.56869269490242, ppl = 4.8538736588174025\n","Valid Epoch #7, Batch 791/4160 loss = 1.568549075126648, ppl = 4.853194751678521\n","Valid Epoch #7, Batch 792/4160 loss = 1.5688839733600617, ppl = 4.854772537435145\n","Valid Epoch #7, Batch 793/4160 loss = 1.5691032898426056, ppl = 4.8558195521864524\n","Valid Epoch #7, Batch 794/4160 loss = 1.5681379652023315, ppl = 4.851357470967985\n","Valid Epoch #7, Batch 795/4160 loss = 1.5678966009616853, ppl = 4.850211679616102\n","Valid Epoch #7, Batch 796/4160 loss = 1.5690763473510743, ppl = 4.855922011002864\n","Valid Epoch #7, Batch 797/4160 loss = 1.5691699230670928, ppl = 4.856384752920075\n","Valid Epoch #7, Batch 798/4160 loss = 1.568037348985672, ppl = 4.851102302575281\n","Valid Epoch #7, Batch 799/4160 loss = 1.5678037750720977, ppl = 4.850013342319251\n","Valid Epoch #7, Batch 800/4160 loss = 1.5670931959152221, ppl = 4.846416615560952\n","Valid Epoch #7, Batch 801/4160 loss = 1.567860223054886, ppl = 4.8490386566472035\n","Valid Epoch #7, Batch 802/4160 loss = 1.5674388074874879, ppl = 4.8474725249562445\n","Valid Epoch #7, Batch 803/4160 loss = 1.5674108815193177, ppl = 4.847379414924935\n","Valid Epoch #7, Batch 804/4160 loss = 1.5680914676189424, ppl = 4.850490912300426\n","Valid Epoch #7, Batch 805/4160 loss = 1.568039973974228, ppl = 4.85033111353188\n","Valid Epoch #7, Batch 806/4160 loss = 1.5684254920482636, ppl = 4.85190566562094\n","Valid Epoch #7, Batch 807/4160 loss = 1.5713821315765382, ppl = 4.862441526424933\n","Valid Epoch #7, Batch 808/4160 loss = 1.572180746793747, ppl = 4.865857090793668\n","Valid Epoch #7, Batch 809/4160 loss = 1.5724901247024536, ppl = 4.867044502598275\n","Valid Epoch #7, Batch 810/4160 loss = 1.576393004655838, ppl = 4.883220935905476\n","Valid Epoch #7, Batch 811/4160 loss = 1.5750793421268463, ppl = 4.877568595897716\n","Valid Epoch #7, Batch 812/4160 loss = 1.5725467002391815, ppl = 4.866860672095156\n","Valid Epoch #7, Batch 813/4160 loss = 1.5712284326553345, ppl = 4.860720477771978\n","Valid Epoch #7, Batch 814/4160 loss = 1.5687645018100738, ppl = 4.850953943044779\n","Valid Epoch #7, Batch 815/4160 loss = 1.5690871226787566, ppl = 4.852201823834152\n","Valid Epoch #7, Batch 816/4160 loss = 1.571571831703186, ppl = 4.863866956832141\n","Valid Epoch #7, Batch 817/4160 loss = 1.5710755145549775, ppl = 4.861863888937695\n","Valid Epoch #7, Batch 818/4160 loss = 1.5705527317523957, ppl = 4.859320245051527\n","Valid Epoch #7, Batch 819/4160 loss = 1.570561145544052, ppl = 4.859361988136815\n","Valid Epoch #7, Batch 820/4160 loss = 1.566333304643631, ppl = 4.840185118929059\n","Valid Epoch #7, Batch 821/4160 loss = 1.567719705104828, ppl = 4.8472331402954065\n","Valid Epoch #7, Batch 822/4160 loss = 1.5679653024673461, ppl = 4.848405428340482\n","Valid Epoch #7, Batch 823/4160 loss = 1.5680292797088624, ppl = 4.848724775664863\n","Valid Epoch #7, Batch 824/4160 loss = 1.567112122774124, ppl = 4.843367120908172\n","Valid Epoch #7, Batch 825/4160 loss = 1.565194194316864, ppl = 4.834370717903923\n","Valid Epoch #7, Batch 826/4160 loss = 1.562506376504898, ppl = 4.822505451169262\n","Valid Epoch #7, Batch 827/4160 loss = 1.5607858192920685, ppl = 4.8145855296186575\n","Valid Epoch #7, Batch 828/4160 loss = 1.5612676525115967, ppl = 4.816856388794395\n","Valid Epoch #7, Batch 829/4160 loss = 1.5599143612384796, ppl = 4.810069586278645\n","Valid Epoch #7, Batch 830/4160 loss = 1.5581358408927917, ppl = 4.800465274396375\n","Valid Epoch #7, Batch 831/4160 loss = 1.5595010173320771, ppl = 4.807568437703557\n","Valid Epoch #7, Batch 832/4160 loss = 1.5597064757347108, ppl = 4.80846376576092\n","Valid Epoch #7, Batch 833/4160 loss = 1.5638378274440765, ppl = 4.8308074075199094\n","Valid Epoch #7, Batch 834/4160 loss = 1.561208666563034, ppl = 4.816726894474888\n","Valid Epoch #7, Batch 835/4160 loss = 1.5649378836154937, ppl = 4.8357432155441264\n","Valid Epoch #7, Batch 836/4160 loss = 1.566239334344864, ppl = 4.8411659383300005\n","Valid Epoch #7, Batch 837/4160 loss = 1.5670592093467712, ppl = 4.8455225550248375\n","Valid Epoch #7, Batch 838/4160 loss = 1.5671564495563508, ppl = 4.845976819771405\n","Valid Epoch #7, Batch 839/4160 loss = 1.5646216452121735, ppl = 4.8321370746176635\n","Valid Epoch #7, Batch 840/4160 loss = 1.5660770070552825, ppl = 4.8395662757784725\n","Valid Epoch #7, Batch 841/4160 loss = 1.5653496384620667, ppl = 4.835264413024047\n","Valid Epoch #7, Batch 842/4160 loss = 1.5646371471881866, ppl = 4.830993621320598\n","Valid Epoch #7, Batch 843/4160 loss = 1.5655040550231933, ppl = 4.83619470641547\n","Valid Epoch #7, Batch 844/4160 loss = 1.563156658411026, ppl = 4.823434458860093\n","Valid Epoch #7, Batch 845/4160 loss = 1.562272800207138, ppl = 4.819277247864427\n","Valid Epoch #7, Batch 846/4160 loss = 1.5622382688522338, ppl = 4.819096345214309\n","Valid Epoch #7, Batch 847/4160 loss = 1.5608300495147704, ppl = 4.812044097583982\n","Valid Epoch #7, Batch 848/4160 loss = 1.5616327512264252, ppl = 4.816757053043655\n","Valid Epoch #7, Batch 849/4160 loss = 1.5620463371276856, ppl = 4.818961550984733\n","Valid Epoch #7, Batch 850/4160 loss = 1.5622846066951752, ppl = 4.820212182711593\n","Valid Epoch #7, Batch 851/4160 loss = 1.5595348298549652, ppl = 4.806067143795034\n","Valid Epoch #7, Batch 852/4160 loss = 1.5606283235549927, ppl = 4.811475076529273\n","Valid Epoch #7, Batch 853/4160 loss = 1.5606067872047424, ppl = 4.811348993519741\n","Valid Epoch #7, Batch 854/4160 loss = 1.5623162198066711, ppl = 4.820267719719296\n","Valid Epoch #7, Batch 855/4160 loss = 1.5633080387115479, ppl = 4.824669639907629\n","Valid Epoch #7, Batch 856/4160 loss = 1.5629700601100922, ppl = 4.822945408228312\n","Valid Epoch #7, Batch 857/4160 loss = 1.5621889972686767, ppl = 4.819280607593041\n","Valid Epoch #7, Batch 858/4160 loss = 1.5606241130828857, ppl = 4.811225992480003\n","Valid Epoch #7, Batch 859/4160 loss = 1.5624671614170074, ppl = 4.819198602502038\n","Valid Epoch #7, Batch 860/4160 loss = 1.5600533282756806, ppl = 4.807993626033598\n","Valid Epoch #7, Batch 861/4160 loss = 1.559840465784073, ppl = 4.8067972488749895\n","Valid Epoch #7, Batch 862/4160 loss = 1.559964519739151, ppl = 4.807389644332333\n","Valid Epoch #7, Batch 863/4160 loss = 1.5614967787265777, ppl = 4.81476135082287\n","Valid Epoch #7, Batch 864/4160 loss = 1.560832041501999, ppl = 4.811398770490255\n","Valid Epoch #7, Batch 865/4160 loss = 1.5569635677337645, ppl = 4.790497343421277\n","Valid Epoch #7, Batch 866/4160 loss = 1.5598742485046386, ppl = 4.806803439855306\n","Valid Epoch #7, Batch 867/4160 loss = 1.5577562308311463, ppl = 4.7967626150571245\n","Valid Epoch #7, Batch 868/4160 loss = 1.5584595274925233, ppl = 4.800299073481367\n","Valid Epoch #7, Batch 869/4160 loss = 1.5594389855861663, ppl = 4.804776960174679\n","Valid Epoch #7, Batch 870/4160 loss = 1.5560755586624146, ppl = 4.790484940205626\n","Valid Epoch #7, Batch 871/4160 loss = 1.5579072749614715, ppl = 4.800306125682834\n","Valid Epoch #7, Batch 872/4160 loss = 1.5580388844013213, ppl = 4.800920272168715\n","Valid Epoch #7, Batch 873/4160 loss = 1.5580857515335083, ppl = 4.801173200634957\n","Valid Epoch #7, Batch 874/4160 loss = 1.5584131634235383, ppl = 4.802641871988425\n","Valid Epoch #7, Batch 875/4160 loss = 1.5591834282875061, ppl = 4.806846508875477\n","Valid Epoch #7, Batch 876/4160 loss = 1.5617017710208894, ppl = 4.81817528967011\n","Valid Epoch #7, Batch 877/4160 loss = 1.5618436634540558, ppl = 4.818812332074335\n","Valid Epoch #7, Batch 878/4160 loss = 1.5638089644908906, ppl = 4.828174098083641\n","Valid Epoch #7, Batch 879/4160 loss = 1.5639480614662171, ppl = 4.828924602416106\n","Valid Epoch #7, Batch 880/4160 loss = 1.5647319400310515, ppl = 4.833203248750246\n","Valid Epoch #7, Batch 881/4160 loss = 1.5633626902103424, ppl = 4.825635938272909\n","Valid Epoch #7, Batch 882/4160 loss = 1.5626178932189942, ppl = 4.821952673245764\n","Valid Epoch #7, Batch 883/4160 loss = 1.5620948195457458, ppl = 4.819539319374632\n","Valid Epoch #7, Batch 884/4160 loss = 1.5606577396392822, ppl = 4.812492451657949\n","Valid Epoch #7, Batch 885/4160 loss = 1.5626983666419982, ppl = 4.82263520845323\n","Valid Epoch #7, Batch 886/4160 loss = 1.5646409380435944, ppl = 4.8321930907701836\n","Valid Epoch #7, Batch 887/4160 loss = 1.5657339596748352, ppl = 4.8367807373439895\n","Valid Epoch #7, Batch 888/4160 loss = 1.5660284638404847, ppl = 4.838236037102449\n","Valid Epoch #7, Batch 889/4160 loss = 1.5648660039901734, ppl = 4.831895250584153\n","Valid Epoch #7, Batch 890/4160 loss = 1.5652067542076111, ppl = 4.833670474026008\n","Valid Epoch #7, Batch 891/4160 loss = 1.5639672327041625, ppl = 4.82819918168662\n","Valid Epoch #7, Batch 892/4160 loss = 1.5631952285766602, ppl = 4.8246399954743255\n","Valid Epoch #7, Batch 893/4160 loss = 1.5627587556838989, ppl = 4.8225786580735\n","Valid Epoch #7, Batch 894/4160 loss = 1.5626165354251862, ppl = 4.821956915565661\n","Valid Epoch #7, Batch 895/4160 loss = 1.561961681842804, ppl = 4.818983998783081\n","Valid Epoch #7, Batch 896/4160 loss = 1.5615871524810792, ppl = 4.8170976710552695\n","Valid Epoch #7, Batch 897/4160 loss = 1.562274227142334, ppl = 4.820631252119631\n","Valid Epoch #7, Batch 898/4160 loss = 1.5617696452140808, ppl = 4.818463727271888\n","Valid Epoch #7, Batch 899/4160 loss = 1.5611926567554475, ppl = 4.815880253546498\n","Valid Epoch #7, Batch 900/4160 loss = 1.561106369495392, ppl = 4.8154606415381425\n","Valid Epoch #7, Batch 901/4160 loss = 1.5610750257968902, ppl = 4.815349507297374\n","Valid Epoch #7, Batch 902/4160 loss = 1.5601350331306458, ppl = 4.812085077699595\n","Valid Epoch #7, Batch 903/4160 loss = 1.561881844997406, ppl = 4.8184400166042956\n","Valid Epoch #7, Batch 904/4160 loss = 1.5601184248924256, ppl = 4.8107944890183845\n","Valid Epoch #7, Batch 905/4160 loss = 1.5597857570648193, ppl = 4.809781725185405\n","Valid Epoch #7, Batch 906/4160 loss = 1.5586727845668793, ppl = 4.805396443613441\n","Valid Epoch #7, Batch 907/4160 loss = 1.5559200537204743, ppl = 4.795491481142578\n","Valid Epoch #7, Batch 908/4160 loss = 1.5533758652210237, ppl = 4.785495514246617\n","Valid Epoch #7, Batch 909/4160 loss = 1.5537421369552613, ppl = 4.786949613223654\n","Valid Epoch #7, Batch 910/4160 loss = 1.5509907162189485, ppl = 4.774908287136953\n","Valid Epoch #7, Batch 911/4160 loss = 1.5525628232955933, ppl = 4.781762751969819\n","Valid Epoch #7, Batch 912/4160 loss = 1.5561745262145996, ppl = 4.7979239234846744\n","Valid Epoch #7, Batch 913/4160 loss = 1.556316831111908, ppl = 4.798548451497416\n","Valid Epoch #7, Batch 914/4160 loss = 1.5569250965118409, ppl = 4.800740644376818\n","Valid Epoch #7, Batch 915/4160 loss = 1.557682809829712, ppl = 4.803834711811899\n","Valid Epoch #7, Batch 916/4160 loss = 1.5562571275234223, ppl = 4.79678965458427\n","Valid Epoch #7, Batch 917/4160 loss = 1.5573222994804383, ppl = 4.8012142071219595\n","Valid Epoch #7, Batch 918/4160 loss = 1.5562188184261323, ppl = 4.796262477820244\n","Valid Epoch #7, Batch 919/4160 loss = 1.557866599559784, ppl = 4.805153410833072\n","Valid Epoch #7, Batch 920/4160 loss = 1.5589832758903504, ppl = 4.809458916886462\n","Valid Epoch #7, Batch 921/4160 loss = 1.55749902009964, ppl = 4.801949379513339\n","Valid Epoch #7, Batch 922/4160 loss = 1.557214059829712, ppl = 4.800591866581457\n","Valid Epoch #7, Batch 923/4160 loss = 1.5576820003986358, ppl = 4.802990797823742\n","Valid Epoch #7, Batch 924/4160 loss = 1.557754477262497, ppl = 4.80339652791033\n","Valid Epoch #7, Batch 925/4160 loss = 1.5578106701374055, ppl = 4.8036363150095\n","Valid Epoch #7, Batch 926/4160 loss = 1.5622934556007386, ppl = 4.825399710866734\n","Valid Epoch #7, Batch 927/4160 loss = 1.5632725381851196, ppl = 4.829738894859061\n","Valid Epoch #7, Batch 928/4160 loss = 1.5640369725227357, ppl = 4.833573845114844\n","Valid Epoch #7, Batch 929/4160 loss = 1.565855188369751, ppl = 4.842912445380264\n","Valid Epoch #7, Batch 930/4160 loss = 1.5658824920654297, ppl = 4.843047350851267\n","Valid Epoch #7, Batch 931/4160 loss = 1.567634791135788, ppl = 4.8537080248376325\n","Valid Epoch #7, Batch 932/4160 loss = 1.5682078230381011, ppl = 4.856304556182864\n","Valid Epoch #7, Batch 933/4160 loss = 1.5636947047710419, ppl = 4.83232484872492\n","Valid Epoch #7, Batch 934/4160 loss = 1.5679485654830934, ppl = 4.85714954196496\n","Valid Epoch #7, Batch 935/4160 loss = 1.5651809561252594, ppl = 4.842380028194184\n","Valid Epoch #7, Batch 936/4160 loss = 1.5682657659053802, ppl = 4.858437555393412\n","Valid Epoch #7, Batch 937/4160 loss = 1.567569795846939, ppl = 4.854716648181274\n","Valid Epoch #7, Batch 938/4160 loss = 1.56907292842865, ppl = 4.862330758343026\n","Valid Epoch #7, Batch 939/4160 loss = 1.571594042778015, ppl = 4.876085942477823\n","Valid Epoch #7, Batch 940/4160 loss = 1.5732308900356293, ppl = 4.885840942314534\n","Valid Epoch #7, Batch 941/4160 loss = 1.5731590473651886, ppl = 4.885432778010045\n","Valid Epoch #7, Batch 942/4160 loss = 1.5738129007816315, ppl = 4.889340480000007\n","Valid Epoch #7, Batch 943/4160 loss = 1.5706279146671296, ppl = 4.87225645286691\n","Valid Epoch #7, Batch 944/4160 loss = 1.5724262368679047, ppl = 4.881758244908866\n","Valid Epoch #7, Batch 945/4160 loss = 1.572587616443634, ppl = 4.882490130122793\n","Valid Epoch #7, Batch 946/4160 loss = 1.572508100271225, ppl = 4.882075929073759\n","Valid Epoch #7, Batch 947/4160 loss = 1.574273167848587, ppl = 4.891078618594257\n","Valid Epoch #7, Batch 948/4160 loss = 1.5721679043769836, ppl = 4.879478939662945\n","Valid Epoch #7, Batch 949/4160 loss = 1.5733505141735078, ppl = 4.886309691225301\n","Valid Epoch #7, Batch 950/4160 loss = 1.574239480495453, ppl = 4.891247752900863\n","Valid Epoch #7, Batch 951/4160 loss = 1.5764866638183594, ppl = 4.9025087679047\n","Valid Epoch #7, Batch 952/4160 loss = 1.5771448123455047, ppl = 4.9060604768122165\n","Valid Epoch #7, Batch 953/4160 loss = 1.5763239312171935, ppl = 4.901451614699757\n","Valid Epoch #7, Batch 954/4160 loss = 1.5734037470817566, ppl = 4.8870774273825255\n","Valid Epoch #7, Batch 955/4160 loss = 1.577215473651886, ppl = 4.908708954214283\n","Valid Epoch #7, Batch 956/4160 loss = 1.5785887229442597, ppl = 4.916092363481797\n","Valid Epoch #7, Batch 957/4160 loss = 1.5770844185352326, ppl = 4.909791892555624\n","Valid Epoch #7, Batch 958/4160 loss = 1.577905148267746, ppl = 4.913858970426209\n","Valid Epoch #7, Batch 959/4160 loss = 1.5776122319698334, ppl = 4.912491653953676\n","Valid Epoch #7, Batch 960/4160 loss = 1.5787924218177796, ppl = 4.917632866084446\n","Valid Epoch #7, Batch 961/4160 loss = 1.5767125499248504, ppl = 4.907190623612448\n","Valid Epoch #7, Batch 962/4160 loss = 1.5759156274795532, ppl = 4.903510027682617\n","Valid Epoch #7, Batch 963/4160 loss = 1.5757559502124787, ppl = 4.90268804242747\n","Valid Epoch #7, Batch 964/4160 loss = 1.574840533733368, ppl = 4.898408469172875\n","Valid Epoch #7, Batch 965/4160 loss = 1.5757379162311553, ppl = 4.902563158073586\n","Valid Epoch #7, Batch 966/4160 loss = 1.5731163585186005, ppl = 4.887672838770342\n","Valid Epoch #7, Batch 967/4160 loss = 1.575315648317337, ppl = 4.898142931185195\n","Valid Epoch #7, Batch 968/4160 loss = 1.5756275463104248, ppl = 4.899792670615245\n","Valid Epoch #7, Batch 969/4160 loss = 1.575642820596695, ppl = 4.899866033257383\n","Valid Epoch #7, Batch 970/4160 loss = 1.579406774044037, ppl = 4.916202896251189\n","Valid Epoch #7, Batch 971/4160 loss = 1.577301778793335, ppl = 4.905064640227824\n","Valid Epoch #7, Batch 972/4160 loss = 1.5772647833824158, ppl = 4.904891186188942\n","Valid Epoch #7, Batch 973/4160 loss = 1.5791089940071106, ppl = 4.915846352178544\n","Valid Epoch #7, Batch 974/4160 loss = 1.5797692430019379, ppl = 4.9189583851705985\n","Valid Epoch #7, Batch 975/4160 loss = 1.57727108836174, ppl = 4.906420957542032\n","Valid Epoch #7, Batch 976/4160 loss = 1.5757144105434417, ppl = 4.899085271260995\n","Valid Epoch #7, Batch 977/4160 loss = 1.5754037117958068, ppl = 4.897702033453461\n","Valid Epoch #7, Batch 978/4160 loss = 1.5760469663143157, ppl = 4.901188068749557\n","Valid Epoch #7, Batch 979/4160 loss = 1.5750552880764008, ppl = 4.896058661580831\n","Valid Epoch #7, Batch 980/4160 loss = 1.5749048745632173, ppl = 4.895211448049664\n","Valid Epoch #7, Batch 981/4160 loss = 1.5743504440784455, ppl = 4.892430132996918\n","Valid Epoch #7, Batch 982/4160 loss = 1.5744920134544373, ppl = 4.893109287685565\n","Valid Epoch #7, Batch 983/4160 loss = 1.5751118850708008, ppl = 4.895983255203963\n","Valid Epoch #7, Batch 984/4160 loss = 1.5746995723247528, ppl = 4.894141465554672\n","Valid Epoch #7, Batch 985/4160 loss = 1.5742738699913026, ppl = 4.891851412300937\n","Valid Epoch #7, Batch 986/4160 loss = 1.572441418170929, ppl = 4.882787132778455\n","Valid Epoch #7, Batch 987/4160 loss = 1.5722562730312348, ppl = 4.8819743437429075\n","Valid Epoch #7, Batch 988/4160 loss = 1.5722214102745056, ppl = 4.881799823701484\n","Valid Epoch #7, Batch 989/4160 loss = 1.5722160303592683, ppl = 4.881772158311973\n","Valid Epoch #7, Batch 990/4160 loss = 1.5694756650924682, ppl = 4.8690706468125615\n","Valid Epoch #7, Batch 991/4160 loss = 1.5718028819561005, ppl = 4.879934736243842\n","Valid Epoch #7, Batch 992/4160 loss = 1.5732755219936372, ppl = 4.886970744288815\n","Valid Epoch #7, Batch 993/4160 loss = 1.5725766956806182, ppl = 4.883852125859365\n","Valid Epoch #7, Batch 994/4160 loss = 1.5731561732292176, ppl = 4.886441755957806\n","Valid Epoch #7, Batch 995/4160 loss = 1.5741537082195283, ppl = 4.891049733654908\n","Valid Epoch #7, Batch 996/4160 loss = 1.572417871952057, ppl = 4.883173225032521\n","Valid Epoch #7, Batch 997/4160 loss = 1.5725371956825256, ppl = 4.88381202637949\n","Valid Epoch #7, Batch 998/4160 loss = 1.5754396116733551, ppl = 4.897915873549172\n","Valid Epoch #7, Batch 999/4160 loss = 1.5770630097389222, ppl = 4.905582441550553\n","Valid Epoch #7, Batch 1000/4160 loss = 1.5761921095848084, ppl = 4.901543938367493\n","Valid Epoch #7, Batch 1001/4160 loss = 1.5755445659160614, ppl = 4.89932420632059\n","Valid Epoch #7, Batch 1002/4160 loss = 1.5757398414611816, ppl = 4.899977346491259\n","Valid Epoch #7, Batch 1003/4160 loss = 1.575541043281555, ppl = 4.899196892203726\n","Valid Epoch #7, Batch 1004/4160 loss = 1.574306037425995, ppl = 4.894590890461306\n","Valid Epoch #7, Batch 1005/4160 loss = 1.5765313231945037, ppl = 4.9020529125237875\n","Valid Epoch #7, Batch 1006/4160 loss = 1.5760865962505342, ppl = 4.900432621073399\n","Valid Epoch #7, Batch 1007/4160 loss = 1.5778743648529052, ppl = 4.906551253583352\n","Valid Epoch #7, Batch 1008/4160 loss = 1.578336124420166, ppl = 4.908181825512752\n","Valid Epoch #7, Batch 1009/4160 loss = 1.5761624383926391, ppl = 4.900282859156865\n","Valid Epoch #7, Batch 1010/4160 loss = 1.5771952188014984, ppl = 4.904419325240678\n","Valid Epoch #7, Batch 1011/4160 loss = 1.5796688187122345, ppl = 4.9176423802328335\n","Valid Epoch #7, Batch 1012/4160 loss = 1.5770511603355408, ppl = 4.905364015910354\n","Valid Epoch #7, Batch 1013/4160 loss = 1.5779458427429198, ppl = 4.9095007732017715\n","Valid Epoch #7, Batch 1014/4160 loss = 1.5797495758533477, ppl = 4.916843467248055\n","Valid Epoch #7, Batch 1015/4160 loss = 1.5808342206478119, ppl = 4.921701133432262\n","Valid Epoch #7, Batch 1016/4160 loss = 1.582327595949173, ppl = 4.929106326889676\n","Valid Epoch #7, Batch 1017/4160 loss = 1.5818403005599975, ppl = 4.9270236205397975\n","Valid Epoch #7, Batch 1018/4160 loss = 1.5852011811733246, ppl = 4.943978146713825\n","Valid Epoch #7, Batch 1019/4160 loss = 1.5828887963294982, ppl = 4.9318957751850725\n","Valid Epoch #7, Batch 1020/4160 loss = 1.585835610628128, ppl = 4.945860482961752\n","Valid Epoch #7, Batch 1021/4160 loss = 1.5871271538734435, ppl = 4.952330894676698\n","Valid Epoch #7, Batch 1022/4160 loss = 1.586357045173645, ppl = 4.948849976780337\n","Valid Epoch #7, Batch 1023/4160 loss = 1.5861070263385773, ppl = 4.947554279259379\n","Valid Epoch #7, Batch 1024/4160 loss = 1.5838349378108978, ppl = 4.936135178050069\n","Valid Epoch #7, Batch 1025/4160 loss = 1.5864436495304108, ppl = 4.9488898274221125\n","Valid Epoch #7, Batch 1026/4160 loss = 1.5843823087215423, ppl = 4.937668406952251\n","Valid Epoch #7, Batch 1027/4160 loss = 1.5856218016147614, ppl = 4.943807625011239\n","Valid Epoch #7, Batch 1028/4160 loss = 1.5875988984107972, ppl = 4.955199112700715\n","Valid Epoch #7, Batch 1029/4160 loss = 1.58721923828125, ppl = 4.9531064597840855\n","Valid Epoch #7, Batch 1030/4160 loss = 1.5850864803791047, ppl = 4.9436036291183\n","Valid Epoch #7, Batch 1031/4160 loss = 1.5825153875350952, ppl = 4.928566865495499\n","Valid Epoch #7, Batch 1032/4160 loss = 1.5825930476188659, ppl = 4.92893034831953\n","Valid Epoch #7, Batch 1033/4160 loss = 1.5827805960178376, ppl = 4.92972628554454\n","Valid Epoch #7, Batch 1034/4160 loss = 1.5795640861988067, ppl = 4.910019658047001\n","Valid Epoch #7, Batch 1035/4160 loss = 1.5790245950222015, ppl = 4.907586891327339\n","Valid Epoch #7, Batch 1036/4160 loss = 1.5800914883613586, ppl = 4.9143978728329065\n","Valid Epoch #7, Batch 1037/4160 loss = 1.5782681798934937, ppl = 4.905793350593358\n","Valid Epoch #7, Batch 1038/4160 loss = 1.5773702478408813, ppl = 4.901107977064444\n","Valid Epoch #7, Batch 1039/4160 loss = 1.5752073061466216, ppl = 4.889102125053719\n","Valid Epoch #7, Batch 1040/4160 loss = 1.5722697520256042, ppl = 4.872657038463623\n","Valid Epoch #7, Batch 1041/4160 loss = 1.5733074235916138, ppl = 4.878846873487154\n","Valid Epoch #7, Batch 1042/4160 loss = 1.57127898812294, ppl = 4.867511900176048\n","Valid Epoch #7, Batch 1043/4160 loss = 1.571548742055893, ppl = 4.868757349628816\n","Valid Epoch #7, Batch 1044/4160 loss = 1.570154925584793, ppl = 4.861246418471547\n","Valid Epoch #7, Batch 1045/4160 loss = 1.5733877789974213, ppl = 4.878695401722276\n","Valid Epoch #7, Batch 1046/4160 loss = 1.574053828716278, ppl = 4.882268771173075\n","Valid Epoch #7, Batch 1047/4160 loss = 1.5751956844329833, ppl = 4.888998808896461\n","Valid Epoch #7, Batch 1048/4160 loss = 1.573985559940338, ppl = 4.883356718188276\n","Valid Epoch #7, Batch 1049/4160 loss = 1.5736456775665284, ppl = 4.8813101646588395\n","Valid Epoch #7, Batch 1050/4160 loss = 1.5726663327217103, ppl = 4.875894212125291\n","Valid Epoch #7, Batch 1051/4160 loss = 1.573588458299637, ppl = 4.88129914389973\n","Valid Epoch #7, Batch 1052/4160 loss = 1.5725553584098817, ppl = 4.875826104974681\n","Valid Epoch #7, Batch 1053/4160 loss = 1.5709835588932037, ppl = 4.8679903790965655\n","Valid Epoch #7, Batch 1054/4160 loss = 1.5734837603569032, ppl = 4.880030111265378\n","Valid Epoch #7, Batch 1055/4160 loss = 1.5712752270698547, ppl = 4.866505070609236\n","Valid Epoch #7, Batch 1056/4160 loss = 1.5707177495956421, ppl = 4.863385001723427\n","Valid Epoch #7, Batch 1057/4160 loss = 1.573554995059967, ppl = 4.876117831712986\n","Valid Epoch #7, Batch 1058/4160 loss = 1.575441951751709, ppl = 4.886837050973694\n","Valid Epoch #7, Batch 1059/4160 loss = 1.5736501395702363, ppl = 4.879291099901559\n","Valid Epoch #7, Batch 1060/4160 loss = 1.5756632447242738, ppl = 4.889590281321153\n","Valid Epoch #7, Batch 1061/4160 loss = 1.5755862748622895, ppl = 4.889243974350017\n","Valid Epoch #7, Batch 1062/4160 loss = 1.576249781847, ppl = 4.892287768280755\n","Valid Epoch #7, Batch 1063/4160 loss = 1.5754385316371917, ppl = 4.888308467126961\n","Valid Epoch #7, Batch 1064/4160 loss = 1.576673446893692, ppl = 4.89417634437056\n","Valid Epoch #7, Batch 1065/4160 loss = 1.5774602580070496, ppl = 4.898138846472594\n","Valid Epoch #7, Batch 1066/4160 loss = 1.5728514862060547, ppl = 4.879793786840086\n","Valid Epoch #7, Batch 1067/4160 loss = 1.5744905996322631, ppl = 4.889239572468716\n","Valid Epoch #7, Batch 1068/4160 loss = 1.5718651354312896, ppl = 4.876834496009194\n","Valid Epoch #7, Batch 1069/4160 loss = 1.5724207842350006, ppl = 4.879580920636963\n","Valid Epoch #7, Batch 1070/4160 loss = 1.572909940481186, ppl = 4.882191938127161\n","Valid Epoch #7, Batch 1071/4160 loss = 1.5733708810806275, ppl = 4.884434517226695\n","Valid Epoch #7, Batch 1072/4160 loss = 1.5754199481010438, ppl = 4.895077014975818\n","Valid Epoch #7, Batch 1073/4160 loss = 1.5705360305309295, ppl = 4.869942944609685\n","Valid Epoch #7, Batch 1074/4160 loss = 1.570407508611679, ppl = 4.869320953666711\n","Valid Epoch #7, Batch 1075/4160 loss = 1.572591222524643, ppl = 4.880102739828964\n","Valid Epoch #7, Batch 1076/4160 loss = 1.571525672674179, ppl = 4.875700822722136\n","Valid Epoch #7, Batch 1077/4160 loss = 1.572272310256958, ppl = 4.879098771991866\n","Valid Epoch #7, Batch 1078/4160 loss = 1.5714163899421691, ppl = 4.874508673789845\n","Valid Epoch #7, Batch 1079/4160 loss = 1.5702445793151856, ppl = 4.869068099218539\n","Valid Epoch #7, Batch 1080/4160 loss = 1.5692083132266998, ppl = 4.863565104421475\n","Valid Epoch #7, Batch 1081/4160 loss = 1.569901727437973, ppl = 4.867068145235484\n","Valid Epoch #7, Batch 1082/4160 loss = 1.5685785245895385, ppl = 4.861080168221386\n","Valid Epoch #7, Batch 1083/4160 loss = 1.5682714807987213, ppl = 4.859634325925623\n","Valid Epoch #7, Batch 1084/4160 loss = 1.5714919865131378, ppl = 4.876259297407693\n","Valid Epoch #7, Batch 1085/4160 loss = 1.5695131516456604, ppl = 4.86680540175063\n","Valid Epoch #7, Batch 1086/4160 loss = 1.569347003698349, ppl = 4.866062734626679\n","Valid Epoch #7, Batch 1087/4160 loss = 1.5703298127651215, ppl = 4.870554574831353\n","Valid Epoch #7, Batch 1088/4160 loss = 1.5702153360843658, ppl = 4.869985774425825\n","Valid Epoch #7, Batch 1089/4160 loss = 1.5704711544513703, ppl = 4.871317893715584\n","Valid Epoch #7, Batch 1090/4160 loss = 1.572512959241867, ppl = 4.880444056293333\n","Valid Epoch #7, Batch 1091/4160 loss = 1.5732941460609435, ppl = 4.8846955381540145\n","Valid Epoch #7, Batch 1092/4160 loss = 1.5716791105270387, ppl = 4.877032530553771\n","Valid Epoch #7, Batch 1093/4160 loss = 1.5720201563835143, ppl = 4.878527283247797\n","Valid Epoch #7, Batch 1094/4160 loss = 1.5732979953289032, ppl = 4.88479692940326\n","Valid Epoch #7, Batch 1095/4160 loss = 1.5745604944229126, ppl = 4.891328199738894\n","Valid Epoch #7, Batch 1096/4160 loss = 1.5761025404930116, ppl = 4.898256063641585\n","Valid Epoch #7, Batch 1097/4160 loss = 1.5776308381557465, ppl = 4.9071489878882595\n","Valid Epoch #7, Batch 1098/4160 loss = 1.576971491575241, ppl = 4.903576632279847\n","Valid Epoch #7, Batch 1099/4160 loss = 1.5775270795822143, ppl = 4.906499599714546\n","Valid Epoch #7, Batch 1100/4160 loss = 1.582306491136551, ppl = 4.933694482753387\n","Valid Epoch #7, Batch 1101/4160 loss = 1.5841820168495178, ppl = 4.940539590267171\n","Valid Epoch #7, Batch 1102/4160 loss = 1.585214821100235, ppl = 4.944214359510014\n","Valid Epoch #7, Batch 1103/4160 loss = 1.5873165929317474, ppl = 4.9533058502412\n","Valid Epoch #7, Batch 1104/4160 loss = 1.585989693403244, ppl = 4.94895168765323\n","Valid Epoch #7, Batch 1105/4160 loss = 1.586156768798828, ppl = 4.9495818349014575\n","Valid Epoch #7, Batch 1106/4160 loss = 1.586253399848938, ppl = 4.949927792992068\n","Valid Epoch #7, Batch 1107/4160 loss = 1.5858604764938355, ppl = 4.948487704028039\n","Valid Epoch #7, Batch 1108/4160 loss = 1.5870547950267793, ppl = 4.953071497176175\n","Valid Epoch #7, Batch 1109/4160 loss = 1.589832136631012, ppl = 4.963486304284496\n","Valid Epoch #7, Batch 1110/4160 loss = 1.5898075366020203, ppl = 4.96338272889695\n","Valid Epoch #7, Batch 1111/4160 loss = 1.5846247386932373, ppl = 4.938977640709785\n","Valid Epoch #7, Batch 1112/4160 loss = 1.5855468893051148, ppl = 4.9429415760611155\n","Valid Epoch #7, Batch 1113/4160 loss = 1.5834294509887696, ppl = 4.933717639918957\n","Valid Epoch #7, Batch 1114/4160 loss = 1.5848787105083466, ppl = 4.940656027991404\n","Valid Epoch #7, Batch 1115/4160 loss = 1.5843135201931, ppl = 4.938059101896671\n","Valid Epoch #7, Batch 1116/4160 loss = 1.5841177606582642, ppl = 4.937024266717838\n","Valid Epoch #7, Batch 1117/4160 loss = 1.5848878479003907, ppl = 4.940362992525576\n","Valid Epoch #7, Batch 1118/4160 loss = 1.5816284608840943, ppl = 4.923841432875296\n","Valid Epoch #7, Batch 1119/4160 loss = 1.584248753786087, ppl = 4.937753850615176\n","Valid Epoch #7, Batch 1120/4160 loss = 1.5823805212974549, ppl = 4.9284300649544805\n","Valid Epoch #7, Batch 1121/4160 loss = 1.5796477890014649, ppl = 4.915660569715755\n","Valid Epoch #7, Batch 1122/4160 loss = 1.580952832698822, ppl = 4.921722118509096\n","Valid Epoch #7, Batch 1123/4160 loss = 1.5815185177326203, ppl = 4.924700681484138\n","Valid Epoch #7, Batch 1124/4160 loss = 1.5831702256202698, ppl = 4.932740168150904\n","Valid Epoch #7, Batch 1125/4160 loss = 1.5806363105773926, ppl = 4.920306789913218\n","Valid Epoch #7, Batch 1126/4160 loss = 1.5812991344928742, ppl = 4.92366601156333\n","Valid Epoch #7, Batch 1127/4160 loss = 1.5800540554523468, ppl = 4.917500811844938\n","Valid Epoch #7, Batch 1128/4160 loss = 1.577567197084427, ppl = 4.903519572773018\n","Valid Epoch #7, Batch 1129/4160 loss = 1.577132693529129, ppl = 4.901220121103884\n","Valid Epoch #7, Batch 1130/4160 loss = 1.577553195953369, ppl = 4.9029368747598\n","Valid Epoch #7, Batch 1131/4160 loss = 1.580358749628067, ppl = 4.919547052812992\n","Valid Epoch #7, Batch 1132/4160 loss = 1.5801431047916412, ppl = 4.918544664198501\n","Valid Epoch #7, Batch 1133/4160 loss = 1.5829429483413697, ppl = 4.932386090927948\n","Valid Epoch #7, Batch 1134/4160 loss = 1.580793353319168, ppl = 4.922339334531591\n","Valid Epoch #7, Batch 1135/4160 loss = 1.5833669292926789, ppl = 4.935220877940206\n","Valid Epoch #7, Batch 1136/4160 loss = 1.5811208832263945, ppl = 4.92168118191212\n","Valid Epoch #7, Batch 1137/4160 loss = 1.5819806849956513, ppl = 4.9255437399364\n","Valid Epoch #7, Batch 1138/4160 loss = 1.5837159979343414, ppl = 4.934994373655691\n","Valid Epoch #7, Batch 1139/4160 loss = 1.5850005912780762, ppl = 4.941809800769403\n","Valid Epoch #7, Batch 1140/4160 loss = 1.5861749649047852, ppl = 4.94781128608875\n","Valid Epoch #7, Batch 1141/4160 loss = 1.5824944877624512, ppl = 4.928474285396031\n","Valid Epoch #7, Batch 1142/4160 loss = 1.5835813248157502, ppl = 4.934261193979318\n","Valid Epoch #7, Batch 1143/4160 loss = 1.5851011097431182, ppl = 4.941941959568547\n","Valid Epoch #7, Batch 1144/4160 loss = 1.5853932726383209, ppl = 4.9434308238134195\n","Valid Epoch #7, Batch 1145/4160 loss = 1.5852211928367614, ppl = 4.942353134358094\n","Valid Epoch #7, Batch 1146/4160 loss = 1.585478937625885, ppl = 4.943801081992577\n","Valid Epoch #7, Batch 1147/4160 loss = 1.5837653505802154, ppl = 4.9339792440297705\n","Valid Epoch #7, Batch 1148/4160 loss = 1.584656902551651, ppl = 4.938069192435185\n","Valid Epoch #7, Batch 1149/4160 loss = 1.5836881875991822, ppl = 4.932603772548874\n","Valid Epoch #7, Batch 1150/4160 loss = 1.5814727020263672, ppl = 4.922143390027301\n","Valid Epoch #7, Batch 1151/4160 loss = 1.5793893456459045, ppl = 4.9106040975210705\n","Valid Epoch #7, Batch 1152/4160 loss = 1.5791607332229614, ppl = 4.909467505365061\n","Valid Epoch #7, Batch 1153/4160 loss = 1.579490841627121, ppl = 4.9110125763393935\n","Valid Epoch #7, Batch 1154/4160 loss = 1.5802443027496338, ppl = 4.915271768261491\n","Valid Epoch #7, Batch 1155/4160 loss = 1.5789102959632872, ppl = 4.908437262887402\n","Valid Epoch #7, Batch 1156/4160 loss = 1.5772979772090912, ppl = 4.900333526442215\n","Valid Epoch #7, Batch 1157/4160 loss = 1.5781978785991668, ppl = 4.905187136530481\n","Valid Epoch #7, Batch 1158/4160 loss = 1.576300812959671, ppl = 4.894415765528512\n","Valid Epoch #7, Batch 1159/4160 loss = 1.5776046180725098, ppl = 4.89977082114444\n","Valid Epoch #7, Batch 1160/4160 loss = 1.5765375924110412, ppl = 4.8940543517834865\n","Valid Epoch #7, Batch 1161/4160 loss = 1.5756684160232544, ppl = 4.8903232356512225\n","Valid Epoch #7, Batch 1162/4160 loss = 1.5776077210903168, ppl = 4.9004701947355525\n","Valid Epoch #7, Batch 1163/4160 loss = 1.576848884820938, ppl = 4.897029143166952\n","Valid Epoch #7, Batch 1164/4160 loss = 1.5747616064548493, ppl = 4.887513731745065\n","Valid Epoch #7, Batch 1165/4160 loss = 1.575017863512039, ppl = 4.888873060975964\n","Valid Epoch #7, Batch 1166/4160 loss = 1.57973153591156, ppl = 4.90774200216556\n","Valid Epoch #7, Batch 1167/4160 loss = 1.579789057970047, ppl = 4.908102431394237\n","Valid Epoch #7, Batch 1168/4160 loss = 1.5797843873500823, ppl = 4.908083138001612\n","Valid Epoch #7, Batch 1169/4160 loss = 1.5799879109859467, ppl = 4.909127903930648\n","Valid Epoch #7, Batch 1170/4160 loss = 1.5812428939342498, ppl = 4.916441233951806\n","Valid Epoch #7, Batch 1171/4160 loss = 1.5797749161720276, ppl = 4.909644407405333\n","Valid Epoch #7, Batch 1172/4160 loss = 1.575924701690674, ppl = 4.891288299157737\n","Valid Epoch #7, Batch 1173/4160 loss = 1.5789124941825867, ppl = 4.905187106760576\n","Valid Epoch #7, Batch 1174/4160 loss = 1.579655350446701, ppl = 4.908895182647227\n","Valid Epoch #7, Batch 1175/4160 loss = 1.5789807033538819, ppl = 4.905309594618479\n","Valid Epoch #7, Batch 1176/4160 loss = 1.5788156497478485, ppl = 4.904668723968772\n","Valid Epoch #7, Batch 1177/4160 loss = 1.5798098647594452, ppl = 4.909605773395885\n","Valid Epoch #7, Batch 1178/4160 loss = 1.580116432905197, ppl = 4.911204856688566\n","Valid Epoch #7, Batch 1179/4160 loss = 1.5791353833675386, ppl = 4.9071154979832885\n","Valid Epoch #7, Batch 1180/4160 loss = 1.579453662633896, ppl = 4.908745429313568\n","Valid Epoch #7, Batch 1181/4160 loss = 1.5789816665649414, ppl = 4.906334679271682\n","Valid Epoch #7, Batch 1182/4160 loss = 1.5804005146026612, ppl = 4.9127869700882725\n","Valid Epoch #7, Batch 1183/4160 loss = 1.5824251973628998, ppl = 4.923193360967409\n","Valid Epoch #7, Batch 1184/4160 loss = 1.5783408784866333, ppl = 4.902947405399129\n","Valid Epoch #7, Batch 1185/4160 loss = 1.5790973019599914, ppl = 4.90634222812958\n","Valid Epoch #7, Batch 1186/4160 loss = 1.5799129319190979, ppl = 4.910109362321124\n","Valid Epoch #7, Batch 1187/4160 loss = 1.582244634628296, ppl = 4.922710525603353\n","Valid Epoch #7, Batch 1188/4160 loss = 1.5795397508144378, ppl = 4.911002312541572\n","Valid Epoch #7, Batch 1189/4160 loss = 1.5777563881874084, ppl = 4.902387529023907\n","Valid Epoch #7, Batch 1190/4160 loss = 1.5794012784957885, ppl = 4.9112224333242125\n","Valid Epoch #7, Batch 1191/4160 loss = 1.5774998009204864, ppl = 4.901425425061827\n","Valid Epoch #7, Batch 1192/4160 loss = 1.5777725207805633, ppl = 4.9026341500252535\n","Valid Epoch #7, Batch 1193/4160 loss = 1.5779418432712555, ppl = 4.903395418533059\n","Valid Epoch #7, Batch 1194/4160 loss = 1.5786601555347444, ppl = 4.90728787703261\n","Valid Epoch #7, Batch 1195/4160 loss = 1.5774089550971986, ppl = 4.900811476771688\n","Valid Epoch #7, Batch 1196/4160 loss = 1.5772690522670745, ppl = 4.9001379591192835\n","Valid Epoch #7, Batch 1197/4160 loss = 1.5756263661384582, ppl = 4.8906325037000205\n","Valid Epoch #7, Batch 1198/4160 loss = 1.5759732902050019, ppl = 4.892482770256004\n","Valid Epoch #7, Batch 1199/4160 loss = 1.5752235853672027, ppl = 4.888576232000977\n","Valid Epoch #7, Batch 1200/4160 loss = 1.5709365463256837, ppl = 4.86362127081469\n","Valid Epoch #7, Batch 1201/4160 loss = 1.5727212500572205, ppl = 4.871441943931769\n","Valid Epoch #7, Batch 1202/4160 loss = 1.5739347624778748, ppl = 4.876273731901616\n","Valid Epoch #7, Batch 1203/4160 loss = 1.5740859842300414, ppl = 4.87700452090192\n","Valid Epoch #7, Batch 1204/4160 loss = 1.5755126190185547, ppl = 4.881709902125483\n","Valid Epoch #7, Batch 1205/4160 loss = 1.5776294481754303, ppl = 4.890676242391516\n","Valid Epoch #7, Batch 1206/4160 loss = 1.5772661757469177, ppl = 4.889392814787468\n","Valid Epoch #7, Batch 1207/4160 loss = 1.5777100014686585, ppl = 4.891023638375682\n","Valid Epoch #7, Batch 1208/4160 loss = 1.577695517539978, ppl = 4.89096470613503\n","Valid Epoch #7, Batch 1209/4160 loss = 1.5776417577266693, ppl = 4.890734441574514\n","Valid Epoch #7, Batch 1210/4160 loss = 1.576780925989151, ppl = 4.887265904921361\n","Valid Epoch #7, Batch 1211/4160 loss = 1.5807141697406768, ppl = 4.904583166227703\n","Valid Epoch #7, Batch 1212/4160 loss = 1.5789442467689514, ppl = 4.897283839899588\n","Valid Epoch #7, Batch 1213/4160 loss = 1.5797178173065185, ppl = 4.900429566551188\n","Valid Epoch #7, Batch 1214/4160 loss = 1.5790637588500978, ppl = 4.897173494806482\n","Valid Epoch #7, Batch 1215/4160 loss = 1.578712797164917, ppl = 4.8956332310953785\n","Valid Epoch #7, Batch 1216/4160 loss = 1.576806480884552, ppl = 4.886547755036318\n","Valid Epoch #7, Batch 1217/4160 loss = 1.5769946086406708, ppl = 4.8874032159513385\n","Valid Epoch #7, Batch 1218/4160 loss = 1.5775945556163788, ppl = 4.890054299396517\n","Valid Epoch #7, Batch 1219/4160 loss = 1.575391697883606, ppl = 4.878121571551902\n","Valid Epoch #7, Batch 1220/4160 loss = 1.5770421147346496, ppl = 4.886266487140098\n","Valid Epoch #7, Batch 1221/4160 loss = 1.5807199132442475, ppl = 4.904329109923846\n","Valid Epoch #7, Batch 1222/4160 loss = 1.5831896018981935, ppl = 4.918208265254836\n","Valid Epoch #7, Batch 1223/4160 loss = 1.581914370059967, ppl = 4.911724161414545\n","Valid Epoch #7, Batch 1224/4160 loss = 1.5803858208656312, ppl = 4.904239399198418\n","Valid Epoch #7, Batch 1225/4160 loss = 1.579929962158203, ppl = 4.902318159314401\n","Valid Epoch #7, Batch 1226/4160 loss = 1.578444150686264, ppl = 4.895086246791469\n","Valid Epoch #7, Batch 1227/4160 loss = 1.5802283442020417, ppl = 4.904168514805525\n","Valid Epoch #7, Batch 1228/4160 loss = 1.5822370970249175, ppl = 4.91518519058334\n","Valid Epoch #7, Batch 1229/4160 loss = 1.582309217453003, ppl = 4.915559979704366\n","Valid Epoch #7, Batch 1230/4160 loss = 1.5856795620918274, ppl = 4.932269060870286\n","Valid Epoch #7, Batch 1231/4160 loss = 1.5812876081466676, ppl = 4.908135202605893\n","Valid Epoch #7, Batch 1232/4160 loss = 1.5816846358776093, ppl = 4.909997618596623\n","Valid Epoch #7, Batch 1233/4160 loss = 1.5803337287902832, ppl = 4.902835386283966\n","Valid Epoch #7, Batch 1234/4160 loss = 1.582344182729721, ppl = 4.912164433128096\n","Valid Epoch #7, Batch 1235/4160 loss = 1.580722223520279, ppl = 4.903664548843181\n","Valid Epoch #7, Batch 1236/4160 loss = 1.5802223980426788, ppl = 4.901043256140117\n","Valid Epoch #7, Batch 1237/4160 loss = 1.5816845560073853, ppl = 4.908424757843596\n","Valid Epoch #7, Batch 1238/4160 loss = 1.5807655251026154, ppl = 4.903215850511959\n","Valid Epoch #7, Batch 1239/4160 loss = 1.5811439514160157, ppl = 4.905396310366288\n","Valid Epoch #7, Batch 1240/4160 loss = 1.5827253830432892, ppl = 4.914676297096725\n","Valid Epoch #7, Batch 1241/4160 loss = 1.5871172559261322, ppl = 4.938643582306741\n","Valid Epoch #7, Batch 1242/4160 loss = 1.5896013510227203, ppl = 4.954488666072755\n","Valid Epoch #7, Batch 1243/4160 loss = 1.5916268229484558, ppl = 4.96671952968568\n","Valid Epoch #7, Batch 1244/4160 loss = 1.5922951292991638, ppl = 4.97029330566577\n","Valid Epoch #7, Batch 1245/4160 loss = 1.5915827965736389, ppl = 4.9660242844029066\n","Valid Epoch #7, Batch 1246/4160 loss = 1.5900937736034393, ppl = 4.958151712937857\n","Valid Epoch #7, Batch 1247/4160 loss = 1.5918926119804382, ppl = 4.968507523698023\n","Valid Epoch #7, Batch 1248/4160 loss = 1.593260953426361, ppl = 4.97553878995598\n","Valid Epoch #7, Batch 1249/4160 loss = 1.5932490527629852, ppl = 4.975474884913057\n","Valid Epoch #7, Batch 1250/4160 loss = 1.5947243964672089, ppl = 4.982179993857238\n","Valid Epoch #7, Batch 1251/4160 loss = 1.594739307165146, ppl = 4.982254332181596\n","Valid Epoch #7, Batch 1252/4160 loss = 1.5962756550312043, ppl = 4.990416566998946\n","Valid Epoch #7, Batch 1253/4160 loss = 1.5987874519824983, ppl = 5.004003108761426\n","Valid Epoch #7, Batch 1254/4160 loss = 1.5967986643314362, ppl = 4.993419280782152\n","Valid Epoch #7, Batch 1255/4160 loss = 1.5981361854076386, ppl = 5.0002730218810685\n","Valid Epoch #7, Batch 1256/4160 loss = 1.6015278220176696, ppl = 5.018975122469195\n","Valid Epoch #7, Batch 1257/4160 loss = 1.6018388485908508, ppl = 5.020756817614807\n","Valid Epoch #7, Batch 1258/4160 loss = 1.6017383444309234, ppl = 5.020241177406142\n","Valid Epoch #7, Batch 1259/4160 loss = 1.6035903811454773, ppl = 5.029154550312598\n","Valid Epoch #7, Batch 1260/4160 loss = 1.6021979188919067, ppl = 5.02255561080531\n","Valid Epoch #7, Batch 1261/4160 loss = 1.6056493782997132, ppl = 5.039492123757645\n","Valid Epoch #7, Batch 1262/4160 loss = 1.6020609605312348, ppl = 5.0221369074094\n","Valid Epoch #7, Batch 1263/4160 loss = 1.6036256909370423, ppl = 5.029529915052155\n","Valid Epoch #7, Batch 1264/4160 loss = 1.6046775376796723, ppl = 5.034076943282628\n","Valid Epoch #7, Batch 1265/4160 loss = 1.602013487815857, ppl = 5.021511487474977\n","Valid Epoch #7, Batch 1266/4160 loss = 1.6007202231884003, ppl = 5.015421194748073\n","Valid Epoch #7, Batch 1267/4160 loss = 1.5971387779712678, ppl = 4.996504690619941\n","Valid Epoch #7, Batch 1268/4160 loss = 1.5981768798828124, ppl = 5.0010223108957605\n","Valid Epoch #7, Batch 1269/4160 loss = 1.5969692754745484, ppl = 4.995123263796036\n","Valid Epoch #7, Batch 1270/4160 loss = 1.5945030200481414, ppl = 4.981570493414464\n","Valid Epoch #7, Batch 1271/4160 loss = 1.5967439830303192, ppl = 4.992368038763324\n","Valid Epoch #7, Batch 1272/4160 loss = 1.5974875974655152, ppl = 4.995385247659482\n","Valid Epoch #7, Batch 1273/4160 loss = 1.6001307415962218, ppl = 5.011665887811797\n","Valid Epoch #7, Batch 1274/4160 loss = 1.5982268750667572, ppl = 5.0026869458097964\n","Valid Epoch #7, Batch 1275/4160 loss = 1.5984050035476685, ppl = 5.003610279577021\n","Valid Epoch #7, Batch 1276/4160 loss = 1.6015634775161742, ppl = 5.017913134917131\n","Valid Epoch #7, Batch 1277/4160 loss = 1.6011857295036316, ppl = 5.015979285183266\n","Valid Epoch #7, Batch 1278/4160 loss = 1.6021708607673646, ppl = 5.021462631181658\n","Valid Epoch #7, Batch 1279/4160 loss = 1.604624991416931, ppl = 5.032497436057691\n","Valid Epoch #7, Batch 1280/4160 loss = 1.6026231968402862, ppl = 5.02305834994946\n","Valid Epoch #7, Batch 1281/4160 loss = 1.6041170072555542, ppl = 5.031094741923434\n","Valid Epoch #7, Batch 1282/4160 loss = 1.6032143592834474, ppl = 5.0268846768968505\n","Valid Epoch #7, Batch 1283/4160 loss = 1.601535098552704, ppl = 5.018107989304328\n","Valid Epoch #7, Batch 1284/4160 loss = 1.6032445013523102, ppl = 5.025589797576483\n","Valid Epoch #7, Batch 1285/4160 loss = 1.6043116581439971, ppl = 5.030837647450051\n","Valid Epoch #7, Batch 1286/4160 loss = 1.6041776633262634, ppl = 5.03019748482225\n","Valid Epoch #7, Batch 1287/4160 loss = 1.6025919544696807, ppl = 5.021313015445386\n","Valid Epoch #7, Batch 1288/4160 loss = 1.6050344955921174, ppl = 5.031742025733596\n","Valid Epoch #7, Batch 1289/4160 loss = 1.6063373041152955, ppl = 5.037882217526695\n","Valid Epoch #7, Batch 1290/4160 loss = 1.6034657812118531, ppl = 5.023342941448538\n","Valid Epoch #7, Batch 1291/4160 loss = 1.60342968583107, ppl = 5.023174392442047\n","Valid Epoch #7, Batch 1292/4160 loss = 1.606591204404831, ppl = 5.0398804407413715\n","Valid Epoch #7, Batch 1293/4160 loss = 1.6087898588180543, ppl = 5.051030299579534\n","Valid Epoch #7, Batch 1294/4160 loss = 1.60505664229393, ppl = 5.033533776442567\n","Valid Epoch #7, Batch 1295/4160 loss = 1.6049889051914215, ppl = 5.033205748662503\n","Valid Epoch #7, Batch 1296/4160 loss = 1.6051122164726257, ppl = 5.033798898234917\n","Valid Epoch #7, Batch 1297/4160 loss = 1.6047379875183105, ppl = 5.031843225739253\n","Valid Epoch #7, Batch 1298/4160 loss = 1.6047592270374298, ppl = 5.031958602256059\n","Valid Epoch #7, Batch 1299/4160 loss = 1.6041331005096435, ppl = 5.028913111330063\n","Valid Epoch #7, Batch 1300/4160 loss = 1.6049085319042207, ppl = 5.032672155187958\n","Valid Epoch #7, Batch 1301/4160 loss = 1.6026720440387725, ppl = 5.02308338961116\n","Valid Epoch #7, Batch 1302/4160 loss = 1.6022912955284119, ppl = 5.0215037977726205\n","Valid Epoch #7, Batch 1303/4160 loss = 1.5990073704719543, ppl = 5.007873957822122\n","Valid Epoch #7, Batch 1304/4160 loss = 1.5993423187732696, ppl = 5.009079449292388\n","Valid Epoch #7, Batch 1305/4160 loss = 1.5966310834884643, ppl = 4.997918322238587\n","Valid Epoch #7, Batch 1306/4160 loss = 1.597511465549469, ppl = 5.001111002162499\n","Valid Epoch #7, Batch 1307/4160 loss = 1.598729032278061, ppl = 5.00597503559435\n","Valid Epoch #7, Batch 1308/4160 loss = 1.597326489686966, ppl = 5.000654343081627\n","Valid Epoch #7, Batch 1309/4160 loss = 1.596333384513855, ppl = 4.996615935566209\n","Valid Epoch #7, Batch 1310/4160 loss = 1.5987879121303559, ppl = 5.007349851290883\n","Valid Epoch #7, Batch 1311/4160 loss = 1.5957409060001373, ppl = 4.993362710011858\n","Valid Epoch #7, Batch 1312/4160 loss = 1.5983561158180237, ppl = 5.00463105966948\n","Valid Epoch #7, Batch 1313/4160 loss = 1.5969276738166809, ppl = 4.999006037905932\n","Valid Epoch #7, Batch 1314/4160 loss = 1.5952066087722778, ppl = 4.991389493202753\n","Valid Epoch #7, Batch 1315/4160 loss = 1.5953156626224518, ppl = 4.991862321305505\n","Valid Epoch #7, Batch 1316/4160 loss = 1.5968767261505128, ppl = 4.999171350950956\n","Valid Epoch #7, Batch 1317/4160 loss = 1.5988622438907623, ppl = 5.0092529151794345\n","Valid Epoch #7, Batch 1318/4160 loss = 1.59755615234375, ppl = 5.0036785691097165\n","Valid Epoch #7, Batch 1319/4160 loss = 1.5972112345695495, ppl = 5.002036889527426\n","Valid Epoch #7, Batch 1320/4160 loss = 1.5979412019252777, ppl = 5.006090942249516\n","Valid Epoch #7, Batch 1321/4160 loss = 1.596686955690384, ppl = 4.9991719604098295\n","Valid Epoch #7, Batch 1322/4160 loss = 1.5957840621471404, ppl = 4.993696454487303\n","Valid Epoch #7, Batch 1323/4160 loss = 1.5980043768882752, ppl = 5.0055485474072245\n","Valid Epoch #7, Batch 1324/4160 loss = 1.5981038618087768, ppl = 5.006001656924494\n","Valid Epoch #7, Batch 1325/4160 loss = 1.6022524452209472, ppl = 5.027180878495987\n","Valid Epoch #7, Batch 1326/4160 loss = 1.606079363822937, ppl = 5.04822945331723\n","Valid Epoch #7, Batch 1327/4160 loss = 1.6056038379669189, ppl = 5.045648329281865\n","Valid Epoch #7, Batch 1328/4160 loss = 1.6028055381774902, ppl = 5.030872235639601\n","Valid Epoch #7, Batch 1329/4160 loss = 1.6037064266204835, ppl = 5.035788941502634\n","Valid Epoch #7, Batch 1330/4160 loss = 1.6018226587772368, ppl = 5.0257618585018236\n","Valid Epoch #7, Batch 1331/4160 loss = 1.602338708639145, ppl = 5.028079571911512\n","Valid Epoch #7, Batch 1332/4160 loss = 1.6060732626914977, ppl = 5.049741797897869\n","Valid Epoch #7, Batch 1333/4160 loss = 1.6055245614051818, ppl = 5.047097966693336\n","Valid Epoch #7, Batch 1334/4160 loss = 1.6046951663494111, ppl = 5.043020933349032\n","Valid Epoch #7, Batch 1335/4160 loss = 1.6057403790950775, ppl = 5.048339267456475\n","Valid Epoch #7, Batch 1336/4160 loss = 1.6062825262546538, ppl = 5.0511885879305\n","Valid Epoch #7, Batch 1337/4160 loss = 1.6090974354743957, ppl = 5.068830118335972\n","Valid Epoch #7, Batch 1338/4160 loss = 1.6083530569076538, ppl = 5.0649482810029856\n","Valid Epoch #7, Batch 1339/4160 loss = 1.6065622997283935, ppl = 5.055321317683088\n","Valid Epoch #7, Batch 1340/4160 loss = 1.6053197371959687, ppl = 5.047908206259056\n","Valid Epoch #7, Batch 1341/4160 loss = 1.6049608445167542, ppl = 5.045531107330677\n","Valid Epoch #7, Batch 1342/4160 loss = 1.602654846906662, ppl = 5.0306957406223045\n","Valid Epoch #7, Batch 1343/4160 loss = 1.6019328546524048, ppl = 5.026049300622311\n","Valid Epoch #7, Batch 1344/4160 loss = 1.6011969757080078, ppl = 5.02212729725321\n","Valid Epoch #7, Batch 1345/4160 loss = 1.5991009032726289, ppl = 5.0111935031543595\n","Valid Epoch #7, Batch 1346/4160 loss = 1.5988848459720613, ppl = 5.010145491481644\n","Valid Epoch #7, Batch 1347/4160 loss = 1.5985401046276093, ppl = 5.008013935364861\n","Valid Epoch #7, Batch 1348/4160 loss = 1.5986499345302583, ppl = 5.008621120548061\n","Valid Epoch #7, Batch 1349/4160 loss = 1.5996772015094758, ppl = 5.014427248523744\n","Valid Epoch #7, Batch 1350/4160 loss = 1.6003856372833252, ppl = 5.018015891827854\n","Valid Epoch #7, Batch 1351/4160 loss = 1.6005782878398895, ppl = 5.018986399279832\n","Valid Epoch #7, Batch 1352/4160 loss = 1.6002349996566771, ppl = 5.017052296158136\n","Valid Epoch #7, Batch 1353/4160 loss = 1.5976915645599366, ppl = 5.003315452474176\n","Valid Epoch #7, Batch 1354/4160 loss = 1.5989151513576507, ppl = 5.009576231948209\n","Valid Epoch #7, Batch 1355/4160 loss = 1.5973944282531738, ppl = 5.001853094817442\n","Valid Epoch #7, Batch 1356/4160 loss = 1.5957693874835968, ppl = 4.992100848749123\n","Valid Epoch #7, Batch 1357/4160 loss = 1.5915764665603638, ppl = 4.9721749706748195\n","Valid Epoch #7, Batch 1358/4160 loss = 1.5915770530700684, ppl = 4.972177964775694\n","Valid Epoch #7, Batch 1359/4160 loss = 1.5904712164402008, ppl = 4.966658617255494\n","Valid Epoch #7, Batch 1360/4160 loss = 1.5917977261543275, ppl = 4.972923840778016\n","Valid Epoch #7, Batch 1361/4160 loss = 1.5900534319877624, ppl = 4.963636134046551\n","Valid Epoch #7, Batch 1362/4160 loss = 1.591498372554779, ppl = 4.969886164257027\n","Valid Epoch #7, Batch 1363/4160 loss = 1.5925212919712066, ppl = 4.975383591975454\n","Valid Epoch #7, Batch 1364/4160 loss = 1.59064297914505, ppl = 4.96758466824191\n","Valid Epoch #7, Batch 1365/4160 loss = 1.5929760682582854, ppl = 4.97840103837742\n","Valid Epoch #7, Batch 1366/4160 loss = 1.5934843909740448, ppl = 4.980701365671723\n","Valid Epoch #7, Batch 1367/4160 loss = 1.5954184794425965, ppl = 4.990073642213727\n","Valid Epoch #7, Batch 1368/4160 loss = 1.5965486574172973, ppl = 4.995555607640129\n","Valid Epoch #7, Batch 1369/4160 loss = 1.5955225205421448, ppl = 4.991073481677043\n","Valid Epoch #7, Batch 1370/4160 loss = 1.595467940568924, ppl = 4.990809736488187\n","Valid Epoch #7, Batch 1371/4160 loss = 1.5936487627029419, ppl = 4.981864026980581\n","Valid Epoch #7, Batch 1372/4160 loss = 1.5953853666782378, ppl = 4.989848773775193\n","Valid Epoch #7, Batch 1373/4160 loss = 1.5902430403232575, ppl = 4.9616680354962135\n","Valid Epoch #7, Batch 1374/4160 loss = 1.5919607841968537, ppl = 4.969691899596523\n","Valid Epoch #7, Batch 1375/4160 loss = 1.590470447540283, ppl = 4.962450681880324\n","Valid Epoch #7, Batch 1376/4160 loss = 1.5893062841892243, ppl = 4.95664695751246\n","Valid Epoch #7, Batch 1377/4160 loss = 1.5896462070941926, ppl = 4.958383857022434\n","Valid Epoch #7, Batch 1378/4160 loss = 1.5877406263351441, ppl = 4.948243041179264\n","Valid Epoch #7, Batch 1379/4160 loss = 1.5876692235469818, ppl = 4.947882268167268\n","Valid Epoch #7, Batch 1380/4160 loss = 1.5904611730575562, ppl = 4.961599319015206\n","Valid Epoch #7, Batch 1381/4160 loss = 1.5905881905555725, ppl = 4.962339647073639\n","Valid Epoch #7, Batch 1382/4160 loss = 1.5934943795204162, ppl = 4.977370389154123\n","Valid Epoch #7, Batch 1383/4160 loss = 1.5938898181915284, ppl = 4.979306507672266\n","Valid Epoch #7, Batch 1384/4160 loss = 1.5920753037929536, ppl = 4.971405052044244\n","Valid Epoch #7, Batch 1385/4160 loss = 1.594502021074295, ppl = 4.985644722104879\n","Valid Epoch #7, Batch 1386/4160 loss = 1.5952513647079467, ppl = 4.989337420367843\n","Valid Epoch #7, Batch 1387/4160 loss = 1.5959854876995088, ppl = 4.9932758901915175\n","Valid Epoch #7, Batch 1388/4160 loss = 1.5963199520111084, ppl = 4.994912684463048\n","Valid Epoch #7, Batch 1389/4160 loss = 1.5963662159442902, ppl = 4.995145778909363\n","Valid Epoch #7, Batch 1390/4160 loss = 1.5969598126411437, ppl = 4.997818970703554\n","Valid Epoch #7, Batch 1391/4160 loss = 1.5969565725326538, ppl = 4.997803870606864\n","Valid Epoch #7, Batch 1392/4160 loss = 1.5946258687973023, ppl = 4.984989970447643\n","Valid Epoch #7, Batch 1393/4160 loss = 1.5937152624130249, ppl = 4.980073104922226\n","Valid Epoch #7, Batch 1394/4160 loss = 1.5952001416683197, ppl = 4.986262063249248\n","Valid Epoch #7, Batch 1395/4160 loss = 1.5960491240024566, ppl = 4.990538448048654\n","Valid Epoch #7, Batch 1396/4160 loss = 1.5965736389160157, ppl = 4.993144803541582\n","Valid Epoch #7, Batch 1397/4160 loss = 1.5966959345340728, ppl = 4.993775871804343\n","Valid Epoch #7, Batch 1398/4160 loss = 1.5962454986572265, ppl = 4.99138077831541\n","Valid Epoch #7, Batch 1399/4160 loss = 1.595536779165268, ppl = 4.988155971384869\n","Valid Epoch #7, Batch 1400/4160 loss = 1.5950767815113067, ppl = 4.985890968951255\n","Valid Epoch #7, Batch 1401/4160 loss = 1.5955826461315155, ppl = 4.987876112960713\n","Valid Epoch #7, Batch 1402/4160 loss = 1.592931342124939, ppl = 4.978396926849338\n","Valid Epoch #7, Batch 1403/4160 loss = 1.5928376281261445, ppl = 4.978069880452526\n","Valid Epoch #7, Batch 1404/4160 loss = 1.5937198579311371, ppl = 4.981445234298429\n","Valid Epoch #7, Batch 1405/4160 loss = 1.5933651089668275, ppl = 4.9801961884115045\n","Valid Epoch #7, Batch 1406/4160 loss = 1.594063342809677, ppl = 4.98293594685123\n","Valid Epoch #7, Batch 1407/4160 loss = 1.5934075510501862, ppl = 4.980242687886859\n","Valid Epoch #7, Batch 1408/4160 loss = 1.5944400084018708, ppl = 4.984086170285294\n","Valid Epoch #7, Batch 1409/4160 loss = 1.5934532237052919, ppl = 4.980451690341534\n","Valid Epoch #7, Batch 1410/4160 loss = 1.5905093157291412, ppl = 4.9678750335204205\n","Valid Epoch #7, Batch 1411/4160 loss = 1.5915150237083435, ppl = 4.972029407343055\n","Valid Epoch #7, Batch 1412/4160 loss = 1.588651683330536, ppl = 4.959837143542614\n","Valid Epoch #7, Batch 1413/4160 loss = 1.5888974952697754, ppl = 4.960748788740528\n","Valid Epoch #7, Batch 1414/4160 loss = 1.5873324275016785, ppl = 4.954873304439432\n","Valid Epoch #7, Batch 1415/4160 loss = 1.585858278274536, ppl = 4.948898109578979\n","Valid Epoch #7, Batch 1416/4160 loss = 1.5861176002025603, ppl = 4.95022666244029\n","Valid Epoch #7, Batch 1417/4160 loss = 1.582205822467804, ppl = 4.9321027298519695\n","Valid Epoch #7, Batch 1418/4160 loss = 1.5830288171768188, ppl = 4.935529941703514\n","Valid Epoch #7, Batch 1419/4160 loss = 1.5849774265289307, ppl = 4.945594313773641\n","Valid Epoch #7, Batch 1420/4160 loss = 1.5819346618652343, ppl = 4.930486200955575\n","Valid Epoch #7, Batch 1421/4160 loss = 1.5812893033027648, ppl = 4.927250250975722\n","Valid Epoch #7, Batch 1422/4160 loss = 1.581329791545868, ppl = 4.9274853455102585\n","Valid Epoch #7, Batch 1423/4160 loss = 1.5811816906929017, ppl = 4.926610265271483\n","Valid Epoch #7, Batch 1424/4160 loss = 1.582972184419632, ppl = 4.9355853234190725\n","Valid Epoch #7, Batch 1425/4160 loss = 1.5804147374629975, ppl = 4.921510567805406\n","Valid Epoch #7, Batch 1426/4160 loss = 1.5771510684490204, ppl = 4.903077856967491\n","Valid Epoch #7, Batch 1427/4160 loss = 1.5774822151660919, ppl = 4.904862284702991\n","Valid Epoch #7, Batch 1428/4160 loss = 1.578277997970581, ppl = 4.908652591639584\n","Valid Epoch #7, Batch 1429/4160 loss = 1.5793676900863647, ppl = 4.9152231144249585\n","Valid Epoch #7, Batch 1430/4160 loss = 1.5779266953468323, ppl = 4.908731584541216\n","Valid Epoch #7, Batch 1431/4160 loss = 1.5808078813552857, ppl = 4.92411888150873\n","Valid Epoch #7, Batch 1432/4160 loss = 1.5761147046089172, ppl = 4.898082981302467\n","Valid Epoch #7, Batch 1433/4160 loss = 1.5780548882484435, ppl = 4.908119491292669\n","Valid Epoch #7, Batch 1434/4160 loss = 1.5823301100730895, ppl = 4.933269873263681\n","Valid Epoch #7, Batch 1435/4160 loss = 1.583247857093811, ppl = 4.938420662308752\n","Valid Epoch #7, Batch 1436/4160 loss = 1.5827699780464173, ppl = 4.935901095935379\n","Valid Epoch #7, Batch 1437/4160 loss = 1.580906744003296, ppl = 4.92367747783109\n","Valid Epoch #7, Batch 1438/4160 loss = 1.5816715002059936, ppl = 4.92766969850998\n","Valid Epoch #7, Batch 1439/4160 loss = 1.5830138254165649, ppl = 4.934721801627157\n","Valid Epoch #7, Batch 1440/4160 loss = 1.583948678970337, ppl = 4.940212439781395\n","Valid Epoch #7, Batch 1441/4160 loss = 1.581878343820572, ppl = 4.928047069133351\n","Valid Epoch #7, Batch 1442/4160 loss = 1.5808077478408813, ppl = 4.922239574724202\n","Valid Epoch #7, Batch 1443/4160 loss = 1.5804573321342468, ppl = 4.9201025368823785\n","Valid Epoch #7, Batch 1444/4160 loss = 1.5821286582946776, ppl = 4.929445467871022\n","Valid Epoch #7, Batch 1445/4160 loss = 1.5840758895874023, ppl = 4.9395250208833055\n","Valid Epoch #7, Batch 1446/4160 loss = 1.5854074382781982, ppl = 4.94635924408243\n","Valid Epoch #7, Batch 1447/4160 loss = 1.5853723788261413, ppl = 4.9461465575596435\n","Valid Epoch #7, Batch 1448/4160 loss = 1.5876099371910095, ppl = 4.9600861877909255\n","Valid Epoch #7, Batch 1449/4160 loss = 1.5870286154747009, ppl = 4.956727469271454\n","Valid Epoch #7, Batch 1450/4160 loss = 1.5880128586292266, ppl = 4.962154630682218\n","Valid Epoch #7, Batch 1451/4160 loss = 1.5883668851852417, ppl = 4.963987583784021\n","Valid Epoch #7, Batch 1452/4160 loss = 1.5885262417793273, ppl = 4.9648771536388345\n","Valid Epoch #7, Batch 1453/4160 loss = 1.5892768335342407, ppl = 4.968574336624181\n","Valid Epoch #7, Batch 1454/4160 loss = 1.5878107070922851, ppl = 4.961160954571232\n","Valid Epoch #7, Batch 1455/4160 loss = 1.5906224703788758, ppl = 4.97642846553467\n","Valid Epoch #7, Batch 1456/4160 loss = 1.589843431711197, ppl = 4.972286299115825\n","Valid Epoch #7, Batch 1457/4160 loss = 1.591777684688568, ppl = 4.980449638650008\n","Valid Epoch #7, Batch 1458/4160 loss = 1.5907070350646972, ppl = 4.975266296498939\n","Valid Epoch #7, Batch 1459/4160 loss = 1.5914915323257446, ppl = 4.979118422652565\n","Valid Epoch #7, Batch 1460/4160 loss = 1.5902705824375152, ppl = 4.9733219001063285\n","Valid Epoch #7, Batch 1461/4160 loss = 1.5914845335483552, ppl = 4.979612468906626\n","Valid Epoch #7, Batch 1462/4160 loss = 1.5903631138801575, ppl = 4.974684417068217\n","Valid Epoch #7, Batch 1463/4160 loss = 1.5898624312877656, ppl = 4.971923350619146\n","Valid Epoch #7, Batch 1464/4160 loss = 1.5917393505573272, ppl = 4.9797159282088925\n","Valid Epoch #7, Batch 1465/4160 loss = 1.5929874360561371, ppl = 4.986625578355402\n","Valid Epoch #7, Batch 1466/4160 loss = 1.5946626913547517, ppl = 4.99509020648636\n","Valid Epoch #7, Batch 1467/4160 loss = 1.5919194972515107, ppl = 4.9823040515483346\n","Valid Epoch #7, Batch 1468/4160 loss = 1.5913193833827972, ppl = 4.979316142536626\n","Valid Epoch #7, Batch 1469/4160 loss = 1.5931114721298218, ppl = 4.9874568319699515\n","Valid Epoch #7, Batch 1470/4160 loss = 1.5936180758476257, ppl = 4.989961101522097\n","Valid Epoch #7, Batch 1471/4160 loss = 1.5953371930122375, ppl = 4.99837133942581\n","Valid Epoch #7, Batch 1472/4160 loss = 1.5955742633342742, ppl = 4.999572939430989\n","Valid Epoch #7, Batch 1473/4160 loss = 1.5964065682888031, ppl = 5.0032107075973355\n","Valid Epoch #7, Batch 1474/4160 loss = 1.5974094152450562, ppl = 5.008573424400111\n","Valid Epoch #7, Batch 1475/4160 loss = 1.5979465115070344, ppl = 5.011059591707457\n","Valid Epoch #7, Batch 1476/4160 loss = 1.5986588966846467, ppl = 5.014530507711869\n","Valid Epoch #7, Batch 1477/4160 loss = 1.600335282087326, ppl = 5.0240155488594\n","Valid Epoch #7, Batch 1478/4160 loss = 1.5988801300525666, ppl = 5.017473666534996\n","Valid Epoch #7, Batch 1479/4160 loss = 1.5979859590530396, ppl = 5.013167250010216\n","Valid Epoch #7, Batch 1480/4160 loss = 1.5962766349315642, ppl = 5.0043200575700695\n","Valid Epoch #7, Batch 1481/4160 loss = 1.594041210412979, ppl = 4.992570049826622\n","Valid Epoch #7, Batch 1482/4160 loss = 1.5924900937080384, ppl = 4.984006889283744\n","Valid Epoch #7, Batch 1483/4160 loss = 1.5944494259357453, ppl = 4.994815260497048\n","Valid Epoch #7, Batch 1484/4160 loss = 1.5971234023571015, ppl = 5.006990140965422\n","Valid Epoch #7, Batch 1485/4160 loss = 1.5942900800704956, ppl = 4.9906846462830465\n","Valid Epoch #7, Batch 1486/4160 loss = 1.5939684116840362, ppl = 4.989065540778513\n","Valid Epoch #7, Batch 1487/4160 loss = 1.5930794537067414, ppl = 4.984332685769032\n","Valid Epoch #7, Batch 1488/4160 loss = 1.5945381534099579, ppl = 4.992147398123329\n","Valid Epoch #7, Batch 1489/4160 loss = 1.5950129532814026, ppl = 4.994602984013843\n","Valid Epoch #7, Batch 1490/4160 loss = 1.5981195878982544, ppl = 5.011501929318651\n","Valid Epoch #7, Batch 1491/4160 loss = 1.5987537395954132, ppl = 5.014552535690566\n","Valid Epoch #7, Batch 1492/4160 loss = 1.5979066562652589, ppl = 5.0105873555196485\n","Valid Epoch #7, Batch 1493/4160 loss = 1.5966338670253755, ppl = 5.004423600486962\n","Valid Epoch #7, Batch 1494/4160 loss = 1.5982779097557067, ppl = 5.012438042266066\n","Valid Epoch #7, Batch 1495/4160 loss = 1.5975203335285186, ppl = 5.008604831054272\n","Valid Epoch #7, Batch 1496/4160 loss = 1.596468448638916, ppl = 5.003512193684881\n","Valid Epoch #7, Batch 1497/4160 loss = 1.595310765504837, ppl = 4.9978365936262605\n","Valid Epoch #7, Batch 1498/4160 loss = 1.5962564980983733, ppl = 5.002992893977976\n","Valid Epoch #7, Batch 1499/4160 loss = 1.5949457204341888, ppl = 4.997598712847344\n","Valid Epoch #7, Batch 1500/4160 loss = 1.594486813545227, ppl = 4.995440552576256\n","Valid Epoch #7, Batch 1501/4160 loss = 1.5937498450279235, ppl = 4.992581380716314\n","Valid Epoch #7, Batch 1502/4160 loss = 1.595353434085846, ppl = 4.998011979564581\n","Valid Epoch #7, Batch 1503/4160 loss = 1.5946944200992583, ppl = 4.995796686195851\n","Valid Epoch #7, Batch 1504/4160 loss = 1.5934120190143586, ppl = 4.990985761419427\n","Valid Epoch #7, Batch 1505/4160 loss = 1.5944901669025422, ppl = 4.994923361025676\n","Valid Epoch #7, Batch 1506/4160 loss = 1.5947901487350464, ppl = 4.9961604768901875\n","Valid Epoch #7, Batch 1507/4160 loss = 1.5962262666225433, ppl = 5.002297279341845\n","Valid Epoch #7, Batch 1508/4160 loss = 1.5963513886928558, ppl = 5.002790604395417\n","Valid Epoch #7, Batch 1509/4160 loss = 1.5981827092170715, ppl = 5.0098335383310895\n","Valid Epoch #7, Batch 1510/4160 loss = 1.5993410241603851, ppl = 5.014345543602287\n","Valid Epoch #7, Batch 1511/4160 loss = 1.5989479720592499, ppl = 5.012672017863989\n","Valid Epoch #7, Batch 1512/4160 loss = 1.59883540391922, ppl = 5.012260370319736\n","Valid Epoch #7, Batch 1513/4160 loss = 1.5981248700618744, ppl = 5.0096852545173824\n","Valid Epoch #7, Batch 1514/4160 loss = 1.6013805508613586, ppl = 5.023030812331574\n","Valid Epoch #7, Batch 1515/4160 loss = 1.6028145778179168, ppl = 5.028831447989165\n","Valid Epoch #7, Batch 1516/4160 loss = 1.6017828488349914, ppl = 5.023743846834029\n","Valid Epoch #7, Batch 1517/4160 loss = 1.603068047761917, ppl = 5.028935988943249\n","Valid Epoch #7, Batch 1518/4160 loss = 1.6033093667030334, ppl = 5.029995570952347\n","Valid Epoch #7, Batch 1519/4160 loss = 1.6019349336624145, ppl = 5.022695812906537\n","Valid Epoch #7, Batch 1520/4160 loss = 1.6037081110477447, ppl = 5.0309375741863915\n","Valid Epoch #7, Batch 1521/4160 loss = 1.6024768960475921, ppl = 5.025314364795367\n","Valid Epoch #7, Batch 1522/4160 loss = 1.5997364556789397, ppl = 5.011367933944349\n","Valid Epoch #7, Batch 1523/4160 loss = 1.5978401267528535, ppl = 5.00123684044654\n","Valid Epoch #7, Batch 1524/4160 loss = 1.596996034383774, ppl = 4.996805304856219\n","Valid Epoch #7, Batch 1525/4160 loss = 1.5954978215694426, ppl = 4.990085395687276\n","Valid Epoch #7, Batch 1526/4160 loss = 1.5976241528987885, ppl = 5.001401818360959\n","Valid Epoch #7, Batch 1527/4160 loss = 1.5977879762649536, ppl = 5.002306691108459\n","Valid Epoch #7, Batch 1528/4160 loss = 1.5975059628486634, ppl = 5.000928828979888\n","Valid Epoch #7, Batch 1529/4160 loss = 1.5963181829452515, ppl = 4.993801241502101\n","Valid Epoch #7, Batch 1530/4160 loss = 1.5968218529224396, ppl = 4.995964693190151\n","Valid Epoch #7, Batch 1531/4160 loss = 1.594734219312668, ppl = 4.984383206070622\n","Valid Epoch #7, Batch 1532/4160 loss = 1.595188090801239, ppl = 4.986401768062504\n","Valid Epoch #7, Batch 1533/4160 loss = 1.594630516767502, ppl = 4.983315449833892\n","Valid Epoch #7, Batch 1534/4160 loss = 1.5937163019180298, ppl = 4.976999097203832\n","Valid Epoch #7, Batch 1535/4160 loss = 1.592851438522339, ppl = 4.9721324530368785\n","Valid Epoch #7, Batch 1536/4160 loss = 1.5903242707252503, ppl = 4.960637640808198\n","Valid Epoch #7, Batch 1537/4160 loss = 1.5878544080257415, ppl = 4.9475762792331075\n","Valid Epoch #7, Batch 1538/4160 loss = 1.5869261848926544, ppl = 4.94276960872226\n","Valid Epoch #7, Batch 1539/4160 loss = 1.5868252432346344, ppl = 4.942205758855783\n","Valid Epoch #7, Batch 1540/4160 loss = 1.5851030230522156, ppl = 4.932472709604113\n","Valid Epoch #7, Batch 1541/4160 loss = 1.585205124616623, ppl = 4.933015464776097\n","Valid Epoch #7, Batch 1542/4160 loss = 1.5849892592430115, ppl = 4.931917945725852\n","Valid Epoch #7, Batch 1543/4160 loss = 1.5847302615642547, ppl = 4.9303858666002816\n","Valid Epoch #7, Batch 1544/4160 loss = 1.584284027814865, ppl = 4.927736649395028\n","Valid Epoch #7, Batch 1545/4160 loss = 1.582939201593399, ppl = 4.920568413885883\n","Valid Epoch #7, Batch 1546/4160 loss = 1.5814617931842805, ppl = 4.913039375953061\n","Valid Epoch #7, Batch 1547/4160 loss = 1.5816336059570313, ppl = 4.914088833737626\n","Valid Epoch #7, Batch 1548/4160 loss = 1.5784534156322478, ppl = 4.895148659486531\n","Valid Epoch #7, Batch 1549/4160 loss = 1.5798005366325378, ppl = 4.903240735922009\n","Valid Epoch #7, Batch 1550/4160 loss = 1.5789143025875092, ppl = 4.898330370227127\n","Valid Epoch #7, Batch 1551/4160 loss = 1.577024255990982, ppl = 4.889255146808689\n","Valid Epoch #7, Batch 1552/4160 loss = 1.5769918048381806, ppl = 4.889072844797606\n","Valid Epoch #7, Batch 1553/4160 loss = 1.5777920055389405, ppl = 4.8933323096019015\n","Valid Epoch #7, Batch 1554/4160 loss = 1.5776284945011139, ppl = 4.892570895632272\n","Valid Epoch #7, Batch 1555/4160 loss = 1.5729078340530396, ppl = 4.869132037513977\n","Valid Epoch #7, Batch 1556/4160 loss = 1.5717346668243408, ppl = 4.863472563793225\n","Valid Epoch #7, Batch 1557/4160 loss = 1.5728026568889617, ppl = 4.868704280886392\n","Valid Epoch #7, Batch 1558/4160 loss = 1.5740643692016603, ppl = 4.874872394208218\n","Valid Epoch #7, Batch 1559/4160 loss = 1.576041615009308, ppl = 4.886034241544093\n","Valid Epoch #7, Batch 1560/4160 loss = 1.5784449315071105, ppl = 4.898160599618548\n","Valid Epoch #7, Batch 1561/4160 loss = 1.5768318092823028, ppl = 4.88996289546723\n","Valid Epoch #7, Batch 1562/4160 loss = 1.5807200789451599, ppl = 4.909698466071252\n","Valid Epoch #7, Batch 1563/4160 loss = 1.5786172699928285, ppl = 4.8995000064845335\n","Valid Epoch #7, Batch 1564/4160 loss = 1.5800154197216034, ppl = 4.906333186064385\n","Valid Epoch #7, Batch 1565/4160 loss = 1.5779789078235626, ppl = 4.895482764701919\n","Valid Epoch #7, Batch 1566/4160 loss = 1.5794354927539827, ppl = 4.904087665481193\n","Valid Epoch #7, Batch 1567/4160 loss = 1.5799824345111846, ppl = 4.9063649996432055\n","Valid Epoch #7, Batch 1568/4160 loss = 1.5807679522037505, ppl = 4.91031286336739\n","Valid Epoch #7, Batch 1569/4160 loss = 1.5809452390670777, ppl = 4.911200361332771\n","Valid Epoch #7, Batch 1570/4160 loss = 1.578513571023941, ppl = 4.900257326682782\n","Valid Epoch #7, Batch 1571/4160 loss = 1.5785932767391204, ppl = 4.900683434694853\n","Valid Epoch #7, Batch 1572/4160 loss = 1.5773626673221588, ppl = 4.8947447212016115\n","Valid Epoch #7, Batch 1573/4160 loss = 1.5786873614788055, ppl = 4.901196789420367\n","Valid Epoch #7, Batch 1574/4160 loss = 1.5785324776172638, ppl = 4.90033303153873\n","Valid Epoch #7, Batch 1575/4160 loss = 1.5772823286056519, ppl = 4.894745926524048\n","Valid Epoch #7, Batch 1576/4160 loss = 1.5769528865814209, ppl = 4.893110046152873\n","Valid Epoch #7, Batch 1577/4160 loss = 1.5741849052906036, ppl = 4.878250623693226\n","Valid Epoch #7, Batch 1578/4160 loss = 1.5770020139217378, ppl = 4.891840781467619\n","Valid Epoch #7, Batch 1579/4160 loss = 1.5774174451828002, ppl = 4.893793706097934\n","Valid Epoch #7, Batch 1580/4160 loss = 1.579339519739151, ppl = 4.9038516874403255\n","Valid Epoch #7, Batch 1581/4160 loss = 1.5778977537155152, ppl = 4.897553784627291\n","Valid Epoch #7, Batch 1582/4160 loss = 1.5772525870800018, ppl = 4.894365112565142\n","Valid Epoch #7, Batch 1583/4160 loss = 1.5743568849563598, ppl = 4.879093150037033\n","Valid Epoch #7, Batch 1584/4160 loss = 1.5734569692611695, ppl = 4.874627490158696\n","Valid Epoch #7, Batch 1585/4160 loss = 1.573188818693161, ppl = 4.873310354784013\n","Valid Epoch #7, Batch 1586/4160 loss = 1.5726956939697265, ppl = 4.870927180427131\n","Valid Epoch #7, Batch 1587/4160 loss = 1.5715128624439239, ppl = 4.865247986794753\n","Valid Epoch #7, Batch 1588/4160 loss = 1.5713255500793457, ppl = 4.864179564966718\n","Valid Epoch #7, Batch 1589/4160 loss = 1.5703901624679566, ppl = 4.859450751997052\n","Valid Epoch #7, Batch 1590/4160 loss = 1.567623209953308, ppl = 4.844154440573345\n","Valid Epoch #7, Batch 1591/4160 loss = 1.5666718351840974, ppl = 4.839648896557054\n","Valid Epoch #7, Batch 1592/4160 loss = 1.5672365033626556, ppl = 4.842254602457768\n","Valid Epoch #7, Batch 1593/4160 loss = 1.5667572224140167, ppl = 4.840129490675067\n","Valid Epoch #7, Batch 1594/4160 loss = 1.567813824415207, ppl = 4.84602102444777\n","Valid Epoch #7, Batch 1595/4160 loss = 1.5677548134326935, ppl = 4.845734452238471\n","Valid Epoch #7, Batch 1596/4160 loss = 1.5697162008285523, ppl = 4.855683539313418\n","Valid Epoch #7, Batch 1597/4160 loss = 1.5709898579120636, ppl = 4.861964758489097\n","Valid Epoch #7, Batch 1598/4160 loss = 1.5702963447570801, ppl = 4.85813627638429\n","Valid Epoch #7, Batch 1599/4160 loss = 1.5724617862701415, ppl = 4.867448192914873\n","Valid Epoch #7, Batch 1600/4160 loss = 1.5723037266731261, ppl = 4.866727501842067\n","Valid Epoch #7, Batch 1601/4160 loss = 1.5713377344608306, ppl = 4.863285142563558\n","Valid Epoch #7, Batch 1602/4160 loss = 1.5704967212677001, ppl = 4.860328632735246\n","Valid Epoch #7, Batch 1603/4160 loss = 1.5717079555988311, ppl = 4.864516018378725\n","Valid Epoch #7, Batch 1604/4160 loss = 1.571321303844452, ppl = 4.863182462696257\n","Valid Epoch #7, Batch 1605/4160 loss = 1.5701291596889495, ppl = 4.858852806467588\n","Valid Epoch #7, Batch 1606/4160 loss = 1.5688199257850648, ppl = 4.853715790889328\n","Valid Epoch #7, Batch 1607/4160 loss = 1.5653398180007934, ppl = 4.840233108557809\n","Valid Epoch #7, Batch 1608/4160 loss = 1.5653250896930695, ppl = 4.84017471748214\n","Valid Epoch #7, Batch 1609/4160 loss = 1.5674817371368408, ppl = 4.850304512230329\n","Valid Epoch #7, Batch 1610/4160 loss = 1.5655925285816192, ppl = 4.8432029386846835\n","Valid Epoch #7, Batch 1611/4160 loss = 1.5693946588039398, ppl = 4.862514673441486\n","Valid Epoch #7, Batch 1612/4160 loss = 1.5704666090011596, ppl = 4.866629229496706\n","Valid Epoch #7, Batch 1613/4160 loss = 1.5726311469078065, ppl = 4.8750802005651295\n","Valid Epoch #7, Batch 1614/4160 loss = 1.5719975578784942, ppl = 4.872131729595609\n","Valid Epoch #7, Batch 1615/4160 loss = 1.5730823302268981, ppl = 4.877106725944508\n","Valid Epoch #7, Batch 1616/4160 loss = 1.5752303409576416, ppl = 4.888323439269865\n","Valid Epoch #7, Batch 1617/4160 loss = 1.5750799620151519, ppl = 4.887680883559931\n","Valid Epoch #7, Batch 1618/4160 loss = 1.5766525340080262, ppl = 4.895248841567709\n","Valid Epoch #7, Batch 1619/4160 loss = 1.5773184263706208, ppl = 4.898660311895304\n","Valid Epoch #7, Batch 1620/4160 loss = 1.5768927454948425, ppl = 4.896546450605168\n","Valid Epoch #7, Batch 1621/4160 loss = 1.5776988542079926, ppl = 4.900149383831609\n","Valid Epoch #7, Batch 1622/4160 loss = 1.5777216267585754, ppl = 4.900250235468417\n","Valid Epoch #7, Batch 1623/4160 loss = 1.5775186359882354, ppl = 4.899275268910738\n","Valid Epoch #7, Batch 1624/4160 loss = 1.5782443594932556, ppl = 4.903062584437498\n","Valid Epoch #7, Batch 1625/4160 loss = 1.5796151959896088, ppl = 4.909171209994199\n","Valid Epoch #7, Batch 1626/4160 loss = 1.578805913925171, ppl = 4.904578403354918\n","Valid Epoch #7, Batch 1627/4160 loss = 1.57699889421463, ppl = 4.89537223611846\n","Valid Epoch #7, Batch 1628/4160 loss = 1.5780618107318878, ppl = 4.9007745806396725\n","Valid Epoch #7, Batch 1629/4160 loss = 1.5751109719276428, ppl = 4.8863334112234345\n","Valid Epoch #7, Batch 1630/4160 loss = 1.5768183994293212, ppl = 4.894533872673286\n","Valid Epoch #7, Batch 1631/4160 loss = 1.5772791397571564, ppl = 4.896886151452467\n","Valid Epoch #7, Batch 1632/4160 loss = 1.5783441627025605, ppl = 4.901998476815705\n","Valid Epoch #7, Batch 1633/4160 loss = 1.5810665607452392, ppl = 4.91884004031479\n","Valid Epoch #7, Batch 1634/4160 loss = 1.577011355161667, ppl = 4.896844134687237\n","Valid Epoch #7, Batch 1635/4160 loss = 1.5783702993392945, ppl = 4.9046858541720795\n","Valid Epoch #7, Batch 1636/4160 loss = 1.5827192902565002, ppl = 4.926466902977066\n","Valid Epoch #7, Batch 1637/4160 loss = 1.5840366351604462, ppl = 4.9330313659723135\n","Valid Epoch #7, Batch 1638/4160 loss = 1.5866121697425841, ppl = 4.947548271526817\n","Valid Epoch #7, Batch 1639/4160 loss = 1.587567582130432, ppl = 4.953120152555563\n","Valid Epoch #7, Batch 1640/4160 loss = 1.5884952533245087, ppl = 4.958154231593739\n","Valid Epoch #7, Batch 1641/4160 loss = 1.587739953994751, ppl = 4.9542672900956095\n","Valid Epoch #7, Batch 1642/4160 loss = 1.5893421423435212, ppl = 4.963007105451912\n","Valid Epoch #7, Batch 1643/4160 loss = 1.589755927324295, ppl = 4.9654739401822825\n","Valid Epoch #7, Batch 1644/4160 loss = 1.5889156877994537, ppl = 4.96079535475592\n","Valid Epoch #7, Batch 1645/4160 loss = 1.5876688969135284, ppl = 4.954957980978194\n","Valid Epoch #7, Batch 1646/4160 loss = 1.5899845945835114, ppl = 4.967280486611765\n","Valid Epoch #7, Batch 1647/4160 loss = 1.5900496280193328, ppl = 4.967682448335076\n","Valid Epoch #7, Batch 1648/4160 loss = 1.592271190881729, ppl = 4.980266986091534\n","Valid Epoch #7, Batch 1649/4160 loss = 1.5891947853565216, ppl = 4.963263853287985\n","Valid Epoch #7, Batch 1650/4160 loss = 1.5903382968902589, ppl = 4.969683145514932\n","Valid Epoch #7, Batch 1651/4160 loss = 1.5932916939258575, ppl = 4.9846706052995415\n","Valid Epoch #7, Batch 1652/4160 loss = 1.5931637942790986, ppl = 4.983957831919892\n","Valid Epoch #7, Batch 1653/4160 loss = 1.5935661816596984, ppl = 4.9862320272462615\n","Valid Epoch #7, Batch 1654/4160 loss = 1.5951734626293181, ppl = 4.9942854253551126\n","Valid Epoch #7, Batch 1655/4160 loss = 1.5962763977050782, ppl = 4.998815660601199\n","Valid Epoch #7, Batch 1656/4160 loss = 1.5973896920680999, ppl = 5.004169942653516\n","Valid Epoch #7, Batch 1657/4160 loss = 1.5986936569213868, ppl = 5.01136361299937\n","Valid Epoch #7, Batch 1658/4160 loss = 1.5958063304424286, ppl = 4.9983136997196995\n","Valid Epoch #7, Batch 1659/4160 loss = 1.594805896282196, ppl = 4.9923906005589185\n","Valid Epoch #7, Batch 1660/4160 loss = 1.5931873893737794, ppl = 4.983908466396456\n","Valid Epoch #7, Batch 1661/4160 loss = 1.5943504977226257, ppl = 4.989684732743555\n","Valid Epoch #7, Batch 1662/4160 loss = 1.5903277134895324, ppl = 4.969394306642823\n","Valid Epoch #7, Batch 1663/4160 loss = 1.5917756974697113, ppl = 4.976184132788556\n","Valid Epoch #7, Batch 1664/4160 loss = 1.5929631054401399, ppl = 4.98278673618349\n","Valid Epoch #7, Batch 1665/4160 loss = 1.5941448259353637, ppl = 4.988812544258992\n","Valid Epoch #7, Batch 1666/4160 loss = 1.5951393401622773, ppl = 4.995450603170449\n","Valid Epoch #7, Batch 1667/4160 loss = 1.59598127245903, ppl = 4.999208942581054\n","Valid Epoch #7, Batch 1668/4160 loss = 1.5943721115589142, ppl = 4.991441513740487\n","Valid Epoch #7, Batch 1669/4160 loss = 1.5949631786346437, ppl = 4.99451668779309\n","Valid Epoch #7, Batch 1670/4160 loss = 1.5971491432189941, ppl = 5.004229301169661\n","Valid Epoch #7, Batch 1671/4160 loss = 1.5967884123325349, ppl = 5.002327638068982\n","Valid Epoch #7, Batch 1672/4160 loss = 1.5976244020462036, ppl = 5.006281818379043\n","Valid Epoch #7, Batch 1673/4160 loss = 1.5987204718589783, ppl = 5.01230585556279\n","Valid Epoch #7, Batch 1674/4160 loss = 1.597447510957718, ppl = 5.005691546091849\n","Valid Epoch #7, Batch 1675/4160 loss = 1.59823282122612, ppl = 5.009119234227822\n","Valid Epoch #7, Batch 1676/4160 loss = 1.6000563144683837, ppl = 5.0188893904422045\n","Valid Epoch #7, Batch 1677/4160 loss = 1.5985697674751282, ppl = 5.012452949758234\n","Valid Epoch #7, Batch 1678/4160 loss = 1.5963956224918365, ppl = 5.001636342201097\n","Valid Epoch #7, Batch 1679/4160 loss = 1.5978877687454223, ppl = 5.009359444999594\n","Valid Epoch #7, Batch 1680/4160 loss = 1.5972032153606415, ppl = 5.005553725012995\n","Valid Epoch #7, Batch 1681/4160 loss = 1.597894469499588, ppl = 5.008460103236309\n","Valid Epoch #7, Batch 1682/4160 loss = 1.5970991265773773, ppl = 5.004802039630908\n","Valid Epoch #7, Batch 1683/4160 loss = 1.598868999481201, ppl = 5.013606168454263\n","Valid Epoch #7, Batch 1684/4160 loss = 1.5985536217689513, ppl = 5.012133867766793\n","Valid Epoch #7, Batch 1685/4160 loss = 1.5996392631530763, ppl = 5.0176915014199786\n","Valid Epoch #7, Batch 1686/4160 loss = 1.5989766228199005, ppl = 5.014668660876316\n","Valid Epoch #7, Batch 1687/4160 loss = 1.5993839979171753, ppl = 5.016549260416266\n","Valid Epoch #7, Batch 1688/4160 loss = 1.5963291132450104, ppl = 5.001674540721234\n","Valid Epoch #7, Batch 1689/4160 loss = 1.5965783262252808, ppl = 5.002891522322614\n","Valid Epoch #7, Batch 1690/4160 loss = 1.5977192664146422, ppl = 5.008691021510358\n","Valid Epoch #7, Batch 1691/4160 loss = 1.5994095742702483, ppl = 5.017004069076312\n","Valid Epoch #7, Batch 1692/4160 loss = 1.5979966044425964, ppl = 5.010750213414715\n","Valid Epoch #7, Batch 1693/4160 loss = 1.5989677500724793, ppl = 5.015164756532206\n","Valid Epoch #7, Batch 1694/4160 loss = 1.5966915559768677, ppl = 5.003203459730084\n","Valid Epoch #7, Batch 1695/4160 loss = 1.5984947717189788, ppl = 5.012771245582813\n","Valid Epoch #7, Batch 1696/4160 loss = 1.596383558511734, ppl = 5.002139395131127\n","Valid Epoch #7, Batch 1697/4160 loss = 1.5967587840557098, ppl = 5.004147659252285\n","Valid Epoch #7, Batch 1698/4160 loss = 1.5968508207798005, ppl = 5.004640590873887\n","Valid Epoch #7, Batch 1699/4160 loss = 1.597168390750885, ppl = 5.006183783033158\n","Valid Epoch #7, Batch 1700/4160 loss = 1.5995029246807098, ppl = 5.018078969462101\n","Valid Epoch #7, Batch 1701/4160 loss = 1.6029788362979889, ppl = 5.032187077126354\n","Valid Epoch #7, Batch 1702/4160 loss = 1.602553060054779, ppl = 5.030782470276826\n","Valid Epoch #7, Batch 1703/4160 loss = 1.6020980381965637, ppl = 5.0291496438828425\n","Valid Epoch #7, Batch 1704/4160 loss = 1.6026215696334838, ppl = 5.0309677899997425\n","Valid Epoch #7, Batch 1705/4160 loss = 1.6039988994598389, ppl = 5.036017540601663\n","Valid Epoch #7, Batch 1706/4160 loss = 1.6028438138961791, ppl = 5.032011391990332\n","Valid Epoch #7, Batch 1707/4160 loss = 1.604155591726303, ppl = 5.036551656622102\n","Valid Epoch #7, Batch 1708/4160 loss = 1.605228260755539, ppl = 5.041037461832216\n","Valid Epoch #7, Batch 1709/4160 loss = 1.6020671939849853, ppl = 5.026885722535675\n","Valid Epoch #7, Batch 1710/4160 loss = 1.605544296503067, ppl = 5.041086522263041\n","Valid Epoch #7, Batch 1711/4160 loss = 1.6010897254943848, ppl = 5.019138032024035\n","Valid Epoch #7, Batch 1712/4160 loss = 1.600834220647812, ppl = 5.018116903745199\n","Valid Epoch #7, Batch 1713/4160 loss = 1.602651491165161, ppl = 5.02677006546329\n","Valid Epoch #7, Batch 1714/4160 loss = 1.599511709213257, ppl = 5.014623295979328\n","Valid Epoch #7, Batch 1715/4160 loss = 1.5970121717453003, ppl = 5.003920194819812\n","Valid Epoch #7, Batch 1716/4160 loss = 1.5966363966464996, ppl = 5.001780106336811\n","Valid Epoch #7, Batch 1717/4160 loss = 1.5961526107788087, ppl = 4.999777274509778\n","Valid Epoch #7, Batch 1718/4160 loss = 1.5964763951301575, ppl = 5.001488764835574\n","Valid Epoch #7, Batch 1719/4160 loss = 1.5975205421447753, ppl = 5.007317163924956\n","Valid Epoch #7, Batch 1720/4160 loss = 1.5962387859821319, ppl = 5.001469455651465\n","Valid Epoch #7, Batch 1721/4160 loss = 1.5956367135047913, ppl = 4.998751202030145\n","Valid Epoch #7, Batch 1722/4160 loss = 1.597390697002411, ppl = 5.007251516900677\n","Valid Epoch #7, Batch 1723/4160 loss = 1.5993305432796479, ppl = 5.017429678685828\n","Valid Epoch #7, Batch 1724/4160 loss = 1.600145868062973, ppl = 5.022025671753475\n","Valid Epoch #7, Batch 1725/4160 loss = 1.6014484322071076, ppl = 5.028659681492697\n","Valid Epoch #7, Batch 1726/4160 loss = 1.6001878464221955, ppl = 5.022206512344365\n","Valid Epoch #7, Batch 1727/4160 loss = 1.6005655586719514, ppl = 5.023995779212562\n","Valid Epoch #7, Batch 1728/4160 loss = 1.5994625937938691, ppl = 5.018400898154916\n","Valid Epoch #7, Batch 1729/4160 loss = 1.602240995168686, ppl = 5.031875902143048\n","Valid Epoch #7, Batch 1730/4160 loss = 1.6013153398036957, ppl = 5.027256891827445\n","Valid Epoch #7, Batch 1731/4160 loss = 1.6016595482826232, ppl = 5.029086324350074\n","Valid Epoch #7, Batch 1732/4160 loss = 1.6014290368556976, ppl = 5.027933196268037\n","Valid Epoch #7, Batch 1733/4160 loss = 1.600430450439453, ppl = 5.021217537181444\n","Valid Epoch #7, Batch 1734/4160 loss = 1.6018662190437316, ppl = 5.028008546683184\n","Valid Epoch #7, Batch 1735/4160 loss = 1.5992349231243133, ppl = 5.013730504797972\n","Valid Epoch #7, Batch 1736/4160 loss = 1.598087728023529, ppl = 5.007036675510976\n","Valid Epoch #7, Batch 1737/4160 loss = 1.596813552379608, ppl = 5.000673906196919\n","Valid Epoch #7, Batch 1738/4160 loss = 1.5970089828968048, ppl = 5.001935666948168\n","Valid Epoch #7, Batch 1739/4160 loss = 1.5956153881549835, ppl = 4.993981061022334\n","Valid Epoch #7, Batch 1740/4160 loss = 1.597710475921631, ppl = 5.007224623922005\n","Valid Epoch #7, Batch 1741/4160 loss = 1.59902383685112, ppl = 5.014178068763947\n","Valid Epoch #7, Batch 1742/4160 loss = 1.5964277303218841, ppl = 5.0006796455571365\n","Valid Epoch #7, Batch 1743/4160 loss = 1.5943463361263275, ppl = 4.989244000448629\n","Valid Epoch #7, Batch 1744/4160 loss = 1.592682523727417, ppl = 4.981062855475479\n","Valid Epoch #7, Batch 1745/4160 loss = 1.5939406085014343, ppl = 4.986956502904286\n","Valid Epoch #7, Batch 1746/4160 loss = 1.591729519367218, ppl = 4.975131279734093\n","Valid Epoch #7, Batch 1747/4160 loss = 1.5888272523880005, ppl = 4.959510669207817\n","Valid Epoch #7, Batch 1748/4160 loss = 1.5858809328079224, ppl = 4.943389459906365\n","Valid Epoch #7, Batch 1749/4160 loss = 1.587293850183487, ppl = 4.950553035771885\n","Valid Epoch #7, Batch 1750/4160 loss = 1.5874719417095184, ppl = 4.9516205096147345\n","Valid Epoch #7, Batch 1751/4160 loss = 1.5863579428195953, ppl = 4.945442049229467\n","Valid Epoch #7, Batch 1752/4160 loss = 1.5831246066093445, ppl = 4.9301441471818945\n","Valid Epoch #7, Batch 1753/4160 loss = 1.5829357516765594, ppl = 4.92906538504153\n","Valid Epoch #7, Batch 1754/4160 loss = 1.5807986783981323, ppl = 4.918628732138673\n","Valid Epoch #7, Batch 1755/4160 loss = 1.5806240141391754, ppl = 4.917877598152866\n","Valid Epoch #7, Batch 1756/4160 loss = 1.5795057451725005, ppl = 4.912500703913787\n","Valid Epoch #7, Batch 1757/4160 loss = 1.5764048171043397, ppl = 4.896812010563032\n","Valid Epoch #7, Batch 1758/4160 loss = 1.5814249396324158, ppl = 4.922232414863765\n","Valid Epoch #7, Batch 1759/4160 loss = 1.5803308403491974, ppl = 4.916398360081027\n","Valid Epoch #7, Batch 1760/4160 loss = 1.580538284778595, ppl = 4.9174103714445145\n","Valid Epoch #7, Batch 1761/4160 loss = 1.5804807007312776, ppl = 4.917108312844395\n","Valid Epoch #7, Batch 1762/4160 loss = 1.582719885110855, ppl = 4.9273909946113\n","Valid Epoch #7, Batch 1763/4160 loss = 1.5825780320167542, ppl = 4.926681547071898\n","Valid Epoch #7, Batch 1764/4160 loss = 1.5792821073532104, ppl = 4.910123255226846\n","Valid Epoch #7, Batch 1765/4160 loss = 1.5781524407863616, ppl = 4.904348157038205\n","Valid Epoch #7, Batch 1766/4160 loss = 1.5746552968025207, ppl = 4.883654769864045\n","Valid Epoch #7, Batch 1767/4160 loss = 1.5758195757865905, ppl = 4.8894019818267624\n","Valid Epoch #7, Batch 1768/4160 loss = 1.5760946083068847, ppl = 4.890642596325695\n","Valid Epoch #7, Batch 1769/4160 loss = 1.5757492971420288, ppl = 4.8888239910973015\n","Valid Epoch #7, Batch 1770/4160 loss = 1.5748525214195253, ppl = 4.884581192901608\n","Valid Epoch #7, Batch 1771/4160 loss = 1.5762084007263184, ppl = 4.892098974935539\n","Valid Epoch #7, Batch 1772/4160 loss = 1.5761658132076264, ppl = 4.891889447811643\n","Valid Epoch #7, Batch 1773/4160 loss = 1.5753868854045867, ppl = 4.887541085764545\n","Valid Epoch #7, Batch 1774/4160 loss = 1.575355339050293, ppl = 4.887387624560667\n","Valid Epoch #7, Batch 1775/4160 loss = 1.5750418078899384, ppl = 4.885986775045478\n","Valid Epoch #7, Batch 1776/4160 loss = 1.572931479215622, ppl = 4.874835540552189\n","Valid Epoch #7, Batch 1777/4160 loss = 1.575498447418213, ppl = 4.886588319915596\n","Valid Epoch #7, Batch 1778/4160 loss = 1.573927536010742, ppl = 4.880113572398381\n","Valid Epoch #7, Batch 1779/4160 loss = 1.5728344702720642, ppl = 4.8743445000238275\n","Valid Epoch #7, Batch 1780/4160 loss = 1.5714737939834595, ppl = 4.8675113192538095\n","Valid Epoch #7, Batch 1781/4160 loss = 1.5716319727897643, ppl = 4.868205105915955\n","Valid Epoch #7, Batch 1782/4160 loss = 1.5730076134204865, ppl = 4.874721851325651\n","Valid Epoch #7, Batch 1783/4160 loss = 1.572348301410675, ppl = 4.871258769223331\n","Valid Epoch #7, Batch 1784/4160 loss = 1.573471519947052, ppl = 4.876721151551457\n","Valid Epoch #7, Batch 1785/4160 loss = 1.5712605822086334, ppl = 4.866005576584434\n","Valid Epoch #7, Batch 1786/4160 loss = 1.5729188144207, ppl = 4.873963866123009\n","Valid Epoch #7, Batch 1787/4160 loss = 1.5728630173206328, ppl = 4.873701735096082\n","Valid Epoch #7, Batch 1788/4160 loss = 1.5747225821018218, ppl = 4.88221012484755\n","Valid Epoch #7, Batch 1789/4160 loss = 1.574717651605606, ppl = 4.8821857525048555\n","Valid Epoch #7, Batch 1790/4160 loss = 1.5752203524112702, ppl = 4.884958680553305\n","Valid Epoch #7, Batch 1791/4160 loss = 1.5737659633159637, ppl = 4.8777232599594775\n","Valid Epoch #7, Batch 1792/4160 loss = 1.5753597521781921, ppl = 4.884843104864772\n","Valid Epoch #7, Batch 1793/4160 loss = 1.5742766761779785, ppl = 4.879946766775182\n","Valid Epoch #7, Batch 1794/4160 loss = 1.5743168783187866, ppl = 4.880135273721995\n","Valid Epoch #7, Batch 1795/4160 loss = 1.5726919782161712, ppl = 4.871438624855253\n","Valid Epoch #7, Batch 1796/4160 loss = 1.5723818385601043, ppl = 4.870057394226098\n","Valid Epoch #7, Batch 1797/4160 loss = 1.5719695484638214, ppl = 4.867854813820379\n","Valid Epoch #7, Batch 1798/4160 loss = 1.5705110943317413, ppl = 4.860553008771088\n","Valid Epoch #7, Batch 1799/4160 loss = 1.5711274635791779, ppl = 4.863691726561041\n","Valid Epoch #7, Batch 1800/4160 loss = 1.5687235820293426, ppl = 4.851483919168466\n","Valid Epoch #7, Batch 1801/4160 loss = 1.5653041017055511, ppl = 4.837567892077364\n","Valid Epoch #7, Batch 1802/4160 loss = 1.5663687336444854, ppl = 4.841195477948254\n","Valid Epoch #7, Batch 1803/4160 loss = 1.5674502646923065, ppl = 4.845201611265924\n","Valid Epoch #7, Batch 1804/4160 loss = 1.566321952342987, ppl = 4.841398286067561\n","Valid Epoch #7, Batch 1805/4160 loss = 1.5640553331375122, ppl = 4.83343878368204\n","Valid Epoch #7, Batch 1806/4160 loss = 1.5657978773117065, ppl = 4.839666963112082\n","Valid Epoch #7, Batch 1807/4160 loss = 1.5695331442356109, ppl = 4.856391271924343\n","Valid Epoch #7, Batch 1808/4160 loss = 1.5694645726680756, ppl = 4.856089891454449\n","Valid Epoch #7, Batch 1809/4160 loss = 1.5735762512683868, ppl = 4.875449021536404\n","Valid Epoch #7, Batch 1810/4160 loss = 1.571672841310501, ppl = 4.867068525170202\n","Valid Epoch #7, Batch 1811/4160 loss = 1.5711460387706757, ppl = 4.865061546008426\n","Valid Epoch #7, Batch 1812/4160 loss = 1.5741656613349915, ppl = 4.878970446191923\n","Valid Epoch #7, Batch 1813/4160 loss = 1.5737973260879516, ppl = 4.877087279079393\n","Valid Epoch #7, Batch 1814/4160 loss = 1.576945127248764, ppl = 4.889270211528319\n","Valid Epoch #7, Batch 1815/4160 loss = 1.5784973084926606, ppl = 4.895599089853187\n","Valid Epoch #7, Batch 1816/4160 loss = 1.576189057826996, ppl = 4.884079368329658\n","Valid Epoch #7, Batch 1817/4160 loss = 1.5772397112846375, ppl = 4.888555651541374\n","Valid Epoch #7, Batch 1818/4160 loss = 1.5760125160217284, ppl = 4.882351699079519\n","Valid Epoch #7, Batch 1819/4160 loss = 1.5734101808071137, ppl = 4.868882469838547\n","Valid Epoch #7, Batch 1820/4160 loss = 1.5735374093055725, ppl = 4.869429989997442\n","Valid Epoch #7, Batch 1821/4160 loss = 1.574169509410858, ppl = 4.872288145217124\n","Valid Epoch #7, Batch 1822/4160 loss = 1.5765499997138976, ppl = 4.886489287207569\n","Valid Epoch #7, Batch 1823/4160 loss = 1.5718917644023895, ppl = 4.8649944984212645\n","Valid Epoch #7, Batch 1824/4160 loss = 1.5696377873420715, ppl = 4.853148901965484\n","Valid Epoch #7, Batch 1825/4160 loss = 1.5678909015655518, ppl = 4.8444425091114764\n","Valid Epoch #7, Batch 1826/4160 loss = 1.5682553899288179, ppl = 4.846225554209299\n","Valid Epoch #7, Batch 1827/4160 loss = 1.5695906066894532, ppl = 4.85312093653915\n","Valid Epoch #7, Batch 1828/4160 loss = 1.567342381477356, ppl = 4.8434605842488665\n","Valid Epoch #7, Batch 1829/4160 loss = 1.5670429468154907, ppl = 4.8418219338928115\n","Valid Epoch #7, Batch 1830/4160 loss = 1.569682023525238, ppl = 4.856205369549633\n","Valid Epoch #7, Batch 1831/4160 loss = 1.5691386795043945, ppl = 4.853345952305632\n","Valid Epoch #7, Batch 1832/4160 loss = 1.5705223238468171, ppl = 4.860684097304969\n","Valid Epoch #7, Batch 1833/4160 loss = 1.56669548869133, ppl = 4.8403499282964315\n","Valid Epoch #7, Batch 1834/4160 loss = 1.5665736043453216, ppl = 4.839734810665792\n","Valid Epoch #7, Batch 1835/4160 loss = 1.5668939185142516, ppl = 4.84127885290858\n","Valid Epoch #7, Batch 1836/4160 loss = 1.5662450277805329, ppl = 4.837819096830151\n","Valid Epoch #7, Batch 1837/4160 loss = 1.5677563703060151, ppl = 4.845458321822474\n","Valid Epoch #7, Batch 1838/4160 loss = 1.5627944338321687, ppl = 4.819956468781138\n","Valid Epoch #7, Batch 1839/4160 loss = 1.5646795809268952, ppl = 4.830991989887453\n","Valid Epoch #7, Batch 1840/4160 loss = 1.5644722092151642, ppl = 4.8295539956415094\n","Valid Epoch #7, Batch 1841/4160 loss = 1.563037976026535, ppl = 4.822005314871257\n","Valid Epoch #7, Batch 1842/4160 loss = 1.5650301861763, ppl = 4.832044102746237\n","Valid Epoch #7, Batch 1843/4160 loss = 1.566177614927292, ppl = 4.838053152775705\n","Valid Epoch #7, Batch 1844/4160 loss = 1.567840313911438, ppl = 4.846228355224941\n","Valid Epoch #7, Batch 1845/4160 loss = 1.5672572565078735, ppl = 4.843404654060539\n","Valid Epoch #7, Batch 1846/4160 loss = 1.5683768856525422, ppl = 4.849065991434119\n","Valid Epoch #7, Batch 1847/4160 loss = 1.5708835101127625, ppl = 4.862281134792845\n","Valid Epoch #7, Batch 1848/4160 loss = 1.571550841331482, ppl = 4.86552813620455\n","Valid Epoch #7, Batch 1849/4160 loss = 1.5691890871524812, ppl = 4.854091672508936\n","Valid Epoch #7, Batch 1850/4160 loss = 1.5672335088253022, ppl = 4.8433498583440056\n","Valid Epoch #7, Batch 1851/4160 loss = 1.5662756311893462, ppl = 4.838560726506175\n","Valid Epoch #7, Batch 1852/4160 loss = 1.5695100104808808, ppl = 4.853864404759622\n","Valid Epoch #7, Batch 1853/4160 loss = 1.5686165356636048, ppl = 4.849028083063193\n","Valid Epoch #7, Batch 1854/4160 loss = 1.5699347901344298, ppl = 4.855200410354447\n","Valid Epoch #7, Batch 1855/4160 loss = 1.573615356683731, ppl = 4.874167504255957\n","Valid Epoch #7, Batch 1856/4160 loss = 1.5732198166847229, ppl = 4.872405099202552\n","Valid Epoch #7, Batch 1857/4160 loss = 1.5744706356525422, ppl = 4.87815498703848\n","Valid Epoch #7, Batch 1858/4160 loss = 1.571618106365204, ppl = 4.862170911694417\n","Valid Epoch #7, Batch 1859/4160 loss = 1.5701573860645295, ppl = 4.855313297037885\n","Valid Epoch #7, Batch 1860/4160 loss = 1.5722529530525207, ppl = 4.866804910003941\n","Valid Epoch #7, Batch 1861/4160 loss = 1.571378664970398, ppl = 4.862426202438175\n","Valid Epoch #7, Batch 1862/4160 loss = 1.5715481173992156, ppl = 4.863302124554631\n","Valid Epoch #7, Batch 1863/4160 loss = 1.5705935406684874, ppl = 4.858781016544558\n","Valid Epoch #7, Batch 1864/4160 loss = 1.5740979266166688, ppl = 4.876581545026043\n","Valid Epoch #7, Batch 1865/4160 loss = 1.5746153378486634, ppl = 4.879145837365042\n","Valid Epoch #7, Batch 1866/4160 loss = 1.5736514663696288, ppl = 4.874604071523658\n","Valid Epoch #7, Batch 1867/4160 loss = 1.574080046415329, ppl = 4.876893929614852\n","Valid Epoch #7, Batch 1868/4160 loss = 1.5747819578647613, ppl = 4.880219182362269\n","Valid Epoch #7, Batch 1869/4160 loss = 1.5754450631141663, ppl = 4.88376788067249\n","Valid Epoch #7, Batch 1870/4160 loss = 1.5761870217323304, ppl = 4.887250776635005\n","Valid Epoch #7, Batch 1871/4160 loss = 1.5731422758102418, ppl = 4.87168789133219\n","Valid Epoch #7, Batch 1872/4160 loss = 1.5720810973644257, ppl = 4.866744991740235\n","Valid Epoch #7, Batch 1873/4160 loss = 1.5715693855285644, ppl = 4.864067268636092\n","Valid Epoch #7, Batch 1874/4160 loss = 1.571631156206131, ppl = 4.864368214662007\n","Valid Epoch #7, Batch 1875/4160 loss = 1.5740042006969452, ppl = 4.876148048861292\n","Valid Epoch #7, Batch 1876/4160 loss = 1.5714549899101258, ppl = 4.865468136279766\n","Valid Epoch #7, Batch 1877/4160 loss = 1.5715003764629365, ppl = 4.865704283318538\n","Valid Epoch #7, Batch 1878/4160 loss = 1.5732012701034546, ppl = 4.872761732376935\n","Valid Epoch #7, Batch 1879/4160 loss = 1.5725414919853211, ppl = 4.869572709184122\n","Valid Epoch #7, Batch 1880/4160 loss = 1.5727840125560761, ppl = 4.870723541099795\n","Valid Epoch #7, Batch 1881/4160 loss = 1.5739607679843903, ppl = 4.876244285167914\n","Valid Epoch #7, Batch 1882/4160 loss = 1.5723581504821778, ppl = 4.868735854387624\n","Valid Epoch #7, Batch 1883/4160 loss = 1.573177193403244, ppl = 4.873072857179185\n","Valid Epoch #7, Batch 1884/4160 loss = 1.5724417769908905, ppl = 4.86942748599694\n","Valid Epoch #7, Batch 1885/4160 loss = 1.5742512261867523, ppl = 4.878017131830677\n","Valid Epoch #7, Batch 1886/4160 loss = 1.5742609441280364, ppl = 4.878067769101017\n","Valid Epoch #7, Batch 1887/4160 loss = 1.5756776642799377, ppl = 4.8851980315081\n","Valid Epoch #7, Batch 1888/4160 loss = 1.574729641675949, ppl = 4.8806629436824664\n","Valid Epoch #7, Batch 1889/4160 loss = 1.5743980038166046, ppl = 4.879050880133514\n","Valid Epoch #7, Batch 1890/4160 loss = 1.572647750377655, ppl = 4.869969577124214\n","Valid Epoch #7, Batch 1891/4160 loss = 1.5742571675777435, ppl = 4.878040145457543\n","Valid Epoch #7, Batch 1892/4160 loss = 1.5740067958831787, ppl = 4.876845198327736\n","Valid Epoch #7, Batch 1893/4160 loss = 1.575563280582428, ppl = 4.884054003925287\n","Valid Epoch #7, Batch 1894/4160 loss = 1.5759357881546021, ppl = 4.885837203610944\n","Valid Epoch #7, Batch 1895/4160 loss = 1.5757252025604247, ppl = 4.884810069354384\n","Valid Epoch #7, Batch 1896/4160 loss = 1.5764506888389587, ppl = 4.888109470133774\n","Valid Epoch #7, Batch 1897/4160 loss = 1.5765840101242066, ppl = 4.888811803153679\n","Valid Epoch #7, Batch 1898/4160 loss = 1.576430617570877, ppl = 4.88810392200758\n","Valid Epoch #7, Batch 1899/4160 loss = 1.5759642291069031, ppl = 4.885711231574179\n","Valid Epoch #7, Batch 1900/4160 loss = 1.5785367953777314, ppl = 4.898890941892537\n","Valid Epoch #7, Batch 1901/4160 loss = 1.5782704532146454, ppl = 4.897993807586641\n","Valid Epoch #7, Batch 1902/4160 loss = 1.58011545419693, ppl = 4.9052717298060395\n","Valid Epoch #7, Batch 1903/4160 loss = 1.5790323388576508, ppl = 4.901260040129452\n","Valid Epoch #7, Batch 1904/4160 loss = 1.5794878351688384, ppl = 4.902743979522063\n","Valid Epoch #7, Batch 1905/4160 loss = 1.5836140978336335, ppl = 4.918724583836446\n","Valid Epoch #7, Batch 1906/4160 loss = 1.5831789767742157, ppl = 4.9170662854127665\n","Valid Epoch #7, Batch 1907/4160 loss = 1.579931422472, ppl = 4.902187807951578\n","Valid Epoch #7, Batch 1908/4160 loss = 1.5791725933551788, ppl = 4.898987059236123\n","Valid Epoch #7, Batch 1909/4160 loss = 1.5768105828762053, ppl = 4.88690624422348\n","Valid Epoch #7, Batch 1910/4160 loss = 1.5787330627441407, ppl = 4.895379035305082\n","Valid Epoch #7, Batch 1911/4160 loss = 1.580756298303604, ppl = 4.903699093280404\n","Valid Epoch #7, Batch 1912/4160 loss = 1.5783719539642334, ppl = 4.892378126040126\n","Valid Epoch #7, Batch 1913/4160 loss = 1.5752580058574677, ppl = 4.878948347980568\n","Valid Epoch #7, Batch 1914/4160 loss = 1.576396803855896, ppl = 4.884389823196463\n","Valid Epoch #7, Batch 1915/4160 loss = 1.575432176589966, ppl = 4.880341875384656\n","Valid Epoch #7, Batch 1916/4160 loss = 1.5765379691123962, ppl = 4.885529626705727\n","Valid Epoch #7, Batch 1917/4160 loss = 1.5775023305416107, ppl = 4.890073455163352\n","Valid Epoch #7, Batch 1918/4160 loss = 1.5766092765331268, ppl = 4.886014037740533\n","Valid Epoch #7, Batch 1919/4160 loss = 1.5774444031715393, ppl = 4.889960962284203\n","Valid Epoch #7, Batch 1920/4160 loss = 1.577889038324356, ppl = 4.891930073355303\n","Valid Epoch #7, Batch 1921/4160 loss = 1.5814905261993408, ppl = 4.912159584991462\n","Valid Epoch #7, Batch 1922/4160 loss = 1.577712016105652, ppl = 4.891064788142713\n","Valid Epoch #7, Batch 1923/4160 loss = 1.5809526872634887, ppl = 4.904930555895976\n","Valid Epoch #7, Batch 1924/4160 loss = 1.5809123027324676, ppl = 4.904741720932178\n","Valid Epoch #7, Batch 1925/4160 loss = 1.5822857916355133, ppl = 4.911457245523285\n","Valid Epoch #7, Batch 1926/4160 loss = 1.581294926404953, ppl = 4.906757814719741\n","Valid Epoch #7, Batch 1927/4160 loss = 1.5827499175071715, ppl = 4.915397858889734\n","Valid Epoch #7, Batch 1928/4160 loss = 1.5822741270065308, ppl = 4.913617349078996\n","Valid Epoch #7, Batch 1929/4160 loss = 1.5840498805046082, ppl = 4.92409295118272\n","Valid Epoch #7, Batch 1930/4160 loss = 1.5817454886436462, ppl = 4.911330459971537\n","Valid Epoch #7, Batch 1931/4160 loss = 1.5815736138820649, ppl = 4.910457818407992\n","Valid Epoch #7, Batch 1932/4160 loss = 1.579993679523468, ppl = 4.90215847557854\n","Valid Epoch #7, Batch 1933/4160 loss = 1.5818449544906616, ppl = 4.911028647609588\n","Valid Epoch #7, Batch 1934/4160 loss = 1.583057690858841, ppl = 4.917496016190858\n","Valid Epoch #7, Batch 1935/4160 loss = 1.5836262047290801, ppl = 4.920361280348526\n","Valid Epoch #7, Batch 1936/4160 loss = 1.5853756201267242, ppl = 4.930227298694478\n","Valid Epoch #7, Batch 1937/4160 loss = 1.5878218495845795, ppl = 4.945320808084677\n","Valid Epoch #7, Batch 1938/4160 loss = 1.5906359839439392, ppl = 4.958221481113387\n","Valid Epoch #7, Batch 1939/4160 loss = 1.5870384752750397, ppl = 4.938814296825404\n","Valid Epoch #7, Batch 1940/4160 loss = 1.5817373871803284, ppl = 4.910576976696132\n","Valid Epoch #7, Batch 1941/4160 loss = 1.5822955238819123, ppl = 4.913386624488986\n","Valid Epoch #7, Batch 1942/4160 loss = 1.582248101234436, ppl = 4.913123691610092\n","Valid Epoch #7, Batch 1943/4160 loss = 1.582108155488968, ppl = 4.912353351817734\n","Valid Epoch #7, Batch 1944/4160 loss = 1.5836649537086487, ppl = 4.921343483121551\n","Valid Epoch #7, Batch 1945/4160 loss = 1.5847036802768708, ppl = 4.926491466060702\n","Valid Epoch #7, Batch 1946/4160 loss = 1.5835704290866852, ppl = 4.920765077961108\n","Valid Epoch #7, Batch 1947/4160 loss = 1.5835249507427216, ppl = 4.920494623376053\n","Valid Epoch #7, Batch 1948/4160 loss = 1.586247934103012, ppl = 4.936236847147528\n","Valid Epoch #7, Batch 1949/4160 loss = 1.5887855398654938, ppl = 4.948637813589371\n","Valid Epoch #7, Batch 1950/4160 loss = 1.5886351597309112, ppl = 4.947895521441925\n","Valid Epoch #7, Batch 1951/4160 loss = 1.5873549509048461, ppl = 4.942170743298674\n","Valid Epoch #7, Batch 1952/4160 loss = 1.5873123478889466, ppl = 4.941935312800732\n","Valid Epoch #7, Batch 1953/4160 loss = 1.5865872538089751, ppl = 4.938315958192725\n","Valid Epoch #7, Batch 1954/4160 loss = 1.586458958387375, ppl = 4.937678885420752\n","Valid Epoch #7, Batch 1955/4160 loss = 1.583878117799759, ppl = 4.923667418507062\n","Valid Epoch #7, Batch 1956/4160 loss = 1.5844811367988587, ppl = 4.926382539295223\n","Valid Epoch #7, Batch 1957/4160 loss = 1.583680876493454, ppl = 4.922621457741328\n","Valid Epoch #7, Batch 1958/4160 loss = 1.5838910484313964, ppl = 4.923649925398816\n","Valid Epoch #7, Batch 1959/4160 loss = 1.58549591422081, ppl = 4.931240152020436\n","Valid Epoch #7, Batch 1960/4160 loss = 1.5832513856887818, ppl = 4.919019712906541\n","Valid Epoch #7, Batch 1961/4160 loss = 1.583643058538437, ppl = 4.9209340765763026\n","Valid Epoch #7, Batch 1962/4160 loss = 1.586189956665039, ppl = 4.936055129962584\n","Valid Epoch #7, Batch 1963/4160 loss = 1.5851068806648254, ppl = 4.931421799490993\n","Valid Epoch #7, Batch 1964/4160 loss = 1.5821831238269806, ppl = 4.916156821143875\n","Valid Epoch #7, Batch 1965/4160 loss = 1.584164581298828, ppl = 4.927300804934143\n","Valid Epoch #7, Batch 1966/4160 loss = 1.5831976675987243, ppl = 4.923163972602606\n","Valid Epoch #7, Batch 1967/4160 loss = 1.5828388142585754, ppl = 4.9212400049063785\n","Valid Epoch #7, Batch 1968/4160 loss = 1.5806900477409362, ppl = 4.9117545198819546\n","Valid Epoch #7, Batch 1969/4160 loss = 1.5785923635959624, ppl = 4.901288257338212\n","Valid Epoch #7, Batch 1970/4160 loss = 1.5767251324653626, ppl = 4.8929925192410115\n","Valid Epoch #7, Batch 1971/4160 loss = 1.5794816970825196, ppl = 4.906871173468448\n","Valid Epoch #7, Batch 1972/4160 loss = 1.5806219923496245, ppl = 4.912204033698853\n","Valid Epoch #7, Batch 1973/4160 loss = 1.5781010448932649, ppl = 4.900839472950132\n","Valid Epoch #7, Batch 1974/4160 loss = 1.5780267477035523, ppl = 4.900477724288424\n","Valid Epoch #7, Batch 1975/4160 loss = 1.5748432028293609, ppl = 4.885273706500246\n","Valid Epoch #7, Batch 1976/4160 loss = 1.5780277466773986, ppl = 4.899066859318865\n","Valid Epoch #7, Batch 1977/4160 loss = 1.5773170924186706, ppl = 4.895489532855495\n","Valid Epoch #7, Batch 1978/4160 loss = 1.5789733958244323, ppl = 4.903617538959013\n","Valid Epoch #7, Batch 1979/4160 loss = 1.5806079614162445, ppl = 4.911920518475831\n","Valid Epoch #7, Batch 1980/4160 loss = 1.579900952577591, ppl = 4.9086419690855685\n","Valid Epoch #7, Batch 1981/4160 loss = 1.5814435648918153, ppl = 4.916936627289476\n","Valid Epoch #7, Batch 1982/4160 loss = 1.5835547876358032, ppl = 4.927090674596105\n","Valid Epoch #7, Batch 1983/4160 loss = 1.58121861577034, ppl = 4.915600951449701\n","Valid Epoch #7, Batch 1984/4160 loss = 1.5809819066524506, ppl = 4.914483506175162\n","Valid Epoch #7, Batch 1985/4160 loss = 1.579285019636154, ppl = 4.906384072308519\n","Valid Epoch #7, Batch 1986/4160 loss = 1.5784832525253296, ppl = 4.902367446037425\n","Valid Epoch #7, Batch 1987/4160 loss = 1.5772981095314025, ppl = 4.896334744656344\n","Valid Epoch #7, Batch 1988/4160 loss = 1.5765861105918884, ppl = 4.893200531311821\n","Valid Epoch #7, Batch 1989/4160 loss = 1.577019875049591, ppl = 4.895319886824328\n","Valid Epoch #7, Batch 1990/4160 loss = 1.578007173538208, ppl = 4.900246523325016\n","Valid Epoch #7, Batch 1991/4160 loss = 1.576350862979889, ppl = 4.891959726822174\n","Valid Epoch #7, Batch 1992/4160 loss = 1.5758900356292724, ppl = 4.889837043039863\n","Valid Epoch #7, Batch 1993/4160 loss = 1.5762079930305481, ppl = 4.891452778960367\n","Valid Epoch #7, Batch 1994/4160 loss = 1.5755831062793733, ppl = 4.888498636772922\n","Valid Epoch #7, Batch 1995/4160 loss = 1.5760901868343353, ppl = 4.891009091086433\n","Valid Epoch #7, Batch 1996/4160 loss = 1.5783848452568054, ppl = 4.903169906190365\n","Valid Epoch #7, Batch 1997/4160 loss = 1.577942420244217, ppl = 4.900874796913166\n","Valid Epoch #7, Batch 1998/4160 loss = 1.578613075017929, ppl = 4.904051410759299\n","Valid Epoch #7, Batch 1999/4160 loss = 1.57761394739151, ppl = 4.899286248774517\n","Valid Epoch #7, Batch 2000/4160 loss = 1.5787593710422516, ppl = 4.906337740941178\n","Valid Epoch #7, Batch 2001/4160 loss = 1.5811035776138305, ppl = 4.915118150825133\n","Valid Epoch #7, Batch 2002/4160 loss = 1.57716038107872, ppl = 4.901041747515588\n","Valid Epoch #7, Batch 2003/4160 loss = 1.5785754561424254, ppl = 4.90637252485747\n","Valid Epoch #7, Batch 2004/4160 loss = 1.5812622809410095, ppl = 4.916644957011653\n","Valid Epoch #7, Batch 2005/4160 loss = 1.5804846322536468, ppl = 4.913108512733103\n","Valid Epoch #7, Batch 2006/4160 loss = 1.5799491727352142, ppl = 4.911164402168492\n","Valid Epoch #7, Batch 2007/4160 loss = 1.5780976998806, ppl = 4.9046103667442065\n","Valid Epoch #7, Batch 2008/4160 loss = 1.577340919971466, ppl = 4.901651226194043\n","Valid Epoch #7, Batch 2009/4160 loss = 1.5761982238292693, ppl = 4.896754919707237\n","Valid Epoch #7, Batch 2010/4160 loss = 1.5758481621742249, ppl = 4.895088411539089\n","Valid Epoch #7, Batch 2011/4160 loss = 1.574685161113739, ppl = 4.890101358245077\n","Valid Epoch #7, Batch 2012/4160 loss = 1.5748488569259644, ppl = 4.890795275905928\n","Valid Epoch #7, Batch 2013/4160 loss = 1.5791923749446868, ppl = 4.910791785689959\n","Valid Epoch #7, Batch 2014/4160 loss = 1.5776240825653076, ppl = 4.903453730587515\n","Valid Epoch #7, Batch 2015/4160 loss = 1.5779092133045196, ppl = 4.9046098712491775\n","Valid Epoch #7, Batch 2016/4160 loss = 1.5775295674800873, ppl = 4.90276376352951\n","Valid Epoch #7, Batch 2017/4160 loss = 1.5774474585056304, ppl = 4.902359594029702\n","Valid Epoch #7, Batch 2018/4160 loss = 1.5803065478801728, ppl = 4.916742264243072\n","Valid Epoch #7, Batch 2019/4160 loss = 1.5799341928958892, ppl = 4.914941688030888\n","Valid Epoch #7, Batch 2020/4160 loss = 1.580559058189392, ppl = 4.917861209063741\n","Valid Epoch #7, Batch 2021/4160 loss = 1.5756960320472717, ppl = 4.892101406842761\n","Valid Epoch #7, Batch 2022/4160 loss = 1.5760085809230804, ppl = 4.89356004482949\n","Valid Epoch #7, Batch 2023/4160 loss = 1.5764742803573608, ppl = 4.895948065031343\n","Valid Epoch #7, Batch 2024/4160 loss = 1.5775588166713714, ppl = 4.901293677355883\n","Valid Epoch #7, Batch 2025/4160 loss = 1.5768400847911834, ppl = 4.89766463761187\n","Valid Epoch #7, Batch 2026/4160 loss = 1.5781768882274627, ppl = 4.904117551259042\n","Valid Epoch #7, Batch 2027/4160 loss = 1.5785740578174592, ppl = 4.906702764075401\n","Valid Epoch #7, Batch 2028/4160 loss = 1.5827771270275115, ppl = 4.9257917584240465\n","Valid Epoch #7, Batch 2029/4160 loss = 1.5809941267967225, ppl = 4.915277103648579\n","Valid Epoch #7, Batch 2030/4160 loss = 1.5822958302497865, ppl = 4.92212353346847\n","Valid Epoch #7, Batch 2031/4160 loss = 1.5827821743488313, ppl = 4.924632145533089\n","Valid Epoch #7, Batch 2032/4160 loss = 1.585658940076828, ppl = 4.940794863939152\n","Valid Epoch #7, Batch 2033/4160 loss = 1.587347425222397, ppl = 4.950449125336918\n","Valid Epoch #7, Batch 2034/4160 loss = 1.5860066711902618, ppl = 4.943343708000301\n","Valid Epoch #7, Batch 2035/4160 loss = 1.5844184458255768, ppl = 4.935730094090709\n","Valid Epoch #7, Batch 2036/4160 loss = 1.5808266413211822, ppl = 4.917180558242922\n","Valid Epoch #7, Batch 2037/4160 loss = 1.578817607164383, ppl = 4.904520906534869\n","Valid Epoch #7, Batch 2038/4160 loss = 1.5781425082683562, ppl = 4.901087431759498\n","Valid Epoch #7, Batch 2039/4160 loss = 1.5778914213180542, ppl = 4.899975992805494\n","Valid Epoch #7, Batch 2040/4160 loss = 1.5806761634349824, ppl = 4.912945717689434\n","Valid Epoch #7, Batch 2041/4160 loss = 1.5821810114383696, ppl = 4.921351040953708\n","Valid Epoch #7, Batch 2042/4160 loss = 1.5818554413318635, ppl = 4.919579207239407\n","Valid Epoch #7, Batch 2043/4160 loss = 1.5799774467945098, ppl = 4.910220143257972\n","Valid Epoch #7, Batch 2044/4160 loss = 1.578525264263153, ppl = 4.9017912670311805\n","Valid Epoch #7, Batch 2045/4160 loss = 1.5799398028850555, ppl = 4.90971973795837\n","Valid Epoch #7, Batch 2046/4160 loss = 1.5800325059890747, ppl = 4.910164187888052\n","Valid Epoch #7, Batch 2047/4160 loss = 1.5778913938999175, ppl = 4.898728118574434\n","Valid Epoch #7, Batch 2048/4160 loss = 1.5765205252170562, ppl = 4.890267991918268\n","Valid Epoch #7, Batch 2049/4160 loss = 1.5757343125343324, ppl = 4.886084396675338\n","Valid Epoch #7, Batch 2050/4160 loss = 1.577106419801712, ppl = 4.893289471008743\n","Valid Epoch #7, Batch 2051/4160 loss = 1.5768874537944795, ppl = 4.892381624314237\n","Valid Epoch #7, Batch 2052/4160 loss = 1.5765119016170501, ppl = 4.890349090732304\n","Valid Epoch #7, Batch 2053/4160 loss = 1.5779149103164674, ppl = 4.897598103669571\n","Valid Epoch #7, Batch 2054/4160 loss = 1.5766953992843629, ppl = 4.891933591929388\n","Valid Epoch #7, Batch 2055/4160 loss = 1.5777661776542664, ppl = 4.897311758596201\n","Valid Epoch #7, Batch 2056/4160 loss = 1.5779595184326172, ppl = 4.8982175231473475\n","Valid Epoch #7, Batch 2057/4160 loss = 1.5776046180725098, ppl = 4.8966435010288585\n","Valid Epoch #7, Batch 2058/4160 loss = 1.57826021194458, ppl = 4.899994084492882\n","Valid Epoch #7, Batch 2059/4160 loss = 1.5789716243743896, ppl = 4.903768593141965\n","Valid Epoch #7, Batch 2060/4160 loss = 1.5796189630031585, ppl = 4.9070162881337644\n","Valid Epoch #7, Batch 2061/4160 loss = 1.5784558689594268, ppl = 4.901543840466276\n","Valid Epoch #7, Batch 2062/4160 loss = 1.576020599603653, ppl = 4.887007973846373\n","Valid Epoch #7, Batch 2063/4160 loss = 1.580635735988617, ppl = 4.910762797070362\n","Valid Epoch #7, Batch 2064/4160 loss = 1.583073468208313, ppl = 4.92317120548133\n","Valid Epoch #7, Batch 2065/4160 loss = 1.5808834028244019, ppl = 4.910977371167592\n","Valid Epoch #7, Batch 2066/4160 loss = 1.5822798204421997, ppl = 4.917084059013811\n","Valid Epoch #7, Batch 2067/4160 loss = 1.5797712647914885, ppl = 4.905401059509928\n","Valid Epoch #7, Batch 2068/4160 loss = 1.5824008440971375, ppl = 4.917302859578594\n","Valid Epoch #7, Batch 2069/4160 loss = 1.5823920750617981, ppl = 4.917263552899926\n","Valid Epoch #7, Batch 2070/4160 loss = 1.5851805365085603, ppl = 4.9302592998553285\n","Valid Epoch #7, Batch 2071/4160 loss = 1.5838486301898955, ppl = 4.923075805877801\n","Valid Epoch #7, Batch 2072/4160 loss = 1.5831941914558412, ppl = 4.919941045504866\n","Valid Epoch #7, Batch 2073/4160 loss = 1.586102077960968, ppl = 4.9333177224975335\n","Valid Epoch #7, Batch 2074/4160 loss = 1.5841288352012635, ppl = 4.924630985799939\n","Valid Epoch #7, Batch 2075/4160 loss = 1.588191398382187, ppl = 4.94495854354146\n","Valid Epoch #7, Batch 2076/4160 loss = 1.587646222114563, ppl = 4.942275136265337\n","Valid Epoch #7, Batch 2077/4160 loss = 1.5880448353290557, ppl = 4.944250346771572\n","Valid Epoch #7, Batch 2078/4160 loss = 1.5883852541446686, ppl = 4.946094260568568\n","Valid Epoch #7, Batch 2079/4160 loss = 1.5855535447597504, ppl = 4.932515775562702\n","Valid Epoch #7, Batch 2080/4160 loss = 1.5870740711688995, ppl = 4.9398650422172565\n","Valid Epoch #7, Batch 2081/4160 loss = 1.586406066417694, ppl = 4.93611562877372\n","Valid Epoch #7, Batch 2082/4160 loss = 1.5860369575023652, ppl = 4.934182291752588\n","Valid Epoch #7, Batch 2083/4160 loss = 1.5870116317272187, ppl = 4.938652054261737\n","Valid Epoch #7, Batch 2084/4160 loss = 1.586854293346405, ppl = 4.937923798950685\n","Valid Epoch #7, Batch 2085/4160 loss = 1.5875831139087677, ppl = 4.9412349290823565\n","Valid Epoch #7, Batch 2086/4160 loss = 1.5888757121562957, ppl = 4.947874209257524\n","Valid Epoch #7, Batch 2087/4160 loss = 1.5895472502708434, ppl = 4.951204532746016\n","Valid Epoch #7, Batch 2088/4160 loss = 1.592000515460968, ppl = 4.963013220278828\n","Valid Epoch #7, Batch 2089/4160 loss = 1.592514134645462, ppl = 4.9656445601785855\n","Valid Epoch #7, Batch 2090/4160 loss = 1.5914297878742218, ppl = 4.960259392425271\n","Valid Epoch #7, Batch 2091/4160 loss = 1.592061266899109, ppl = 4.963258042169492\n","Valid Epoch #7, Batch 2092/4160 loss = 1.5921030962467193, ppl = 4.9634467072864155\n","Valid Epoch #7, Batch 2093/4160 loss = 1.5912254273891449, ppl = 4.959108610491445\n","Valid Epoch #7, Batch 2094/4160 loss = 1.5922448170185088, ppl = 4.964025089363221\n","Valid Epoch #7, Batch 2095/4160 loss = 1.5925429236888886, ppl = 4.965561477801224\n","Valid Epoch #7, Batch 2096/4160 loss = 1.5909009623527526, ppl = 4.956580656428382\n","Valid Epoch #7, Batch 2097/4160 loss = 1.591383203268051, ppl = 4.959087337056271\n","Valid Epoch #7, Batch 2098/4160 loss = 1.591932464838028, ppl = 4.961852418763288\n","Valid Epoch #7, Batch 2099/4160 loss = 1.5942614686489105, ppl = 4.973745798297255\n","Valid Epoch #7, Batch 2100/4160 loss = 1.5908945572376252, ppl = 4.955119798674718\n","Valid Epoch #7, Batch 2101/4160 loss = 1.5893902885913849, ppl = 4.9492516815212735\n","Valid Epoch #7, Batch 2102/4160 loss = 1.5912476658821106, ppl = 4.955195485790325\n","Valid Epoch #7, Batch 2103/4160 loss = 1.5901979577541352, ppl = 4.9511697010485785\n","Valid Epoch #7, Batch 2104/4160 loss = 1.5884561836719513, ppl = 4.944200378367625\n","Valid Epoch #7, Batch 2105/4160 loss = 1.5881584703922271, ppl = 4.9429176431803805\n","Valid Epoch #7, Batch 2106/4160 loss = 1.5878000581264495, ppl = 4.941673305176545\n","Valid Epoch #7, Batch 2107/4160 loss = 1.5884562194347382, ppl = 4.943858569465932\n","Valid Epoch #7, Batch 2108/4160 loss = 1.5903009259700776, ppl = 4.951483910806354\n","Valid Epoch #7, Batch 2109/4160 loss = 1.5897264182567596, ppl = 4.949225678814101\n","Valid Epoch #7, Batch 2110/4160 loss = 1.590048679113388, ppl = 4.950757695139444\n","Valid Epoch #7, Batch 2111/4160 loss = 1.5895835542678833, ppl = 4.94891999964036\n","Valid Epoch #7, Batch 2112/4160 loss = 1.5893425476551055, ppl = 4.94790228456054\n","Valid Epoch #7, Batch 2113/4160 loss = 1.58473726272583, ppl = 4.926955982496094\n","Valid Epoch #7, Batch 2114/4160 loss = 1.5868488335609436, ppl = 4.937116557599229\n","Valid Epoch #7, Batch 2115/4160 loss = 1.586920223236084, ppl = 4.937411223576678\n","Valid Epoch #7, Batch 2116/4160 loss = 1.5859342968463899, ppl = 4.932931825271939\n","Valid Epoch #7, Batch 2117/4160 loss = 1.585661827325821, ppl = 4.931614164925574\n","Valid Epoch #7, Batch 2118/4160 loss = 1.582788289785385, ppl = 4.917168754169048\n","Valid Epoch #7, Batch 2119/4160 loss = 1.582678450345993, ppl = 4.91665028967538\n","Valid Epoch #7, Batch 2120/4160 loss = 1.5808010303974152, ppl = 4.908400274821133\n","Valid Epoch #7, Batch 2121/4160 loss = 1.5858501017093658, ppl = 4.935416190133279\n","Valid Epoch #7, Batch 2122/4160 loss = 1.5865968656539917, ppl = 4.9390915412505025\n","Valid Epoch #7, Batch 2123/4160 loss = 1.5847961401939392, ppl = 4.93044310802156\n","Valid Epoch #7, Batch 2124/4160 loss = 1.5886606204509734, ppl = 4.954978739514532\n","Valid Epoch #7, Batch 2125/4160 loss = 1.588399839401245, ppl = 4.953725165951977\n","Valid Epoch #7, Batch 2126/4160 loss = 1.5887273681163787, ppl = 4.955442181701922\n","Valid Epoch #7, Batch 2127/4160 loss = 1.5867644464969635, ppl = 4.943609263471648\n","Valid Epoch #7, Batch 2128/4160 loss = 1.5874756932258607, ppl = 4.947709881369754\n","Valid Epoch #7, Batch 2129/4160 loss = 1.586781132221222, ppl = 4.944095228254116\n","Valid Epoch #7, Batch 2130/4160 loss = 1.5837745928764344, ppl = 4.929529679150271\n","Valid Epoch #7, Batch 2131/4160 loss = 1.5813761293888091, ppl = 4.918260312848692\n","Valid Epoch #7, Batch 2132/4160 loss = 1.580792976617813, ppl = 4.914597940967799\n","Valid Epoch #7, Batch 2133/4160 loss = 1.5775806021690368, ppl = 4.897525048622485\n","Valid Epoch #7, Batch 2134/4160 loss = 1.5794319057464599, ppl = 4.907596668790448\n","Valid Epoch #7, Batch 2135/4160 loss = 1.5824533700942993, ppl = 4.923199843243781\n","Valid Epoch #7, Batch 2136/4160 loss = 1.5835145592689515, ppl = 4.928005284728687\n","Valid Epoch #7, Batch 2137/4160 loss = 1.5856878459453583, ppl = 4.9418168331718375\n","Valid Epoch #7, Batch 2138/4160 loss = 1.5872610354423522, ppl = 4.950192407217231\n","Valid Epoch #7, Batch 2139/4160 loss = 1.5886707389354706, ppl = 4.956809944949338\n","Valid Epoch #7, Batch 2140/4160 loss = 1.5896319961547851, ppl = 4.962193802498265\n","Valid Epoch #7, Batch 2141/4160 loss = 1.5878387367725373, ppl = 4.952317049984745\n","Valid Epoch #7, Batch 2142/4160 loss = 1.5868552923202515, ppl = 4.94730218547591\n","Valid Epoch #7, Batch 2143/4160 loss = 1.5896577227115631, ppl = 4.9619552683444805\n","Valid Epoch #7, Batch 2144/4160 loss = 1.5913413655757904, ppl = 4.971844346901574\n","Valid Epoch #7, Batch 2145/4160 loss = 1.5912800168991088, ppl = 4.971476723933753\n","Valid Epoch #7, Batch 2146/4160 loss = 1.5924199736118316, ppl = 4.97729262976401\n","Valid Epoch #7, Batch 2147/4160 loss = 1.5934816122055053, ppl = 4.982657364901768\n","Valid Epoch #7, Batch 2148/4160 loss = 1.5910036480426788, ppl = 4.970019601191927\n","Valid Epoch #7, Batch 2149/4160 loss = 1.5921189928054809, ppl = 4.976054625115767\n","Valid Epoch #7, Batch 2150/4160 loss = 1.59174173951149, ppl = 4.973974106787875\n","Valid Epoch #7, Batch 2151/4160 loss = 1.5933859503269197, ppl = 4.9813027323211685\n","Valid Epoch #7, Batch 2152/4160 loss = 1.5933947849273682, ppl = 4.981349674763343\n","Valid Epoch #7, Batch 2153/4160 loss = 1.5967837595939636, ppl = 5.0036886686896205\n","Valid Epoch #7, Batch 2154/4160 loss = 1.5970557260513305, ppl = 5.0048927636028235\n","Valid Epoch #7, Batch 2155/4160 loss = 1.5948880290985108, ppl = 4.9945709394764455\n","Valid Epoch #7, Batch 2156/4160 loss = 1.5956219375133514, ppl = 4.998173069481417\n","Valid Epoch #7, Batch 2157/4160 loss = 1.5970703160762787, ppl = 5.004963351436519\n","Valid Epoch #7, Batch 2158/4160 loss = 1.5962488210201264, ppl = 5.00079914404834\n","Valid Epoch #7, Batch 2159/4160 loss = 1.5944505178928374, ppl = 4.9917523688336685\n","Valid Epoch #7, Batch 2160/4160 loss = 1.5945446801185608, ppl = 4.992242539922176\n","Valid Epoch #7, Batch 2161/4160 loss = 1.596783425807953, ppl = 5.003374991870161\n","Valid Epoch #7, Batch 2162/4160 loss = 1.595112338066101, ppl = 4.995262442751615\n","Valid Epoch #7, Batch 2163/4160 loss = 1.5927881968021393, ppl = 4.981936201292964\n","Valid Epoch #7, Batch 2164/4160 loss = 1.5909407544136047, ppl = 4.9722609646537785\n","Valid Epoch #7, Batch 2165/4160 loss = 1.5901197564601899, ppl = 4.968335462231458\n","Valid Epoch #7, Batch 2166/4160 loss = 1.5906015467643737, ppl = 4.970648178861878\n","Valid Epoch #7, Batch 2167/4160 loss = 1.5915156149864196, ppl = 4.97457009608882\n","Valid Epoch #7, Batch 2168/4160 loss = 1.5901530289649963, ppl = 4.968013354009101\n","Valid Epoch #7, Batch 2169/4160 loss = 1.5896037006378174, ppl = 4.965618482689598\n","Valid Epoch #7, Batch 2170/4160 loss = 1.5898475563526153, ppl = 4.9669368004863\n","Valid Epoch #7, Batch 2171/4160 loss = 1.589631644487381, ppl = 4.965859800769758\n","Valid Epoch #7, Batch 2172/4160 loss = 1.5887945127487182, ppl = 4.962137688876329\n","Valid Epoch #7, Batch 2173/4160 loss = 1.5885453140735626, ppl = 4.960832926649227\n","Valid Epoch #7, Batch 2174/4160 loss = 1.5893484675884246, ppl = 4.964163192483248\n","Valid Epoch #7, Batch 2175/4160 loss = 1.5875703310966491, ppl = 4.954244706624027\n","Valid Epoch #7, Batch 2176/4160 loss = 1.5878418433666228, ppl = 4.955562830210466\n","Valid Epoch #7, Batch 2177/4160 loss = 1.5868938100337981, ppl = 4.950991014990652\n","Valid Epoch #7, Batch 2178/4160 loss = 1.5844948542118074, ppl = 4.939240181406372\n","Valid Epoch #7, Batch 2179/4160 loss = 1.5861156511306762, ppl = 4.946539155661667\n","Valid Epoch #7, Batch 2180/4160 loss = 1.5848236465454102, ppl = 4.940224348182861\n","Valid Epoch #7, Batch 2181/4160 loss = 1.582639034986496, ppl = 4.9295731917969166\n","Valid Epoch #7, Batch 2182/4160 loss = 1.581383807659149, ppl = 4.923507730622559\n","Valid Epoch #7, Batch 2183/4160 loss = 1.5826192283630371, ppl = 4.929836739469929\n","Valid Epoch #7, Batch 2184/4160 loss = 1.5831842947006225, ppl = 4.932506396174366\n","Valid Epoch #7, Batch 2185/4160 loss = 1.5824820971488953, ppl = 4.929312019240475\n","Valid Epoch #7, Batch 2186/4160 loss = 1.581966528892517, ppl = 4.926560564375738\n","Valid Epoch #7, Batch 2187/4160 loss = 1.5824349427223205, ppl = 4.929019557452736\n","Valid Epoch #7, Batch 2188/4160 loss = 1.5792081487178802, ppl = 4.9140494337485325\n","Valid Epoch #7, Batch 2189/4160 loss = 1.577965077161789, ppl = 4.907905821007924\n","Valid Epoch #7, Batch 2190/4160 loss = 1.5788462686538696, ppl = 4.912237114717958\n","Valid Epoch #7, Batch 2191/4160 loss = 1.57928795337677, ppl = 4.914449933193577\n","Valid Epoch #7, Batch 2192/4160 loss = 1.5804403948783874, ppl = 4.919970741374112\n","Valid Epoch #7, Batch 2193/4160 loss = 1.5820250499248505, ppl = 4.9280910067973815\n","Valid Epoch #7, Batch 2194/4160 loss = 1.5825091779232026, ppl = 4.93060739142124\n","Valid Epoch #7, Batch 2195/4160 loss = 1.5819272541999816, ppl = 4.927650212613906\n","Valid Epoch #7, Batch 2196/4160 loss = 1.582279086112976, ppl = 4.929452434262315\n","Valid Epoch #7, Batch 2197/4160 loss = 1.581324529647827, ppl = 4.924605097861954\n","Valid Epoch #7, Batch 2198/4160 loss = 1.5817643070220948, ppl = 4.926931146282307\n","Valid Epoch #7, Batch 2199/4160 loss = 1.5806104004383088, ppl = 4.920692613673407\n","Valid Epoch #7, Batch 2200/4160 loss = 1.5814695084095, ppl = 4.9248667202968965\n","Valid Epoch #7, Batch 2201/4160 loss = 1.5823201858997344, ppl = 4.928076441480212\n","Valid Epoch #7, Batch 2202/4160 loss = 1.5805750739574433, ppl = 4.922461408331286\n","Valid Epoch #7, Batch 2203/4160 loss = 1.5816126072406769, ppl = 4.926438037153783\n","Valid Epoch #7, Batch 2204/4160 loss = 1.5808692252635956, ppl = 4.9238138340085245\n","Valid Epoch #7, Batch 2205/4160 loss = 1.5798346042633056, ppl = 4.919641621066409\n","Valid Epoch #7, Batch 2206/4160 loss = 1.5817552864551545, ppl = 4.926862322229652\n","Valid Epoch #7, Batch 2207/4160 loss = 1.5834281206130982, ppl = 4.933127711946548\n","Valid Epoch #7, Batch 2208/4160 loss = 1.583156747817993, ppl = 4.931915829384325\n","Valid Epoch #7, Batch 2209/4160 loss = 1.5830368638038634, ppl = 4.931460738308264\n","Valid Epoch #7, Batch 2210/4160 loss = 1.5792596971988677, ppl = 4.916263681226295\n","Valid Epoch #7, Batch 2211/4160 loss = 1.58142129778862, ppl = 4.9255774190669435\n","Valid Epoch #7, Batch 2212/4160 loss = 1.5816253340244293, ppl = 4.926437419707279\n","Valid Epoch #7, Batch 2213/4160 loss = 1.583089052438736, ppl = 4.932082195471407\n","Valid Epoch #7, Batch 2214/4160 loss = 1.5797135138511658, ppl = 4.9167902629612605\n","Valid Epoch #7, Batch 2215/4160 loss = 1.5807676911354065, ppl = 4.921395476493494\n","Valid Epoch #7, Batch 2216/4160 loss = 1.5825905203819275, ppl = 4.930039570989226\n","Valid Epoch #7, Batch 2217/4160 loss = 1.5843000042438506, ppl = 4.938933019101071\n","Valid Epoch #7, Batch 2218/4160 loss = 1.5850295782089234, ppl = 4.942217221535282\n","Valid Epoch #7, Batch 2219/4160 loss = 1.585200585126877, ppl = 4.943026887223622\n","Valid Epoch #7, Batch 2220/4160 loss = 1.5865381491184234, ppl = 4.948743925691197\n","Valid Epoch #7, Batch 2221/4160 loss = 1.584507384300232, ppl = 4.936219663830459\n","Valid Epoch #7, Batch 2222/4160 loss = 1.581694073677063, ppl = 4.923694337357126\n","Valid Epoch #7, Batch 2223/4160 loss = 1.582541630268097, ppl = 4.927571412415927\n","Valid Epoch #7, Batch 2224/4160 loss = 1.578422074317932, ppl = 4.901725896746586\n","Valid Epoch #7, Batch 2225/4160 loss = 1.5779600358009338, ppl = 4.899583585969278\n","Valid Epoch #7, Batch 2226/4160 loss = 1.5784711337089539, ppl = 4.902377849760436\n","Valid Epoch #7, Batch 2227/4160 loss = 1.5777145838737487, ppl = 4.8984024534414425\n","Valid Epoch #7, Batch 2228/4160 loss = 1.5771498334407807, ppl = 4.895122762679689\n","Valid Epoch #7, Batch 2229/4160 loss = 1.575599491596222, ppl = 4.887905312219635\n","Valid Epoch #7, Batch 2230/4160 loss = 1.5778501391410829, ppl = 4.898387096712691\n","Valid Epoch #7, Batch 2231/4160 loss = 1.5784463810920715, ppl = 4.900941432715174\n","Valid Epoch #7, Batch 2232/4160 loss = 1.5774299144744872, ppl = 4.895046710597715\n","Valid Epoch #7, Batch 2233/4160 loss = 1.5791179895401002, ppl = 4.903334195257103\n","Valid Epoch #7, Batch 2234/4160 loss = 1.5793948316574096, ppl = 4.905007056069546\n","Valid Epoch #7, Batch 2235/4160 loss = 1.5769843637943268, ppl = 4.892190698106038\n","Valid Epoch #7, Batch 2236/4160 loss = 1.580041172504425, ppl = 4.909256068768451\n","Valid Epoch #7, Batch 2237/4160 loss = 1.5798511028289794, ppl = 4.907924831758353\n","Valid Epoch #7, Batch 2238/4160 loss = 1.5769373881816864, ppl = 4.893381669478643\n","Valid Epoch #7, Batch 2239/4160 loss = 1.5759638166427612, ppl = 4.8887127222956925\n","Valid Epoch #7, Batch 2240/4160 loss = 1.5732243418693543, ppl = 4.87463612355458\n","Valid Epoch #7, Batch 2241/4160 loss = 1.574169397354126, ppl = 4.879620257435999\n","Valid Epoch #7, Batch 2242/4160 loss = 1.5753957450389862, ppl = 4.885951583382027\n","Valid Epoch #7, Batch 2243/4160 loss = 1.574928687810898, ppl = 4.883215713136236\n","Valid Epoch #7, Batch 2244/4160 loss = 1.5730533385276795, ppl = 4.872302602317168\n","Valid Epoch #7, Batch 2245/4160 loss = 1.5714672815799713, ppl = 4.863540714508407\n","Valid Epoch #7, Batch 2246/4160 loss = 1.5714411973953246, ppl = 4.863400090749653\n","Valid Epoch #7, Batch 2247/4160 loss = 1.5697074925899506, ppl = 4.854922101824015\n","Valid Epoch #7, Batch 2248/4160 loss = 1.5720302116870881, ppl = 4.866672864709643\n","Valid Epoch #7, Batch 2249/4160 loss = 1.5699594402313233, ppl = 4.855977248736881\n","Valid Epoch #7, Batch 2250/4160 loss = 1.5684886682033539, ppl = 4.848575742287545\n","Valid Epoch #7, Batch 2251/4160 loss = 1.5700543105602265, ppl = 4.856768178199882\n","Valid Epoch #7, Batch 2252/4160 loss = 1.5706917190551757, ppl = 4.860266849227041\n","Valid Epoch #7, Batch 2253/4160 loss = 1.5678231263160705, ppl = 4.840885864177499\n","Valid Epoch #7, Batch 2254/4160 loss = 1.569424674510956, ppl = 4.848680914160384\n","Valid Epoch #7, Batch 2255/4160 loss = 1.5702602541446686, ppl = 4.852397083922525\n","Valid Epoch #7, Batch 2256/4160 loss = 1.5701785922050475, ppl = 4.851983080145546\n","Valid Epoch #7, Batch 2257/4160 loss = 1.5693953812122345, ppl = 4.848189407288132\n","Valid Epoch #7, Batch 2258/4160 loss = 1.5685291349887849, ppl = 4.844153570638048\n","Valid Epoch #7, Batch 2259/4160 loss = 1.5694439005851746, ppl = 4.848552240086127\n","Valid Epoch #7, Batch 2260/4160 loss = 1.5682438480854035, ppl = 4.842637766671172\n","Valid Epoch #7, Batch 2261/4160 loss = 1.5667247879505157, ppl = 4.834816092506284\n","Valid Epoch #7, Batch 2262/4160 loss = 1.5656475985050202, ppl = 4.830261213597667\n","Valid Epoch #7, Batch 2263/4160 loss = 1.565015617609024, ppl = 4.827141943494152\n","Valid Epoch #7, Batch 2264/4160 loss = 1.5651233530044555, ppl = 4.827658427062982\n","Valid Epoch #7, Batch 2265/4160 loss = 1.5660849130153656, ppl = 4.832288919396486\n","Valid Epoch #7, Batch 2266/4160 loss = 1.5654096114635467, ppl = 4.829078213042264\n","Valid Epoch #7, Batch 2267/4160 loss = 1.5682861053943633, ppl = 4.844041925100676\n","Valid Epoch #7, Batch 2268/4160 loss = 1.5704241228103637, ppl = 4.8547488468004625\n","Valid Epoch #7, Batch 2269/4160 loss = 1.5706395161151887, ppl = 4.855672236173608\n","Valid Epoch #7, Batch 2270/4160 loss = 1.5706048440933227, ppl = 4.855482828239127\n","Valid Epoch #7, Batch 2271/4160 loss = 1.5681306171417235, ppl = 4.844666950559892\n","Valid Epoch #7, Batch 2272/4160 loss = 1.5708502864837646, ppl = 4.8579899293949\n","Valid Epoch #7, Batch 2273/4160 loss = 1.5695887982845307, ppl = 4.851861610177188\n","Valid Epoch #7, Batch 2274/4160 loss = 1.5706170177459717, ppl = 4.856534746948102\n","Valid Epoch #7, Batch 2275/4160 loss = 1.5724019026756286, ppl = 4.8664943354589125\n","Valid Epoch #7, Batch 2276/4160 loss = 1.570843436717987, ppl = 4.859392931354161\n","Valid Epoch #7, Batch 2277/4160 loss = 1.5698442244529724, ppl = 4.855021164954352\n","Valid Epoch #7, Batch 2278/4160 loss = 1.572146761417389, ppl = 4.866243348652369\n","Valid Epoch #7, Batch 2279/4160 loss = 1.5734354186058044, ppl = 4.8729525962559155\n","Valid Epoch #7, Batch 2280/4160 loss = 1.573619043827057, ppl = 4.873801120621417\n","Valid Epoch #7, Batch 2281/4160 loss = 1.5742239701747893, ppl = 4.876521475408163\n","Valid Epoch #7, Batch 2282/4160 loss = 1.575574952363968, ppl = 4.883081651565899\n","Valid Epoch #7, Batch 2283/4160 loss = 1.574516098499298, ppl = 4.877610009673046\n","Valid Epoch #7, Batch 2284/4160 loss = 1.5780694115161895, ppl = 4.898342119488206\n","Valid Epoch #7, Batch 2285/4160 loss = 1.5793713402748109, ppl = 4.904448087523647\n","Valid Epoch #7, Batch 2286/4160 loss = 1.5811016845703125, ppl = 4.914271917556874\n","Valid Epoch #7, Batch 2287/4160 loss = 1.5794673430919648, ppl = 4.906169844803228\n","Valid Epoch #7, Batch 2288/4160 loss = 1.5830696439743042, ppl = 4.923216975749969\n","Valid Epoch #7, Batch 2289/4160 loss = 1.5829215002059938, ppl = 4.922534439655376\n","Valid Epoch #7, Batch 2290/4160 loss = 1.5841635417938233, ppl = 4.929325342445882\n","Valid Epoch #7, Batch 2291/4160 loss = 1.5828995931148528, ppl = 4.923244533398548\n","Valid Epoch #7, Batch 2292/4160 loss = 1.5816701447963715, ppl = 4.917377007067623\n","Valid Epoch #7, Batch 2293/4160 loss = 1.5815278148651124, ppl = 4.9165939367271525\n","Valid Epoch #7, Batch 2294/4160 loss = 1.5818201363086701, ppl = 4.918173405101422\n","Valid Epoch #7, Batch 2295/4160 loss = 1.5807945358753204, ppl = 4.913362665812164\n","Valid Epoch #7, Batch 2296/4160 loss = 1.5786135864257813, ppl = 4.903147679862437\n","Valid Epoch #7, Batch 2297/4160 loss = 1.5808559513092042, ppl = 4.915312812726902\n","Valid Epoch #7, Batch 2298/4160 loss = 1.5806247532367705, ppl = 4.914077223834654\n","Valid Epoch #7, Batch 2299/4160 loss = 1.5819373285770417, ppl = 4.921231279038471\n","Valid Epoch #7, Batch 2300/4160 loss = 1.5796096050739288, ppl = 4.910701892181291\n","Valid Epoch #7, Batch 2301/4160 loss = 1.5799096632003784, ppl = 4.911900786819526\n","Valid Epoch #7, Batch 2302/4160 loss = 1.5826809859275819, ppl = 4.921305335749619\n","Valid Epoch #7, Batch 2303/4160 loss = 1.5818270361423492, ppl = 4.918002636783208\n","Valid Epoch #7, Batch 2304/4160 loss = 1.5844529104232787, ppl = 4.928214010587444\n","Valid Epoch #7, Batch 2305/4160 loss = 1.5847174751758575, ppl = 4.929240169405861\n","Valid Epoch #7, Batch 2306/4160 loss = 1.5830672872066498, ppl = 4.922954431133138\n","Valid Epoch #7, Batch 2307/4160 loss = 1.5825525033473968, ppl = 4.920913593029028\n","Valid Epoch #7, Batch 2308/4160 loss = 1.5814635753631592, ppl = 4.9163683610330535\n","Valid Epoch #7, Batch 2309/4160 loss = 1.5817110645771026, ppl = 4.917313885375495\n","Valid Epoch #7, Batch 2310/4160 loss = 1.5825332140922546, ppl = 4.920151284623664\n","Valid Epoch #7, Batch 2311/4160 loss = 1.5807181704044342, ppl = 4.912198635646689\n","Valid Epoch #7, Batch 2312/4160 loss = 1.5823892259597778, ppl = 4.919943202210903\n","Valid Epoch #7, Batch 2313/4160 loss = 1.5821392941474914, ppl = 4.918919929441803\n","Valid Epoch #7, Batch 2314/4160 loss = 1.5854640245437621, ppl = 4.933941348295339\n","Valid Epoch #7, Batch 2315/4160 loss = 1.5840101253986358, ppl = 4.92771301398761\n","Valid Epoch #7, Batch 2316/4160 loss = 1.5827123165130614, ppl = 4.921399246579994\n","Valid Epoch #7, Batch 2317/4160 loss = 1.5795864760875702, ppl = 4.906205875039002\n","Valid Epoch #7, Batch 2318/4160 loss = 1.5802702915668487, ppl = 4.909509412059256\n","Valid Epoch #7, Batch 2319/4160 loss = 1.5800503921508788, ppl = 4.908470789137855\n","Valid Epoch #7, Batch 2320/4160 loss = 1.5788690567016601, ppl = 4.903382742890172\n","Valid Epoch #7, Batch 2321/4160 loss = 1.5760175681114197, ppl = 4.889582977309455\n","Valid Epoch #7, Batch 2322/4160 loss = 1.5791958820819856, ppl = 4.904007095211075\n","Valid Epoch #7, Batch 2323/4160 loss = 1.5792028498649597, ppl = 4.904040350130967\n","Valid Epoch #7, Batch 2324/4160 loss = 1.577966592311859, ppl = 4.898144402184511\n","Valid Epoch #7, Batch 2325/4160 loss = 1.578710254430771, ppl = 4.901641894510582\n","Valid Epoch #7, Batch 2326/4160 loss = 1.5774665200710296, ppl = 4.8950832431510625\n","Valid Epoch #7, Batch 2327/4160 loss = 1.5778201949596404, ppl = 4.89690427635133\n","Valid Epoch #7, Batch 2328/4160 loss = 1.5759449446201323, ppl = 4.887251992675962\n","Valid Epoch #7, Batch 2329/4160 loss = 1.578371568918228, ppl = 4.899071987948423\n","Valid Epoch #7, Batch 2330/4160 loss = 1.5755719971656799, ppl = 4.886372076058754\n","Valid Epoch #7, Batch 2331/4160 loss = 1.577385848760605, ppl = 4.895148601716997\n","Valid Epoch #7, Batch 2332/4160 loss = 1.5764640748500824, ppl = 4.89029713492248\n","Valid Epoch #7, Batch 2333/4160 loss = 1.5748293328285217, ppl = 4.8822506487789745\n","Valid Epoch #7, Batch 2334/4160 loss = 1.5736151134967804, ppl = 4.875245412497318\n","Valid Epoch #7, Batch 2335/4160 loss = 1.5748874807357789, ppl = 4.881625170769507\n","Valid Epoch #7, Batch 2336/4160 loss = 1.5727143371105194, ppl = 4.868969384764474\n","Valid Epoch #7, Batch 2337/4160 loss = 1.569747828245163, ppl = 4.8511608286266235\n","Valid Epoch #7, Batch 2338/4160 loss = 1.5721958076953888, ppl = 4.863085734596174\n","Valid Epoch #7, Batch 2339/4160 loss = 1.5730411911010742, ppl = 4.867113638056762\n","Valid Epoch #7, Batch 2340/4160 loss = 1.5739714777469636, ppl = 4.87146836179602\n","Valid Epoch #7, Batch 2341/4160 loss = 1.5729715192317963, ppl = 4.866208897730072\n","Valid Epoch #7, Batch 2342/4160 loss = 1.5726077604293822, ppl = 4.864249253285224\n","Valid Epoch #7, Batch 2343/4160 loss = 1.5714700388908387, ppl = 4.858095943455674\n","Valid Epoch #7, Batch 2344/4160 loss = 1.5717295980453492, ppl = 4.859487152138217\n","Valid Epoch #7, Batch 2345/4160 loss = 1.5722654855251312, ppl = 4.862293524102086\n","Valid Epoch #7, Batch 2346/4160 loss = 1.570614973306656, ppl = 4.854101597068501\n","Valid Epoch #7, Batch 2347/4160 loss = 1.572927441596985, ppl = 4.865753171977457\n","Valid Epoch #7, Batch 2348/4160 loss = 1.571653997898102, ppl = 4.858974393646633\n","Valid Epoch #7, Batch 2349/4160 loss = 1.5719383800029754, ppl = 4.860315378580897\n","Valid Epoch #7, Batch 2350/4160 loss = 1.574173513650894, ppl = 4.872015447998345\n","Valid Epoch #7, Batch 2351/4160 loss = 1.5748965632915497, ppl = 4.876254200360536\n","Valid Epoch #7, Batch 2352/4160 loss = 1.5766317927837372, ppl = 4.88699000423043\n","Valid Epoch #7, Batch 2353/4160 loss = 1.573168958425522, ppl = 4.869916087413575\n","Valid Epoch #7, Batch 2354/4160 loss = 1.5717662954330445, ppl = 4.863022538064343\n","Valid Epoch #7, Batch 2355/4160 loss = 1.5735562968254089, ppl = 4.872109697503127\n","Valid Epoch #7, Batch 2356/4160 loss = 1.5741279101371766, ppl = 4.875079886075016\n","Valid Epoch #7, Batch 2357/4160 loss = 1.5754253160953522, ppl = 4.881530724292537\n","Valid Epoch #7, Batch 2358/4160 loss = 1.5752976632118225, ppl = 4.880964996153059\n","Valid Epoch #7, Batch 2359/4160 loss = 1.574619871377945, ppl = 4.877667491845326\n","Valid Epoch #7, Batch 2360/4160 loss = 1.576535450220108, ppl = 4.887461412095383\n","Valid Epoch #7, Batch 2361/4160 loss = 1.5771765673160554, ppl = 4.890618267666023\n","Valid Epoch #7, Batch 2362/4160 loss = 1.5785040330886841, ppl = 4.896303544774589\n","Valid Epoch #7, Batch 2363/4160 loss = 1.5788248682022095, ppl = 4.897862454031871\n","Valid Epoch #7, Batch 2364/4160 loss = 1.5795166313648223, ppl = 4.901314693488493\n","Valid Epoch #7, Batch 2365/4160 loss = 1.5797205412387847, ppl = 4.902355181580708\n","Valid Epoch #7, Batch 2366/4160 loss = 1.5798131239414215, ppl = 4.902782644204944\n","Valid Epoch #7, Batch 2367/4160 loss = 1.5776479506492616, ppl = 4.891128874780566\n","Valid Epoch #7, Batch 2368/4160 loss = 1.5736920619010926, ppl = 4.87295597909224\n","Valid Epoch #7, Batch 2369/4160 loss = 1.5752868366241455, ppl = 4.880448208194556\n","Valid Epoch #7, Batch 2370/4160 loss = 1.5749877786636353, ppl = 4.878841476061635\n","Valid Epoch #7, Batch 2371/4160 loss = 1.5771939885616302, ppl = 4.888352392273371\n","Valid Epoch #7, Batch 2372/4160 loss = 1.5763622426986694, ppl = 4.88388700467409\n","Valid Epoch #7, Batch 2373/4160 loss = 1.5758228361606599, ppl = 4.881493506041744\n","Valid Epoch #7, Batch 2374/4160 loss = 1.5760871148109437, ppl = 4.882774279545682\n","Valid Epoch #7, Batch 2375/4160 loss = 1.5738772809505464, ppl = 4.870694190830796\n","Valid Epoch #7, Batch 2376/4160 loss = 1.5755338084697723, ppl = 4.8782805249548025\n","Valid Epoch #7, Batch 2377/4160 loss = 1.5754694616794587, ppl = 4.878013684739653\n","Valid Epoch #7, Batch 2378/4160 loss = 1.5737026810646058, ppl = 4.869176926930526\n","Valid Epoch #7, Batch 2379/4160 loss = 1.5714446902275085, ppl = 4.85796109384419\n","Valid Epoch #7, Batch 2380/4160 loss = 1.5712566089630127, ppl = 4.857092171311282\n","Valid Epoch #7, Batch 2381/4160 loss = 1.5708115339279174, ppl = 4.855074747983643\n","Valid Epoch #7, Batch 2382/4160 loss = 1.5704157733917237, ppl = 4.8530603797766805\n","Valid Epoch #7, Batch 2383/4160 loss = 1.5705546820163727, ppl = 4.853745607810006\n","Valid Epoch #7, Batch 2384/4160 loss = 1.5652173221111298, ppl = 4.825073681942544\n","Valid Epoch #7, Batch 2385/4160 loss = 1.5667971348762513, ppl = 4.8336340808726\n","Valid Epoch #7, Batch 2386/4160 loss = 1.5636102342605591, ppl = 4.816761452180582\n","Valid Epoch #7, Batch 2387/4160 loss = 1.5662819361686706, ppl = 4.830737197823905\n","Valid Epoch #7, Batch 2388/4160 loss = 1.568916779756546, ppl = 4.847726436270172\n","Valid Epoch #7, Batch 2389/4160 loss = 1.5706861472129823, ppl = 4.856578144469439\n","Valid Epoch #7, Batch 2390/4160 loss = 1.5692695152759553, ppl = 4.84889849859386\n","Valid Epoch #7, Batch 2391/4160 loss = 1.5703717720508577, ppl = 4.854157876652755\n","Valid Epoch #7, Batch 2392/4160 loss = 1.5723557710647582, ppl = 4.86400047241019\n","Valid Epoch #7, Batch 2393/4160 loss = 1.5712740635871887, ppl = 4.85839976633822\n","Valid Epoch #7, Batch 2394/4160 loss = 1.5713705813884735, ppl = 4.858931491778397\n","Valid Epoch #7, Batch 2395/4160 loss = 1.5717172837257385, ppl = 4.860502866413717\n","Valid Epoch #7, Batch 2396/4160 loss = 1.5736138594150544, ppl = 4.869256282558291\n","Valid Epoch #7, Batch 2397/4160 loss = 1.5713707554340361, ppl = 4.857087572895314\n","Valid Epoch #7, Batch 2398/4160 loss = 1.571401435136795, ppl = 4.857249894837665\n","Valid Epoch #7, Batch 2399/4160 loss = 1.5673213076591492, ppl = 4.8377648361624805\n","Valid Epoch #7, Batch 2400/4160 loss = 1.5720048749446869, ppl = 4.86176350240755\n","Valid Epoch #7, Batch 2401/4160 loss = 1.5718323254585267, ppl = 4.861069681783264\n","Valid Epoch #7, Batch 2402/4160 loss = 1.570278822183609, ppl = 4.855479120860703\n","Valid Epoch #7, Batch 2403/4160 loss = 1.5697208034992218, ppl = 4.853468411559483\n","Valid Epoch #7, Batch 2404/4160 loss = 1.5682592225074767, ppl = 4.847455913945549\n","Valid Epoch #7, Batch 2405/4160 loss = 1.5675289523601532, ppl = 4.844688097316924\n","Valid Epoch #7, Batch 2406/4160 loss = 1.5711048924922943, ppl = 4.859748934970314\n","Valid Epoch #7, Batch 2407/4160 loss = 1.5713556718826294, ppl = 4.860730018801926\n","Valid Epoch #7, Batch 2408/4160 loss = 1.5716814529895782, ppl = 4.862038344652337\n","Valid Epoch #7, Batch 2409/4160 loss = 1.5719760751724243, ppl = 4.863194878383434\n","Valid Epoch #7, Batch 2410/4160 loss = 1.576679413318634, ppl = 4.884783933076259\n","Valid Epoch #7, Batch 2411/4160 loss = 1.5765487134456635, ppl = 4.884265066461854\n","Valid Epoch #7, Batch 2412/4160 loss = 1.5775921964645385, ppl = 4.88980021014449\n","Valid Epoch #7, Batch 2413/4160 loss = 1.578817241191864, ppl = 4.895069551837525\n","Valid Epoch #7, Batch 2414/4160 loss = 1.5759117257595063, ppl = 4.881678675829576\n","Valid Epoch #7, Batch 2415/4160 loss = 1.5762346363067627, ppl = 4.882984838255138\n","Valid Epoch #7, Batch 2416/4160 loss = 1.5744546842575073, ppl = 4.875555984224794\n","Valid Epoch #7, Batch 2417/4160 loss = 1.5749255084991456, ppl = 4.877552012445605\n","Valid Epoch #7, Batch 2418/4160 loss = 1.5751612329483031, ppl = 4.878744181593093\n","Valid Epoch #7, Batch 2419/4160 loss = 1.574422904253006, ppl = 4.875419379454247\n","Valid Epoch #7, Batch 2420/4160 loss = 1.5759478998184204, ppl = 4.88210400565176\n","Valid Epoch #7, Batch 2421/4160 loss = 1.5766694128513337, ppl = 4.885233082737651\n","Valid Epoch #7, Batch 2422/4160 loss = 1.576011153459549, ppl = 4.881858160243487\n","Valid Epoch #7, Batch 2423/4160 loss = 1.5772369241714477, ppl = 4.888084186580331\n","Valid Epoch #7, Batch 2424/4160 loss = 1.5807438337802886, ppl = 4.9069043117597895\n","Valid Epoch #7, Batch 2425/4160 loss = 1.5800905311107636, ppl = 4.903818035246499\n","Valid Epoch #7, Batch 2426/4160 loss = 1.5815724682807923, ppl = 4.911728584956154\n","Valid Epoch #7, Batch 2427/4160 loss = 1.5794790136814116, ppl = 4.901830105781116\n","Valid Epoch #7, Batch 2428/4160 loss = 1.582715975046158, ppl = 4.9197170335066485\n","Valid Epoch #7, Batch 2429/4160 loss = 1.5806260311603546, ppl = 4.909370726176104\n","Valid Epoch #7, Batch 2430/4160 loss = 1.5822218644618988, ppl = 4.916172171076685\n","Valid Epoch #7, Batch 2431/4160 loss = 1.5825999391078949, ppl = 4.918210743647049\n","Valid Epoch #7, Batch 2432/4160 loss = 1.5807016623020171, ppl = 4.909523746094994\n","Valid Epoch #7, Batch 2433/4160 loss = 1.5834678268432618, ppl = 4.923961639680514\n","Valid Epoch #7, Batch 2434/4160 loss = 1.5829892587661742, ppl = 4.9214260110518815\n","Valid Epoch #7, Batch 2435/4160 loss = 1.5837668550014496, ppl = 4.925743952838456\n","Valid Epoch #7, Batch 2436/4160 loss = 1.5817607653141021, ppl = 4.916266887042155\n","Valid Epoch #7, Batch 2437/4160 loss = 1.5846700119972228, ppl = 4.933679316806814\n","Valid Epoch #7, Batch 2438/4160 loss = 1.5838241076469421, ppl = 4.9292247785609415\n","Valid Epoch #7, Batch 2439/4160 loss = 1.5839230608940125, ppl = 4.9297189001724595\n","Valid Epoch #7, Batch 2440/4160 loss = 1.5825534427165986, ppl = 4.923444298363806\n","Valid Epoch #7, Batch 2441/4160 loss = 1.583296102285385, ppl = 4.92729980086539\n","Valid Epoch #7, Batch 2442/4160 loss = 1.5825888371467591, ppl = 4.9236877354834885\n","Valid Epoch #7, Batch 2443/4160 loss = 1.5837940895557403, ppl = 4.930228761107604\n","Valid Epoch #7, Batch 2444/4160 loss = 1.583061354160309, ppl = 4.92639245575132\n","Valid Epoch #7, Batch 2445/4160 loss = 1.5824667203426361, ppl = 4.923287484496762\n","Valid Epoch #7, Batch 2446/4160 loss = 1.5843854975700378, ppl = 4.932943331229173\n","Valid Epoch #7, Batch 2447/4160 loss = 1.5857917582988739, ppl = 4.941464838713526\n","Valid Epoch #7, Batch 2448/4160 loss = 1.5874581122398377, ppl = 4.950515489654112\n","Valid Epoch #7, Batch 2449/4160 loss = 1.5915234303474426, ppl = 4.974506061085848\n","Valid Epoch #7, Batch 2450/4160 loss = 1.5931406664848327, ppl = 4.984759771709516\n","Valid Epoch #7, Batch 2451/4160 loss = 1.5885112619400024, ppl = 4.962240917923234\n","Valid Epoch #7, Batch 2452/4160 loss = 1.5843320345878602, ppl = 4.939220449257782\n","Valid Epoch #7, Batch 2453/4160 loss = 1.585726580619812, ppl = 4.945395010837383\n","Valid Epoch #7, Batch 2454/4160 loss = 1.5867350697517395, ppl = 4.950252697027184\n","Valid Epoch #7, Batch 2455/4160 loss = 1.5875978910923003, ppl = 4.95524908357063\n","Valid Epoch #7, Batch 2456/4160 loss = 1.5864852011203765, ppl = 4.949619562840383\n","Valid Epoch #7, Batch 2457/4160 loss = 1.5836652755737304, ppl = 4.93659238733652\n","Valid Epoch #7, Batch 2458/4160 loss = 1.5866135609149934, ppl = 4.9516919640799095\n","Valid Epoch #7, Batch 2459/4160 loss = 1.5875978219509124, ppl = 4.956555435732231\n","Valid Epoch #7, Batch 2460/4160 loss = 1.5868799436092376, ppl = 4.952663689036463\n","Valid Epoch #7, Batch 2461/4160 loss = 1.586024466753006, ppl = 4.948495677583315\n","Valid Epoch #7, Batch 2462/4160 loss = 1.5876106345653533, ppl = 4.956356763393951\n","Valid Epoch #7, Batch 2463/4160 loss = 1.5889756679534912, ppl = 4.963577955284217\n","Valid Epoch #7, Batch 2464/4160 loss = 1.5899904406070708, ppl = 4.969094522643095\n","Valid Epoch #7, Batch 2465/4160 loss = 1.5900067400932312, ppl = 4.969178613171452\n","Valid Epoch #7, Batch 2466/4160 loss = 1.5896137988567351, ppl = 4.967391302342548\n","Valid Epoch #7, Batch 2467/4160 loss = 1.590841245651245, ppl = 4.973686923354193\n","Valid Epoch #7, Batch 2468/4160 loss = 1.5924311292171478, ppl = 4.980140454927809\n","Valid Epoch #7, Batch 2469/4160 loss = 1.5923001551628113, ppl = 4.979479113117892\n","Valid Epoch #7, Batch 2470/4160 loss = 1.5893303275108337, ppl = 4.965879859785871\n","Valid Epoch #7, Batch 2471/4160 loss = 1.5903289079666139, ppl = 4.970924726924895\n","Valid Epoch #7, Batch 2472/4160 loss = 1.5905822932720184, ppl = 4.972245953916876\n","Valid Epoch #7, Batch 2473/4160 loss = 1.593990740776062, ppl = 4.9897856311944935\n","Valid Epoch #7, Batch 2474/4160 loss = 1.592076725959778, ppl = 4.981231378659744\n","Valid Epoch #7, Batch 2475/4160 loss = 1.5922171866893768, ppl = 4.981922333730281\n","Valid Epoch #7, Batch 2476/4160 loss = 1.5934513878822327, ppl = 4.988450178393494\n","Valid Epoch #7, Batch 2477/4160 loss = 1.59393035531044, ppl = 4.9904782090226\n","Valid Epoch #7, Batch 2478/4160 loss = 1.5971953773498535, ppl = 5.00813423587084\n","Valid Epoch #7, Batch 2479/4160 loss = 1.6003353214263916, ppl = 5.0244663744783935\n","Valid Epoch #7, Batch 2480/4160 loss = 1.600102986097336, ppl = 5.023415320757996\n","Valid Epoch #7, Batch 2481/4160 loss = 1.6005352532863617, ppl = 5.025373425518754\n","Valid Epoch #7, Batch 2482/4160 loss = 1.6001305162906647, ppl = 5.023394187642364\n","Valid Epoch #7, Batch 2483/4160 loss = 1.5989993917942047, ppl = 5.018081691456651\n","Valid Epoch #7, Batch 2484/4160 loss = 1.5994862604141236, ppl = 5.02010991204582\n","Valid Epoch #7, Batch 2485/4160 loss = 1.5978886437416078, ppl = 5.011460539666676\n","Valid Epoch #7, Batch 2486/4160 loss = 1.5977496874332429, ppl = 5.010840185607511\n","Valid Epoch #7, Batch 2487/4160 loss = 1.599140533208847, ppl = 5.019735108023678\n","Valid Epoch #7, Batch 2488/4160 loss = 1.5960853278636933, ppl = 5.000425934870567\n","Valid Epoch #7, Batch 2489/4160 loss = 1.5963758158683776, ppl = 5.002034784131648\n","Valid Epoch #7, Batch 2490/4160 loss = 1.5962494480609895, ppl = 5.001401126599423\n","Valid Epoch #7, Batch 2491/4160 loss = 1.5955152809619904, ppl = 4.997834010911397\n","Valid Epoch #7, Batch 2492/4160 loss = 1.595592772960663, ppl = 4.998259490567171\n","Valid Epoch #7, Batch 2493/4160 loss = 1.597412428855896, ppl = 5.0080438828618945\n","Valid Epoch #7, Batch 2494/4160 loss = 1.5953718316555023, ppl = 4.997825698862013\n","Valid Epoch #7, Batch 2495/4160 loss = 1.5943089377880098, ppl = 4.993175798654233\n","Valid Epoch #7, Batch 2496/4160 loss = 1.5923829805850982, ppl = 4.98429940961832\n","Valid Epoch #7, Batch 2497/4160 loss = 1.5946150958538055, ppl = 4.9964016070351995\n","Valid Epoch #7, Batch 2498/4160 loss = 1.592812442779541, ppl = 4.987660870666703\n","Valid Epoch #7, Batch 2499/4160 loss = 1.5966006374359132, ppl = 5.005472614562004\n","Valid Epoch #7, Batch 2500/4160 loss = 1.593720189332962, ppl = 4.989411976325959\n","Valid Epoch #7, Batch 2501/4160 loss = 1.593801875114441, ppl = 4.9897389424377705\n","Valid Epoch #7, Batch 2502/4160 loss = 1.5940109062194825, ppl = 4.990441578710236\n","Valid Epoch #7, Batch 2503/4160 loss = 1.5944087064266206, ppl = 4.991863444942911\n","Valid Epoch #7, Batch 2504/4160 loss = 1.592194331884384, ppl = 4.984274852920306\n","Valid Epoch #7, Batch 2505/4160 loss = 1.591373506784439, ppl = 4.981395809571392\n","Valid Epoch #7, Batch 2506/4160 loss = 1.5883491051197052, ppl = 4.968321543440657\n","Valid Epoch #7, Batch 2507/4160 loss = 1.58703094124794, ppl = 4.963429292600281\n","Valid Epoch #7, Batch 2508/4160 loss = 1.586768500804901, ppl = 4.962372013924392\n","Valid Epoch #7, Batch 2509/4160 loss = 1.5868104004859924, ppl = 4.962539275301535\n","Valid Epoch #7, Batch 2510/4160 loss = 1.582113037109375, ppl = 4.940971706382378\n","Valid Epoch #7, Batch 2511/4160 loss = 1.5846257150173186, ppl = 4.952237976581437\n","Valid Epoch #7, Batch 2512/4160 loss = 1.5817772769927978, ppl = 4.938391911022993\n","Valid Epoch #7, Batch 2513/4160 loss = 1.581079581975937, ppl = 4.935312002344226\n","Valid Epoch #7, Batch 2514/4160 loss = 1.585113765001297, ppl = 4.955048248507368\n","Valid Epoch #7, Batch 2515/4160 loss = 1.5845148527622224, ppl = 4.952658617301096\n","Valid Epoch #7, Batch 2516/4160 loss = 1.5851401114463806, ppl = 4.955118967852184\n","Valid Epoch #7, Batch 2517/4160 loss = 1.585908888578415, ppl = 4.958587076944988\n","Valid Epoch #7, Batch 2518/4160 loss = 1.5832969522476197, ppl = 4.946824003355001\n","Valid Epoch #7, Batch 2519/4160 loss = 1.5857094752788543, ppl = 4.958662491835313\n","Valid Epoch #7, Batch 2520/4160 loss = 1.5854852735996245, ppl = 4.957614682818679\n","Valid Epoch #7, Batch 2521/4160 loss = 1.5877063846588135, ppl = 4.9687946049448355\n","Valid Epoch #7, Batch 2522/4160 loss = 1.5883635759353638, ppl = 4.97216386925365\n","Valid Epoch #7, Batch 2523/4160 loss = 1.5862059998512268, ppl = 4.961690072806487\n","Valid Epoch #7, Batch 2524/4160 loss = 1.586274838447571, ppl = 4.962129567857655\n","Valid Epoch #7, Batch 2525/4160 loss = 1.5856152606010436, ppl = 4.959211609337183\n","Valid Epoch #7, Batch 2526/4160 loss = 1.5829060804843902, ppl = 4.945581619798763\n","Valid Epoch #7, Batch 2527/4160 loss = 1.585583862066269, ppl = 4.958633485299697\n","Valid Epoch #7, Batch 2528/4160 loss = 1.580285472869873, ppl = 4.932029144611712\n","Valid Epoch #7, Batch 2529/4160 loss = 1.582670785188675, ppl = 4.944019963423066\n","Valid Epoch #7, Batch 2530/4160 loss = 1.5831650519371032, ppl = 4.946356348735727\n","Valid Epoch #7, Batch 2531/4160 loss = 1.5818662774562835, ppl = 4.939664148038376\n","Valid Epoch #7, Batch 2532/4160 loss = 1.5837559843063354, ppl = 4.948308105681266\n","Valid Epoch #7, Batch 2533/4160 loss = 1.5809906566143035, ppl = 4.933874003856938\n","Valid Epoch #7, Batch 2534/4160 loss = 1.580129427909851, ppl = 4.929605655407105\n","Valid Epoch #7, Batch 2535/4160 loss = 1.5809377598762513, ppl = 4.934464793041301\n","Valid Epoch #7, Batch 2536/4160 loss = 1.5852390348911285, ppl = 4.957393248410632\n","Valid Epoch #7, Batch 2537/4160 loss = 1.582859959602356, ppl = 4.942788543447384\n","Valid Epoch #7, Batch 2538/4160 loss = 1.583489146232605, ppl = 4.946065699417973\n","Valid Epoch #7, Batch 2539/4160 loss = 1.5839568603038787, ppl = 4.948468551697656\n","Valid Epoch #7, Batch 2540/4160 loss = 1.5839773905277252, ppl = 4.948556402544695\n","Valid Epoch #7, Batch 2541/4160 loss = 1.5850198066234589, ppl = 4.954474628693502\n","Valid Epoch #7, Batch 2542/4160 loss = 1.5864353454113007, ppl = 4.961969205370246\n","Valid Epoch #7, Batch 2543/4160 loss = 1.584746869802475, ppl = 4.953019216025904\n","Valid Epoch #7, Batch 2544/4160 loss = 1.586775040626526, ppl = 4.964365339444209\n","Valid Epoch #7, Batch 2545/4160 loss = 1.587492858171463, ppl = 4.968136944443449\n","Valid Epoch #7, Batch 2546/4160 loss = 1.5881405889987945, ppl = 4.971837792756273\n","Valid Epoch #7, Batch 2547/4160 loss = 1.5873249423503877, ppl = 4.966749873105951\n","Valid Epoch #7, Batch 2548/4160 loss = 1.5857327497005462, ppl = 4.958070769769472\n","Valid Epoch #7, Batch 2549/4160 loss = 1.581112141609192, ppl = 4.931496749021666\n","Valid Epoch #7, Batch 2550/4160 loss = 1.577479841709137, ppl = 4.910582396284893\n","Valid Epoch #7, Batch 2551/4160 loss = 1.5796015465259552, ppl = 4.919622952645764\n","Valid Epoch #7, Batch 2552/4160 loss = 1.5809830129146576, ppl = 4.926196430277618\n","Valid Epoch #7, Batch 2553/4160 loss = 1.5817111313343049, ppl = 4.92977914670186\n","Valid Epoch #7, Batch 2554/4160 loss = 1.5828227806091308, ppl = 4.935733077916614\n","Valid Epoch #7, Batch 2555/4160 loss = 1.5819657933712006, ppl = 4.930769048151601\n","Valid Epoch #7, Batch 2556/4160 loss = 1.5797768914699555, ppl = 4.921365905102245\n","Valid Epoch #7, Batch 2557/4160 loss = 1.5841652500629424, ppl = 4.94339588166402\n","Valid Epoch #7, Batch 2558/4160 loss = 1.5796539831161498, ppl = 4.921924560048868\n","Valid Epoch #7, Batch 2559/4160 loss = 1.579883805513382, ppl = 4.923130779146461\n","Valid Epoch #7, Batch 2560/4160 loss = 1.5798890256881715, ppl = 4.923158082144461\n","Valid Epoch #7, Batch 2561/4160 loss = 1.5771195030212402, ppl = 4.911868850916917\n","Valid Epoch #7, Batch 2562/4160 loss = 1.5791237270832061, ppl = 4.923762510656917\n","Valid Epoch #7, Batch 2563/4160 loss = 1.5773102271556854, ppl = 4.914376032735822\n","Valid Epoch #7, Batch 2564/4160 loss = 1.5767183029651641, ppl = 4.9110903519251\n","Valid Epoch #7, Batch 2565/4160 loss = 1.5756021118164063, ppl = 4.905637128689412\n","Valid Epoch #7, Batch 2566/4160 loss = 1.5755942285060882, ppl = 4.905601984836006\n","Valid Epoch #7, Batch 2567/4160 loss = 1.5755469739437102, ppl = 4.905345042895556\n","Valid Epoch #7, Batch 2568/4160 loss = 1.5754375886917114, ppl = 4.904867420858503\n","Valid Epoch #7, Batch 2569/4160 loss = 1.5741983270645141, ppl = 4.899020540762103\n","Valid Epoch #7, Batch 2570/4160 loss = 1.5770301032066345, ppl = 4.9118941480598215\n","Valid Epoch #7, Batch 2571/4160 loss = 1.5776292419433593, ppl = 4.9151718739377\n","Valid Epoch #7, Batch 2572/4160 loss = 1.5763686168193818, ppl = 4.9089174696527325\n","Valid Epoch #7, Batch 2573/4160 loss = 1.5719123911857604, ppl = 4.887081765175701\n","Valid Epoch #7, Batch 2574/4160 loss = 1.5730614960193634, ppl = 4.8920198984646115\n","Valid Epoch #7, Batch 2575/4160 loss = 1.571177374124527, ppl = 4.883512840692996\n","Valid Epoch #7, Batch 2576/4160 loss = 1.5692212295532226, ppl = 4.873523781236699\n","Valid Epoch #7, Batch 2577/4160 loss = 1.5699676048755646, ppl = 4.876884197439389\n","Valid Epoch #7, Batch 2578/4160 loss = 1.566618140935898, ppl = 4.858843661936889\n","Valid Epoch #7, Batch 2579/4160 loss = 1.5652741026878356, ppl = 4.851221563012439\n","Valid Epoch #7, Batch 2580/4160 loss = 1.5652986896038055, ppl = 4.851331639068025\n","Valid Epoch #7, Batch 2581/4160 loss = 1.5686121213436126, ppl = 4.869513969972351\n","Valid Epoch #7, Batch 2582/4160 loss = 1.570372198820114, ppl = 4.878735829689226\n","Valid Epoch #7, Batch 2583/4160 loss = 1.5699860048294068, ppl = 4.8770553197976305\n","Valid Epoch #7, Batch 2584/4160 loss = 1.5701380777359009, ppl = 4.877709339723754\n","Valid Epoch #7, Batch 2585/4160 loss = 1.5703406763076782, ppl = 4.878731223759731\n","Valid Epoch #7, Batch 2586/4160 loss = 1.5721930515766145, ppl = 4.887753455885408\n","Valid Epoch #7, Batch 2587/4160 loss = 1.5687023687362671, ppl = 4.867568449392575\n","Valid Epoch #7, Batch 2588/4160 loss = 1.5690776562690736, ppl = 4.869634930487834\n","Valid Epoch #7, Batch 2589/4160 loss = 1.5660568749904633, ppl = 4.854984391926348\n","Valid Epoch #7, Batch 2590/4160 loss = 1.5658016288280487, ppl = 4.853728652209549\n","Valid Epoch #7, Batch 2591/4160 loss = 1.5683769929409026, ppl = 4.867483126576887\n","Valid Epoch #7, Batch 2592/4160 loss = 1.5680243790149688, ppl = 4.865573411341786\n","Valid Epoch #7, Batch 2593/4160 loss = 1.5663156938552856, ppl = 4.856336101326211\n","Valid Epoch #7, Batch 2594/4160 loss = 1.5665221202373505, ppl = 4.857277573708202\n","Valid Epoch #7, Batch 2595/4160 loss = 1.5670083713531495, ppl = 4.859343577306749\n","Valid Epoch #7, Batch 2596/4160 loss = 1.5674498879909515, ppl = 4.861230120756613\n","Valid Epoch #7, Batch 2597/4160 loss = 1.5644448685646057, ppl = 4.845528549344409\n","Valid Epoch #7, Batch 2598/4160 loss = 1.5654800713062287, ppl = 4.850354716331412\n","Valid Epoch #7, Batch 2599/4160 loss = 1.5648044097423552, ppl = 4.846664259951472\n","Valid Epoch #7, Batch 2600/4160 loss = 1.5659782457351685, ppl = 4.8526566560505655\n","Valid Epoch #7, Batch 2601/4160 loss = 1.5659227132797242, ppl = 4.85243408410902\n","Valid Epoch #7, Batch 2602/4160 loss = 1.5672512066364288, ppl = 4.857259973575868\n","Valid Epoch #7, Batch 2603/4160 loss = 1.5647275030612946, ppl = 4.849128075049074\n","Valid Epoch #7, Batch 2604/4160 loss = 1.5677182698249816, ppl = 4.859800970527211\n","Valid Epoch #7, Batch 2605/4160 loss = 1.5692443394660949, ppl = 4.865349597782935\n","Valid Epoch #7, Batch 2606/4160 loss = 1.5709823632240296, ppl = 4.872376966727824\n","Valid Epoch #7, Batch 2607/4160 loss = 1.5707987999916078, ppl = 4.871745417598375\n","Valid Epoch #7, Batch 2608/4160 loss = 1.5707854044437408, ppl = 4.87169219242826\n","Valid Epoch #7, Batch 2609/4160 loss = 1.5696422374248504, ppl = 4.867370866174466\n","Valid Epoch #7, Batch 2610/4160 loss = 1.5728464484214784, ppl = 4.880957614024192\n","Valid Epoch #7, Batch 2611/4160 loss = 1.5702272307872773, ppl = 4.869273379216609\n","Valid Epoch #7, Batch 2612/4160 loss = 1.5703974056243897, ppl = 4.869994478781356\n","Valid Epoch #7, Batch 2613/4160 loss = 1.5723086965084077, ppl = 4.878971343111245\n","Valid Epoch #7, Batch 2614/4160 loss = 1.569819722175598, ppl = 4.8658716057610265\n","Valid Epoch #7, Batch 2615/4160 loss = 1.5696806371212007, ppl = 4.865336842769306\n","Valid Epoch #7, Batch 2616/4160 loss = 1.5709512948989868, ppl = 4.870836764948173\n","Valid Epoch #7, Batch 2617/4160 loss = 1.568312134742737, ppl = 4.859965103904136\n","Valid Epoch #7, Batch 2618/4160 loss = 1.5714283657073975, ppl = 4.874374988120203\n","Valid Epoch #7, Batch 2619/4160 loss = 1.5687951517105103, ppl = 4.861589421225059\n","Valid Epoch #7, Batch 2620/4160 loss = 1.5695657539367676, ppl = 4.865291424700914\n","Valid Epoch #7, Batch 2621/4160 loss = 1.5668765223026275, ppl = 4.852055717947014\n","Valid Epoch #7, Batch 2622/4160 loss = 1.565509239435196, ppl = 4.845286440632795\n","Valid Epoch #7, Batch 2623/4160 loss = 1.5663216972351075, ppl = 4.84896779260416\n","Valid Epoch #7, Batch 2624/4160 loss = 1.5621108245849609, ppl = 4.8269510030772595\n","Valid Epoch #7, Batch 2625/4160 loss = 1.5647069358825683, ppl = 4.839637094931667\n","Valid Epoch #7, Batch 2626/4160 loss = 1.5650213265419006, ppl = 4.841036088207636\n","Valid Epoch #7, Batch 2627/4160 loss = 1.5644959807395935, ppl = 4.838192704815629\n","Valid Epoch #7, Batch 2628/4160 loss = 1.5685825657844543, ppl = 4.8574149831619104\n","Valid Epoch #7, Batch 2629/4160 loss = 1.5682667338848113, ppl = 4.855658327143395\n","Valid Epoch #7, Batch 2630/4160 loss = 1.570589075088501, ppl = 4.868323241718858\n","Valid Epoch #7, Batch 2631/4160 loss = 1.5700411665439606, ppl = 4.865750523649199\n","Valid Epoch #7, Batch 2632/4160 loss = 1.5714487934112549, ppl = 4.87333837687165\n","Valid Epoch #7, Batch 2633/4160 loss = 1.5715118491649627, ppl = 4.873624996953905\n","Valid Epoch #7, Batch 2634/4160 loss = 1.5719018924236297, ppl = 4.875512622315466\n","Valid Epoch #7, Batch 2635/4160 loss = 1.5695376634597777, ppl = 4.862337159697011\n","Valid Epoch #7, Batch 2636/4160 loss = 1.5670781064033508, ppl = 4.84803576808913\n","Valid Epoch #7, Batch 2637/4160 loss = 1.5662840831279754, ppl = 4.843885222114226\n","Valid Epoch #7, Batch 2638/4160 loss = 1.5656194841861726, ppl = 4.840429676797883\n","Valid Epoch #7, Batch 2639/4160 loss = 1.5660941421985626, ppl = 4.842985860059783\n","Valid Epoch #7, Batch 2640/4160 loss = 1.568762890100479, ppl = 4.856088074995972\n","Valid Epoch #7, Batch 2641/4160 loss = 1.5652177298069, ppl = 4.838243129845979\n","Valid Epoch #7, Batch 2642/4160 loss = 1.565282756090164, ppl = 4.838613556783926\n","Valid Epoch #7, Batch 2643/4160 loss = 1.5657720458507538, ppl = 4.841053509505348\n","Valid Epoch #7, Batch 2644/4160 loss = 1.5645007359981538, ppl = 4.833674845482387\n","Valid Epoch #7, Batch 2645/4160 loss = 1.5643261218070983, ppl = 4.832732306193546\n","Valid Epoch #7, Batch 2646/4160 loss = 1.5623247408866883, ppl = 4.822029664186866\n","Valid Epoch #7, Batch 2647/4160 loss = 1.5599946200847625, ppl = 4.809585411437215\n","Valid Epoch #7, Batch 2648/4160 loss = 1.5615736544132233, ppl = 4.818186977697673\n","Valid Epoch #7, Batch 2649/4160 loss = 1.5639151000976563, ppl = 4.830123721994338\n","Valid Epoch #7, Batch 2650/4160 loss = 1.5662938642501831, ppl = 4.842947988956902\n","Valid Epoch #7, Batch 2651/4160 loss = 1.5686329329013824, ppl = 4.855410137987384\n","Valid Epoch #7, Batch 2652/4160 loss = 1.5672592616081238, ppl = 4.8488712624295625\n","Valid Epoch #7, Batch 2653/4160 loss = 1.5683368635177612, ppl = 4.85467614806154\n","Valid Epoch #7, Batch 2654/4160 loss = 1.567493509054184, ppl = 4.850099186971229\n","Valid Epoch #7, Batch 2655/4160 loss = 1.56482452750206, ppl = 4.8371036109769285\n","Valid Epoch #7, Batch 2656/4160 loss = 1.5666801631450653, ppl = 4.844938970355371\n","Valid Epoch #7, Batch 2657/4160 loss = 1.5660144555568696, ppl = 4.84094474334621\n","Valid Epoch #7, Batch 2658/4160 loss = 1.5688946056365967, ppl = 4.853516027763245\n","Valid Epoch #7, Batch 2659/4160 loss = 1.5688477289676666, ppl = 4.853267740724537\n","Valid Epoch #7, Batch 2660/4160 loss = 1.5678681588172914, ppl = 4.84838597748053\n","Valid Epoch #7, Batch 2661/4160 loss = 1.5712196159362792, ppl = 4.862471508086136\n","Valid Epoch #7, Batch 2662/4160 loss = 1.5656286799907684, ppl = 4.834424637001956\n","Valid Epoch #7, Batch 2663/4160 loss = 1.565102491378784, ppl = 4.832004856277196\n","Valid Epoch #7, Batch 2664/4160 loss = 1.5631857335567474, ppl = 4.822606489051288\n","Valid Epoch #7, Batch 2665/4160 loss = 1.5632544994354247, ppl = 4.822925142466378\n","Valid Epoch #7, Batch 2666/4160 loss = 1.5635222434997558, ppl = 4.824134393238445\n","Valid Epoch #7, Batch 2667/4160 loss = 1.5624907779693604, ppl = 4.818818038327973\n","Valid Epoch #7, Batch 2668/4160 loss = 1.5649732387065887, ppl = 4.8310543654034\n","Valid Epoch #7, Batch 2669/4160 loss = 1.5661097276210785, ppl = 4.836388335001028\n","Valid Epoch #7, Batch 2670/4160 loss = 1.5663524198532104, ppl = 4.837670721671767\n","Valid Epoch #7, Batch 2671/4160 loss = 1.563040269613266, ppl = 4.82177935148381\n","Valid Epoch #7, Batch 2672/4160 loss = 1.5655972278118133, ppl = 4.835342735429912\n","Valid Epoch #7, Batch 2673/4160 loss = 1.5674558365345002, ppl = 4.843286363538495\n","Valid Epoch #7, Batch 2674/4160 loss = 1.5678329074382782, ppl = 4.8450344120319\n","Valid Epoch #7, Batch 2675/4160 loss = 1.5675605905056, ppl = 4.843932137461048\n","Valid Epoch #7, Batch 2676/4160 loss = 1.5677598893642426, ppl = 4.84486280383087\n","Valid Epoch #7, Batch 2677/4160 loss = 1.569734468460083, ppl = 4.855062790821577\n","Valid Epoch #7, Batch 2678/4160 loss = 1.567479932308197, ppl = 4.84591042923695\n","Valid Epoch #7, Batch 2679/4160 loss = 1.5663792824745177, ppl = 4.840388145019039\n","Valid Epoch #7, Batch 2680/4160 loss = 1.5668392384052277, ppl = 4.842498059787912\n","Valid Epoch #7, Batch 2681/4160 loss = 1.5620283365249634, ppl = 4.817878734568597\n","Valid Epoch #7, Batch 2682/4160 loss = 1.5602488839626312, ppl = 4.808564121486893\n","Valid Epoch #7, Batch 2683/4160 loss = 1.5617007064819335, ppl = 4.815232853738561\n","Valid Epoch #7, Batch 2684/4160 loss = 1.5622088599205017, ppl = 4.817491837848468\n","Valid Epoch #7, Batch 2685/4160 loss = 1.5627286946773529, ppl = 4.820210526409968\n","Valid Epoch #7, Batch 2686/4160 loss = 1.5629795682430268, ppl = 4.82156603428806\n","Valid Epoch #7, Batch 2687/4160 loss = 1.563276549577713, ppl = 4.823022534590972\n","Valid Epoch #7, Batch 2688/4160 loss = 1.560770355463028, ppl = 4.810585396306629\n","Valid Epoch #7, Batch 2689/4160 loss = 1.5606912899017333, ppl = 4.81025823608936\n","Valid Epoch #7, Batch 2690/4160 loss = 1.5612613320350648, ppl = 4.813107482986048\n","Valid Epoch #7, Batch 2691/4160 loss = 1.5575743865966798, ppl = 4.7944268358616675\n","Valid Epoch #7, Batch 2692/4160 loss = 1.5556240057945252, ppl = 4.784998277191587\n","Valid Epoch #7, Batch 2693/4160 loss = 1.5557484602928162, ppl = 4.7856190998364205\n","Valid Epoch #7, Batch 2694/4160 loss = 1.556156152486801, ppl = 4.787536587423295\n","Valid Epoch #7, Batch 2695/4160 loss = 1.5561767411231995, ppl = 4.7876263016306275\n","Valid Epoch #7, Batch 2696/4160 loss = 1.558660043478012, ppl = 4.799938654297576\n","Valid Epoch #7, Batch 2697/4160 loss = 1.5589682388305663, ppl = 4.801340646140189\n","Valid Epoch #7, Batch 2698/4160 loss = 1.5589212381839752, ppl = 4.8011105306808055\n","Valid Epoch #7, Batch 2699/4160 loss = 1.5600880777835846, ppl = 4.807644717649629\n","Valid Epoch #7, Batch 2700/4160 loss = 1.560700569152832, ppl = 4.811062160365335\n","Valid Epoch #7, Batch 2701/4160 loss = 1.559170471429825, ppl = 4.80539149267288\n","Valid Epoch #7, Batch 2702/4160 loss = 1.5582242786884308, ppl = 4.801889285598421\n","Valid Epoch #7, Batch 2703/4160 loss = 1.5601292395591735, ppl = 4.807833690672649\n","Valid Epoch #7, Batch 2704/4160 loss = 1.5592821872234344, ppl = 4.8044803895063914\n","Valid Epoch #7, Batch 2705/4160 loss = 1.5600299632549286, ppl = 4.80752434645405\n","Valid Epoch #7, Batch 2706/4160 loss = 1.5577978682518006, ppl = 4.7987123195693595\n","Valid Epoch #7, Batch 2707/4160 loss = 1.5608509063720704, ppl = 4.810883783591788\n","Valid Epoch #7, Batch 2708/4160 loss = 1.560187873840332, ppl = 4.808336469599485\n","Valid Epoch #7, Batch 2709/4160 loss = 1.562600507736206, ppl = 4.818072485255389\n","Valid Epoch #7, Batch 2710/4160 loss = 1.5584432590007782, ppl = 4.801215802842886\n","Valid Epoch #7, Batch 2711/4160 loss = 1.5584203839302062, ppl = 4.801126641169809\n","Valid Epoch #7, Batch 2712/4160 loss = 1.5590894043445587, ppl = 4.804083549791162\n","Valid Epoch #7, Batch 2713/4160 loss = 1.5549216449260712, ppl = 4.7864970344838556\n","Valid Epoch #7, Batch 2714/4160 loss = 1.5550386929512023, ppl = 4.787042770443418\n","Valid Epoch #7, Batch 2715/4160 loss = 1.5575426065921782, ppl = 4.79790658271422\n","Valid Epoch #7, Batch 2716/4160 loss = 1.556717814207077, ppl = 4.794257485787864\n","Valid Epoch #7, Batch 2717/4160 loss = 1.5582268404960633, ppl = 4.800120740318286\n","Valid Epoch #7, Batch 2718/4160 loss = 1.5553902745246888, ppl = 4.786828573575524\n","Valid Epoch #7, Batch 2719/4160 loss = 1.560206663608551, ppl = 4.813088778551408\n","Valid Epoch #7, Batch 2720/4160 loss = 1.558510160446167, ppl = 4.805300010147358\n","Valid Epoch #7, Batch 2721/4160 loss = 1.5584331834316254, ppl = 4.804971078452279\n","Valid Epoch #7, Batch 2722/4160 loss = 1.5582095503807067, ppl = 4.803949328950502\n","Valid Epoch #7, Batch 2723/4160 loss = 1.5586756181716919, ppl = 4.8062001362602835\n","Valid Epoch #7, Batch 2724/4160 loss = 1.5614284241199494, ppl = 4.81952499119984\n","Valid Epoch #7, Batch 2725/4160 loss = 1.5615418529510499, ppl = 4.820157910477176\n","Valid Epoch #7, Batch 2726/4160 loss = 1.5622962784767152, ppl = 4.823699975400349\n","Valid Epoch #7, Batch 2727/4160 loss = 1.5635819053649902, ppl = 4.830932060134274\n","Valid Epoch #7, Batch 2728/4160 loss = 1.5621843075752258, ppl = 4.823458066239143\n","Valid Epoch #7, Batch 2729/4160 loss = 1.5632155597209931, ppl = 4.829405164717115\n","Valid Epoch #7, Batch 2730/4160 loss = 1.5631024193763734, ppl = 4.828717633009645\n","Valid Epoch #7, Batch 2731/4160 loss = 1.5648699796199799, ppl = 4.837549522664881\n","Valid Epoch #7, Batch 2732/4160 loss = 1.5644305646419525, ppl = 4.835065204962033\n","Valid Epoch #7, Batch 2733/4160 loss = 1.5648702824115752, ppl = 4.837114987400514\n","Valid Epoch #7, Batch 2734/4160 loss = 1.56737398147583, ppl = 4.85115372879949\n","Valid Epoch #7, Batch 2735/4160 loss = 1.5669570899009704, ppl = 4.849136623153343\n","Valid Epoch #7, Batch 2736/4160 loss = 1.5675254082679748, ppl = 4.852135852517703\n","Valid Epoch #7, Batch 2737/4160 loss = 1.5670850193500518, ppl = 4.849972015880779\n","Valid Epoch #7, Batch 2738/4160 loss = 1.5683582425117493, ppl = 4.856799975886281\n","Valid Epoch #7, Batch 2739/4160 loss = 1.5688686668872833, ppl = 4.859687593911593\n","Valid Epoch #7, Batch 2740/4160 loss = 1.5691071498394011, ppl = 4.861037633399226\n","Valid Epoch #7, Batch 2741/4160 loss = 1.5724017786979676, ppl = 4.877403391914882\n","Valid Epoch #7, Batch 2742/4160 loss = 1.5710395658016205, ppl = 4.87012516590608\n","Valid Epoch #7, Batch 2743/4160 loss = 1.5697930109500886, ppl = 4.864136629352582\n","Valid Epoch #7, Batch 2744/4160 loss = 1.5689193284511567, ppl = 4.859583104261045\n","Valid Epoch #7, Batch 2745/4160 loss = 1.5683367323875428, ppl = 4.856554791260844\n","Valid Epoch #7, Batch 2746/4160 loss = 1.5706350922584533, ppl = 4.8690360670615\n","Valid Epoch #7, Batch 2747/4160 loss = 1.5706929337978364, ppl = 4.869311177372074\n","Valid Epoch #7, Batch 2748/4160 loss = 1.5682845842838287, ppl = 4.856707563095302\n","Valid Epoch #7, Batch 2749/4160 loss = 1.5674673962593078, ppl = 4.852220606674419\n","Valid Epoch #7, Batch 2750/4160 loss = 1.5664141583442688, ppl = 4.846164851021234\n","Valid Epoch #7, Batch 2751/4160 loss = 1.5666791987419129, ppl = 4.847769694434836\n","Valid Epoch #7, Batch 2752/4160 loss = 1.566318895816803, ppl = 4.846198183701068\n","Valid Epoch #7, Batch 2753/4160 loss = 1.565084581375122, ppl = 4.839600010627624\n","Valid Epoch #7, Batch 2754/4160 loss = 1.5636942374706269, ppl = 4.832848418298485\n","Valid Epoch #7, Batch 2755/4160 loss = 1.565842422246933, ppl = 4.843028683805326\n","Valid Epoch #7, Batch 2756/4160 loss = 1.5673757302761078, ppl = 4.8506950229827694\n","Valid Epoch #7, Batch 2757/4160 loss = 1.5655450022220612, ppl = 4.840987916623317\n","Valid Epoch #7, Batch 2758/4160 loss = 1.5657493257522583, ppl = 4.84202489314366\n","Valid Epoch #7, Batch 2759/4160 loss = 1.5635268437862395, ppl = 4.831494366084452\n","Valid Epoch #7, Batch 2760/4160 loss = 1.562864898443222, ppl = 4.828456113272521\n","Valid Epoch #7, Batch 2761/4160 loss = 1.5614179944992066, ppl = 4.821792892304371\n","Valid Epoch #7, Batch 2762/4160 loss = 1.565371631383896, ppl = 4.839949148923467\n","Valid Epoch #7, Batch 2763/4160 loss = 1.5668069529533386, ppl = 4.846861853262651\n","Valid Epoch #7, Batch 2764/4160 loss = 1.5685119462013244, ppl = 4.855131190633879\n","Valid Epoch #7, Batch 2765/4160 loss = 1.570426115989685, ppl = 4.864940691550758\n","Valid Epoch #7, Batch 2766/4160 loss = 1.5705793595314026, ppl = 4.865647516074943\n","Valid Epoch #7, Batch 2767/4160 loss = 1.570284903049469, ppl = 4.86422776724727\n","Valid Epoch #7, Batch 2768/4160 loss = 1.5695059311389923, ppl = 4.860056418655912\n","Valid Epoch #7, Batch 2769/4160 loss = 1.5685719859600067, ppl = 4.855629219824283\n","Valid Epoch #7, Batch 2770/4160 loss = 1.5680910813808442, ppl = 4.853118024426129\n","Valid Epoch #7, Batch 2771/4160 loss = 1.5680674302577973, ppl = 4.853022418713835\n","Valid Epoch #7, Batch 2772/4160 loss = 1.5661222875118255, ppl = 4.842396088631167\n","Valid Epoch #7, Batch 2773/4160 loss = 1.5657196569442748, ppl = 4.840547849098648\n","Valid Epoch #7, Batch 2774/4160 loss = 1.5655470275878907, ppl = 4.839739378628166\n","Valid Epoch #7, Batch 2775/4160 loss = 1.5686190283298493, ppl = 4.854098364751996\n","Valid Epoch #7, Batch 2776/4160 loss = 1.568008062839508, ppl = 4.851303073794923\n","Valid Epoch #7, Batch 2777/4160 loss = 1.5664916563034057, ppl = 4.843293663600363\n","Valid Epoch #7, Batch 2778/4160 loss = 1.5692141819000245, ppl = 4.854618481984333\n","Valid Epoch #7, Batch 2779/4160 loss = 1.569179025888443, ppl = 4.8544519159288635\n","Valid Epoch #7, Batch 2780/4160 loss = 1.5677733325958252, ppl = 4.848297000939194\n","Valid Epoch #7, Batch 2781/4160 loss = 1.5694651103019714, ppl = 4.855642134156815\n","Valid Epoch #7, Batch 2782/4160 loss = 1.5713841700553894, ppl = 4.865760067528514\n","Valid Epoch #7, Batch 2783/4160 loss = 1.5730130219459533, ppl = 4.874489901665319\n","Valid Epoch #7, Batch 2784/4160 loss = 1.5737173449993134, ppl = 4.8778169709221615\n","Valid Epoch #7, Batch 2785/4160 loss = 1.5720790278911592, ppl = 4.869706589647806\n","Valid Epoch #7, Batch 2786/4160 loss = 1.5707703828811646, ppl = 4.862995419564406\n","Valid Epoch #7, Batch 2787/4160 loss = 1.5699437308311461, ppl = 4.8590462097438465\n","Valid Epoch #7, Batch 2788/4160 loss = 1.5707260835170747, ppl = 4.8625996609407505\n","Valid Epoch #7, Batch 2789/4160 loss = 1.57323695063591, ppl = 4.874363304526194\n","Valid Epoch #7, Batch 2790/4160 loss = 1.5718312513828279, ppl = 4.8676200712139455\n","Valid Epoch #7, Batch 2791/4160 loss = 1.5731180775165559, ppl = 4.873374069126959\n","Valid Epoch #7, Batch 2792/4160 loss = 1.573330591917038, ppl = 4.87431443531575\n","Valid Epoch #7, Batch 2793/4160 loss = 1.5730163383483886, ppl = 4.872761580681622\n","Valid Epoch #7, Batch 2794/4160 loss = 1.5732934188842773, ppl = 4.874110107694977\n","Valid Epoch #7, Batch 2795/4160 loss = 1.5738778221607208, ppl = 4.876735203983305\n","Valid Epoch #7, Batch 2796/4160 loss = 1.571840661764145, ppl = 4.86641567470595\n","Valid Epoch #7, Batch 2797/4160 loss = 1.5732296204566956, ppl = 4.8732989291004865\n","Valid Epoch #7, Batch 2798/4160 loss = 1.5737833988666534, ppl = 4.87608016364804\n","Valid Epoch #7, Batch 2799/4160 loss = 1.5723267674446106, ppl = 4.868037963891308\n","Valid Epoch #7, Batch 2800/4160 loss = 1.5742510735988617, ppl = 4.880243680428778\n","Valid Epoch #7, Batch 2801/4160 loss = 1.5750220227241516, ppl = 4.882992460689184\n","Valid Epoch #7, Batch 2802/4160 loss = 1.574208595752716, ppl = 4.880235510929989\n","Valid Epoch #7, Batch 2803/4160 loss = 1.5750416314601898, ppl = 4.883212723836377\n","Valid Epoch #7, Batch 2804/4160 loss = 1.5753319251537323, ppl = 4.88433008990231\n","Valid Epoch #7, Batch 2805/4160 loss = 1.5745063614845276, ppl = 4.880982358971838\n","Valid Epoch #7, Batch 2806/4160 loss = 1.5763842177391052, ppl = 4.888261330464969\n","Valid Epoch #7, Batch 2807/4160 loss = 1.5719816422462463, ppl = 4.871786196842826\n","Valid Epoch #7, Batch 2808/4160 loss = 1.5742503559589387, ppl = 4.881249564404301\n","Valid Epoch #7, Batch 2809/4160 loss = 1.573347932100296, ppl = 4.877330442632444\n","Valid Epoch #7, Batch 2810/4160 loss = 1.5753026711940765, ppl = 4.8843903060322535\n","Valid Epoch #7, Batch 2811/4160 loss = 1.577837438583374, ppl = 4.895622403428081\n","Valid Epoch #7, Batch 2812/4160 loss = 1.5750269305706024, ppl = 4.884427277523202\n","Valid Epoch #7, Batch 2813/4160 loss = 1.5802965188026428, ppl = 4.908024144552438\n","Valid Epoch #7, Batch 2814/4160 loss = 1.5788309323787688, ppl = 4.901630729349735\n","Valid Epoch #7, Batch 2815/4160 loss = 1.576885267496109, ppl = 4.892959033225447\n","Valid Epoch #7, Batch 2816/4160 loss = 1.5774104523658752, ppl = 4.895247654251295\n","Valid Epoch #7, Batch 2817/4160 loss = 1.5769189190864563, ppl = 4.893239850873667\n","Valid Epoch #7, Batch 2818/4160 loss = 1.5803735530376435, ppl = 4.909963404349289\n","Valid Epoch #7, Batch 2819/4160 loss = 1.578639769554138, ppl = 4.8990272785568125\n","Valid Epoch #7, Batch 2820/4160 loss = 1.5793425273895263, ppl = 4.9020942489512995\n","Valid Epoch #7, Batch 2821/4160 loss = 1.5803321063518525, ppl = 4.906522050323478\n","Valid Epoch #7, Batch 2822/4160 loss = 1.5803178882598876, ppl = 4.906457859066556\n","Valid Epoch #7, Batch 2823/4160 loss = 1.5822652244567872, ppl = 4.917084187824217\n","Valid Epoch #7, Batch 2824/4160 loss = 1.582010371685028, ppl = 4.915690838661534\n","Valid Epoch #7, Batch 2825/4160 loss = 1.5801208424568176, ppl = 4.9060291174504576\n","Valid Epoch #7, Batch 2826/4160 loss = 1.581368453502655, ppl = 4.912506084175405\n","Valid Epoch #7, Batch 2827/4160 loss = 1.5781737875938415, ppl = 4.896112800643156\n","Valid Epoch #7, Batch 2828/4160 loss = 1.5799820852279662, ppl = 4.905989158908172\n","Valid Epoch #7, Batch 2829/4160 loss = 1.5768808138370514, ppl = 4.889805499274313\n","Valid Epoch #7, Batch 2830/4160 loss = 1.5760300433635712, ppl = 4.884877334279187\n","Valid Epoch #7, Batch 2831/4160 loss = 1.5768800806999206, ppl = 4.889713747021502\n","Valid Epoch #7, Batch 2832/4160 loss = 1.5751593208312988, ppl = 4.8809710447739425\n","Valid Epoch #7, Batch 2833/4160 loss = 1.5767706072330474, ppl = 4.889301681564801\n","Valid Epoch #7, Batch 2834/4160 loss = 1.577510552406311, ppl = 4.894169627746366\n","Valid Epoch #7, Batch 2835/4160 loss = 1.5765187561511993, ppl = 4.889695738194346\n","Valid Epoch #7, Batch 2836/4160 loss = 1.5753211617469787, ppl = 4.883568507283224\n","Valid Epoch #7, Batch 2837/4160 loss = 1.5756505358219146, ppl = 4.885177860531601\n","Valid Epoch #7, Batch 2838/4160 loss = 1.576554605960846, ppl = 4.890581949268825\n","Valid Epoch #7, Batch 2839/4160 loss = 1.5778081357479095, ppl = 4.898331632231389\n","Valid Epoch #7, Batch 2840/4160 loss = 1.5785577595233917, ppl = 4.902791072375004\n","Valid Epoch #7, Batch 2841/4160 loss = 1.5786572861671448, ppl = 4.903374264316397\n","Valid Epoch #7, Batch 2842/4160 loss = 1.5798901629447937, ppl = 4.909918079202814\n","Valid Epoch #7, Batch 2843/4160 loss = 1.5819643366336822, ppl = 4.920315437868583\n","Valid Epoch #7, Batch 2844/4160 loss = 1.5822928166389465, ppl = 4.921980941258813\n","Valid Epoch #7, Batch 2845/4160 loss = 1.5838020157814026, ppl = 4.930204340188052\n","Valid Epoch #7, Batch 2846/4160 loss = 1.5833090782165526, ppl = 4.92728068864923\n","Valid Epoch #7, Batch 2847/4160 loss = 1.5849583375453948, ppl = 4.9358336535899605\n","Valid Epoch #7, Batch 2848/4160 loss = 1.5877673590183259, ppl = 4.950844631245256\n","Valid Epoch #7, Batch 2849/4160 loss = 1.589011687040329, ppl = 4.957826943694493\n","Valid Epoch #7, Batch 2850/4160 loss = 1.5901592576503754, ppl = 4.964456847765361\n","Valid Epoch #7, Batch 2851/4160 loss = 1.5880201065540314, ppl = 4.952640554081164\n","Valid Epoch #7, Batch 2852/4160 loss = 1.5909372651576996, ppl = 4.967149850122351\n","Valid Epoch #7, Batch 2853/4160 loss = 1.591249692440033, ppl = 4.96874378408472\n","Valid Epoch #7, Batch 2854/4160 loss = 1.590837858915329, ppl = 4.96691756518019\n","Valid Epoch #7, Batch 2855/4160 loss = 1.590736665725708, ppl = 4.966387345639198\n","Valid Epoch #7, Batch 2856/4160 loss = 1.5901792311668397, ppl = 4.963463366903375\n","Valid Epoch #7, Batch 2857/4160 loss = 1.5913041067123412, ppl = 4.96921598661968\n","Valid Epoch #7, Batch 2858/4160 loss = 1.5927774834632873, ppl = 4.977355160971367\n","Valid Epoch #7, Batch 2859/4160 loss = 1.591731835603714, ppl = 4.97315433043368\n","Valid Epoch #7, Batch 2860/4160 loss = 1.5949667418003082, ppl = 4.9901112634476785\n","Valid Epoch #7, Batch 2861/4160 loss = 1.594773873090744, ppl = 4.9892936895085365\n","Valid Epoch #7, Batch 2862/4160 loss = 1.5920851242542267, ppl = 4.9761859144037315\n","Valid Epoch #7, Batch 2863/4160 loss = 1.590099823474884, ppl = 4.9668764928983435\n","Valid Epoch #7, Batch 2864/4160 loss = 1.5900885272026062, ppl = 4.966816935533707\n","Valid Epoch #7, Batch 2865/4160 loss = 1.5903198027610779, ppl = 4.968134375386879\n","Valid Epoch #7, Batch 2866/4160 loss = 1.588740667104721, ppl = 4.961344951623357\n","Valid Epoch #7, Batch 2867/4160 loss = 1.588154890537262, ppl = 4.958641897276475\n","Valid Epoch #7, Batch 2868/4160 loss = 1.586095356941223, ppl = 4.9490579659732825\n","Valid Epoch #7, Batch 2869/4160 loss = 1.5873818123340606, ppl = 4.955266636922351\n","Valid Epoch #7, Batch 2870/4160 loss = 1.5848731458187104, ppl = 4.943957142241419\n","Valid Epoch #7, Batch 2871/4160 loss = 1.588110728263855, ppl = 4.959393241317803\n","Valid Epoch #7, Batch 2872/4160 loss = 1.5892230200767516, ppl = 4.965215678948672\n","Valid Epoch #7, Batch 2873/4160 loss = 1.5893680131435395, ppl = 4.9658726991003865\n","Valid Epoch #7, Batch 2874/4160 loss = 1.5886977183818818, ppl = 4.9628625543640075\n","Valid Epoch #7, Batch 2875/4160 loss = 1.5863348245620728, ppl = 4.9514377648343\n","Valid Epoch #7, Batch 2876/4160 loss = 1.5893009030818939, ppl = 4.966757698502289\n","Valid Epoch #7, Batch 2877/4160 loss = 1.5881942319869995, ppl = 4.961633220659849\n","Valid Epoch #7, Batch 2878/4160 loss = 1.5875108790397645, ppl = 4.958494674859238\n","Valid Epoch #7, Batch 2879/4160 loss = 1.587514818906784, ppl = 4.958513312476761\n","Valid Epoch #7, Batch 2880/4160 loss = 1.5900600600242614, ppl = 4.970333368218422\n","Valid Epoch #7, Batch 2881/4160 loss = 1.5910031473636628, ppl = 4.975000679872817\n","Valid Epoch #7, Batch 2882/4160 loss = 1.589485651254654, ppl = 4.96684235202969\n","Valid Epoch #7, Batch 2883/4160 loss = 1.58784769654274, ppl = 4.958067617235761\n","Valid Epoch #7, Batch 2884/4160 loss = 1.5876413190364838, ppl = 4.957068346907031\n","Valid Epoch #7, Batch 2885/4160 loss = 1.5863169407844544, ppl = 4.951416986730218\n","Valid Epoch #7, Batch 2886/4160 loss = 1.585459176301956, ppl = 4.9474712805087835\n","Valid Epoch #7, Batch 2887/4160 loss = 1.585522755384445, ppl = 4.947763567091777\n","Valid Epoch #7, Batch 2888/4160 loss = 1.5863745629787445, ppl = 4.9519620767923245\n","Valid Epoch #7, Batch 2889/4160 loss = 1.5861790299415588, ppl = 4.950936231656247\n","Valid Epoch #7, Batch 2890/4160 loss = 1.5867559015750885, ppl = 4.953589370033142\n","Valid Epoch #7, Batch 2891/4160 loss = 1.5871178328990936, ppl = 4.955345685026761\n","Valid Epoch #7, Batch 2892/4160 loss = 1.5887520444393157, ppl = 4.963285183114905\n","Valid Epoch #7, Batch 2893/4160 loss = 1.58859344124794, ppl = 4.962519795846696\n","Valid Epoch #7, Batch 2894/4160 loss = 1.5882941925525664, ppl = 4.961064983983722\n","Valid Epoch #7, Batch 2895/4160 loss = 1.5908248472213744, ppl = 4.974381927841301\n","Valid Epoch #7, Batch 2896/4160 loss = 1.589672518968582, ppl = 4.9694109531439\n","Valid Epoch #7, Batch 2897/4160 loss = 1.5879481327533722, ppl = 4.96100389187501\n","Valid Epoch #7, Batch 2898/4160 loss = 1.586272156238556, ppl = 4.953037641033767\n","Valid Epoch #7, Batch 2899/4160 loss = 1.5858761858940125, ppl = 4.951046492770807\n","Valid Epoch #7, Batch 2900/4160 loss = 1.5822455322742461, ppl = 4.929817280370515\n","Valid Epoch #7, Batch 2901/4160 loss = 1.582359743118286, ppl = 4.9302428175014965\n","Valid Epoch #7, Batch 2902/4160 loss = 1.5817679464817047, ppl = 4.92837337384361\n","Valid Epoch #7, Batch 2903/4160 loss = 1.5798587155342103, ppl = 4.9218994243754\n","Valid Epoch #7, Batch 2904/4160 loss = 1.5778831577301025, ppl = 4.914898694273144\n","Valid Epoch #7, Batch 2905/4160 loss = 1.5771687757968902, ppl = 4.912216686933798\n","Valid Epoch #7, Batch 2906/4160 loss = 1.5755489146709443, ppl = 4.9058586281376115\n","Valid Epoch #7, Batch 2907/4160 loss = 1.5812406861782073, ppl = 4.928699302245642\n","Valid Epoch #7, Batch 2908/4160 loss = 1.5781344759464264, ppl = 4.916250590233256\n","Valid Epoch #7, Batch 2909/4160 loss = 1.5792088305950165, ppl = 4.920957336395315\n","Valid Epoch #7, Batch 2910/4160 loss = 1.5783852803707124, ppl = 4.917813987752405\n","Valid Epoch #7, Batch 2911/4160 loss = 1.577060672044754, ppl = 4.911590355424382\n","Valid Epoch #7, Batch 2912/4160 loss = 1.5784377658367157, ppl = 4.916683619160484\n","Valid Epoch #7, Batch 2913/4160 loss = 1.575418096780777, ppl = 4.901668497568932\n","Valid Epoch #7, Batch 2914/4160 loss = 1.5786109638214112, ppl = 4.916904263488055\n","Valid Epoch #7, Batch 2915/4160 loss = 1.5800294959545136, ppl = 4.923057560772196\n","Valid Epoch #7, Batch 2916/4160 loss = 1.582714147567749, ppl = 4.936832949038273\n","Valid Epoch #7, Batch 2917/4160 loss = 1.583983643054962, ppl = 4.942227316454041\n","Valid Epoch #7, Batch 2918/4160 loss = 1.5804820990562438, ppl = 4.925314092272529\n","Valid Epoch #7, Batch 2919/4160 loss = 1.5788621866703034, ppl = 4.916675031910838\n","Valid Epoch #7, Batch 2920/4160 loss = 1.5787971770763398, ppl = 4.916382184581436\n","Valid Epoch #7, Batch 2921/4160 loss = 1.579808485507965, ppl = 4.9213834268005945\n","Valid Epoch #7, Batch 2922/4160 loss = 1.5800892436504363, ppl = 4.922668029978121\n","Valid Epoch #7, Batch 2923/4160 loss = 1.5753453600406646, ppl = 4.8999835517736114\n","Valid Epoch #7, Batch 2924/4160 loss = 1.5728531384468079, ppl = 4.8880761527701235\n","Valid Epoch #7, Batch 2925/4160 loss = 1.5748625099658966, ppl = 4.898414425164519\n","Valid Epoch #7, Batch 2926/4160 loss = 1.5729045629501344, ppl = 4.888595125897888\n","Valid Epoch #7, Batch 2927/4160 loss = 1.5762803947925568, ppl = 4.906084339861439\n","Valid Epoch #7, Batch 2928/4160 loss = 1.5750342583656312, ppl = 4.899089317672034\n","Valid Epoch #7, Batch 2929/4160 loss = 1.57772469997406, ppl = 4.912830038433413\n","Valid Epoch #7, Batch 2930/4160 loss = 1.5760200309753418, ppl = 4.90413208711097\n","Valid Epoch #7, Batch 2931/4160 loss = 1.57500772356987, ppl = 4.898418237617701\n","Valid Epoch #7, Batch 2932/4160 loss = 1.5762066769599914, ppl = 4.904349146405973\n","Valid Epoch #7, Batch 2933/4160 loss = 1.5738808965682984, ppl = 4.892732846528751\n","Valid Epoch #7, Batch 2934/4160 loss = 1.570646448135376, ppl = 4.873871556728021\n","Valid Epoch #7, Batch 2935/4160 loss = 1.5734975230693817, ppl = 4.88802744395981\n","Valid Epoch #7, Batch 2936/4160 loss = 1.57547470331192, ppl = 4.89855619632784\n","Valid Epoch #7, Batch 2937/4160 loss = 1.5750931477546692, ppl = 4.896696708423043\n","Valid Epoch #7, Batch 2938/4160 loss = 1.573452650308609, ppl = 4.887237744217225\n","Valid Epoch #7, Batch 2939/4160 loss = 1.5709463083744049, ppl = 4.872655077561775\n","Valid Epoch #7, Batch 2940/4160 loss = 1.5715464270114898, ppl = 4.876474053060032\n","Valid Epoch #7, Batch 2941/4160 loss = 1.568166617155075, ppl = 4.859585310978781\n","Valid Epoch #7, Batch 2942/4160 loss = 1.5667236626148224, ppl = 4.852004705549508\n","Valid Epoch #7, Batch 2943/4160 loss = 1.566151144504547, ppl = 4.848916144056671\n","Valid Epoch #7, Batch 2944/4160 loss = 1.5679835987091064, ppl = 4.859281440744428\n","Valid Epoch #7, Batch 2945/4160 loss = 1.5669648742675781, ppl = 4.8535956907995725\n","Valid Epoch #7, Batch 2946/4160 loss = 1.565377243757248, ppl = 4.845101613361073\n","Valid Epoch #7, Batch 2947/4160 loss = 1.5649560022354125, ppl = 4.84278120194447\n","Valid Epoch #7, Batch 2948/4160 loss = 1.5632248747348785, ppl = 4.833037939854493\n","Valid Epoch #7, Batch 2949/4160 loss = 1.5612754213809967, ppl = 4.822467988760944\n","Valid Epoch #7, Batch 2950/4160 loss = 1.559895533323288, ppl = 4.8145860474259585\n","Valid Epoch #7, Batch 2951/4160 loss = 1.55865581035614, ppl = 4.80880983058212\n","Valid Epoch #7, Batch 2952/4160 loss = 1.5577088510990142, ppl = 4.8036287138847795\n","Valid Epoch #7, Batch 2953/4160 loss = 1.5601838374137877, ppl = 4.818180366567573\n","Valid Epoch #7, Batch 2954/4160 loss = 1.5596441972255706, ppl = 4.815898467465147\n","Valid Epoch #7, Batch 2955/4160 loss = 1.5579530155658723, ppl = 4.807787188194476\n","Valid Epoch #7, Batch 2956/4160 loss = 1.558186113834381, ppl = 4.808990089785006\n","Valid Epoch #7, Batch 2957/4160 loss = 1.555505132675171, ppl = 4.796274530341257\n","Valid Epoch #7, Batch 2958/4160 loss = 1.554604458808899, ppl = 4.7911574266858965\n","Valid Epoch #7, Batch 2959/4160 loss = 1.558505220413208, ppl = 4.809339743626911\n","Valid Epoch #7, Batch 2960/4160 loss = 1.5559954452514648, ppl = 4.795721731957647\n","Valid Epoch #7, Batch 2961/4160 loss = 1.5585144543647766, ppl = 4.80774845756118\n","Valid Epoch #7, Batch 2962/4160 loss = 1.559815402030945, ppl = 4.813651850076899\n","Valid Epoch #7, Batch 2963/4160 loss = 1.5625872695446015, ppl = 4.827192059493469\n","Valid Epoch #7, Batch 2964/4160 loss = 1.5633636498451233, ppl = 4.831446059263313\n","Valid Epoch #7, Batch 2965/4160 loss = 1.5628205609321595, ppl = 4.828399955127132\n","Valid Epoch #7, Batch 2966/4160 loss = 1.5650331914424895, ppl = 4.838229036703114\n","Valid Epoch #7, Batch 2967/4160 loss = 1.5648922741413116, ppl = 4.837602063981506\n","Valid Epoch #7, Batch 2968/4160 loss = 1.568342000246048, ppl = 4.854865655147508\n","Valid Epoch #7, Batch 2969/4160 loss = 1.5662528765201569, ppl = 4.845168855983438\n","Valid Epoch #7, Batch 2970/4160 loss = 1.5673687064647674, ppl = 4.849850951455332\n","Valid Epoch #7, Batch 2971/4160 loss = 1.5655646967887877, ppl = 4.840638422682509\n","Valid Epoch #7, Batch 2972/4160 loss = 1.5629699063301086, ppl = 4.827997168145178\n","Valid Epoch #7, Batch 2973/4160 loss = 1.5643022084236144, ppl = 4.834501917578197\n","Valid Epoch #7, Batch 2974/4160 loss = 1.5663372600078582, ppl = 4.844301332627584\n","Valid Epoch #7, Batch 2975/4160 loss = 1.570350649356842, ppl = 4.865468186129222\n","Valid Epoch #7, Batch 2976/4160 loss = 1.5679743099212646, ppl = 4.852843537577383\n","Valid Epoch #7, Batch 2977/4160 loss = 1.5662773597240447, ppl = 4.846008834502818\n","Valid Epoch #7, Batch 2978/4160 loss = 1.5663693928718567, ppl = 4.846419137192321\n","Valid Epoch #7, Batch 2979/4160 loss = 1.5665104269981385, ppl = 4.84709116107986\n","Valid Epoch #7, Batch 2980/4160 loss = 1.565517431497574, ppl = 4.842118930861174\n","Valid Epoch #7, Batch 2981/4160 loss = 1.56658611536026, ppl = 4.847968109826443\n","Valid Epoch #7, Batch 2982/4160 loss = 1.566286132335663, ppl = 4.846496800972473\n","Valid Epoch #7, Batch 2983/4160 loss = 1.5664078521728515, ppl = 4.8471005913030645\n","Valid Epoch #7, Batch 2984/4160 loss = 1.5652495980262757, ppl = 4.841859437271819\n","Valid Epoch #7, Batch 2985/4160 loss = 1.5681645202636718, ppl = 4.855365390832717\n","Valid Epoch #7, Batch 2986/4160 loss = 1.5683687460422515, ppl = 4.856274362298685\n","Valid Epoch #7, Batch 2987/4160 loss = 1.5697482383251191, ppl = 4.863096074116347\n","Valid Epoch #7, Batch 2988/4160 loss = 1.5689857614040374, ppl = 4.8593212731717434\n","Valid Epoch #7, Batch 2989/4160 loss = 1.5679145193099975, ppl = 4.854043601920967\n","Valid Epoch #7, Batch 2990/4160 loss = 1.5708617281913757, ppl = 4.870266427885477\n","Valid Epoch #7, Batch 2991/4160 loss = 1.5711320328712464, ppl = 4.871620208060879\n","Valid Epoch #7, Batch 2992/4160 loss = 1.5698195219039917, ppl = 4.865142790729959\n","Valid Epoch #7, Batch 2993/4160 loss = 1.5700962054729461, ppl = 4.866485945517933\n","Valid Epoch #7, Batch 2994/4160 loss = 1.572153309583664, ppl = 4.8774242865284485\n","Valid Epoch #7, Batch 2995/4160 loss = 1.5697285318374634, ppl = 4.864599567343076\n","Valid Epoch #7, Batch 2996/4160 loss = 1.5691818845272065, ppl = 4.8624343894350694\n","Valid Epoch #7, Batch 2997/4160 loss = 1.570450623035431, ppl = 4.868477225769444\n","Valid Epoch #7, Batch 2998/4160 loss = 1.5733918476104736, ppl = 4.8834067121566545\n","Valid Epoch #7, Batch 2999/4160 loss = 1.572051385641098, ppl = 4.877222476733736\n","Valid Epoch #7, Batch 3000/4160 loss = 1.5717983448505402, ppl = 4.876010665006747\n","Valid Epoch #7, Batch 3001/4160 loss = 1.5720809304714203, ppl = 4.877084675674178\n","Valid Epoch #7, Batch 3002/4160 loss = 1.5729825985431671, ppl = 4.879978013118121\n","Valid Epoch #7, Batch 3003/4160 loss = 1.575480774641037, ppl = 4.888711586927952\n","Valid Epoch #7, Batch 3004/4160 loss = 1.5763388419151305, ppl = 4.891583267622469\n","Valid Epoch #7, Batch 3005/4160 loss = 1.5766688644886018, ppl = 4.892798485784266\n","Valid Epoch #7, Batch 3006/4160 loss = 1.5775612688064575, ppl = 4.896173544098699\n","Valid Epoch #7, Batch 3007/4160 loss = 1.574352980852127, ppl = 4.881729878909441\n","Valid Epoch #7, Batch 3008/4160 loss = 1.5735579586029054, ppl = 4.879118147698752\n","Valid Epoch #7, Batch 3009/4160 loss = 1.573095874786377, ppl = 4.877031644995639\n","Valid Epoch #7, Batch 3010/4160 loss = 1.5724922394752503, ppl = 4.87488663475241\n","Valid Epoch #7, Batch 3011/4160 loss = 1.5720691168308258, ppl = 4.87306615371402\n","Valid Epoch #7, Batch 3012/4160 loss = 1.5727007210254669, ppl = 4.875647373881104\n","Valid Epoch #7, Batch 3013/4160 loss = 1.5708398461341857, ppl = 4.868414936507364\n","Valid Epoch #7, Batch 3014/4160 loss = 1.569423657655716, ppl = 4.861054487829843\n","Valid Epoch #7, Batch 3015/4160 loss = 1.5686960244178771, ppl = 4.857789243635948\n","Valid Epoch #7, Batch 3016/4160 loss = 1.5679741454124452, ppl = 4.853714575416237\n","Valid Epoch #7, Batch 3017/4160 loss = 1.5667905962467195, ppl = 4.848664198109847\n","Valid Epoch #7, Batch 3018/4160 loss = 1.5686632096767426, ppl = 4.856971521899679\n","Valid Epoch #7, Batch 3019/4160 loss = 1.5694809877872467, ppl = 4.861157901478637\n","Valid Epoch #7, Batch 3020/4160 loss = 1.5696021604537964, ppl = 4.861705282754219\n","Valid Epoch #7, Batch 3021/4160 loss = 1.5727098572254181, ppl = 4.880656500943413\n","Valid Epoch #7, Batch 3022/4160 loss = 1.5707444405555726, ppl = 4.872377195762435\n","Valid Epoch #7, Batch 3023/4160 loss = 1.5741592121124268, ppl = 4.8875875189096165\n","Valid Epoch #7, Batch 3024/4160 loss = 1.5763683247566223, ppl = 4.897988153833034\n","Valid Epoch #7, Batch 3025/4160 loss = 1.5770735812187195, ppl = 4.902138093894058\n","Valid Epoch #7, Batch 3026/4160 loss = 1.5799494767189026, ppl = 4.917266312563619\n","Valid Epoch #7, Batch 3027/4160 loss = 1.5774869990348817, ppl = 4.90394240884815\n","Valid Epoch #7, Batch 3028/4160 loss = 1.577074934244156, ppl = 4.9018146059620875\n","Valid Epoch #7, Batch 3029/4160 loss = 1.5763659358024598, ppl = 4.897827666717247\n","Valid Epoch #7, Batch 3030/4160 loss = 1.5757712507247925, ppl = 4.8951257472998515\n","Valid Epoch #7, Batch 3031/4160 loss = 1.5768276643753052, ppl = 4.9011019407893555\n","Valid Epoch #7, Batch 3032/4160 loss = 1.57645489692688, ppl = 4.899181228217015\n","Valid Epoch #7, Batch 3033/4160 loss = 1.5773725652694701, ppl = 4.903444883396251\n","Valid Epoch #7, Batch 3034/4160 loss = 1.5763160371780396, ppl = 4.898492829584381\n","Valid Epoch #7, Batch 3035/4160 loss = 1.5756721568107606, ppl = 4.894934326424246\n","Valid Epoch #7, Batch 3036/4160 loss = 1.5746584153175354, ppl = 4.889276397913057\n","Valid Epoch #7, Batch 3037/4160 loss = 1.5743050837516785, ppl = 4.887616595513031\n","Valid Epoch #7, Batch 3038/4160 loss = 1.5737295544147492, ppl = 4.884649113254922\n","Valid Epoch #7, Batch 3039/4160 loss = 1.57553915143013, ppl = 4.894804703130254\n","Valid Epoch #7, Batch 3040/4160 loss = 1.5742042768001556, ppl = 4.886611524168087\n","Valid Epoch #7, Batch 3041/4160 loss = 1.577203812599182, ppl = 4.9013029282000184\n","Valid Epoch #7, Batch 3042/4160 loss = 1.5765251064300536, ppl = 4.898098368186091\n","Valid Epoch #7, Batch 3043/4160 loss = 1.5759972524642945, ppl = 4.89540325106437\n","Valid Epoch #7, Batch 3044/4160 loss = 1.5773500549793242, ppl = 4.904370797470938\n","Valid Epoch #7, Batch 3045/4160 loss = 1.5758325219154359, ppl = 4.896905898659384\n","Valid Epoch #7, Batch 3046/4160 loss = 1.5773678362369536, ppl = 4.905098059990403\n","Valid Epoch #7, Batch 3047/4160 loss = 1.578490695953369, ppl = 4.911507067584196\n","Valid Epoch #7, Batch 3048/4160 loss = 1.579583991765976, ppl = 4.917462822191716\n","Valid Epoch #7, Batch 3049/4160 loss = 1.5807094585895538, ppl = 4.923312633984414\n","Valid Epoch #7, Batch 3050/4160 loss = 1.5809978699684144, ppl = 4.924871364967045\n","Valid Epoch #7, Batch 3051/4160 loss = 1.583195730447769, ppl = 4.935629087733277\n","Valid Epoch #7, Batch 3052/4160 loss = 1.5830445659160615, ppl = 4.934846490323195\n","Valid Epoch #7, Batch 3053/4160 loss = 1.5807466793060303, ppl = 4.9212207228919915\n","Valid Epoch #7, Batch 3054/4160 loss = 1.5834359991550446, ppl = 4.933919724588781\n","Valid Epoch #7, Batch 3055/4160 loss = 1.5839183962345122, ppl = 4.936095329452483\n","Valid Epoch #7, Batch 3056/4160 loss = 1.583342981338501, ppl = 4.933175960922773\n","Valid Epoch #7, Batch 3057/4160 loss = 1.5863680601119996, ppl = 4.94778444654022\n","Valid Epoch #7, Batch 3058/4160 loss = 1.585431433916092, ppl = 4.942930014333213\n","Valid Epoch #7, Batch 3059/4160 loss = 1.586170309782028, ppl = 4.947246880615517\n","Valid Epoch #7, Batch 3060/4160 loss = 1.5869720423221587, ppl = 4.951231582087051\n","Valid Epoch #7, Batch 3061/4160 loss = 1.587711431980133, ppl = 4.955376324605002\n","Valid Epoch #7, Batch 3062/4160 loss = 1.587260386943817, ppl = 4.953242062576275\n","Valid Epoch #7, Batch 3063/4160 loss = 1.5876505196094512, ppl = 4.955467243304159\n","Valid Epoch #7, Batch 3064/4160 loss = 1.5884477937221526, ppl = 4.96019339914732\n","Valid Epoch #7, Batch 3065/4160 loss = 1.5853550732135773, ppl = 4.945674290104888\n","Valid Epoch #7, Batch 3066/4160 loss = 1.5871286702156067, ppl = 4.9552838244336845\n","Valid Epoch #7, Batch 3067/4160 loss = 1.5883501040935517, ppl = 4.961023452508419\n","Valid Epoch #7, Batch 3068/4160 loss = 1.5864972174167633, ppl = 4.95101561980995\n","Valid Epoch #7, Batch 3069/4160 loss = 1.588186981678009, ppl = 4.95869887851158\n","Valid Epoch #7, Batch 3070/4160 loss = 1.5899177837371825, ppl = 4.967078418048965\n","Valid Epoch #7, Batch 3071/4160 loss = 1.5892216205596923, ppl = 4.963944703587124\n","Valid Epoch #7, Batch 3072/4160 loss = 1.590801832675934, ppl = 4.971249465504084\n","Valid Epoch #7, Batch 3073/4160 loss = 1.5890392792224883, ppl = 4.962822558024207\n","Valid Epoch #7, Batch 3074/4160 loss = 1.5884330892562866, ppl = 4.959692314371252\n","Valid Epoch #7, Batch 3075/4160 loss = 1.5849749863147735, ppl = 4.940972919091519\n","Valid Epoch #7, Batch 3076/4160 loss = 1.5831238198280335, ppl = 4.933019465958521\n","Valid Epoch #7, Batch 3077/4160 loss = 1.5879962015151978, ppl = 4.9562207467956805\n","Valid Epoch #7, Batch 3078/4160 loss = 1.5889993023872375, ppl = 4.960946442577679\n","Valid Epoch #7, Batch 3079/4160 loss = 1.5897935461997985, ppl = 4.964913186698852\n","Valid Epoch #7, Batch 3080/4160 loss = 1.589554362297058, ppl = 4.963787515907648\n","Valid Epoch #7, Batch 3081/4160 loss = 1.5886857175827027, ppl = 4.95898618634001\n","Valid Epoch #7, Batch 3082/4160 loss = 1.5874225795269012, ppl = 4.953253111096188\n","Valid Epoch #7, Batch 3083/4160 loss = 1.5882135653495788, ppl = 4.957361042394497\n","Valid Epoch #7, Batch 3084/4160 loss = 1.5892752742767333, ppl = 4.96214176230295\n","Valid Epoch #7, Batch 3085/4160 loss = 1.5877892935276032, ppl = 4.95476605659938\n","Valid Epoch #7, Batch 3086/4160 loss = 1.5908248353004455, ppl = 4.97071328293403\n","Valid Epoch #7, Batch 3087/4160 loss = 1.5899667751789093, ppl = 4.966360134392254\n","Valid Epoch #7, Batch 3088/4160 loss = 1.588287011384964, ppl = 4.9589931753685175\n","Valid Epoch #7, Batch 3089/4160 loss = 1.5897105741500854, ppl = 4.966133876950503\n","Valid Epoch #7, Batch 3090/4160 loss = 1.5879719471931457, ppl = 4.9559914420431825\n","Valid Epoch #7, Batch 3091/4160 loss = 1.5871556317806244, ppl = 4.952012171519999\n","Valid Epoch #7, Batch 3092/4160 loss = 1.588283783197403, ppl = 4.957527629899983\n","Valid Epoch #7, Batch 3093/4160 loss = 1.5880846965312958, ppl = 4.95655742562406\n","Valid Epoch #7, Batch 3094/4160 loss = 1.5856650149822236, ppl = 4.943913742344666\n","Valid Epoch #7, Batch 3095/4160 loss = 1.585254602432251, ppl = 4.942034433121455\n","Valid Epoch #7, Batch 3096/4160 loss = 1.587197414636612, ppl = 4.95029791853628\n","Valid Epoch #7, Batch 3097/4160 loss = 1.5897559189796449, ppl = 4.965084065846326\n","Valid Epoch #7, Batch 3098/4160 loss = 1.5864866650104523, ppl = 4.9487456356326796\n","Valid Epoch #7, Batch 3099/4160 loss = 1.5862576830387116, ppl = 4.947769664092693\n","Valid Epoch #7, Batch 3100/4160 loss = 1.58587850689888, ppl = 4.946010235562547\n","Valid Epoch #7, Batch 3101/4160 loss = 1.5880619549751283, ppl = 4.955416096443722\n","Valid Epoch #7, Batch 3102/4160 loss = 1.5897985458374024, ppl = 4.961780203031903\n","Valid Epoch #7, Batch 3103/4160 loss = 1.5890656292438508, ppl = 4.95898814729288\n","Valid Epoch #7, Batch 3104/4160 loss = 1.5891459393501282, ppl = 4.959269745287366\n","Valid Epoch #7, Batch 3105/4160 loss = 1.5881037294864655, ppl = 4.955564835292821\n","Valid Epoch #7, Batch 3106/4160 loss = 1.5899967408180238, ppl = 4.963803589070703\n","Valid Epoch #7, Batch 3107/4160 loss = 1.5887459206581116, ppl = 4.959314143461173\n","Valid Epoch #7, Batch 3108/4160 loss = 1.5897946453094483, ppl = 4.962803974353883\n","Valid Epoch #7, Batch 3109/4160 loss = 1.5893451356887818, ppl = 4.960864696177413\n","Valid Epoch #7, Batch 3110/4160 loss = 1.5919779670238494, ppl = 4.971247840649363\n","Valid Epoch #7, Batch 3111/4160 loss = 1.5932203507423401, ppl = 4.9768198591188675\n","Valid Epoch #7, Batch 3112/4160 loss = 1.5908710753917694, ppl = 4.967990254027566\n","Valid Epoch #7, Batch 3113/4160 loss = 1.5920514476299286, ppl = 4.9724205752285044\n","Valid Epoch #7, Batch 3114/4160 loss = 1.5924570190906524, ppl = 4.974423073966341\n","Valid Epoch #7, Batch 3115/4160 loss = 1.5915251421928405, ppl = 4.970573725709884\n","Valid Epoch #7, Batch 3116/4160 loss = 1.5895668601989745, ppl = 4.960893097482109\n","Valid Epoch #7, Batch 3117/4160 loss = 1.5908921658992767, ppl = 4.966589440463564\n","Valid Epoch #7, Batch 3118/4160 loss = 1.591124379634857, ppl = 4.96773227153187\n","Valid Epoch #7, Batch 3119/4160 loss = 1.5899717378616334, ppl = 4.9619280312427705\n","Valid Epoch #7, Batch 3120/4160 loss = 1.5896412634849548, ppl = 4.960450640950344\n","Valid Epoch #7, Batch 3121/4160 loss = 1.5854005432128906, ppl = 4.935929651124206\n","Valid Epoch #7, Batch 3122/4160 loss = 1.5904526686668397, ppl = 4.960987890918469\n","Valid Epoch #7, Batch 3123/4160 loss = 1.5897546076774598, ppl = 4.957442673065268\n","Valid Epoch #7, Batch 3124/4160 loss = 1.5914151740074158, ppl = 4.966921254795353\n","Valid Epoch #7, Batch 3125/4160 loss = 1.5885083782672882, ppl = 4.951548866302382\n","Valid Epoch #7, Batch 3126/4160 loss = 1.58625066280365, ppl = 4.939315840716772\n","Valid Epoch #7, Batch 3127/4160 loss = 1.5885481894016267, ppl = 4.951641095792783\n","Valid Epoch #7, Batch 3128/4160 loss = 1.5872279584407807, ppl = 4.945385277696293\n","Valid Epoch #7, Batch 3129/4160 loss = 1.588495157957077, ppl = 4.952716225008749\n","Valid Epoch #7, Batch 3130/4160 loss = 1.5900252962112427, ppl = 4.960007252445786\n","Valid Epoch #7, Batch 3131/4160 loss = 1.5886555767059327, ppl = 4.952376691768084\n","Valid Epoch #7, Batch 3132/4160 loss = 1.5898255622386932, ppl = 4.9586534990160995\n","Valid Epoch #7, Batch 3133/4160 loss = 1.589883978366852, ppl = 4.958938386087029\n","Valid Epoch #7, Batch 3134/4160 loss = 1.5901320087909698, ppl = 4.960054380748796\n","Valid Epoch #7, Batch 3135/4160 loss = 1.5891031873226167, ppl = 4.954823239657411\n","Valid Epoch #7, Batch 3136/4160 loss = 1.5871300220489502, ppl = 4.945326988441273\n","Valid Epoch #7, Batch 3137/4160 loss = 1.5870386922359467, ppl = 4.944907413311165\n","Valid Epoch #7, Batch 3138/4160 loss = 1.5875377321243287, ppl = 4.947470599210603\n","Valid Epoch #7, Batch 3139/4160 loss = 1.5870993530750275, ppl = 4.944839173805078\n","Valid Epoch #7, Batch 3140/4160 loss = 1.587873809337616, ppl = 4.9494590002522445\n","Valid Epoch #7, Batch 3141/4160 loss = 1.5872160363197327, ppl = 4.945849995537187\n","Valid Epoch #7, Batch 3142/4160 loss = 1.5887966203689574, ppl = 4.953663697871367\n","Valid Epoch #7, Batch 3143/4160 loss = 1.5901803135871888, ppl = 4.961042467742174\n","Valid Epoch #7, Batch 3144/4160 loss = 1.5862037694454194, ppl = 4.937788461778462\n","Valid Epoch #7, Batch 3145/4160 loss = 1.58702019572258, ppl = 4.941663556848258\n","Valid Epoch #7, Batch 3146/4160 loss = 1.5851690018177031, ppl = 4.931936367952445\n","Valid Epoch #7, Batch 3147/4160 loss = 1.580795202255249, ppl = 4.910558766258889\n","Valid Epoch #7, Batch 3148/4160 loss = 1.5815710031986236, ppl = 4.915197815325079\n","Valid Epoch #7, Batch 3149/4160 loss = 1.5814362502098083, ppl = 4.9144622270844005\n","Valid Epoch #7, Batch 3150/4160 loss = 1.5816755139827727, ppl = 4.915789894667242\n","Valid Epoch #7, Batch 3151/4160 loss = 1.5813464736938476, ppl = 4.914025092455421\n","Valid Epoch #7, Batch 3152/4160 loss = 1.5817768132686616, ppl = 4.91628448335384\n","Valid Epoch #7, Batch 3153/4160 loss = 1.579466245174408, ppl = 4.9054029425920485\n","Valid Epoch #7, Batch 3154/4160 loss = 1.5793502295017243, ppl = 4.904781763476169\n","Valid Epoch #7, Batch 3155/4160 loss = 1.5810927867889404, ppl = 4.913575711859744\n","Valid Epoch #7, Batch 3156/4160 loss = 1.581311331987381, ppl = 4.914664763549811\n","Valid Epoch #7, Batch 3157/4160 loss = 1.5781405293941497, ppl = 4.899458010848877\n","Valid Epoch #7, Batch 3158/4160 loss = 1.5772070848941804, ppl = 4.895051939802543\n","Valid Epoch #7, Batch 3159/4160 loss = 1.5756320011615754, ppl = 4.886219253818853\n","Valid Epoch #7, Batch 3160/4160 loss = 1.5742850029468536, ppl = 4.879701394599476\n","Valid Epoch #7, Batch 3161/4160 loss = 1.5710147023200989, ppl = 4.863479988989693\n","Valid Epoch #7, Batch 3162/4160 loss = 1.572796207666397, ppl = 4.872500743924591\n","Valid Epoch #7, Batch 3163/4160 loss = 1.5702088284492492, ppl = 4.85924257169292\n","Valid Epoch #7, Batch 3164/4160 loss = 1.570501095056534, ppl = 4.8610716785963834\n","Valid Epoch #7, Batch 3165/4160 loss = 1.5719004571437836, ppl = 4.867088725897461\n","Valid Epoch #7, Batch 3166/4160 loss = 1.5731804394721984, ppl = 4.875162681522554\n","Valid Epoch #7, Batch 3167/4160 loss = 1.5739111137390136, ppl = 4.878946704478903\n","Valid Epoch #7, Batch 3168/4160 loss = 1.575203037261963, ppl = 4.88572667383245\n","Valid Epoch #7, Batch 3169/4160 loss = 1.576271446943283, ppl = 4.891299046032778\n","Valid Epoch #7, Batch 3170/4160 loss = 1.5756457030773163, ppl = 4.8881009294766775\n","Valid Epoch #7, Batch 3171/4160 loss = 1.579046061038971, ppl = 4.905704324715627\n","Valid Epoch #7, Batch 3172/4160 loss = 1.5786704516410828, ppl = 4.9038620325415145\n","Valid Epoch #7, Batch 3173/4160 loss = 1.5780927813053132, ppl = 4.9014079619347175\n","Valid Epoch #7, Batch 3174/4160 loss = 1.5781602597236633, ppl = 4.901747095403986\n","Valid Epoch #7, Batch 3175/4160 loss = 1.5803530025482178, ppl = 4.912856033701031\n","Valid Epoch #7, Batch 3176/4160 loss = 1.5835284447669984, ppl = 4.927473562049745\n","Valid Epoch #7, Batch 3177/4160 loss = 1.5811301004886626, ppl = 4.914645585818309\n","Valid Epoch #7, Batch 3178/4160 loss = 1.5806049036979675, ppl = 4.912112274177369\n","Valid Epoch #7, Batch 3179/4160 loss = 1.5823980844020844, ppl = 4.922315962290528\n","Valid Epoch #7, Batch 3180/4160 loss = 1.5802632117271422, ppl = 4.913376456317161\n","Valid Epoch #7, Batch 3181/4160 loss = 1.5792666673660278, ppl = 4.908358151145513\n","Valid Epoch #7, Batch 3182/4160 loss = 1.580443150997162, ppl = 4.913674369233387\n","Valid Epoch #7, Batch 3183/4160 loss = 1.579797738790512, ppl = 4.910298272332614\n","Valid Epoch #7, Batch 3184/4160 loss = 1.5801766860485076, ppl = 4.912131312904392\n","Valid Epoch #7, Batch 3185/4160 loss = 1.581240301132202, ppl = 4.917297956686885\n","Valid Epoch #7, Batch 3186/4160 loss = 1.5800621783733368, ppl = 4.910528437534797\n","Valid Epoch #7, Batch 3187/4160 loss = 1.5805117917060851, ppl = 4.912762827624029\n","Valid Epoch #7, Batch 3188/4160 loss = 1.5852469992637634, ppl = 4.93715590458711\n","Valid Epoch #7, Batch 3189/4160 loss = 1.5851498496532441, ppl = 4.936635617460842\n","Valid Epoch #7, Batch 3190/4160 loss = 1.584957948923111, ppl = 4.9356204180089644\n","Valid Epoch #7, Batch 3191/4160 loss = 1.585249637365341, ppl = 4.937005155270298\n","Valid Epoch #7, Batch 3192/4160 loss = 1.5854421758651733, ppl = 4.938010202902306\n","Valid Epoch #7, Batch 3193/4160 loss = 1.5870149290561677, ppl = 4.9462279110785525\n","Valid Epoch #7, Batch 3194/4160 loss = 1.5867956984043121, ppl = 4.945226382925561\n","Valid Epoch #7, Batch 3195/4160 loss = 1.5862710654735566, ppl = 4.942933677646277\n","Valid Epoch #7, Batch 3196/4160 loss = 1.5873353564739228, ppl = 4.948189169813239\n","Valid Epoch #7, Batch 3197/4160 loss = 1.5844637477397918, ppl = 4.93183974638179\n","Valid Epoch #7, Batch 3198/4160 loss = 1.5857284891605377, ppl = 4.937536048878815\n","Valid Epoch #7, Batch 3199/4160 loss = 1.5876831805706024, ppl = 4.946632438704237\n","Valid Epoch #7, Batch 3200/4160 loss = 1.5899373853206635, ppl = 4.958143962883439\n","Valid Epoch #7, Batch 3201/4160 loss = 1.5884234309196472, ppl = 4.951407085008972\n","Valid Epoch #7, Batch 3202/4160 loss = 1.5874451422691345, ppl = 4.94768658884625\n","Valid Epoch #7, Batch 3203/4160 loss = 1.5882038497924804, ppl = 4.95058067145788\n","Valid Epoch #7, Batch 3204/4160 loss = 1.5896701729297638, ppl = 4.956140502523488\n","Valid Epoch #7, Batch 3205/4160 loss = 1.5914177465438843, ppl = 4.962581167447793\n","Valid Epoch #7, Batch 3206/4160 loss = 1.5910512626171112, ppl = 4.960862121809491\n","Valid Epoch #7, Batch 3207/4160 loss = 1.59223775267601, ppl = 4.965106720834351\n","Valid Epoch #7, Batch 3208/4160 loss = 1.594859254360199, ppl = 4.975612659608272\n","Valid Epoch #7, Batch 3209/4160 loss = 1.595422614812851, ppl = 4.97805710636002\n","Valid Epoch #7, Batch 3210/4160 loss = 1.5931975173950195, ppl = 4.969108598062498\n","Valid Epoch #7, Batch 3211/4160 loss = 1.5933910584449769, ppl = 4.970040645687909\n","Valid Epoch #7, Batch 3212/4160 loss = 1.5949894630908965, ppl = 4.975819651246584\n","Valid Epoch #7, Batch 3213/4160 loss = 1.5949461793899535, ppl = 4.975647789023525\n","Valid Epoch #7, Batch 3214/4160 loss = 1.5943510818481446, ppl = 4.972736992609726\n","Valid Epoch #7, Batch 3215/4160 loss = 1.5953653073310852, ppl = 4.976944068528432\n","Valid Epoch #7, Batch 3216/4160 loss = 1.5959673535823822, ppl = 4.9797210932709355\n","Valid Epoch #7, Batch 3217/4160 loss = 1.5980455875396729, ppl = 4.9903220463721825\n","Valid Epoch #7, Batch 3218/4160 loss = 1.598385808467865, ppl = 4.992045091321475\n","Valid Epoch #7, Batch 3219/4160 loss = 1.5998566520214081, ppl = 4.999573066726684\n","Valid Epoch #7, Batch 3220/4160 loss = 1.5982285010814667, ppl = 4.992966422379771\n","Valid Epoch #7, Batch 3221/4160 loss = 1.6008744168281555, ppl = 5.007028851791878\n","Valid Epoch #7, Batch 3222/4160 loss = 1.5987830066680908, ppl = 4.995105755696889\n","Valid Epoch #7, Batch 3223/4160 loss = 1.5988133454322815, ppl = 4.995254746696508\n","Valid Epoch #7, Batch 3224/4160 loss = 1.5982108569145204, ppl = 4.9916324952942945\n","Valid Epoch #7, Batch 3225/4160 loss = 1.5959721148014068, ppl = 4.982491875776389\n","Valid Epoch #7, Batch 3226/4160 loss = 1.596841529607773, ppl = 4.9868787978879645\n","Valid Epoch #7, Batch 3227/4160 loss = 1.59595822930336, ppl = 4.981802586741698\n","Valid Epoch #7, Batch 3228/4160 loss = 1.5957079386711122, ppl = 4.980706938049267\n","Valid Epoch #7, Batch 3229/4160 loss = 1.5929520046710968, ppl = 4.965870165531747\n","Valid Epoch #7, Batch 3230/4160 loss = 1.592234355211258, ppl = 4.9623115342651465\n","Valid Epoch #7, Batch 3231/4160 loss = 1.592563705444336, ppl = 4.964052024686146\n","Valid Epoch #7, Batch 3232/4160 loss = 1.590881586074829, ppl = 4.955250488270846\n","Valid Epoch #7, Batch 3233/4160 loss = 1.592773345708847, ppl = 4.965436407810646\n","Valid Epoch #7, Batch 3234/4160 loss = 1.5940779614448548, ppl = 4.971784626396126\n","Valid Epoch #7, Batch 3235/4160 loss = 1.5932449412345886, ppl = 4.967926143163006\n","Valid Epoch #7, Batch 3236/4160 loss = 1.5944676339626311, ppl = 4.9735882224369155\n","Valid Epoch #7, Batch 3237/4160 loss = 1.5957046818733216, ppl = 4.979610184456036\n","Valid Epoch #7, Batch 3238/4160 loss = 1.595030471086502, ppl = 4.9761771833633475\n","Valid Epoch #7, Batch 3239/4160 loss = 1.5947391974925995, ppl = 4.974491489294204\n","Valid Epoch #7, Batch 3240/4160 loss = 1.5921900379657745, ppl = 4.960542096174269\n","Valid Epoch #7, Batch 3241/4160 loss = 1.5926210486888885, ppl = 4.9628800219250255\n","Valid Epoch #7, Batch 3242/4160 loss = 1.5929415535926819, ppl = 4.964620714906365\n","Valid Epoch #7, Batch 3243/4160 loss = 1.591296797990799, ppl = 4.955960680024125\n","Valid Epoch #7, Batch 3244/4160 loss = 1.592718826532364, ppl = 4.963237436915142\n","Valid Epoch #7, Batch 3245/4160 loss = 1.5939996492862702, ppl = 4.96999160423213\n","Valid Epoch #7, Batch 3246/4160 loss = 1.5947582018375397, ppl = 4.973761061971488\n","Valid Epoch #7, Batch 3247/4160 loss = 1.598067650794983, ppl = 4.989046138205718\n","Valid Epoch #7, Batch 3248/4160 loss = 1.5955543363094329, ppl = 4.975235001736301\n","Valid Epoch #7, Batch 3249/4160 loss = 1.5972205567359925, ppl = 4.985065673663242\n","Valid Epoch #7, Batch 3250/4160 loss = 1.5975035738945007, ppl = 4.986677693910266\n","Valid Epoch #7, Batch 3251/4160 loss = 1.5970090794563294, ppl = 4.984132328141395\n","Valid Epoch #7, Batch 3252/4160 loss = 1.5964023303985595, ppl = 4.980974477241607\n","Valid Epoch #7, Batch 3253/4160 loss = 1.5985505819320678, ppl = 4.9910067939920415\n","Valid Epoch #7, Batch 3254/4160 loss = 1.6005474984645844, ppl = 5.002772615569261\n","Valid Epoch #7, Batch 3255/4160 loss = 1.6014401888847352, ppl = 5.007907329551171\n","Valid Epoch #7, Batch 3256/4160 loss = 1.6020517098903655, ppl = 5.011084220353509\n","Valid Epoch #7, Batch 3257/4160 loss = 1.604436960220337, ppl = 5.022063009175252\n","Valid Epoch #7, Batch 3258/4160 loss = 1.6052134609222413, ppl = 5.025699213672583\n","Valid Epoch #7, Batch 3259/4160 loss = 1.6045266914367675, ppl = 5.022262675895038\n","Valid Epoch #7, Batch 3260/4160 loss = 1.6064728558063508, ppl = 5.031974148463363\n","Valid Epoch #7, Batch 3261/4160 loss = 1.609394509792328, ppl = 5.046202965577141\n","Valid Epoch #7, Batch 3262/4160 loss = 1.6078609073162078, ppl = 5.038343318371907\n","Valid Epoch #7, Batch 3263/4160 loss = 1.6082718348503113, ppl = 5.040226740118643\n","Valid Epoch #7, Batch 3264/4160 loss = 1.6049951672554017, ppl = 5.022484335305006\n","Valid Epoch #7, Batch 3265/4160 loss = 1.6057507872581482, ppl = 5.0261009365779294\n","Valid Epoch #7, Batch 3266/4160 loss = 1.60351989030838, ppl = 5.012663487148871\n","Valid Epoch #7, Batch 3267/4160 loss = 1.6011099350452422, ppl = 5.001162697365102\n","Valid Epoch #7, Batch 3268/4160 loss = 1.6006327438354493, ppl = 4.998555858022492\n","Valid Epoch #7, Batch 3269/4160 loss = 1.5975631916522979, ppl = 4.984020685779131\n","Valid Epoch #7, Batch 3270/4160 loss = 1.5989525389671326, ppl = 4.991402588872358\n","Valid Epoch #7, Batch 3271/4160 loss = 1.5955676925182343, ppl = 4.9738666673624605\n","Valid Epoch #7, Batch 3272/4160 loss = 1.595090297460556, ppl = 4.971622821965753\n","Valid Epoch #7, Batch 3273/4160 loss = 1.5975869524478912, ppl = 4.983325970645887\n","Valid Epoch #7, Batch 3274/4160 loss = 1.5968489050865173, ppl = 4.979738184806993\n","Valid Epoch #7, Batch 3275/4160 loss = 1.596718955039978, ppl = 4.979009755153523\n","Valid Epoch #7, Batch 3276/4160 loss = 1.598342399597168, ppl = 4.988480134699044\n","Valid Epoch #7, Batch 3277/4160 loss = 1.598689148426056, ppl = 4.990150045144379\n","Valid Epoch #7, Batch 3278/4160 loss = 1.5991177582740783, ppl = 4.992207425893543\n","Valid Epoch #7, Batch 3279/4160 loss = 1.5957997298240663, ppl = 4.974656087271286\n","Valid Epoch #7, Batch 3280/4160 loss = 1.5982227158546447, ppl = 4.984954876597687\n","Valid Epoch #7, Batch 3281/4160 loss = 1.5982048451900481, ppl = 4.984869371155257\n","Valid Epoch #7, Batch 3282/4160 loss = 1.6006735622882844, ppl = 4.998281403944403\n","Valid Epoch #7, Batch 3283/4160 loss = 1.6010886681079866, ppl = 5.000427708342706\n","Valid Epoch #7, Batch 3284/4160 loss = 1.6022248315811156, ppl = 5.006358899524643\n","Valid Epoch #7, Batch 3285/4160 loss = 1.600966020822525, ppl = 5.0003023137555145\n","Valid Epoch #7, Batch 3286/4160 loss = 1.6002887606620788, ppl = 4.996756911297912\n","Valid Epoch #7, Batch 3287/4160 loss = 1.6012497711181641, ppl = 5.001883279094631\n","Valid Epoch #7, Batch 3288/4160 loss = 1.5996623098850251, ppl = 4.992390591673341\n","Valid Epoch #7, Batch 3289/4160 loss = 1.6018044197559356, ppl = 5.005122040317082\n","Valid Epoch #7, Batch 3290/4160 loss = 1.600099446773529, ppl = 4.996908670169133\n","Valid Epoch #7, Batch 3291/4160 loss = 1.6020234429836273, ppl = 5.0071279338277455\n","Valid Epoch #7, Batch 3292/4160 loss = 1.6017089331150054, ppl = 5.005496137487637\n","Valid Epoch #7, Batch 3293/4160 loss = 1.5997400331497191, ppl = 4.99540441445457\n","Valid Epoch #7, Batch 3294/4160 loss = 1.6010048580169678, ppl = 5.001496665997114\n","Valid Epoch #7, Batch 3295/4160 loss = 1.6005970048904419, ppl = 4.999795572840498\n","Valid Epoch #7, Batch 3296/4160 loss = 1.5994045841693878, ppl = 4.993944270637607\n","Valid Epoch #7, Batch 3297/4160 loss = 1.5992885220050812, ppl = 4.993377114462159\n","Valid Epoch #7, Batch 3298/4160 loss = 1.5975048708915711, ppl = 4.985544272574469\n","Valid Epoch #7, Batch 3299/4160 loss = 1.595851868391037, ppl = 4.977738451071536\n","Valid Epoch #7, Batch 3300/4160 loss = 1.5955018019676208, ppl = 4.975776262180563\n","Valid Epoch #7, Batch 3301/4160 loss = 1.5949854862689972, ppl = 4.973702265720699\n","Valid Epoch #7, Batch 3302/4160 loss = 1.5957606387138368, ppl = 4.9766199982305865\n","Valid Epoch #7, Batch 3303/4160 loss = 1.5949676990509034, ppl = 4.9736004432309056\n","Valid Epoch #7, Batch 3304/4160 loss = 1.5961919820308685, ppl = 4.978909552707651\n","Valid Epoch #7, Batch 3305/4160 loss = 1.595231955051422, ppl = 4.975232547146137\n","Valid Epoch #7, Batch 3306/4160 loss = 1.5952472639083863, ppl = 4.975303101742002\n","Valid Epoch #7, Batch 3307/4160 loss = 1.5949621522426605, ppl = 4.97423670027532\n","Valid Epoch #7, Batch 3308/4160 loss = 1.5945389020442962, ppl = 4.972348683416864\n","Valid Epoch #7, Batch 3309/4160 loss = 1.5921519076824189, ppl = 4.962872814748624\n","Valid Epoch #7, Batch 3310/4160 loss = 1.5925431954860687, ppl = 4.964305693384411\n","Valid Epoch #7, Batch 3311/4160 loss = 1.5914800477027893, ppl = 4.95940143759613\n","Valid Epoch #7, Batch 3312/4160 loss = 1.593532464504242, ppl = 4.968314117092835\n","Valid Epoch #7, Batch 3313/4160 loss = 1.5941405916213989, ppl = 4.970798293344971\n","Valid Epoch #7, Batch 3314/4160 loss = 1.5927351415157318, ppl = 4.964573985459188\n","Valid Epoch #7, Batch 3315/4160 loss = 1.5920161807537079, ppl = 4.961547977822176\n","Valid Epoch #7, Batch 3316/4160 loss = 1.5910512948036193, ppl = 4.957176283557265\n","Valid Epoch #7, Batch 3317/4160 loss = 1.5887519657611846, ppl = 4.945571806286761\n","Valid Epoch #7, Batch 3318/4160 loss = 1.5874799692630768, ppl = 4.93941918695616\n","Valid Epoch #7, Batch 3319/4160 loss = 1.5875097346305846, ppl = 4.939583252363825\n","Valid Epoch #7, Batch 3320/4160 loss = 1.5891220259666443, ppl = 4.946120216489497\n","Valid Epoch #7, Batch 3321/4160 loss = 1.5880035769939422, ppl = 4.939719490039177\n","Valid Epoch #7, Batch 3322/4160 loss = 1.5878989470005036, ppl = 4.939185994993107\n","Valid Epoch #7, Batch 3323/4160 loss = 1.5881898605823517, ppl = 4.9406378297826645\n","Valid Epoch #7, Batch 3324/4160 loss = 1.5883538985252381, ppl = 4.941602530233235\n","Valid Epoch #7, Batch 3325/4160 loss = 1.5910911023616792, ppl = 4.95307220288588\n","Valid Epoch #7, Batch 3326/4160 loss = 1.589401262998581, ppl = 4.9448810910476615\n","Valid Epoch #7, Batch 3327/4160 loss = 1.5873940896987915, ppl = 4.934884821979199\n","Valid Epoch #7, Batch 3328/4160 loss = 1.5890100371837617, ppl = 4.942466580069772\n","Valid Epoch #7, Batch 3329/4160 loss = 1.588868157863617, ppl = 4.941807869508759\n","Valid Epoch #7, Batch 3330/4160 loss = 1.588073922395706, ppl = 4.938156038332895\n","Valid Epoch #7, Batch 3331/4160 loss = 1.5903742492198945, ppl = 4.952050553495975\n","Valid Epoch #7, Batch 3332/4160 loss = 1.5903390157222748, ppl = 4.951881566253992\n","Valid Epoch #7, Batch 3333/4160 loss = 1.5901036059856415, ppl = 4.95050661116312\n","Valid Epoch #7, Batch 3334/4160 loss = 1.5892500627040862, ppl = 4.946260282558473\n","Valid Epoch #7, Batch 3335/4160 loss = 1.5920757341384888, ppl = 4.960763719079298\n","Valid Epoch #7, Batch 3336/4160 loss = 1.5927193367481232, ppl = 4.9640341649336115\n","Valid Epoch #7, Batch 3337/4160 loss = 1.5907159841060639, ppl = 4.9546387074861515\n","Valid Epoch #7, Batch 3338/4160 loss = 1.5901995587348938, ppl = 4.952161299766942\n","Valid Epoch #7, Batch 3339/4160 loss = 1.5893835735321045, ppl = 4.947692187796521\n","Valid Epoch #7, Batch 3340/4160 loss = 1.5889906775951386, ppl = 4.94584120410428\n","Valid Epoch #7, Batch 3341/4160 loss = 1.5879151248931884, ppl = 4.9401898310022725\n","Valid Epoch #7, Batch 3342/4160 loss = 1.5878645181655884, ppl = 4.9399112584043365\n","Valid Epoch #7, Batch 3343/4160 loss = 1.589406100511551, ppl = 4.9479851916298205\n","Valid Epoch #7, Batch 3344/4160 loss = 1.5891096484661102, ppl = 4.946381667023866\n","Valid Epoch #7, Batch 3345/4160 loss = 1.5875619542598725, ppl = 4.938325852724902\n","Valid Epoch #7, Batch 3346/4160 loss = 1.5892158913612366, ppl = 4.947606740439189\n","Valid Epoch #7, Batch 3347/4160 loss = 1.5912067019939422, ppl = 4.959556863915897\n","Valid Epoch #7, Batch 3348/4160 loss = 1.5919293034076691, ppl = 4.96317886502209\n","Valid Epoch #7, Batch 3349/4160 loss = 1.589143922328949, ppl = 4.947607243195936\n","Valid Epoch #7, Batch 3350/4160 loss = 1.5895659697055817, ppl = 4.9500975161435825\n","Valid Epoch #7, Batch 3351/4160 loss = 1.5907652854919434, ppl = 4.956495502954577\n","Valid Epoch #7, Batch 3352/4160 loss = 1.5921115148067475, ppl = 4.9637702927735425\n","Valid Epoch #7, Batch 3353/4160 loss = 1.5902507817745208, ppl = 4.954959091588997\n","Valid Epoch #7, Batch 3354/4160 loss = 1.5873553740978241, ppl = 4.938618935853233\n","Valid Epoch #7, Batch 3355/4160 loss = 1.5847116959095002, ppl = 4.924651344092177\n","Valid Epoch #7, Batch 3356/4160 loss = 1.5856231045722962, ppl = 4.929761765258362\n","Valid Epoch #7, Batch 3357/4160 loss = 1.5853153908252715, ppl = 4.928194044942424\n","Valid Epoch #7, Batch 3358/4160 loss = 1.5864234948158265, ppl = 4.9338973119782885\n","Valid Epoch #7, Batch 3359/4160 loss = 1.58768803358078, ppl = 4.94041348122176\n","Valid Epoch #7, Batch 3360/4160 loss = 1.585858565568924, ppl = 4.931232592199664\n","Valid Epoch #7, Batch 3361/4160 loss = 1.5842730271816254, ppl = 4.92299801281771\n","Valid Epoch #7, Batch 3362/4160 loss = 1.5832546699047088, ppl = 4.918406693996296\n","Valid Epoch #7, Batch 3363/4160 loss = 1.5855794072151184, ppl = 4.930650245007991\n","Valid Epoch #7, Batch 3364/4160 loss = 1.5854923593997956, ppl = 4.930253641926207\n","Valid Epoch #7, Batch 3365/4160 loss = 1.5838388454914094, ppl = 4.922680103289359\n","Valid Epoch #7, Batch 3366/4160 loss = 1.5831015586853028, ppl = 4.918858737258894\n","Valid Epoch #7, Batch 3367/4160 loss = 1.583656873703003, ppl = 4.921268589635224\n","Valid Epoch #7, Batch 3368/4160 loss = 1.5825724017620086, ppl = 4.915787073965861\n","Valid Epoch #7, Batch 3369/4160 loss = 1.583160730600357, ppl = 4.918238649014555\n","Valid Epoch #7, Batch 3370/4160 loss = 1.5831147122383118, ppl = 4.917977366810928\n","Valid Epoch #7, Batch 3371/4160 loss = 1.5847690534591674, ppl = 4.925809158601381\n","Valid Epoch #7, Batch 3372/4160 loss = 1.585540064573288, ppl = 4.929487209772258\n","Valid Epoch #7, Batch 3373/4160 loss = 1.5865769851207734, ppl = 4.935274662693967\n","Valid Epoch #7, Batch 3374/4160 loss = 1.5839019310474396, ppl = 4.924280659507702\n","Valid Epoch #7, Batch 3375/4160 loss = 1.584211803674698, ppl = 4.926033392174156\n","Valid Epoch #7, Batch 3376/4160 loss = 1.5823467123508452, ppl = 4.915280254673494\n","Valid Epoch #7, Batch 3377/4160 loss = 1.5800858855247497, ppl = 4.905365440539818\n","Valid Epoch #7, Batch 3378/4160 loss = 1.5794852089881897, ppl = 4.902506607052357\n","Valid Epoch #7, Batch 3379/4160 loss = 1.581226156949997, ppl = 4.9109891878708245\n","Valid Epoch #7, Batch 3380/4160 loss = 1.5812529230117798, ppl = 4.911117466323277\n","Valid Epoch #7, Batch 3381/4160 loss = 1.5808921837806702, ppl = 4.909423719433495\n","Valid Epoch #7, Batch 3382/4160 loss = 1.5784930467605591, ppl = 4.896346120459047\n","Valid Epoch #7, Batch 3383/4160 loss = 1.5795553481578828, ppl = 4.9022622100541895\n","Valid Epoch #7, Batch 3384/4160 loss = 1.5790316939353943, ppl = 4.899444721024822\n","Valid Epoch #7, Batch 3385/4160 loss = 1.5790671634674072, ppl = 4.8996051459659995\n","Valid Epoch #7, Batch 3386/4160 loss = 1.5779960834980011, ppl = 4.894465990410844\n","Valid Epoch #7, Batch 3387/4160 loss = 1.576313201189041, ppl = 4.885800255457635\n","Valid Epoch #7, Batch 3388/4160 loss = 1.5755127835273743, ppl = 4.881555911309488\n","Valid Epoch #7, Batch 3389/4160 loss = 1.571333408355713, ppl = 4.859001319920483\n","Valid Epoch #7, Batch 3390/4160 loss = 1.5717484080791473, ppl = 4.860873491089257\n","Valid Epoch #7, Batch 3391/4160 loss = 1.5693289935588837, ppl = 4.848326000598432\n","Valid Epoch #7, Batch 3392/4160 loss = 1.568895275592804, ppl = 4.846158258214888\n","Valid Epoch #7, Batch 3393/4160 loss = 1.570618554353714, ppl = 4.854879927181284\n","Valid Epoch #7, Batch 3394/4160 loss = 1.57024684548378, ppl = 4.853008901823449\n","Valid Epoch #7, Batch 3395/4160 loss = 1.5723128473758698, ppl = 4.862386751578503\n","Valid Epoch #7, Batch 3396/4160 loss = 1.5734741640090943, ppl = 4.868076394343488\n","Valid Epoch #7, Batch 3397/4160 loss = 1.5729265546798705, ppl = 4.86548744698072\n","Valid Epoch #7, Batch 3398/4160 loss = 1.5741565990447999, ppl = 4.870738023829344\n","Valid Epoch #7, Batch 3399/4160 loss = 1.577853912115097, ppl = 4.890164745416603\n","Valid Epoch #7, Batch 3400/4160 loss = 1.575731326341629, ppl = 4.879631664105968\n","Valid Epoch #7, Batch 3401/4160 loss = 1.5737526726722717, ppl = 4.872605069788352\n","Valid Epoch #7, Batch 3402/4160 loss = 1.572569670677185, ppl = 4.868240595060207\n","Valid Epoch #7, Batch 3403/4160 loss = 1.5720443868637084, ppl = 4.866368154156001\n","Valid Epoch #7, Batch 3404/4160 loss = 1.570980315208435, ppl = 4.86171740023832\n","Valid Epoch #7, Batch 3405/4160 loss = 1.5710682964324951, ppl = 4.862039877613837\n","Valid Epoch #7, Batch 3406/4160 loss = 1.5699866902828217, ppl = 4.857311534628431\n","Valid Epoch #7, Batch 3407/4160 loss = 1.5697213363647462, ppl = 4.856345981724021\n","Valid Epoch #7, Batch 3408/4160 loss = 1.568035726547241, ppl = 4.849571843636597\n","Valid Epoch #7, Batch 3409/4160 loss = 1.5699578893184662, ppl = 4.857020911555628\n","Valid Epoch #7, Batch 3410/4160 loss = 1.5688626122474671, ppl = 4.853147090875353\n","Valid Epoch #7, Batch 3411/4160 loss = 1.570633931159973, ppl = 4.861619698170286\n","Valid Epoch #7, Batch 3412/4160 loss = 1.5703139865398408, ppl = 4.860107202206446\n","Valid Epoch #7, Batch 3413/4160 loss = 1.5710164415836334, ppl = 4.863171195923309\n","Valid Epoch #7, Batch 3414/4160 loss = 1.5719648706912994, ppl = 4.867274765514262\n","Valid Epoch #7, Batch 3415/4160 loss = 1.572527619600296, ppl = 4.869624675176635\n","Valid Epoch #7, Batch 3416/4160 loss = 1.5723954486846923, ppl = 4.869058015755086\n","Valid Epoch #7, Batch 3417/4160 loss = 1.57309889793396, ppl = 4.87232943648511\n","Valid Epoch #7, Batch 3418/4160 loss = 1.5733897137641906, ppl = 4.873667906563012\n","Valid Epoch #7, Batch 3419/4160 loss = 1.5728725373744965, ppl = 4.870885576128498\n","Valid Epoch #7, Batch 3420/4160 loss = 1.5732515776157379, ppl = 4.8725815330805995\n","Valid Epoch #7, Batch 3421/4160 loss = 1.574620133638382, ppl = 4.8805141997641615\n","Valid Epoch #7, Batch 3422/4160 loss = 1.5731854486465453, ppl = 4.873735047810555\n","Valid Epoch #7, Batch 3423/4160 loss = 1.5716401875019073, ppl = 4.866485115246769\n","Valid Epoch #7, Batch 3424/4160 loss = 1.5711322033405304, ppl = 4.863548334892364\n","Valid Epoch #7, Batch 3425/4160 loss = 1.570341418981552, ppl = 4.85990645062702\n","Valid Epoch #7, Batch 3426/4160 loss = 1.5709029614925385, ppl = 4.862476372200394\n","Valid Epoch #7, Batch 3427/4160 loss = 1.5685771238803863, ppl = 4.853144001474936\n","Valid Epoch #7, Batch 3428/4160 loss = 1.5675356411933898, ppl = 4.848118343634115\n","Valid Epoch #7, Batch 3429/4160 loss = 1.567385708093643, ppl = 4.847432323524453\n","Valid Epoch #7, Batch 3430/4160 loss = 1.567107664346695, ppl = 4.846220916336606\n","Valid Epoch #7, Batch 3431/4160 loss = 1.5642573845386505, ppl = 4.829451757646728\n","Valid Epoch #7, Batch 3432/4160 loss = 1.566815609931946, ppl = 4.843409219152831\n","Valid Epoch #7, Batch 3433/4160 loss = 1.5648855781555175, ppl = 4.83327779693966\n","Valid Epoch #7, Batch 3434/4160 loss = 1.5655486512184142, ppl = 4.836544887405359\n","Valid Epoch #7, Batch 3435/4160 loss = 1.5649583315849305, ppl = 4.833167384579198\n","Valid Epoch #7, Batch 3436/4160 loss = 1.5632517528533936, ppl = 4.824935766747161\n","Valid Epoch #7, Batch 3437/4160 loss = 1.5669848644733428, ppl = 4.844104156631562\n","Valid Epoch #7, Batch 3438/4160 loss = 1.5688226091861726, ppl = 4.853534551892684\n","Valid Epoch #7, Batch 3439/4160 loss = 1.5685519111156463, ppl = 4.85213070461047\n","Valid Epoch #7, Batch 3440/4160 loss = 1.5715549981594086, ppl = 4.8683105867798755\n","Valid Epoch #7, Batch 3441/4160 loss = 1.5710832393169403, ppl = 4.86601721824086\n","Valid Epoch #7, Batch 3442/4160 loss = 1.5711040580272675, ppl = 4.866131647408255\n","Valid Epoch #7, Batch 3443/4160 loss = 1.5702168548107147, ppl = 4.861333609565438\n","Valid Epoch #7, Batch 3444/4160 loss = 1.5714045393466949, ppl = 4.868054308942093\n","Valid Epoch #7, Batch 3445/4160 loss = 1.5721309614181518, ppl = 4.871680425328584\n","Valid Epoch #7, Batch 3446/4160 loss = 1.5703947591781615, ppl = 4.861976779900251\n","Valid Epoch #7, Batch 3447/4160 loss = 1.5688527715206146, ppl = 4.852516965119994\n","Valid Epoch #7, Batch 3448/4160 loss = 1.5687296080589295, ppl = 4.851880965947337\n","Valid Epoch #7, Batch 3449/4160 loss = 1.5712931668758392, ppl = 4.866047423112255\n","Valid Epoch #7, Batch 3450/4160 loss = 1.56867742061615, ppl = 4.852178236881219\n","Valid Epoch #7, Batch 3451/4160 loss = 1.5689955639839173, ppl = 4.85400819831899\n","Valid Epoch #7, Batch 3452/4160 loss = 1.5684616982936859, ppl = 4.851005599285411\n","Valid Epoch #7, Batch 3453/4160 loss = 1.569665366411209, ppl = 4.856516538440592\n","Valid Epoch #7, Batch 3454/4160 loss = 1.570355521440506, ppl = 4.8599933159280235\n","Valid Epoch #7, Batch 3455/4160 loss = 1.5702334880828857, ppl = 4.8594334635008645\n","Valid Epoch #7, Batch 3456/4160 loss = 1.566821516752243, ppl = 4.8424743107892185\n","Valid Epoch #7, Batch 3457/4160 loss = 1.5672140550613403, ppl = 4.84448273951981\n","Valid Epoch #7, Batch 3458/4160 loss = 1.5646328842639923, ppl = 4.832113145111781\n","Valid Epoch #7, Batch 3459/4160 loss = 1.5618026614189149, ppl = 4.818591122972132\n","Valid Epoch #7, Batch 3460/4160 loss = 1.562571474313736, ppl = 4.822245810183596\n","Valid Epoch #7, Batch 3461/4160 loss = 1.560582835674286, ppl = 4.813602724126006\n","Valid Epoch #7, Batch 3462/4160 loss = 1.5617933475971222, ppl = 4.819114054199263\n","Valid Epoch #7, Batch 3463/4160 loss = 1.5611672604084015, ppl = 4.815531873781153\n","Valid Epoch #7, Batch 3464/4160 loss = 1.5612968802452087, ppl = 4.816123702162128\n","Valid Epoch #7, Batch 3465/4160 loss = 1.56325221657753, ppl = 4.825219974390168\n","Valid Epoch #7, Batch 3466/4160 loss = 1.5642164719104767, ppl = 4.830275573874939\n","Valid Epoch #7, Batch 3467/4160 loss = 1.564718587398529, ppl = 4.832572813352189\n","Valid Epoch #7, Batch 3468/4160 loss = 1.564625027179718, ppl = 4.832127175870041\n","Valid Epoch #7, Batch 3469/4160 loss = 1.565745657682419, ppl = 4.837215346493045\n","Valid Epoch #7, Batch 3470/4160 loss = 1.565567933320999, ppl = 4.836217479960566\n","Valid Epoch #7, Batch 3471/4160 loss = 1.5643939077854156, ppl = 4.8305276699946385\n","Valid Epoch #7, Batch 3472/4160 loss = 1.5652012288570405, ppl = 4.834695277715566\n","Valid Epoch #7, Batch 3473/4160 loss = 1.5663869273662567, ppl = 4.8420920057339965\n","Valid Epoch #7, Batch 3474/4160 loss = 1.5702267169952393, ppl = 4.858872055468512\n","Valid Epoch #7, Batch 3475/4160 loss = 1.568092304468155, ppl = 4.847831316467514\n","Valid Epoch #7, Batch 3476/4160 loss = 1.5665856885910034, ppl = 4.840496262163895\n","Valid Epoch #7, Batch 3477/4160 loss = 1.5708642852306367, ppl = 4.861366001218696\n","Valid Epoch #7, Batch 3478/4160 loss = 1.571496856212616, ppl = 4.864381486094023\n","Valid Epoch #7, Batch 3479/4160 loss = 1.5723530650138855, ppl = 4.869127213348919\n","Valid Epoch #7, Batch 3480/4160 loss = 1.5749075198173523, ppl = 4.88309404724428\n","Valid Epoch #7, Batch 3481/4160 loss = 1.575004779100418, ppl = 4.883544700972856\n","Valid Epoch #7, Batch 3482/4160 loss = 1.5736341953277588, ppl = 4.877367113316448\n","Valid Epoch #7, Batch 3483/4160 loss = 1.5692979145050048, ppl = 4.856713126126072\n","Valid Epoch #7, Batch 3484/4160 loss = 1.5686795020103455, ppl = 4.853570332975978\n","Valid Epoch #7, Batch 3485/4160 loss = 1.5697079944610595, ppl = 4.858478421075449\n","Valid Epoch #7, Batch 3486/4160 loss = 1.568740906715393, ppl = 4.854288178658026\n","Valid Epoch #7, Batch 3487/4160 loss = 1.5688243663311006, ppl = 4.854684443837658\n","Valid Epoch #7, Batch 3488/4160 loss = 1.567824718952179, ppl = 4.849839176652387\n","Valid Epoch #7, Batch 3489/4160 loss = 1.5695435190200806, ppl = 4.8579917838325\n","Valid Epoch #7, Batch 3490/4160 loss = 1.5703659284114837, ppl = 4.861939510028546\n","Valid Epoch #7, Batch 3491/4160 loss = 1.5711582672595978, ppl = 4.865719415328381\n","Valid Epoch #7, Batch 3492/4160 loss = 1.5713227927684783, ppl = 4.866530673189595\n","Valid Epoch #7, Batch 3493/4160 loss = 1.5696237504482269, ppl = 4.857921537644896\n","Valid Epoch #7, Batch 3494/4160 loss = 1.5695555424690246, ppl = 4.857585695574426\n","Valid Epoch #7, Batch 3495/4160 loss = 1.569381912946701, ppl = 4.856720883362523\n","Valid Epoch #7, Batch 3496/4160 loss = 1.5684519267082215, ppl = 4.852112520972624\n","Valid Epoch #7, Batch 3497/4160 loss = 1.5693483364582062, ppl = 4.85642596526362\n","Valid Epoch #7, Batch 3498/4160 loss = 1.570327055454254, ppl = 4.861090480509141\n","Valid Epoch #7, Batch 3499/4160 loss = 1.5653191161155702, ppl = 4.836329353140857\n","Valid Epoch #7, Batch 3500/4160 loss = 1.5655867075920105, ppl = 4.837537388825731\n","Valid Epoch #7, Batch 3501/4160 loss = 1.566606056690216, ppl = 4.840983638911255\n","Valid Epoch #7, Batch 3502/4160 loss = 1.5673405015468598, ppl = 4.843632198772264\n","Valid Epoch #7, Batch 3503/4160 loss = 1.5705489599704743, ppl = 4.856765871444583\n","Valid Epoch #7, Batch 3504/4160 loss = 1.56862775683403, ppl = 4.849525444199694\n","Valid Epoch #7, Batch 3505/4160 loss = 1.5695175433158874, ppl = 4.852951298324364\n","Valid Epoch #7, Batch 3506/4160 loss = 1.568176611661911, ppl = 4.847756659225299\n","Valid Epoch #7, Batch 3507/4160 loss = 1.5684712898731232, ppl = 4.848830496155176\n","Valid Epoch #7, Batch 3508/4160 loss = 1.57013564825058, ppl = 4.855511927249131\n","Valid Epoch #7, Batch 3509/4160 loss = 1.571240050792694, ppl = 4.860486004400705\n","Valid Epoch #7, Batch 3510/4160 loss = 1.5726268482208252, ppl = 4.865464403738107\n","Valid Epoch #7, Batch 3511/4160 loss = 1.5702264821529388, ppl = 4.854326262473343\n","Valid Epoch #7, Batch 3512/4160 loss = 1.5687144100666046, ppl = 4.847797884358868\n","Valid Epoch #7, Batch 3513/4160 loss = 1.5661167895793915, ppl = 4.837464963753532\n","Valid Epoch #7, Batch 3514/4160 loss = 1.5667911648750306, ppl = 4.8406288208731345\n","Valid Epoch #7, Batch 3515/4160 loss = 1.5665600621700286, ppl = 4.83964776102954\n","Valid Epoch #7, Batch 3516/4160 loss = 1.5664720392227174, ppl = 4.839274511805547\n","Valid Epoch #7, Batch 3517/4160 loss = 1.564134237766266, ppl = 4.829234811716577\n","Valid Epoch #7, Batch 3518/4160 loss = 1.5624179542064667, ppl = 4.821870305685679\n","Valid Epoch #7, Batch 3519/4160 loss = 1.5593182611465455, ppl = 4.807898959989528\n","Valid Epoch #7, Batch 3520/4160 loss = 1.5603157794475555, ppl = 4.81268191187481\n","Valid Epoch #7, Batch 3521/4160 loss = 1.557758401632309, ppl = 4.79868666527033\n","Valid Epoch #7, Batch 3522/4160 loss = 1.5588866770267487, ppl = 4.803935202262803\n","Valid Epoch #7, Batch 3523/4160 loss = 1.5601721727848052, ppl = 4.809886737079054\n","Valid Epoch #7, Batch 3524/4160 loss = 1.5575890469551086, ppl = 4.797057396704157\n","Valid Epoch #7, Batch 3525/4160 loss = 1.5572957384586334, ppl = 4.795778149871445\n","Valid Epoch #7, Batch 3526/4160 loss = 1.5583376228809356, ppl = 4.800946049896728\n","Valid Epoch #7, Batch 3527/4160 loss = 1.5621529591083527, ppl = 4.817501537163647\n","Valid Epoch #7, Batch 3528/4160 loss = 1.5618715631961821, ppl = 4.816231107081309\n","Valid Epoch #7, Batch 3529/4160 loss = 1.564526320695877, ppl = 4.830038963694111\n","Valid Epoch #7, Batch 3530/4160 loss = 1.5637992131710052, ppl = 4.827025744358097\n","Valid Epoch #7, Batch 3531/4160 loss = 1.5644238638877868, ppl = 4.830303175635835\n","Valid Epoch #7, Batch 3532/4160 loss = 1.5623773777484893, ppl = 4.81885957504428\n","Valid Epoch #7, Batch 3533/4160 loss = 1.5623069214820862, ppl = 4.81852544727088\n","Valid Epoch #7, Batch 3534/4160 loss = 1.563285013437271, ppl = 4.823757961890939\n","Valid Epoch #7, Batch 3535/4160 loss = 1.5644793009757996, ppl = 4.830803714731724\n","Valid Epoch #7, Batch 3536/4160 loss = 1.5648484230041504, ppl = 4.832467066466499\n","Valid Epoch #7, Batch 3537/4160 loss = 1.5624568200111388, ppl = 4.819379772228021\n","Valid Epoch #7, Batch 3538/4160 loss = 1.5606979942321777, ppl = 4.810319736614506\n","Valid Epoch #7, Batch 3539/4160 loss = 1.5604390788078308, ppl = 4.80901208790782\n","Valid Epoch #7, Batch 3540/4160 loss = 1.5603899490833282, ppl = 4.808706408745198\n","Valid Epoch #7, Batch 3541/4160 loss = 1.5600867199897765, ppl = 4.807288421298868\n","Valid Epoch #7, Batch 3542/4160 loss = 1.5599395155906677, ppl = 4.8064844082140326\n","Valid Epoch #7, Batch 3543/4160 loss = 1.5616067230701447, ppl = 4.815867116792585\n","Valid Epoch #7, Batch 3544/4160 loss = 1.5615168714523315, ppl = 4.815330301792196\n","Valid Epoch #7, Batch 3545/4160 loss = 1.5615020895004272, ppl = 4.815253858018672\n","Valid Epoch #7, Batch 3546/4160 loss = 1.560773309469223, ppl = 4.81165673384693\n","Valid Epoch #7, Batch 3547/4160 loss = 1.5598590171337128, ppl = 4.806699145641944\n","Valid Epoch #7, Batch 3548/4160 loss = 1.5596625435352325, ppl = 4.805700658968138\n","Valid Epoch #7, Batch 3549/4160 loss = 1.556997640132904, ppl = 4.791045364689583\n","Valid Epoch #7, Batch 3550/4160 loss = 1.5570677053928375, ppl = 4.791371533787761\n","Valid Epoch #7, Batch 3551/4160 loss = 1.5569430720806121, ppl = 4.790647698562914\n","Valid Epoch #7, Batch 3552/4160 loss = 1.556533854007721, ppl = 4.788452266207581\n","Valid Epoch #7, Batch 3553/4160 loss = 1.554674998521805, ppl = 4.78020898304724\n","Valid Epoch #7, Batch 3554/4160 loss = 1.5535983002185823, ppl = 4.7748872368597715\n","Valid Epoch #7, Batch 3555/4160 loss = 1.5558460891246795, ppl = 4.786379933262008\n","Valid Epoch #7, Batch 3556/4160 loss = 1.5583017230033875, ppl = 4.7979885871675805\n","Valid Epoch #7, Batch 3557/4160 loss = 1.558223578929901, ppl = 4.797582451968331\n","Valid Epoch #7, Batch 3558/4160 loss = 1.5593361103534698, ppl = 4.8025253188528385\n","Valid Epoch #7, Batch 3559/4160 loss = 1.56261989235878, ppl = 4.818592706047408\n","Valid Epoch #7, Batch 3560/4160 loss = 1.5655975556373596, ppl = 4.835722618453243\n","Valid Epoch #7, Batch 3561/4160 loss = 1.5667777287960052, ppl = 4.840643463747501\n","Valid Epoch #7, Batch 3562/4160 loss = 1.5673082375526428, ppl = 4.843277195188154\n","Valid Epoch #7, Batch 3563/4160 loss = 1.5666421568393707, ppl = 4.839704550894237\n","Valid Epoch #7, Batch 3564/4160 loss = 1.5689485311508178, ppl = 4.85162548135584\n","Valid Epoch #7, Batch 3565/4160 loss = 1.5681123042106628, ppl = 4.847516802659496\n","Valid Epoch #7, Batch 3566/4160 loss = 1.5672262907028198, ppl = 4.842853498303134\n","Valid Epoch #7, Batch 3567/4160 loss = 1.5679882514476775, ppl = 4.846567514137516\n","Valid Epoch #7, Batch 3568/4160 loss = 1.567663880586624, ppl = 4.845054390157855\n","Valid Epoch #7, Batch 3569/4160 loss = 1.5700703358650208, ppl = 4.858112698203882\n","Valid Epoch #7, Batch 3570/4160 loss = 1.5692520439624786, ppl = 4.8537402872274376\n","Valid Epoch #7, Batch 3571/4160 loss = 1.5701354134082794, ppl = 4.8579586398840915\n","Valid Epoch #7, Batch 3572/4160 loss = 1.5669986355304717, ppl = 4.84349085967589\n","Valid Epoch #7, Batch 3573/4160 loss = 1.565138773918152, ppl = 4.832263487224297\n","Valid Epoch #7, Batch 3574/4160 loss = 1.5630363190174104, ppl = 4.8222848073247375\n","Valid Epoch #7, Batch 3575/4160 loss = 1.5643039989471434, ppl = 4.828556362183873\n","Valid Epoch #7, Batch 3576/4160 loss = 1.5633307933807372, ppl = 4.824373077295706\n","Valid Epoch #7, Batch 3577/4160 loss = 1.560899124145508, ppl = 4.811431489921408\n","Valid Epoch #7, Batch 3578/4160 loss = 1.5615214788913727, ppl = 4.814590375831787\n","Valid Epoch #7, Batch 3579/4160 loss = 1.561317629814148, ppl = 4.813423371365004\n","Valid Epoch #7, Batch 3580/4160 loss = 1.558516387939453, ppl = 4.7982867018641056\n","Valid Epoch #7, Batch 3581/4160 loss = 1.5572531580924989, ppl = 4.792761316608263\n","Valid Epoch #7, Batch 3582/4160 loss = 1.5563406884670257, ppl = 4.789093845900952\n","Valid Epoch #7, Batch 3583/4160 loss = 1.5583134627342223, ppl = 4.797391355585182\n","Valid Epoch #7, Batch 3584/4160 loss = 1.558518477678299, ppl = 4.798411788953783\n","Valid Epoch #7, Batch 3585/4160 loss = 1.5598674511909485, ppl = 4.805664135102068\n","Valid Epoch #7, Batch 3586/4160 loss = 1.5609167170524598, ppl = 4.810229476567151\n","Valid Epoch #7, Batch 3587/4160 loss = 1.560917807817459, ppl = 4.81023467743062\n","Valid Epoch #7, Batch 3588/4160 loss = 1.561831306219101, ppl = 4.8146430487649035\n","Valid Epoch #7, Batch 3589/4160 loss = 1.562854620218277, ppl = 4.820205668011274\n","Valid Epoch #7, Batch 3590/4160 loss = 1.562367389202118, ppl = 4.817827772493552\n","Valid Epoch #7, Batch 3591/4160 loss = 1.563416419029236, ppl = 4.823315949852951\n","Valid Epoch #7, Batch 3592/4160 loss = 1.5616837334632874, ppl = 4.815406769078367\n","Valid Epoch #7, Batch 3593/4160 loss = 1.5634048879146576, ppl = 4.824137870455475\n","Valid Epoch #7, Batch 3594/4160 loss = 1.5630931484699249, ppl = 4.822631756046643\n","Valid Epoch #7, Batch 3595/4160 loss = 1.563916038274765, ppl = 4.826866776425305\n","Valid Epoch #7, Batch 3596/4160 loss = 1.5645225059986114, ppl = 4.829823173337951\n","Valid Epoch #7, Batch 3597/4160 loss = 1.5637671422958375, ppl = 4.82616306149693\n","Valid Epoch #7, Batch 3598/4160 loss = 1.5653317606449126, ppl = 4.834636396173296\n","Valid Epoch #7, Batch 3599/4160 loss = 1.5683586084842682, ppl = 4.8481015362996285\n","Valid Epoch #7, Batch 3600/4160 loss = 1.569914790391922, ppl = 4.855805172426566\n","Valid Epoch #7, Batch 3601/4160 loss = 1.5692771172523499, ppl = 4.853608347095312\n","Valid Epoch #7, Batch 3602/4160 loss = 1.5724331367015838, ppl = 4.867487850750594\n","Valid Epoch #7, Batch 3603/4160 loss = 1.5680780875682832, ppl = 4.850593153523659\n","Valid Epoch #7, Batch 3604/4160 loss = 1.566353852748871, ppl = 4.845179408746564\n","Valid Epoch #7, Batch 3605/4160 loss = 1.5656909930706024, ppl = 4.842598524262545\n","Valid Epoch #7, Batch 3606/4160 loss = 1.564276168346405, ppl = 4.837822706736208\n","Valid Epoch #7, Batch 3607/4160 loss = 1.5659840786457062, ppl = 4.8447100705530906\n","Valid Epoch #7, Batch 3608/4160 loss = 1.5642009353637696, ppl = 4.83759296225146\n","Valid Epoch #7, Batch 3609/4160 loss = 1.5653991031646728, ppl = 4.843648343666787\n","Valid Epoch #7, Batch 3610/4160 loss = 1.566165907382965, ppl = 4.846712313578617\n","Valid Epoch #7, Batch 3611/4160 loss = 1.5672410225868225, ppl = 4.851372248021237\n","Valid Epoch #7, Batch 3612/4160 loss = 1.567316207885742, ppl = 4.8516740704470696\n","Valid Epoch #7, Batch 3613/4160 loss = 1.5689044797420502, ppl = 4.857670469834651\n","Valid Epoch #7, Batch 3614/4160 loss = 1.570667005777359, ppl = 4.867021233759798\n","Valid Epoch #7, Batch 3615/4160 loss = 1.571766860485077, ppl = 4.8718998843090295\n","Valid Epoch #7, Batch 3616/4160 loss = 1.5720482969284058, ppl = 4.873104909684777\n","Valid Epoch #7, Batch 3617/4160 loss = 1.575378019809723, ppl = 4.888166692899552\n","Valid Epoch #7, Batch 3618/4160 loss = 1.5770300114154816, ppl = 4.895231936914904\n","Valid Epoch #7, Batch 3619/4160 loss = 1.5791406428813934, ppl = 4.904266836308783\n","Valid Epoch #7, Batch 3620/4160 loss = 1.5765778529644012, ppl = 4.892877287737127\n","Valid Epoch #7, Batch 3621/4160 loss = 1.577026011943817, ppl = 4.895078541757655\n","Valid Epoch #7, Batch 3622/4160 loss = 1.579127629995346, ppl = 4.906583413973647\n","Valid Epoch #7, Batch 3623/4160 loss = 1.5776909220218658, ppl = 4.899980771746108\n","Valid Epoch #7, Batch 3624/4160 loss = 1.579694890975952, ppl = 4.909638905464263\n","Valid Epoch #7, Batch 3625/4160 loss = 1.5809620797634125, ppl = 4.915445126126118\n","Valid Epoch #7, Batch 3626/4160 loss = 1.5780884611606598, ppl = 4.902400101013832\n","Valid Epoch #7, Batch 3627/4160 loss = 1.5790605795383454, ppl = 4.907728866430348\n","Valid Epoch #7, Batch 3628/4160 loss = 1.5796328377723694, ppl = 4.910350584329501\n","Valid Epoch #7, Batch 3629/4160 loss = 1.5790896153450011, ppl = 4.907219395058897\n","Valid Epoch #7, Batch 3630/4160 loss = 1.5808779513835907, ppl = 4.9150430272400865\n","Valid Epoch #7, Batch 3631/4160 loss = 1.5798591554164887, ppl = 4.909800484078431\n","Valid Epoch #7, Batch 3632/4160 loss = 1.5800076377391816, ppl = 4.910554291481309\n","Valid Epoch #7, Batch 3633/4160 loss = 1.580381177663803, ppl = 4.912352896109344\n","Valid Epoch #7, Batch 3634/4160 loss = 1.5805353915691376, ppl = 4.913225612658696\n","Valid Epoch #7, Batch 3635/4160 loss = 1.5788844001293183, ppl = 4.903700257273364\n","Valid Epoch #7, Batch 3636/4160 loss = 1.5808790874481202, ppl = 4.913832685038591\n","Valid Epoch #7, Batch 3637/4160 loss = 1.5828271806240082, ppl = 4.92425086368549\n","Valid Epoch #7, Batch 3638/4160 loss = 1.5828094112873077, ppl = 4.924167218596815\n","Valid Epoch #7, Batch 3639/4160 loss = 1.5815312111377715, ppl = 4.918185341816039\n","Valid Epoch #7, Batch 3640/4160 loss = 1.5805638110637665, ppl = 4.912462353511544\n","Valid Epoch #7, Batch 3641/4160 loss = 1.5836966633796692, ppl = 4.9294074435312005\n","Valid Epoch #7, Batch 3642/4160 loss = 1.5838528621196746, ppl = 4.93026096737431\n","Valid Epoch #7, Batch 3643/4160 loss = 1.5827060782909392, ppl = 4.9236409964815415\n","Valid Epoch #7, Batch 3644/4160 loss = 1.5800113093852997, ppl = 4.909591368960913\n","Valid Epoch #7, Batch 3645/4160 loss = 1.5810264086723327, ppl = 4.915112485017319\n","Valid Epoch #7, Batch 3646/4160 loss = 1.5815598380565643, ppl = 4.917719534651304\n","Valid Epoch #7, Batch 3647/4160 loss = 1.5808806121349335, ppl = 4.914319142245653\n","Valid Epoch #7, Batch 3648/4160 loss = 1.582631857395172, ppl = 4.92395065100369\n","Valid Epoch #7, Batch 3649/4160 loss = 1.5829161560535432, ppl = 4.925334612461066\n","Valid Epoch #7, Batch 3650/4160 loss = 1.5851040804386138, ppl = 4.936759949265978\n","Valid Epoch #7, Batch 3651/4160 loss = 1.5822619092464447, ppl = 4.922481191474806\n","Valid Epoch #7, Batch 3652/4160 loss = 1.5814431202411652, ppl = 4.918349171345717\n","Valid Epoch #7, Batch 3653/4160 loss = 1.5830719006061553, ppl = 4.925487161913554\n","Valid Epoch #7, Batch 3654/4160 loss = 1.5827676999568938, ppl = 4.924084537438573\n","Valid Epoch #7, Batch 3655/4160 loss = 1.5818905913829804, ppl = 4.919290416220699\n","Valid Epoch #7, Batch 3656/4160 loss = 1.5797425997257233, ppl = 4.9089847719404425\n","Valid Epoch #7, Batch 3657/4160 loss = 1.5782629096508025, ppl = 4.901864240154677\n","Valid Epoch #7, Batch 3658/4160 loss = 1.577737296819687, ppl = 4.899460412083155\n","Valid Epoch #7, Batch 3659/4160 loss = 1.5770512664318084, ppl = 4.895654494528954\n","Valid Epoch #7, Batch 3660/4160 loss = 1.5750363922119142, ppl = 4.883515986242477\n","Valid Epoch #7, Batch 3661/4160 loss = 1.5748183155059814, ppl = 4.882562418581924\n","Valid Epoch #7, Batch 3662/4160 loss = 1.5735653507709504, ppl = 4.876559492860998\n","Valid Epoch #7, Batch 3663/4160 loss = 1.5719320392608642, ppl = 4.868743149586032\n","Valid Epoch #7, Batch 3664/4160 loss = 1.5727855062484741, ppl = 4.8738996116684925\n","Valid Epoch #7, Batch 3665/4160 loss = 1.5735553073883057, ppl = 4.877669208074343\n","Valid Epoch #7, Batch 3666/4160 loss = 1.5740991258621215, ppl = 4.88048232752549\n","Valid Epoch #7, Batch 3667/4160 loss = 1.5733624958992005, ppl = 4.876887287617244\n","Valid Epoch #7, Batch 3668/4160 loss = 1.5726978588104248, ppl = 4.873936064040556\n","Valid Epoch #7, Batch 3669/4160 loss = 1.5705290377140044, ppl = 4.862031967704246\n","Valid Epoch #7, Batch 3670/4160 loss = 1.5688443267345429, ppl = 4.854081760878403\n","Valid Epoch #7, Batch 3671/4160 loss = 1.5697902607917786, ppl = 4.859031757480512\n","Valid Epoch #7, Batch 3672/4160 loss = 1.5715379643440246, ppl = 4.866530631995205\n","Valid Epoch #7, Batch 3673/4160 loss = 1.5708455228805542, ppl = 4.862855956389982\n","Valid Epoch #7, Batch 3674/4160 loss = 1.5717177593708038, ppl = 4.866742869876628\n","Valid Epoch #7, Batch 3675/4160 loss = 1.5702759790420533, ppl = 4.8596704261799\n","Valid Epoch #7, Batch 3676/4160 loss = 1.5738684237003326, ppl = 4.877360941065662\n","Valid Epoch #7, Batch 3677/4160 loss = 1.5733485198020936, ppl = 4.874979208645284\n","Valid Epoch #7, Batch 3678/4160 loss = 1.5724428498744965, ppl = 4.870446142024736\n","Valid Epoch #7, Batch 3679/4160 loss = 1.5709744584560394, ppl = 4.862707300590222\n","Valid Epoch #7, Batch 3680/4160 loss = 1.5725400972366332, ppl = 4.870642629916627\n","Valid Epoch #7, Batch 3681/4160 loss = 1.5752897441387177, ppl = 4.883629748169737\n","Valid Epoch #7, Batch 3682/4160 loss = 1.5771276247501373, ppl = 4.891374740398418\n","Valid Epoch #7, Batch 3683/4160 loss = 1.5805675542354585, ppl = 4.910402621321734\n","Valid Epoch #7, Batch 3684/4160 loss = 1.5802356910705566, ppl = 4.9087612152615\n","Valid Epoch #7, Batch 3685/4160 loss = 1.5806239676475524, ppl = 4.9110365130254285\n","Valid Epoch #7, Batch 3686/4160 loss = 1.5814455294609069, ppl = 4.914960932297177\n","Valid Epoch #7, Batch 3687/4160 loss = 1.5814992809295654, ppl = 4.9152179280823916\n","Valid Epoch #7, Batch 3688/4160 loss = 1.5830829656124115, ppl = 4.923882906704903\n","Valid Epoch #7, Batch 3689/4160 loss = 1.5816489005088805, ppl = 4.916242745112119\n","Valid Epoch #7, Batch 3690/4160 loss = 1.5817236661911012, ppl = 4.916600150936406\n","Valid Epoch #7, Batch 3691/4160 loss = 1.5803215181827546, ppl = 4.909390356470345\n","Valid Epoch #7, Batch 3692/4160 loss = 1.5823537337779998, ppl = 4.91881119758516\n","Valid Epoch #7, Batch 3693/4160 loss = 1.5817805600166321, ppl = 4.915735192195102\n","Valid Epoch #7, Batch 3694/4160 loss = 1.5831898975372314, ppl = 4.922933941263173\n","Valid Epoch #7, Batch 3695/4160 loss = 1.581105763912201, ppl = 4.912848033008702\n","Valid Epoch #7, Batch 3696/4160 loss = 1.5820363867282867, ppl = 4.917748036544262\n","Valid Epoch #7, Batch 3697/4160 loss = 1.5851181077957153, ppl = 4.934584920482519\n","Valid Epoch #7, Batch 3698/4160 loss = 1.58271009683609, ppl = 4.922065153754718\n","Valid Epoch #7, Batch 3699/4160 loss = 1.5812074255943298, ppl = 4.91487176979277\n","Valid Epoch #7, Batch 3700/4160 loss = 1.5819589853286744, ppl = 4.919044064242572\n","Valid Epoch #7, Batch 3701/4160 loss = 1.5829462897777558, ppl = 4.922506194810766\n","Valid Epoch #7, Batch 3702/4160 loss = 1.5801115179061889, ppl = 4.909847747206979\n","Valid Epoch #7, Batch 3703/4160 loss = 1.5813550543785095, ppl = 4.913946987226876\n","Valid Epoch #7, Batch 3704/4160 loss = 1.5836717438697816, ppl = 4.921447088104253\n","Valid Epoch #7, Batch 3705/4160 loss = 1.581453528404236, ppl = 4.9139550588988365\n","Valid Epoch #7, Batch 3706/4160 loss = 1.5851098573207856, ppl = 4.927826394756057\n","Valid Epoch #7, Batch 3707/4160 loss = 1.5836755514144898, ppl = 4.921964804048114\n","Valid Epoch #7, Batch 3708/4160 loss = 1.5841897177696227, ppl = 4.9238885075085435\n","Valid Epoch #7, Batch 3709/4160 loss = 1.5810492277145385, ppl = 4.909435181927172\n","Valid Epoch #7, Batch 3710/4160 loss = 1.5830940556526185, ppl = 4.918853222706642\n","Valid Epoch #7, Batch 3711/4160 loss = 1.5832280433177948, ppl = 4.919469873173433\n","Valid Epoch #7, Batch 3712/4160 loss = 1.5833305323123932, ppl = 4.919884975180747\n","Valid Epoch #7, Batch 3713/4160 loss = 1.5842104482650756, ppl = 4.923640638312919\n","Valid Epoch #7, Batch 3714/4160 loss = 1.5813265717029572, ppl = 4.90914356513487\n","Valid Epoch #7, Batch 3715/4160 loss = 1.5812702906131744, ppl = 4.908880677898469\n","Valid Epoch #7, Batch 3716/4160 loss = 1.5816920757293702, ppl = 4.910751339495434\n","Valid Epoch #7, Batch 3717/4160 loss = 1.5784105229377747, ppl = 4.8958736265910145\n","Valid Epoch #7, Batch 3718/4160 loss = 1.5787235641479491, ppl = 4.897349044296909\n","Valid Epoch #7, Batch 3719/4160 loss = 1.5790974366664887, ppl = 4.899157901363447\n","Valid Epoch #7, Batch 3720/4160 loss = 1.5813584315776825, ppl = 4.9090497284316195\n","Valid Epoch #7, Batch 3721/4160 loss = 1.5828698337078095, ppl = 4.917244679420677\n","Valid Epoch #7, Batch 3722/4160 loss = 1.580164031982422, ppl = 4.902855720194925\n","Valid Epoch #7, Batch 3723/4160 loss = 1.581160365343094, ppl = 4.907332827322101\n","Valid Epoch #7, Batch 3724/4160 loss = 1.5806601440906525, ppl = 4.9047378315658765\n","Valid Epoch #7, Batch 3725/4160 loss = 1.5793373036384581, ppl = 4.898693096129478\n","Valid Epoch #7, Batch 3726/4160 loss = 1.5830902636051178, ppl = 4.916538930472345\n","Valid Epoch #7, Batch 3727/4160 loss = 1.5796014380455017, ppl = 4.899596860970993\n","Valid Epoch #7, Batch 3728/4160 loss = 1.5785145711898805, ppl = 4.894742297871252\n","Valid Epoch #7, Batch 3729/4160 loss = 1.5762415528297424, ppl = 4.883338177025511\n","Valid Epoch #7, Batch 3730/4160 loss = 1.577096883058548, ppl = 4.887604496841732\n","Valid Epoch #7, Batch 3731/4160 loss = 1.5780705785751343, ppl = 4.892603487964817\n","Valid Epoch #7, Batch 3732/4160 loss = 1.577692004442215, ppl = 4.8907034505794496\n","Valid Epoch #7, Batch 3733/4160 loss = 1.5778143107891083, ppl = 4.8913071104376895\n","Valid Epoch #7, Batch 3734/4160 loss = 1.5749060583114625, ppl = 4.876915687771685\n","Valid Epoch #7, Batch 3735/4160 loss = 1.5763084924221038, ppl = 4.884904536464137\n","Valid Epoch #7, Batch 3736/4160 loss = 1.5729497492313385, ppl = 4.8689194450564255\n","Valid Epoch #7, Batch 3737/4160 loss = 1.573383287191391, ppl = 4.871527238300574\n","Valid Epoch #7, Batch 3738/4160 loss = 1.5728895616531373, ppl = 4.869261593082276\n","Valid Epoch #7, Batch 3739/4160 loss = 1.5756316256523133, ppl = 4.883102601155393\n","Valid Epoch #7, Batch 3740/4160 loss = 1.5758410465717316, ppl = 4.884294985032835\n","Valid Epoch #7, Batch 3741/4160 loss = 1.5761897492408752, ppl = 4.8865306547693175\n","Valid Epoch #7, Batch 3742/4160 loss = 1.5776701295375823, ppl = 4.895317669858822\n","Valid Epoch #7, Batch 3743/4160 loss = 1.5778726530075073, ppl = 4.896432259485335\n","Valid Epoch #7, Batch 3744/4160 loss = 1.5805883276462556, ppl = 4.9106063572728695\n","Valid Epoch #7, Batch 3745/4160 loss = 1.5797974216938018, ppl = 4.906256868280154\n","Valid Epoch #7, Batch 3746/4160 loss = 1.5801339876651763, ppl = 4.907974789666628\n","Valid Epoch #7, Batch 3747/4160 loss = 1.5812141370773316, ppl = 4.913493431223207\n","Valid Epoch #7, Batch 3748/4160 loss = 1.5808598732948302, ppl = 4.911406649334112\n","Valid Epoch #7, Batch 3749/4160 loss = 1.580268771648407, ppl = 4.90857266261581\n","Valid Epoch #7, Batch 3750/4160 loss = 1.5793627655506135, ppl = 4.903536648267652\n","Valid Epoch #7, Batch 3751/4160 loss = 1.5793137443065643, ppl = 4.90332423446092\n","Valid Epoch #7, Batch 3752/4160 loss = 1.577773014307022, ppl = 4.8964092878840075\n","Valid Epoch #7, Batch 3753/4160 loss = 1.5785100221633912, ppl = 4.9000415428895865\n","Valid Epoch #7, Batch 3754/4160 loss = 1.5798843145370483, ppl = 4.906731481433371\n","Valid Epoch #7, Batch 3755/4160 loss = 1.579968317747116, ppl = 4.90717263677844\n","Valid Epoch #7, Batch 3756/4160 loss = 1.5790604484081268, ppl = 4.903439935114075\n","Valid Epoch #7, Batch 3757/4160 loss = 1.5809211421012879, ppl = 4.912570972832491\n","Valid Epoch #7, Batch 3758/4160 loss = 1.581189248561859, ppl = 4.913781337003609\n","Valid Epoch #7, Batch 3759/4160 loss = 1.5801818585395813, ppl = 4.908645160089786\n","Valid Epoch #7, Batch 3760/4160 loss = 1.5801616632938384, ppl = 4.908535451346336\n","Valid Epoch #7, Batch 3761/4160 loss = 1.5813894224166871, ppl = 4.914185400144451\n","Valid Epoch #7, Batch 3762/4160 loss = 1.5823784375190735, ppl = 4.918860473072989\n","Valid Epoch #7, Batch 3763/4160 loss = 1.5830288100242615, ppl = 4.921820846068645\n","Valid Epoch #7, Batch 3764/4160 loss = 1.5810827779769898, ppl = 4.910674215416409\n","Valid Epoch #7, Batch 3765/4160 loss = 1.5795842945575713, ppl = 4.903594038070076\n","Valid Epoch #7, Batch 3766/4160 loss = 1.5798483610153198, ppl = 4.905016201670498\n","Valid Epoch #7, Batch 3767/4160 loss = 1.5790519094467164, ppl = 4.901415891980967\n","Valid Epoch #7, Batch 3768/4160 loss = 1.5816025340557098, ppl = 4.9138930149653905\n","Valid Epoch #7, Batch 3769/4160 loss = 1.5797759342193602, ppl = 4.905687432845393\n","Valid Epoch #7, Batch 3770/4160 loss = 1.5815565478801727, ppl = 4.9141317654275305\n","Valid Epoch #7, Batch 3771/4160 loss = 1.5803722941875458, ppl = 4.9080067725386245\n","Valid Epoch #7, Batch 3772/4160 loss = 1.5809218418598174, ppl = 4.910648694168541\n","Valid Epoch #7, Batch 3773/4160 loss = 1.5828246104717254, ppl = 4.921390369902171\n","Valid Epoch #7, Batch 3774/4160 loss = 1.5820663630962373, ppl = 4.917992371639321\n","Valid Epoch #7, Batch 3775/4160 loss = 1.5841018617153169, ppl = 4.928286913843292\n","Valid Epoch #7, Batch 3776/4160 loss = 1.5827791380882263, ppl = 4.921024356613047\n","Valid Epoch #7, Batch 3777/4160 loss = 1.5810295963287353, ppl = 4.9138609656213275\n","Valid Epoch #7, Batch 3778/4160 loss = 1.581884858608246, ppl = 4.918130797979333\n","Valid Epoch #7, Batch 3779/4160 loss = 1.581879950761795, ppl = 4.9181067907140195\n","Valid Epoch #7, Batch 3780/4160 loss = 1.5794604241847991, ppl = 4.906339480821865\n","Valid Epoch #7, Batch 3781/4160 loss = 1.577414344549179, ppl = 4.896343481915251\n","Valid Epoch #7, Batch 3782/4160 loss = 1.5783017480373382, ppl = 4.900624381515105\n","Valid Epoch #7, Batch 3783/4160 loss = 1.576436641216278, ppl = 4.889501134944553\n","Valid Epoch #7, Batch 3784/4160 loss = 1.577173181772232, ppl = 4.893219220156206\n","Valid Epoch #7, Batch 3785/4160 loss = 1.5743371081352233, ppl = 4.8784659415367\n","Valid Epoch #7, Batch 3786/4160 loss = 1.572687132358551, ppl = 4.8708977112668\n","Valid Epoch #7, Batch 3787/4160 loss = 1.5726982080936431, ppl = 4.8709508382835836\n","Valid Epoch #7, Batch 3788/4160 loss = 1.5705625224113464, ppl = 4.859574018791733\n","Valid Epoch #7, Batch 3789/4160 loss = 1.5694570815563202, ppl = 4.854388722922107\n","Valid Epoch #7, Batch 3790/4160 loss = 1.5704367220401765, ppl = 4.8593272202756825\n","Valid Epoch #7, Batch 3791/4160 loss = 1.5710993766784669, ppl = 4.862608793690168\n","Valid Epoch #7, Batch 3792/4160 loss = 1.5708949291706085, ppl = 4.861572097050862\n","Valid Epoch #7, Batch 3793/4160 loss = 1.5694862914085388, ppl = 4.854720920106377\n","Valid Epoch #7, Batch 3794/4160 loss = 1.5686857509613037, ppl = 4.850507820159095\n","Valid Epoch #7, Batch 3795/4160 loss = 1.5691625463962555, ppl = 4.85263338351394\n","Valid Epoch #7, Batch 3796/4160 loss = 1.5683735823631286, ppl = 4.848450151912004\n","Valid Epoch #7, Batch 3797/4160 loss = 1.5650850296020509, ppl = 4.830658350100648\n","Valid Epoch #7, Batch 3798/4160 loss = 1.5641747748851775, ppl = 4.826657551906731\n","Valid Epoch #7, Batch 3799/4160 loss = 1.5657567751407624, ppl = 4.834261562048732\n","Valid Epoch #7, Batch 3800/4160 loss = 1.5670235180854797, ppl = 4.8420439871398715\n","Valid Epoch #7, Batch 3801/4160 loss = 1.5668940496444703, ppl = 4.841570279274064\n","Valid Epoch #7, Batch 3802/4160 loss = 1.5697481846809387, ppl = 4.854328121370793\n","Valid Epoch #7, Batch 3803/4160 loss = 1.5686397850513458, ppl = 4.850650066946262\n","Valid Epoch #7, Batch 3804/4160 loss = 1.569371110200882, ppl = 4.853401903233066\n","Valid Epoch #7, Batch 3805/4160 loss = 1.5705432057380677, ppl = 4.857153369832932\n","Valid Epoch #7, Batch 3806/4160 loss = 1.5668856179714203, ppl = 4.84327807842393\n","Valid Epoch #7, Batch 3807/4160 loss = 1.5683133721351623, ppl = 4.849110937412394\n","Valid Epoch #7, Batch 3808/4160 loss = 1.5673215508460998, ppl = 4.845486622649161\n","Valid Epoch #7, Batch 3809/4160 loss = 1.5665525579452515, ppl = 4.842587122691358\n","Valid Epoch #7, Batch 3810/4160 loss = 1.5647177290916443, ppl = 4.8340499887954\n","Valid Epoch #7, Batch 3811/4160 loss = 1.5631897163391113, ppl = 4.827484765173915\n","Valid Epoch #7, Batch 3812/4160 loss = 1.5623610150814056, ppl = 4.824247125876976\n","Valid Epoch #7, Batch 3813/4160 loss = 1.5616667687892913, ppl = 4.821256666614791\n","Valid Epoch #7, Batch 3814/4160 loss = 1.5629612219333648, ppl = 4.827250095454047\n","Valid Epoch #7, Batch 3815/4160 loss = 1.562408859729767, ppl = 4.824747048071271\n","Valid Epoch #7, Batch 3816/4160 loss = 1.5643179905414581, ppl = 4.834274615170157\n","Valid Epoch #7, Batch 3817/4160 loss = 1.5672079157829284, ppl = 4.847109815205544\n","Valid Epoch #7, Batch 3818/4160 loss = 1.5670741140842437, ppl = 4.8464735286487075\n","Valid Epoch #7, Batch 3819/4160 loss = 1.566328115463257, ppl = 4.84293018297488\n","Valid Epoch #7, Batch 3820/4160 loss = 1.5646560299396515, ppl = 4.835403483729274\n","Valid Epoch #7, Batch 3821/4160 loss = 1.5627063262462615, ppl = 4.825054642594841\n","Valid Epoch #7, Batch 3822/4160 loss = 1.563997540473938, ppl = 4.831437159222376\n","Valid Epoch #7, Batch 3823/4160 loss = 1.563725689649582, ppl = 4.830170997549576\n","Valid Epoch #7, Batch 3824/4160 loss = 1.564154988527298, ppl = 4.832390125161052\n","Valid Epoch #7, Batch 3825/4160 loss = 1.5636651849746703, ppl = 4.830347176285291\n","Valid Epoch #7, Batch 3826/4160 loss = 1.564960218667984, ppl = 4.838232463119727\n","Valid Epoch #7, Batch 3827/4160 loss = 1.5659048414230348, ppl = 4.84225277784345\n","Valid Epoch #7, Batch 3828/4160 loss = 1.5666410434246063, ppl = 4.845483060626327\n","Valid Epoch #7, Batch 3829/4160 loss = 1.56678081035614, ppl = 4.84611200080391\n","Valid Epoch #7, Batch 3830/4160 loss = 1.5666984903812409, ppl = 4.845685343318114\n","Valid Epoch #7, Batch 3831/4160 loss = 1.5641646659374238, ppl = 4.833625336183355\n","Valid Epoch #7, Batch 3832/4160 loss = 1.5620323276519776, ppl = 4.824168625956747\n","Valid Epoch #7, Batch 3833/4160 loss = 1.5657065844535827, ppl = 4.846217764049656\n","Valid Epoch #7, Batch 3834/4160 loss = 1.5661792397499084, ppl = 4.848281427242492\n","Valid Epoch #7, Batch 3835/4160 loss = 1.5652622365951538, ppl = 4.842931968247061\n","Valid Epoch #7, Batch 3836/4160 loss = 1.5683342969417573, ppl = 4.857333536686801\n","Valid Epoch #7, Batch 3837/4160 loss = 1.5676522874832153, ppl = 4.853281334665598\n","Valid Epoch #7, Batch 3838/4160 loss = 1.5697553145885468, ppl = 4.863758713218356\n","Valid Epoch #7, Batch 3839/4160 loss = 1.5684655654430388, ppl = 4.8567752117501035\n","Valid Epoch #7, Batch 3840/4160 loss = 1.5695093846321106, ppl = 4.86310551158654\n","Valid Epoch #7, Batch 3841/4160 loss = 1.567630225419998, ppl = 4.851929178917177\n","Valid Epoch #7, Batch 3842/4160 loss = 1.5665265822410583, ppl = 4.845256482110859\n","Valid Epoch #7, Batch 3843/4160 loss = 1.566540733575821, ppl = 4.845335211102592\n","Valid Epoch #7, Batch 3844/4160 loss = 1.5662362587451935, ppl = 4.84354785664301\n","Valid Epoch #7, Batch 3845/4160 loss = 1.5654344725608826, ppl = 4.839476021130923\n","Valid Epoch #7, Batch 3846/4160 loss = 1.566984018087387, ppl = 4.848175790115683\n","Valid Epoch #7, Batch 3847/4160 loss = 1.5654807901382446, ppl = 4.84065291443632\n","Valid Epoch #7, Batch 3848/4160 loss = 1.56393984913826, ppl = 4.832388932676244\n","Valid Epoch #7, Batch 3849/4160 loss = 1.5643254828453064, ppl = 4.834218770645534\n","Valid Epoch #7, Batch 3850/4160 loss = 1.5646731162071228, ppl = 4.836097333443701\n","Valid Epoch #7, Batch 3851/4160 loss = 1.5641709399223327, ppl = 4.83398028542568\n","Valid Epoch #7, Batch 3852/4160 loss = 1.565943911075592, ppl = 4.842033072358264\n","Valid Epoch #7, Batch 3853/4160 loss = 1.5653154635429383, ppl = 4.838919178716369\n","Valid Epoch #7, Batch 3854/4160 loss = 1.564806203842163, ppl = 4.836332327427552\n","Valid Epoch #7, Batch 3855/4160 loss = 1.5648488259315492, ppl = 4.836557584836343\n","Valid Epoch #7, Batch 3856/4160 loss = 1.5666543185710906, ppl = 4.844329496903512\n","Valid Epoch #7, Batch 3857/4160 loss = 1.5660860800743104, ppl = 4.841358697566739\n","Valid Epoch #7, Batch 3858/4160 loss = 1.5672068226337432, ppl = 4.84678479238907\n","Valid Epoch #7, Batch 3859/4160 loss = 1.5658410501480102, ppl = 4.840598335572002\n","Valid Epoch #7, Batch 3860/4160 loss = 1.5663799798488618, ppl = 4.843603310657584\n","Valid Epoch #7, Batch 3861/4160 loss = 1.5667437410354614, ppl = 4.845414894052633\n","Valid Epoch #7, Batch 3862/4160 loss = 1.5664765191078187, ppl = 4.844105811506583\n","Valid Epoch #7, Batch 3863/4160 loss = 1.5672947716712953, ppl = 4.848114543617445\n","Valid Epoch #7, Batch 3864/4160 loss = 1.565781179666519, ppl = 4.840826565189838\n","Valid Epoch #7, Batch 3865/4160 loss = 1.5677205157279968, ppl = 4.850199862133652\n","Valid Epoch #7, Batch 3866/4160 loss = 1.5663690197467803, ppl = 4.8433013457367675\n","Valid Epoch #7, Batch 3867/4160 loss = 1.568316445350647, ppl = 4.85263831047827\n","Valid Epoch #7, Batch 3868/4160 loss = 1.5655052196979522, ppl = 4.839056511909607\n","Valid Epoch #7, Batch 3869/4160 loss = 1.5686128151416778, ppl = 4.853979282178245\n","Valid Epoch #7, Batch 3870/4160 loss = 1.5672194790840148, ppl = 4.8472458142649035\n","Valid Epoch #7, Batch 3871/4160 loss = 1.5677450609207153, ppl = 4.849874838224022\n","Valid Epoch #7, Batch 3872/4160 loss = 1.568128446340561, ppl = 4.851805830269548\n","Valid Epoch #7, Batch 3873/4160 loss = 1.5644944214820862, ppl = 4.832916683198847\n","Valid Epoch #7, Batch 3874/4160 loss = 1.5667923307418823, ppl = 4.844060385690704\n","Valid Epoch #7, Batch 3875/4160 loss = 1.5650067186355592, ppl = 4.834919739783779\n","Valid Epoch #7, Batch 3876/4160 loss = 1.5625702941417694, ppl = 4.823815172269384\n","Valid Epoch #7, Batch 3877/4160 loss = 1.5645687341690064, ppl = 4.8321033475852415\n","Valid Epoch #7, Batch 3878/4160 loss = 1.5659421980381012, ppl = 4.839772261526204\n","Valid Epoch #7, Batch 3879/4160 loss = 1.5662752175331116, ppl = 4.84142828428489\n","Valid Epoch #7, Batch 3880/4160 loss = 1.5673372673988342, ppl = 4.8462450967722495\n","Valid Epoch #7, Batch 3881/4160 loss = 1.5684399211406708, ppl = 4.851377482446404\n","Valid Epoch #7, Batch 3882/4160 loss = 1.565421531200409, ppl = 4.83824277620199\n","Valid Epoch #7, Batch 3883/4160 loss = 1.5633574879169465, ppl = 4.828125407029821\n","Valid Epoch #7, Batch 3884/4160 loss = 1.5622387099266053, ppl = 4.822583047219288\n","Valid Epoch #7, Batch 3885/4160 loss = 1.5641949093341827, ppl = 4.832304153094694\n","Valid Epoch #7, Batch 3886/4160 loss = 1.5650553047657012, ppl = 4.836094777624588\n","Valid Epoch #7, Batch 3887/4160 loss = 1.565696370601654, ppl = 4.839272243675413\n","Valid Epoch #7, Batch 3888/4160 loss = 1.5649560809135437, ppl = 4.8358626052287645\n","Valid Epoch #7, Batch 3889/4160 loss = 1.5657539236545563, ppl = 4.839547032574486\n","Valid Epoch #7, Batch 3890/4160 loss = 1.5643220496177674, ppl = 4.832486945065173\n","Valid Epoch #7, Batch 3891/4160 loss = 1.5643023979663848, ppl = 4.832386465631394\n","Valid Epoch #7, Batch 3892/4160 loss = 1.5669160377979279, ppl = 4.847378425840696\n","Valid Epoch #7, Batch 3893/4160 loss = 1.569188631772995, ppl = 4.858934849467924\n","Valid Epoch #7, Batch 3894/4160 loss = 1.5705925559997558, ppl = 4.866553974621511\n","Valid Epoch #7, Batch 3895/4160 loss = 1.5716167604923248, ppl = 4.871477442512893\n","Valid Epoch #7, Batch 3896/4160 loss = 1.5726806545257568, ppl = 4.877197695985725\n","Valid Epoch #7, Batch 3897/4160 loss = 1.5737371444702148, ppl = 4.882289346824322\n","Valid Epoch #7, Batch 3898/4160 loss = 1.5775233316421509, ppl = 4.9016124509955175\n","Valid Epoch #7, Batch 3899/4160 loss = 1.5773742163181306, ppl = 4.900843277429571\n","Valid Epoch #7, Batch 3900/4160 loss = 1.5743703484535216, ppl = 4.883871499445717\n","Valid Epoch #7, Batch 3901/4160 loss = 1.5727929413318633, ppl = 4.878566647425699\n","Valid Epoch #7, Batch 3902/4160 loss = 1.5681050729751587, ppl = 4.859337701942459\n","Valid Epoch #7, Batch 3903/4160 loss = 1.5682376968860625, ppl = 4.859756626482417\n","Valid Epoch #7, Batch 3904/4160 loss = 1.5683519840240479, ppl = 4.860205141785097\n","Valid Epoch #7, Batch 3905/4160 loss = 1.569882286787033, ppl = 4.865813973144547\n","Valid Epoch #7, Batch 3906/4160 loss = 1.5731345868110658, ppl = 4.877890206327118\n","Valid Epoch #7, Batch 3907/4160 loss = 1.5708064138889313, ppl = 4.868784732981631\n","Valid Epoch #7, Batch 3908/4160 loss = 1.571983059644699, ppl = 4.873125076839778\n","Valid Epoch #7, Batch 3909/4160 loss = 1.5724651765823365, ppl = 4.874916750009042\n","Valid Epoch #7, Batch 3910/4160 loss = 1.5738497579097748, ppl = 4.881211751183202\n","Valid Epoch #7, Batch 3911/4160 loss = 1.5717943716049194, ppl = 4.873823438563692\n","Valid Epoch #7, Batch 3912/4160 loss = 1.5726450407505035, ppl = 4.87715060745925\n","Valid Epoch #7, Batch 3913/4160 loss = 1.5756541228294372, ppl = 4.891754694355756\n","Valid Epoch #7, Batch 3914/4160 loss = 1.5737938582897186, ppl = 4.883375540753801\n","Valid Epoch #7, Batch 3915/4160 loss = 1.57442746758461, ppl = 4.886258565369467\n","Valid Epoch #7, Batch 3916/4160 loss = 1.5730195534229279, ppl = 4.879059011611583\n","Valid Epoch #7, Batch 3917/4160 loss = 1.5714866125583649, ppl = 4.87179087823063\n","Valid Epoch #7, Batch 3918/4160 loss = 1.5695469999313354, ppl = 4.863462511805796\n","Valid Epoch #7, Batch 3919/4160 loss = 1.5683217692375182, ppl = 4.858187060963731\n","Valid Epoch #7, Batch 3920/4160 loss = 1.5709708857536315, ppl = 4.870730784035807\n","Valid Epoch #7, Batch 3921/4160 loss = 1.5738005018234253, ppl = 4.8864531505106035\n","Valid Epoch #7, Batch 3922/4160 loss = 1.5720595383644105, ppl = 4.878034086642382\n","Valid Epoch #7, Batch 3923/4160 loss = 1.5734189665317535, ppl = 4.884724488515075\n","Valid Epoch #7, Batch 3924/4160 loss = 1.5711449158191682, ppl = 4.873982951747666\n","Valid Epoch #7, Batch 3925/4160 loss = 1.572669713497162, ppl = 4.880686421167777\n","Valid Epoch #7, Batch 3926/4160 loss = 1.570842354297638, ppl = 4.869844613537151\n","Valid Epoch #7, Batch 3927/4160 loss = 1.5723119521141051, ppl = 4.876905407964831\n","Valid Epoch #7, Batch 3928/4160 loss = 1.574933078289032, ppl = 4.890544308756222\n","Valid Epoch #7, Batch 3929/4160 loss = 1.5772583639621736, ppl = 4.902407010372181\n","Valid Epoch #7, Batch 3930/4160 loss = 1.5767634952068328, ppl = 4.899914862721865\n","Valid Epoch #7, Batch 3931/4160 loss = 1.5779668045043946, ppl = 4.90526244364852\n","Valid Epoch #7, Batch 3932/4160 loss = 1.581828864812851, ppl = 4.924018291364412\n","Valid Epoch #7, Batch 3933/4160 loss = 1.5767548727989196, ppl = 4.895482779806864\n","Valid Epoch #7, Batch 3934/4160 loss = 1.578357059955597, ppl = 4.903250367358644\n","Valid Epoch #7, Batch 3935/4160 loss = 1.5785337150096894, ppl = 4.904243122484828\n","Valid Epoch #7, Batch 3936/4160 loss = 1.5776608681678772, ppl = 4.899692143577123\n","Valid Epoch #7, Batch 3937/4160 loss = 1.5779405152797699, ppl = 4.901320328868852\n","Valid Epoch #7, Batch 3938/4160 loss = 1.5775112748146056, ppl = 4.89899926252796\n","Valid Epoch #7, Batch 3939/4160 loss = 1.5797553277015686, ppl = 4.911761693665528\n","Valid Epoch #7, Batch 3940/4160 loss = 1.576747772693634, ppl = 4.895173120088879\n","Valid Epoch #7, Batch 3941/4160 loss = 1.5772371435165404, ppl = 4.897884556776209\n","Valid Epoch #7, Batch 3942/4160 loss = 1.5772008752822877, ppl = 4.8976775301954\n","Valid Epoch #7, Batch 3943/4160 loss = 1.5745320689678193, ppl = 4.884636938273333\n","Valid Epoch #7, Batch 3944/4160 loss = 1.5723926198482514, ppl = 4.8735016027489815\n","Valid Epoch #7, Batch 3945/4160 loss = 1.5747382533550263, ppl = 4.886395816714418\n","Valid Epoch #7, Batch 3946/4160 loss = 1.573847759962082, ppl = 4.8812321964518395\n","Valid Epoch #7, Batch 3947/4160 loss = 1.5749081230163575, ppl = 4.886420095965412\n","Valid Epoch #7, Batch 3948/4160 loss = 1.5748567473888397, ppl = 4.886165908198802\n","Valid Epoch #7, Batch 3949/4160 loss = 1.5755296766757965, ppl = 4.8895329500201505\n","Valid Epoch #7, Batch 3950/4160 loss = 1.5752091383934022, ppl = 4.887798470162104\n","Valid Epoch #7, Batch 3951/4160 loss = 1.574751192331314, ppl = 4.885958408562989\n","Valid Epoch #7, Batch 3952/4160 loss = 1.5754171419143677, ppl = 4.88937157885487\n","Valid Epoch #7, Batch 3953/4160 loss = 1.5765702676773072, ppl = 4.895239358446115\n","Valid Epoch #7, Batch 3954/4160 loss = 1.576325604915619, ppl = 4.89404263800107\n","Valid Epoch #7, Batch 3955/4160 loss = 1.5762479376792908, ppl = 4.89363288516585\n","Valid Epoch #7, Batch 3956/4160 loss = 1.576599440574646, ppl = 4.895316071755153\n","Valid Epoch #7, Batch 3957/4160 loss = 1.578666741847992, ppl = 4.906984512546469\n","Valid Epoch #7, Batch 3958/4160 loss = 1.5772884380817414, ppl = 4.9003950494515145\n","Valid Epoch #7, Batch 3959/4160 loss = 1.5786200511455535, ppl = 4.906416252082566\n","Valid Epoch #7, Batch 3960/4160 loss = 1.577253383398056, ppl = 4.899100095762297\n","Valid Epoch #7, Batch 3961/4160 loss = 1.5769510412216186, ppl = 4.897589782617263\n","Valid Epoch #7, Batch 3962/4160 loss = 1.577625080347061, ppl = 4.9009601966821705\n","Valid Epoch #7, Batch 3963/4160 loss = 1.5762905073165894, ppl = 4.894585620021831\n","Valid Epoch #7, Batch 3964/4160 loss = 1.5783662581443787, ppl = 4.904873965184768\n","Valid Epoch #7, Batch 3965/4160 loss = 1.5771699333190918, ppl = 4.89887879816389\n","Valid Epoch #7, Batch 3966/4160 loss = 1.5806220376491547, ppl = 4.918533335818833\n","Valid Epoch #7, Batch 3967/4160 loss = 1.577878167629242, ppl = 4.905871715502975\n","Valid Epoch #7, Batch 3968/4160 loss = 1.5781813192367553, ppl = 4.907159510680691\n","Valid Epoch #7, Batch 3969/4160 loss = 1.5750181674957275, ppl = 4.892009897221814\n","Valid Epoch #7, Batch 3970/4160 loss = 1.576734471321106, ppl = 4.900442699308047\n","Valid Epoch #7, Batch 3971/4160 loss = 1.5762486219406129, ppl = 4.898007629832764\n","Valid Epoch #7, Batch 3972/4160 loss = 1.5741514194011688, ppl = 4.888294947076706\n","Valid Epoch #7, Batch 3973/4160 loss = 1.574276088476181, ppl = 4.888835694185013\n","Valid Epoch #7, Batch 3974/4160 loss = 1.5721836543083192, ppl = 4.878587504350808\n","Valid Epoch #7, Batch 3975/4160 loss = 1.5732479095458984, ppl = 4.883837991793305\n","Valid Epoch #7, Batch 3976/4160 loss = 1.5768950986862182, ppl = 4.901552502327352\n","Valid Epoch #7, Batch 3977/4160 loss = 1.5781052565574647, ppl = 4.907438582547677\n","Valid Epoch #7, Batch 3978/4160 loss = 1.5743241930007934, ppl = 4.888624073526581\n","Valid Epoch #7, Batch 3979/4160 loss = 1.5727837908267974, ppl = 4.881405988216654\n","Valid Epoch #7, Batch 3980/4160 loss = 1.5710727512836455, ppl = 4.873887893305112\n","Valid Epoch #7, Batch 3981/4160 loss = 1.5708884418010711, ppl = 4.872990143012378\n","Valid Epoch #7, Batch 3982/4160 loss = 1.5752401125431061, ppl = 4.893314970588511\n","Valid Epoch #7, Batch 3983/4160 loss = 1.5764401543140412, ppl = 4.898941926603002\n","Valid Epoch #7, Batch 3984/4160 loss = 1.577452232837677, ppl = 4.903928554106167\n","Valid Epoch #7, Batch 3985/4160 loss = 1.5759864127635956, ppl = 4.896468737375736\n","Valid Epoch #7, Batch 3986/4160 loss = 1.5785550570487976, ppl = 4.909934675678371\n","Valid Epoch #7, Batch 3987/4160 loss = 1.5797250473499298, ppl = 4.9162859437907045\n","Valid Epoch #7, Batch 3988/4160 loss = 1.5810035407543181, ppl = 4.92233780058357\n","Valid Epoch #7, Batch 3989/4160 loss = 1.5814341855049134, ppl = 4.924452100049962\n","Valid Epoch #7, Batch 3990/4160 loss = 1.5830484652519226, ppl = 4.932486352320101\n","Valid Epoch #7, Batch 3991/4160 loss = 1.5812206482887268, ppl = 4.923953428257211\n","Valid Epoch #7, Batch 3992/4160 loss = 1.581030730009079, ppl = 4.922727172690804\n","Valid Epoch #7, Batch 3993/4160 loss = 1.5780983912944793, ppl = 4.908279089283952\n","Valid Epoch #7, Batch 3994/4160 loss = 1.5771735298633576, ppl = 4.903140558166187\n","Valid Epoch #7, Batch 3995/4160 loss = 1.576715716123581, ppl = 4.9008773713942135\n","Valid Epoch #7, Batch 3996/4160 loss = 1.575786328315735, ppl = 4.895847161248839\n","Valid Epoch #7, Batch 3997/4160 loss = 1.574404685497284, ppl = 4.889293683262543\n","Valid Epoch #7, Batch 3998/4160 loss = 1.572247688770294, ppl = 4.877399014097034\n","Valid Epoch #7, Batch 3999/4160 loss = 1.5703967487812043, ppl = 4.86874775111357\n","Valid Epoch #7, Batch 4000/4160 loss = 1.5691497468948363, ppl = 4.863068946376991\n","Valid Epoch #7, Batch 4001/4160 loss = 1.5708747327327728, ppl = 4.868914259662131\n","Valid Epoch #7, Batch 4002/4160 loss = 1.5712332677841188, ppl = 4.870087954545338\n","Valid Epoch #7, Batch 4003/4160 loss = 1.5738686275482179, ppl = 4.879675617000945\n","Valid Epoch #7, Batch 4004/4160 loss = 1.5724876070022582, ppl = 4.8745844659142\n","Valid Epoch #7, Batch 4005/4160 loss = 1.5711187839508056, ppl = 4.869527801498583\n","Valid Epoch #7, Batch 4006/4160 loss = 1.5734921371936799, ppl = 4.881178962959501\n","Valid Epoch #7, Batch 4007/4160 loss = 1.5756369924545288, ppl = 4.88948810788879\n","Valid Epoch #7, Batch 4008/4160 loss = 1.577375111579895, ppl = 4.896910558140839\n","Valid Epoch #7, Batch 4009/4160 loss = 1.578921182155609, ppl = 4.903275107328087\n","Valid Epoch #7, Batch 4010/4160 loss = 1.5764206528663636, ppl = 4.892503988802604\n","Valid Epoch #7, Batch 4011/4160 loss = 1.5781030106544494, ppl = 4.898436216338082\n","Valid Epoch #7, Batch 4012/4160 loss = 1.578599557876587, ppl = 4.900513246634884\n","Valid Epoch #7, Batch 4013/4160 loss = 1.5766942715644836, ppl = 4.890763604174199\n","Valid Epoch #7, Batch 4014/4160 loss = 1.576503208875656, ppl = 4.8899880040012365\n","Valid Epoch #7, Batch 4015/4160 loss = 1.5767348158359527, ppl = 4.891088284491561\n","Valid Epoch #7, Batch 4016/4160 loss = 1.5788048541545867, ppl = 4.902040503617644\n","Valid Epoch #7, Batch 4017/4160 loss = 1.57942986369133, ppl = 4.904870032894595\n","Valid Epoch #7, Batch 4018/4160 loss = 1.57897430062294, ppl = 4.90313726758119\n","Valid Epoch #7, Batch 4019/4160 loss = 1.5809022855758668, ppl = 4.911743365441918\n","Valid Epoch #7, Batch 4020/4160 loss = 1.582406429052353, ppl = 4.9204920288540945\n","Valid Epoch #7, Batch 4021/4160 loss = 1.5814849317073822, ppl = 4.9148760623224055\n","Valid Epoch #7, Batch 4022/4160 loss = 1.5823948431015014, ppl = 4.919093305697768\n","Valid Epoch #7, Batch 4023/4160 loss = 1.5820620322227479, ppl = 4.917370358985175\n","Valid Epoch #7, Batch 4024/4160 loss = 1.585894032716751, ppl = 4.9370148535517755\n","Valid Epoch #7, Batch 4025/4160 loss = 1.5868894815444947, ppl = 4.94197610755975\n","Valid Epoch #7, Batch 4026/4160 loss = 1.586584380865097, ppl = 4.9403512027409535\n","Valid Epoch #7, Batch 4027/4160 loss = 1.5834836912155152, ppl = 4.9265777670482995\n","Valid Epoch #7, Batch 4028/4160 loss = 1.5807343685626984, ppl = 4.912359134333587\n","Valid Epoch #7, Batch 4029/4160 loss = 1.5798254191875458, ppl = 4.907391222823372\n","Valid Epoch #7, Batch 4030/4160 loss = 1.5810939157009125, ppl = 4.914035059467834\n","Valid Epoch #7, Batch 4031/4160 loss = 1.578644083738327, ppl = 4.903786283337627\n","Valid Epoch #7, Batch 4032/4160 loss = 1.578235114812851, ppl = 4.901440297183487\n","Valid Epoch #7, Batch 4033/4160 loss = 1.5803518986701965, ppl = 4.911618219445109\n","Valid Epoch #7, Batch 4034/4160 loss = 1.5792059457302094, ppl = 4.905937283587671\n","Valid Epoch #7, Batch 4035/4160 loss = 1.5781291925907135, ppl = 4.900149784055887\n","Valid Epoch #7, Batch 4036/4160 loss = 1.5798254239559173, ppl = 4.909373673787872\n","Valid Epoch #7, Batch 4037/4160 loss = 1.5802256405353545, ppl = 4.911784503026138\n","Valid Epoch #7, Batch 4038/4160 loss = 1.582137178182602, ppl = 4.92293219845323\n","Valid Epoch #7, Batch 4039/4160 loss = 1.582063419818878, ppl = 4.922465615296375\n","Valid Epoch #7, Batch 4040/4160 loss = 1.5843584334850311, ppl = 4.9346618341635455\n","Valid Epoch #7, Batch 4041/4160 loss = 1.581627733707428, ppl = 4.921095244898356\n","Valid Epoch #7, Batch 4042/4160 loss = 1.5808029556274414, ppl = 4.916584354486605\n","Valid Epoch #7, Batch 4043/4160 loss = 1.5840467119216919, ppl = 4.932919672390252\n","Valid Epoch #7, Batch 4044/4160 loss = 1.5831843185424805, ppl = 4.929062854031395\n","Valid Epoch #7, Batch 4045/4160 loss = 1.5799933767318726, ppl = 4.9122150324888985\n","Valid Epoch #7, Batch 4046/4160 loss = 1.579103889465332, ppl = 4.907496453634107\n","Valid Epoch #7, Batch 4047/4160 loss = 1.5788336968421937, ppl = 4.906121846616873\n","Valid Epoch #7, Batch 4048/4160 loss = 1.5785030555725097, ppl = 4.904516833894757\n","Valid Epoch #7, Batch 4049/4160 loss = 1.5776873624324799, ppl = 4.900464135666928\n","Valid Epoch #7, Batch 4050/4160 loss = 1.5770882415771483, ppl = 4.8973675720413725\n","Valid Epoch #7, Batch 4051/4160 loss = 1.580542142391205, ppl = 4.913567117832532\n","Valid Epoch #7, Batch 4052/4160 loss = 1.5807138884067535, ppl = 4.9144848557876015\n","Valid Epoch #7, Batch 4053/4160 loss = 1.5774945533275604, ppl = 4.8996552578695365\n","Valid Epoch #7, Batch 4054/4160 loss = 1.5777248847484588, ppl = 4.900781069136915\n","Valid Epoch #7, Batch 4055/4160 loss = 1.5776852726936341, ppl = 4.900573308153668\n","Valid Epoch #7, Batch 4056/4160 loss = 1.5773643100261687, ppl = 4.8990340291955095\n","Valid Epoch #7, Batch 4057/4160 loss = 1.5757320630550384, ppl = 4.889624867564423\n","Valid Epoch #7, Batch 4058/4160 loss = 1.580175563097, ppl = 4.914571591225657\n","Valid Epoch #7, Batch 4059/4160 loss = 1.5819158470630645, ppl = 4.923751910625249\n","Valid Epoch #7, Batch 4060/4160 loss = 1.581297197341919, ppl = 4.920754918842126\n","Valid Epoch #7, Batch 4061/4160 loss = 1.5812307226657867, ppl = 4.920428932053546\n","Valid Epoch #7, Batch 4062/4160 loss = 1.5810750532150268, ppl = 4.919630238876752\n","Valid Epoch #7, Batch 4063/4160 loss = 1.580828776359558, ppl = 4.918544079364985\n","Valid Epoch #7, Batch 4064/4160 loss = 1.5797609388828278, ppl = 4.912985178455039\n","Valid Epoch #7, Batch 4065/4160 loss = 1.5794942486286163, ppl = 4.91174368548039\n","Valid Epoch #7, Batch 4066/4160 loss = 1.5774711465835571, ppl = 4.8994122632277115\n","Valid Epoch #7, Batch 4067/4160 loss = 1.5785570335388184, ppl = 4.904012281365806\n","Valid Epoch #7, Batch 4068/4160 loss = 1.5813727915287017, ppl = 4.918038016636876\n","Valid Epoch #7, Batch 4069/4160 loss = 1.5827572441101074, ppl = 4.924084089557393\n","Valid Epoch #7, Batch 4070/4160 loss = 1.5822368478775024, ppl = 4.921372669668512\n","Valid Epoch #7, Batch 4071/4160 loss = 1.581324065923691, ppl = 4.917105755585665\n","Valid Epoch #7, Batch 4072/4160 loss = 1.5841072857379914, ppl = 4.930463965091638\n","Valid Epoch #7, Batch 4073/4160 loss = 1.5866388881206512, ppl = 4.943037792184708\n","Valid Epoch #7, Batch 4074/4160 loss = 1.5874509000778199, ppl = 4.946762404626072\n","Valid Epoch #7, Batch 4075/4160 loss = 1.586071070432663, ppl = 4.940059450880283\n","Valid Epoch #7, Batch 4076/4160 loss = 1.5871030497550964, ppl = 4.946360850229279\n","Valid Epoch #7, Batch 4077/4160 loss = 1.5882352197170257, ppl = 4.952551350250441\n","Valid Epoch #7, Batch 4078/4160 loss = 1.5900854980945587, ppl = 4.9608732963337525\n","Valid Epoch #7, Batch 4079/4160 loss = 1.5911342668533326, ppl = 4.965665791342481\n","Valid Epoch #7, Batch 4080/4160 loss = 1.5924280095100403, ppl = 4.9712300506038325\n","Valid Epoch #7, Batch 4081/4160 loss = 1.5925691497325898, ppl = 4.9719160420849535\n","Valid Epoch #7, Batch 4082/4160 loss = 1.5912700402736664, ppl = 4.964898482854493\n","Valid Epoch #7, Batch 4083/4160 loss = 1.5910318422317504, ppl = 4.963727228498871\n","Valid Epoch #7, Batch 4084/4160 loss = 1.5896877121925355, ppl = 4.95721146755367\n","Valid Epoch #7, Batch 4085/4160 loss = 1.5884443068504333, ppl = 4.951686609376873\n","Valid Epoch #7, Batch 4086/4160 loss = 1.5870107173919679, ppl = 4.943747287510049\n","Valid Epoch #7, Batch 4087/4160 loss = 1.5868016636371614, ppl = 4.9425572439482215\n","Valid Epoch #7, Batch 4088/4160 loss = 1.5872824215888977, ppl = 4.9450407451094955\n","Valid Epoch #7, Batch 4089/4160 loss = 1.5866703379154206, ppl = 4.942062554598805\n","Valid Epoch #7, Batch 4090/4160 loss = 1.58549640417099, ppl = 4.936092887072267\n","Valid Epoch #7, Batch 4091/4160 loss = 1.5863701713085174, ppl = 4.939977767984069\n","Valid Epoch #7, Batch 4092/4160 loss = 1.5840321743488313, ppl = 4.926644170068963\n","Valid Epoch #7, Batch 4093/4160 loss = 1.5873633801937104, ppl = 4.943405567027809\n","Valid Epoch #7, Batch 4094/4160 loss = 1.5866063368320464, ppl = 4.939539139183943\n","Valid Epoch #7, Batch 4095/4160 loss = 1.587439523935318, ppl = 4.943736853975111\n","Valid Epoch #7, Batch 4096/4160 loss = 1.588287078142166, ppl = 4.948305140525947\n","Valid Epoch #7, Batch 4097/4160 loss = 1.5913748860359191, ppl = 4.964306387415777\n","Valid Epoch #7, Batch 4098/4160 loss = 1.5924596083164215, ppl = 4.969967588719538\n","Valid Epoch #7, Batch 4099/4160 loss = 1.5939592576026917, ppl = 4.976851508645629\n","Valid Epoch #7, Batch 4100/4160 loss = 1.5972016835212708, ppl = 4.993227567979218\n","Valid Epoch #7, Batch 4101/4160 loss = 1.5971961152553558, ppl = 4.993207030809388\n","Valid Epoch #7, Batch 4102/4160 loss = 1.5968059241771697, ppl = 4.991931714794877\n","Valid Epoch #7, Batch 4103/4160 loss = 1.5960267066955567, ppl = 4.9888293635830845\n","Valid Epoch #7, Batch 4104/4160 loss = 1.5988060569763183, ppl = 4.999844131600264\n","Valid Epoch #7, Batch 4105/4160 loss = 1.6004617428779602, ppl = 5.006051118966839\n","Valid Epoch #7, Batch 4106/4160 loss = 1.597138020992279, ppl = 4.9904565664374765\n","Valid Epoch #7, Batch 4107/4160 loss = 1.5967351651191712, ppl = 4.988757022899159\n","Valid Epoch #7, Batch 4108/4160 loss = 1.5945668840408325, ppl = 4.979688295046057\n","Valid Epoch #7, Batch 4109/4160 loss = 1.5950378203392028, ppl = 4.981830726414888\n","Valid Epoch #7, Batch 4110/4160 loss = 1.598310754299164, ppl = 4.996511349262896\n","Valid Epoch #7, Batch 4111/4160 loss = 1.6004073679447175, ppl = 5.005447701458923\n","Valid Epoch #7, Batch 4112/4160 loss = 1.6012356054782868, ppl = 5.009150107340605\n","Valid Epoch #7, Batch 4113/4160 loss = 1.6018301916122437, ppl = 5.01199580663106\n","Valid Epoch #7, Batch 4114/4160 loss = 1.6045419430732728, ppl = 5.024520618561151\n","Valid Epoch #7, Batch 4115/4160 loss = 1.6039277911186218, ppl = 5.021657895546307\n","Valid Epoch #7, Batch 4116/4160 loss = 1.6008793497085572, ppl = 5.006267101329229\n","Valid Epoch #7, Batch 4117/4160 loss = 1.60257932305336, ppl = 5.014920927280121\n","Valid Epoch #7, Batch 4118/4160 loss = 1.6042357897758484, ppl = 5.021618386798332\n","Valid Epoch #7, Batch 4119/4160 loss = 1.6039200699329377, ppl = 5.020093070118699\n","Valid Epoch #7, Batch 4120/4160 loss = 1.6026899337768554, ppl = 5.012841699732755\n","Valid Epoch #7, Batch 4121/4160 loss = 1.6009072244167328, ppl = 5.003341972155404\n","Valid Epoch #7, Batch 4122/4160 loss = 1.600392677783966, ppl = 5.000910117377092\n","Valid Epoch #7, Batch 4123/4160 loss = 1.5987324380874635, ppl = 4.993121771840476\n","Valid Epoch #7, Batch 4124/4160 loss = 1.5977357351779937, ppl = 4.987267477850487\n","Valid Epoch #7, Batch 4125/4160 loss = 1.5975782287120819, ppl = 4.986449216970076\n","Valid Epoch #7, Batch 4126/4160 loss = 1.5984956645965576, ppl = 4.991488776950673\n","Valid Epoch #7, Batch 4127/4160 loss = 1.6033327519893645, ppl = 5.015058833641459\n","Valid Epoch #7, Batch 4128/4160 loss = 1.6073044848442077, ppl = 5.036968728177591\n","Valid Epoch #7, Batch 4129/4160 loss = 1.6065803122520448, ppl = 5.033321534323086\n","Valid Epoch #7, Batch 4130/4160 loss = 1.6064537012577056, ppl = 5.032619903624039\n","Valid Epoch #7, Batch 4131/4160 loss = 1.6099616539478303, ppl = 5.048133241732753\n","Valid Epoch #7, Batch 4132/4160 loss = 1.6092832601070404, ppl = 5.044447216884549\n","Valid Epoch #7, Batch 4133/4160 loss = 1.6091425156593322, ppl = 5.043701599371263\n","Valid Epoch #7, Batch 4134/4160 loss = 1.6095070958137512, ppl = 5.045438861202141\n","Valid Epoch #7, Batch 4135/4160 loss = 1.6076355290412903, ppl = 5.0367496155292955\n","Valid Epoch #7, Batch 4136/4160 loss = 1.606134649515152, ppl = 5.028510058050859\n","Valid Epoch #7, Batch 4137/4160 loss = 1.6053507947921752, ppl = 5.023877098036606\n","Valid Epoch #7, Batch 4138/4160 loss = 1.6019702243804932, ppl = 5.005499124498499\n","Valid Epoch #7, Batch 4139/4160 loss = 1.5984087109565734, ppl = 4.986614630430872\n","Valid Epoch #7, Batch 4140/4160 loss = 1.5961431646347046, ppl = 4.974557930347294\n","Valid Epoch #7, Batch 4141/4160 loss = 1.5961327362060547, ppl = 4.974512895958632\n","Valid Epoch #7, Batch 4142/4160 loss = 1.5974530255794526, ppl = 4.981918261233239\n","Valid Epoch #7, Batch 4143/4160 loss = 1.59628653049469, ppl = 4.975425741228779\n","Valid Epoch #7, Batch 4144/4160 loss = 1.598019117116928, ppl = 4.983526453943639\n","Valid Epoch #7, Batch 4145/4160 loss = 1.599702695608139, ppl = 4.9917450586638825\n","Valid Epoch #7, Batch 4146/4160 loss = 1.5994150352478027, ppl = 4.9903067176014835\n","Valid Epoch #7, Batch 4147/4160 loss = 1.5984164941310883, ppl = 4.985537051019111\n","Valid Epoch #7, Batch 4148/4160 loss = 1.5986480188369752, ppl = 4.9866553460337135\n","Valid Epoch #7, Batch 4149/4160 loss = 1.5992867493629455, ppl = 4.989800528634597\n","Valid Epoch #7, Batch 4150/4160 loss = 1.59850417137146, ppl = 4.986025364341621\n","Valid Epoch #7, Batch 4151/4160 loss = 1.5970766520500184, ppl = 4.978646501846746\n","Valid Epoch #7, Batch 4152/4160 loss = 1.5962754774093628, ppl = 4.974496940814438\n","Valid Epoch #7, Batch 4153/4160 loss = 1.6013757371902466, ppl = 5.0004759392564795\n","Valid Epoch #7, Batch 4154/4160 loss = 1.6020334351062775, ppl = 5.003837112165649\n","Valid Epoch #7, Batch 4155/4160 loss = 1.6014983260631561, ppl = 5.001109701522316\n","Valid Epoch #7, Batch 4156/4160 loss = 1.6012209975719451, ppl = 4.999818895896816\n","Valid Epoch #7, Batch 4157/4160 loss = 1.599956612586975, ppl = 4.993515826736799\n","Valid Epoch #7, Batch 4158/4160 loss = 1.5970222330093384, ppl = 4.975832469791168\n","Valid Epoch #7, Batch 4159/4160 loss = 1.594310930967331, ppl = 4.96218312817244\n","Valid Epoch #7, Batch 4160/4160 loss = 1.593715467453003, ppl = 4.95946839806593\n","Train Epoch #8, Batch 1/24958 loss = 1.5462441408634187, ppl = 4.745801481263408\n","Train Epoch #8, Batch 2/24958 loss = 1.5432885324954986, ppl = 4.7294389676922775\n","Train Epoch #8, Batch 3/24958 loss = 1.5456431996822357, ppl = 4.740338912487025\n","Train Epoch #8, Batch 4/24958 loss = 1.5441992282867432, ppl = 4.7340630833465704\n","Train Epoch #8, Batch 5/24958 loss = 1.5438796854019166, ppl = 4.73268358507947\n","Train Epoch #8, Batch 6/24958 loss = 1.5435961520671844, ppl = 4.731575047715756\n","Train Epoch #8, Batch 7/24958 loss = 1.5453466141223908, ppl = 4.739448081245455\n","Train Epoch #8, Batch 8/24958 loss = 1.5456338894367219, ppl = 4.740735140099889\n","Train Epoch #8, Batch 9/24958 loss = 1.5414808416366577, ppl = 4.7215473884563774\n","Train Epoch #8, Batch 10/24958 loss = 1.5405276131629944, ppl = 4.7175093402073385\n","Train Epoch #8, Batch 11/24958 loss = 1.537947235107422, ppl = 4.706050282358245\n","Train Epoch #8, Batch 12/24958 loss = 1.5372055411338805, ppl = 4.702123761096984\n","Train Epoch #8, Batch 13/24958 loss = 1.5347044551372528, ppl = 4.689418554152655\n","Train Epoch #8, Batch 14/24958 loss = 1.5325247597694398, ppl = 4.678441836228906\n","Train Epoch #8, Batch 15/24958 loss = 1.5320694577693938, ppl = 4.676573035919403\n","Train Epoch #8, Batch 16/24958 loss = 1.5365107929706574, ppl = 4.695203087532789\n","Train Epoch #8, Batch 17/24958 loss = 1.5374735832214355, ppl = 4.6998476694572275\n","Train Epoch #8, Batch 18/24958 loss = 1.536693775653839, ppl = 4.696433501438462\n","Train Epoch #8, Batch 19/24958 loss = 1.5342775118350982, ppl = 4.685336414119011\n","Train Epoch #8, Batch 20/24958 loss = 1.5326268124580382, ppl = 4.678033953532431\n","Train Epoch #8, Batch 21/24958 loss = 1.5314028286933898, ppl = 4.671920624139087\n","Train Epoch #8, Batch 22/24958 loss = 1.534539920091629, ppl = 4.686009524398133\n","Train Epoch #8, Batch 23/24958 loss = 1.5329992485046386, ppl = 4.6781406642609635\n","Train Epoch #8, Batch 24/24958 loss = 1.5271464824676513, ppl = 4.648360404556785\n","Train Epoch #8, Batch 25/24958 loss = 1.525065907239914, ppl = 4.638850767158313\n","Train Epoch #8, Batch 26/24958 loss = 1.5267054104804993, ppl = 4.645068593375564\n","Train Epoch #8, Batch 27/24958 loss = 1.52258127450943, ppl = 4.627171734740833\n","Train Epoch #8, Batch 28/24958 loss = 1.521609902381897, ppl = 4.623056316978045\n","Train Epoch #8, Batch 29/24958 loss = 1.5191151952743531, ppl = 4.612639889775416\n","Train Epoch #8, Batch 30/24958 loss = 1.5180098593235016, ppl = 4.60765954141161\n","Train Epoch #8, Batch 31/24958 loss = 1.5187223660945892, ppl = 4.610971541537556\n","Train Epoch #8, Batch 32/24958 loss = 1.5237068355083465, ppl = 4.63190299847194\n","Train Epoch #8, Batch 33/24958 loss = 1.5213559782505035, ppl = 4.6218129082264925\n","Train Epoch #8, Batch 34/24958 loss = 1.5155391335487365, ppl = 4.58961899976151\n","Train Epoch #8, Batch 35/24958 loss = 1.5132385385036469, ppl = 4.5807126543339045\n","Train Epoch #8, Batch 36/24958 loss = 1.5144460940361022, ppl = 4.585357250863269\n","Train Epoch #8, Batch 37/24958 loss = 1.5117691814899445, ppl = 4.572956772812486\n","Train Epoch #8, Batch 38/24958 loss = 1.5126558899879456, ppl = 4.577469725589908\n","Train Epoch #8, Batch 39/24958 loss = 1.5094335770606995, ppl = 4.564002757388464\n","Train Epoch #8, Batch 40/24958 loss = 1.5092402911186218, ppl = 4.563171663214487\n","Train Epoch #8, Batch 41/24958 loss = 1.5083574783802032, ppl = 4.559618170905583\n","Train Epoch #8, Batch 42/24958 loss = 1.505585709810257, ppl = 4.546841860154684\n","Train Epoch #8, Batch 43/24958 loss = 1.5051481056213378, ppl = 4.544998497277166\n","Train Epoch #8, Batch 44/24958 loss = 1.5019105219841002, ppl = 4.529861450902513\n","Train Epoch #8, Batch 45/24958 loss = 1.499012668132782, ppl = 4.517432185093116\n","Train Epoch #8, Batch 46/24958 loss = 1.4943476915359497, ppl = 4.497668121922971\n","Train Epoch #8, Batch 47/24958 loss = 1.4943794977664948, ppl = 4.497819805169687\n","Train Epoch #8, Batch 48/24958 loss = 1.4948887538909912, ppl = 4.500409212800012\n","Train Epoch #8, Batch 49/24958 loss = 1.4952534580230712, ppl = 4.502177961315608\n","Train Epoch #8, Batch 50/24958 loss = 1.4932694578170775, ppl = 4.494084777270244\n","Train Epoch #8, Batch 51/24958 loss = 1.4949096095561982, ppl = 4.502711878286406\n","Train Epoch #8, Batch 52/24958 loss = 1.49523335814476, ppl = 4.504058603089215\n","Train Epoch #8, Batch 53/24958 loss = 1.4944818115234375, ppl = 4.500495416713598\n","Train Epoch #8, Batch 54/24958 loss = 1.4915279948711395, ppl = 4.48590626890589\n","Train Epoch #8, Batch 55/24958 loss = 1.4902355372905731, ppl = 4.479855811425415\n","Train Epoch #8, Batch 56/24958 loss = 1.494473818540573, ppl = 4.4950168619146735\n","Train Epoch #8, Batch 57/24958 loss = 1.4904536485671998, ppl = 4.476634961751014\n","Train Epoch #8, Batch 58/24958 loss = 1.4926239919662476, ppl = 4.485397871281823\n","Train Epoch #8, Batch 59/24958 loss = 1.4925775456428527, ppl = 4.485220316940151\n","Train Epoch #8, Batch 60/24958 loss = 1.4915419661998748, ppl = 4.480653935584569\n","Train Epoch #8, Batch 61/24958 loss = 1.488461022377014, ppl = 4.465601126699997\n","Train Epoch #8, Batch 62/24958 loss = 1.489877119064331, ppl = 4.472128043459129\n","Train Epoch #8, Batch 63/24958 loss = 1.4880772709846497, ppl = 4.463235342735752\n","Train Epoch #8, Batch 64/24958 loss = 1.4902571833133698, ppl = 4.471755504338355\n","Train Epoch #8, Batch 65/24958 loss = 1.4886436200141906, ppl = 4.4651152971067525\n","Train Epoch #8, Batch 66/24958 loss = 1.486426796913147, ppl = 4.456356556169149\n","Train Epoch #8, Batch 67/24958 loss = 1.4830030655860902, ppl = 4.44274904666598\n","Train Epoch #8, Batch 68/24958 loss = 1.480574245452881, ppl = 4.432238244773211\n","Train Epoch #8, Batch 69/24958 loss = 1.4783165788650512, ppl = 4.4228187244785735\n","Train Epoch #8, Batch 70/24958 loss = 1.4779652118682862, ppl = 4.420885931594197\n","Train Epoch #8, Batch 71/24958 loss = 1.4767487108707429, ppl = 4.415493164741971\n","Train Epoch #8, Batch 72/24958 loss = 1.474290783405304, ppl = 4.405753305173244\n","Train Epoch #8, Batch 73/24958 loss = 1.4729333448410034, ppl = 4.398633225733746\n","Train Epoch #8, Batch 74/24958 loss = 1.4719618546962738, ppl = 4.39397625322951\n","Train Epoch #8, Batch 75/24958 loss = 1.4699906587600708, ppl = 4.385159397697473\n","Train Epoch #8, Batch 76/24958 loss = 1.4661668717861176, ppl = 4.368997471725436\n","Train Epoch #8, Batch 77/24958 loss = 1.4650617682933806, ppl = 4.363890858875803\n","Train Epoch #8, Batch 78/24958 loss = 1.463023192882538, ppl = 4.35418478040422\n","Train Epoch #8, Batch 79/24958 loss = 1.4593499326705932, ppl = 4.336617276695187\n","Train Epoch #8, Batch 80/24958 loss = 1.4577991366386414, ppl = 4.329508260904309\n","Train Epoch #8, Batch 81/24958 loss = 1.4548788285255432, ppl = 4.317235174772796\n","Train Epoch #8, Batch 82/24958 loss = 1.4525113165378571, ppl = 4.30717607739955\n","Train Epoch #8, Batch 83/24958 loss = 1.450015059709549, ppl = 4.296836575297938\n","Train Epoch #8, Batch 84/24958 loss = 1.4492716300487518, ppl = 4.293305876533459\n","Train Epoch #8, Batch 85/24958 loss = 1.4504279029369354, ppl = 4.298023246697783\n","Train Epoch #8, Batch 86/24958 loss = 1.4503554129600524, ppl = 4.297685172785531\n","Train Epoch #8, Batch 87/24958 loss = 1.450623642206192, ppl = 4.298886501941756\n","Train Epoch #8, Batch 88/24958 loss = 1.4489388728141785, ppl = 4.291975843476344\n","Train Epoch #8, Batch 89/24958 loss = 1.4481882524490357, ppl = 4.28841179957519\n","Train Epoch #8, Batch 90/24958 loss = 1.447360533475876, ppl = 4.284913915448665\n","Train Epoch #8, Batch 91/24958 loss = 1.4484509491920472, ppl = 4.2893003047200695\n","Train Epoch #8, Batch 92/24958 loss = 1.4467443323135376, ppl = 4.282570495712922\n","Train Epoch #8, Batch 93/24958 loss = 1.4430967020988463, ppl = 4.266071764655102\n","Train Epoch #8, Batch 94/24958 loss = 1.4443557620048524, ppl = 4.271021031313285\n","Train Epoch #8, Batch 95/24958 loss = 1.4429996597766876, ppl = 4.264611402318941\n","Train Epoch #8, Batch 96/24958 loss = 1.4426194024085999, ppl = 4.262886807509605\n","Train Epoch #8, Batch 97/24958 loss = 1.439145529270172, ppl = 4.247833156622523\n","Train Epoch #8, Batch 98/24958 loss = 1.439423716068268, ppl = 4.249021432922209\n","Train Epoch #8, Batch 99/24958 loss = 1.4379437804222106, ppl = 4.242409067300645\n","Train Epoch #8, Batch 100/24958 loss = 1.438526132106781, ppl = 4.245143724751746\n","Train Epoch #8, Batch 101/24958 loss = 1.4386594367027283, ppl = 4.245727124754075\n","Train Epoch #8, Batch 102/24958 loss = 1.4362035930156707, ppl = 4.235366000572967\n","Train Epoch #8, Batch 103/24958 loss = 1.4328531002998353, ppl = 4.220574712079713\n","Train Epoch #8, Batch 104/24958 loss = 1.4351162564754487, ppl = 4.230835119807903\n","Train Epoch #8, Batch 105/24958 loss = 1.4370212972164154, ppl = 4.239750974270514\n","Train Epoch #8, Batch 106/24958 loss = 1.4375984728336335, ppl = 4.2420411894061\n","Train Epoch #8, Batch 107/24958 loss = 1.43709135055542, ppl = 4.2396168519185595\n","Train Epoch #8, Batch 108/24958 loss = 1.4372707629203796, ppl = 4.240439619846829\n","Train Epoch #8, Batch 109/24958 loss = 1.4367282259464265, ppl = 4.23847146251056\n","Train Epoch #8, Batch 110/24958 loss = 1.4365624070167542, ppl = 4.237807491126508\n","Train Epoch #8, Batch 111/24958 loss = 1.4371749401092528, ppl = 4.240266316065575\n","Train Epoch #8, Batch 112/24958 loss = 1.4373236274719239, ppl = 4.241030300914454\n","Train Epoch #8, Batch 113/24958 loss = 1.4364919483661651, ppl = 4.237462237005386\n","Train Epoch #8, Batch 114/24958 loss = 1.4353143990039825, ppl = 4.232455604957667\n","Train Epoch #8, Batch 115/24958 loss = 1.4347090756893157, ppl = 4.23009920858003\n","Train Epoch #8, Batch 116/24958 loss = 1.4301326727867127, ppl = 4.211022147831824\n","Train Epoch #8, Batch 117/24958 loss = 1.4297451436519624, ppl = 4.209098744397012\n","Train Epoch #8, Batch 118/24958 loss = 1.4313166093826295, ppl = 4.21626231826925\n","Train Epoch #8, Batch 119/24958 loss = 1.4316760659217835, ppl = 4.217748306780797\n","Train Epoch #8, Batch 120/24958 loss = 1.4287773704528808, ppl = 4.207509686855156\n","Train Epoch #8, Batch 121/24958 loss = 1.427658931016922, ppl = 4.202541421192135\n","Train Epoch #8, Batch 122/24958 loss = 1.4249731254577638, ppl = 4.190217491886849\n","Train Epoch #8, Batch 123/24958 loss = 1.4243963730335236, ppl = 4.18756995115379\n","Train Epoch #8, Batch 124/24958 loss = 1.425604430437088, ppl = 4.192377009028763\n","Train Epoch #8, Batch 125/24958 loss = 1.4263221049308776, ppl = 4.195436316958035\n","Train Epoch #8, Batch 126/24958 loss = 1.4254240989685059, ppl = 4.191904757280658\n","Train Epoch #8, Batch 127/24958 loss = 1.4264745616912842, ppl = 4.195788109056181\n","Train Epoch #8, Batch 128/24958 loss = 1.4273112678527833, ppl = 4.199308841063684\n","Train Epoch #8, Batch 129/24958 loss = 1.4298895621299743, ppl = 4.210121273972399\n","Train Epoch #8, Batch 130/24958 loss = 1.426675844192505, ppl = 4.198409238996789\n","Train Epoch #8, Batch 131/24958 loss = 1.4249645578861236, ppl = 4.190834394159947\n","Train Epoch #8, Batch 132/24958 loss = 1.4242399513721467, ppl = 4.187107106230393\n","Train Epoch #8, Batch 133/24958 loss = 1.425458528995514, ppl = 4.192041160534849\n","Train Epoch #8, Batch 134/24958 loss = 1.4225782370567321, ppl = 4.1818303219066895\n","Train Epoch #8, Batch 135/24958 loss = 1.4248831427097322, ppl = 4.1907553522412435\n","Train Epoch #8, Batch 136/24958 loss = 1.4244948184490205, ppl = 4.189200145116322\n","Train Epoch #8, Batch 137/24958 loss = 1.423439885377884, ppl = 4.185155330830117\n","Train Epoch #8, Batch 138/24958 loss = 1.4227800858020783, ppl = 4.181759424354178\n","Train Epoch #8, Batch 139/24958 loss = 1.4271646642684936, ppl = 4.201251773577076\n","Train Epoch #8, Batch 140/24958 loss = 1.4291800963878631, ppl = 4.210760307819258\n","Train Epoch #8, Batch 141/24958 loss = 1.4296945929527283, ppl = 4.212793031107821\n","Train Epoch #8, Batch 142/24958 loss = 1.43110941529274, ppl = 4.218872386288867\n","Train Epoch #8, Batch 143/24958 loss = 1.4301145327091218, ppl = 4.214969916212115\n","Train Epoch #8, Batch 144/24958 loss = 1.4295151507854462, ppl = 4.2126664861625525\n","Train Epoch #8, Batch 145/24958 loss = 1.430076777935028, ppl = 4.214802603587184\n","Train Epoch #8, Batch 146/24958 loss = 1.4347362411022186, ppl = 4.234537445647007\n","Train Epoch #8, Batch 147/24958 loss = 1.4313623690605164, ppl = 4.220858907839074\n","Train Epoch #8, Batch 148/24958 loss = 1.4283583927154542, ppl = 4.207326556035171\n","Train Epoch #8, Batch 149/24958 loss = 1.4255935072898864, ppl = 4.195396522748948\n","Train Epoch #8, Batch 150/24958 loss = 1.427128827571869, ppl = 4.201516476519349\n","Train Epoch #8, Batch 151/24958 loss = 1.4222311556339264, ppl = 4.17943237696623\n","Train Epoch #8, Batch 152/24958 loss = 1.4220188522338868, ppl = 4.178544327585705\n","Train Epoch #8, Batch 153/24958 loss = 1.4213462042808533, ppl = 4.175574548713162\n","Train Epoch #8, Batch 154/24958 loss = 1.420916954278946, ppl = 4.173790733032714\n","Train Epoch #8, Batch 155/24958 loss = 1.4196687591075898, ppl = 4.168644795667612\n","Train Epoch #8, Batch 156/24958 loss = 1.4177080070972443, ppl = 4.160830894491753\n","Train Epoch #8, Batch 157/24958 loss = 1.4194827854633332, ppl = 4.1680449793531205\n","Train Epoch #8, Batch 158/24958 loss = 1.4181449973583222, ppl = 4.162420819226035\n","Train Epoch #8, Batch 159/24958 loss = 1.4164590644836426, ppl = 4.156503623575107\n","Train Epoch #8, Batch 160/24958 loss = 1.417755868434906, ppl = 4.162298520660347\n","Train Epoch #8, Batch 161/24958 loss = 1.417816903591156, ppl = 4.162553921136495\n","Train Epoch #8, Batch 162/24958 loss = 1.4170179736614228, ppl = 4.1587583411822555\n","Train Epoch #8, Batch 163/24958 loss = 1.4164565551280974, ppl = 4.156296379361644\n","Train Epoch #8, Batch 164/24958 loss = 1.4151206040382385, ppl = 4.15085650212929\n","Train Epoch #8, Batch 165/24958 loss = 1.4163425958156586, ppl = 4.1557855177120215\n","Train Epoch #8, Batch 166/24958 loss = 1.4169771587848663, ppl = 4.158097640952502\n","Train Epoch #8, Batch 167/24958 loss = 1.4181772899627685, ppl = 4.1623474003183905\n","Train Epoch #8, Batch 168/24958 loss = 1.4178184485435485, ppl = 4.1609997845132085\n","Train Epoch #8, Batch 169/24958 loss = 1.4213669180870057, ppl = 4.176841189136232\n","Train Epoch #8, Batch 170/24958 loss = 1.4187594509124757, ppl = 4.164436091232435\n","Train Epoch #8, Batch 171/24958 loss = 1.4193954956531525, ppl = 4.167173803728429\n","Train Epoch #8, Batch 172/24958 loss = 1.419174016714096, ppl = 4.166408119514378\n","Train Epoch #8, Batch 173/24958 loss = 1.416386206150055, ppl = 4.154493311495943\n","Train Epoch #8, Batch 174/24958 loss = 1.4155594098567963, ppl = 4.1508711532246965\n","Train Epoch #8, Batch 175/24958 loss = 1.4178512704372406, ppl = 4.16129390631268\n","Train Epoch #8, Batch 176/24958 loss = 1.4194018614292145, ppl = 4.167113963387129\n","Train Epoch #8, Batch 177/24958 loss = 1.4188778162002564, ppl = 4.164882699371533\n","Train Epoch #8, Batch 178/24958 loss = 1.4175031089782715, ppl = 4.159369560834263\n","Train Epoch #8, Batch 179/24958 loss = 1.4199210047721862, ppl = 4.170195225479736\n","Train Epoch #8, Batch 180/24958 loss = 1.4188969111442566, ppl = 4.1660701100925\n","Train Epoch #8, Batch 181/24958 loss = 1.423325846195221, ppl = 4.186234517114334\n","Train Epoch #8, Batch 182/24958 loss = 1.424253786802292, ppl = 4.189896102026127\n","Train Epoch #8, Batch 183/24958 loss = 1.4284423732757567, ppl = 4.2088661933478955\n","Train Epoch #8, Batch 184/24958 loss = 1.4269067740440369, ppl = 4.202353857363152\n","Train Epoch #8, Batch 185/24958 loss = 1.4252031791210173, ppl = 4.195586733148074\n","Train Epoch #8, Batch 186/24958 loss = 1.4242144346237182, ppl = 4.191212022794513\n","Train Epoch #8, Batch 187/24958 loss = 1.4237491512298583, ppl = 4.189148446074472\n","Train Epoch #8, Batch 188/24958 loss = 1.426606764793396, ppl = 4.201605450367527\n","Train Epoch #8, Batch 189/24958 loss = 1.4270781660079956, ppl = 4.203812380030047\n","Train Epoch #8, Batch 190/24958 loss = 1.4265766942501068, ppl = 4.201829814673334\n","Train Epoch #8, Batch 191/24958 loss = 1.4284856295585633, ppl = 4.210760410449173\n","Train Epoch #8, Batch 192/24958 loss = 1.4290979719161987, ppl = 4.213044115807653\n","Train Epoch #8, Batch 193/24958 loss = 1.4308015525341033, ppl = 4.22000569834178\n","Train Epoch #8, Batch 194/24958 loss = 1.4320455265045167, ppl = 4.225547508074292\n","Train Epoch #8, Batch 195/24958 loss = 1.4340014827251435, ppl = 4.2350817156184055\n","Train Epoch #8, Batch 196/24958 loss = 1.433101280927658, ppl = 4.231251131885407\n","Train Epoch #8, Batch 197/24958 loss = 1.4353403806686402, ppl = 4.2403463657345295\n","Train Epoch #8, Batch 198/24958 loss = 1.4343192756175995, ppl = 4.236142065387435\n","Train Epoch #8, Batch 199/24958 loss = 1.4323766267299651, ppl = 4.2288226853600825\n","Train Epoch #8, Batch 200/24958 loss = 1.4308339715003968, ppl = 4.221912289425998\n","Train Epoch #8, Batch 201/24958 loss = 1.4289881491661072, ppl = 4.214486587922162\n","Train Epoch #8, Batch 202/24958 loss = 1.4300776493549348, ppl = 4.21877096456593\n","Train Epoch #8, Batch 203/24958 loss = 1.4322616684436797, ppl = 4.227842011906011\n","Train Epoch #8, Batch 204/24958 loss = 1.431661044359207, ppl = 4.224888810260133\n","Train Epoch #8, Batch 205/24958 loss = 1.4297697150707245, ppl = 4.216031248740622\n","Train Epoch #8, Batch 206/24958 loss = 1.4299283289909364, ppl = 4.216684125700162\n","Train Epoch #8, Batch 207/24958 loss = 1.428231543302536, ppl = 4.2094109437461045\n","Train Epoch #8, Batch 208/24958 loss = 1.424830218553543, ppl = 4.196069716339562\n","Train Epoch #8, Batch 209/24958 loss = 1.4282789885997773, ppl = 4.210607548876452\n","Train Epoch #8, Batch 210/24958 loss = 1.4270702195167542, ppl = 4.206086187811113\n","Train Epoch #8, Batch 211/24958 loss = 1.4284438681602478, ppl = 4.212179825165753\n","Train Epoch #8, Batch 212/24958 loss = 1.426609069108963, ppl = 4.203502402352489\n","Train Epoch #8, Batch 213/24958 loss = 1.4268543195724488, ppl = 4.20452390209181\n","Train Epoch #8, Batch 214/24958 loss = 1.42720019698143, ppl = 4.2059338399841035\n","Train Epoch #8, Batch 215/24958 loss = 1.4274035668373108, ppl = 4.20670965896071\n","Train Epoch #8, Batch 216/24958 loss = 1.427659935951233, ppl = 4.207563295920662\n","Train Epoch #8, Batch 217/24958 loss = 1.4246589016914368, ppl = 4.194943376166651\n","Train Epoch #8, Batch 218/24958 loss = 1.42499085187912, ppl = 4.1966060346739855\n","Train Epoch #8, Batch 219/24958 loss = 1.4254070115089417, ppl = 4.198394494796526\n","Train Epoch #8, Batch 220/24958 loss = 1.4284276401996612, ppl = 4.20913227070397\n","Train Epoch #8, Batch 221/24958 loss = 1.428753399848938, ppl = 4.210522446336173\n","Train Epoch #8, Batch 222/24958 loss = 1.426907458305359, ppl = 4.203780290031002\n","Train Epoch #8, Batch 223/24958 loss = 1.4260755848884583, ppl = 4.200220801717755\n","Train Epoch #8, Batch 224/24958 loss = 1.4246732187271118, ppl = 4.194693341797396\n","Train Epoch #8, Batch 225/24958 loss = 1.4216386580467224, ppl = 4.183130812893221\n","Train Epoch #8, Batch 226/24958 loss = 1.4226291799545288, ppl = 4.187044553017175\n","Train Epoch #8, Batch 227/24958 loss = 1.422680172920227, ppl = 4.18724364555102\n","Train Epoch #8, Batch 228/24958 loss = 1.4238631534576416, ppl = 4.192751989783151\n","Train Epoch #8, Batch 229/24958 loss = 1.4225603532791138, ppl = 4.186940726042187\n","Train Epoch #8, Batch 230/24958 loss = 1.4245873260498048, ppl = 4.1938842285162306\n","Train Epoch #8, Batch 231/24958 loss = 1.4258880126476288, ppl = 4.199521694923392\n","Train Epoch #8, Batch 232/24958 loss = 1.4222638559341432, ppl = 4.1844436633028455\n","Train Epoch #8, Batch 233/24958 loss = 1.4231592226028442, ppl = 4.188472055551355\n","Train Epoch #8, Batch 234/24958 loss = 1.4262229788303376, ppl = 4.199438353298173\n","Train Epoch #8, Batch 235/24958 loss = 1.425426608324051, ppl = 4.196119538811306\n","Train Epoch #8, Batch 236/24958 loss = 1.4266299319267273, ppl = 4.201141904572913\n","Train Epoch #8, Batch 237/24958 loss = 1.4277940213680267, ppl = 4.205630124728021\n","Train Epoch #8, Batch 238/24958 loss = 1.4260002100467681, ppl = 4.197454060220791\n","Train Epoch #8, Batch 239/24958 loss = 1.4224632644653321, ppl = 4.1810949758320435\n","Train Epoch #8, Batch 240/24958 loss = 1.420902202129364, ppl = 4.173565959214523\n","Train Epoch #8, Batch 241/24958 loss = 1.421310110092163, ppl = 4.175253560843543\n","Train Epoch #8, Batch 242/24958 loss = 1.4209177005290985, ppl = 4.17348034213959\n","Train Epoch #8, Batch 243/24958 loss = 1.4219405817985535, ppl = 4.177498353724871\n","Train Epoch #8, Batch 244/24958 loss = 1.424972537755966, ppl = 4.190705657092716\n","Train Epoch #8, Batch 245/24958 loss = 1.4253297853469848, ppl = 4.192128200302862\n","Train Epoch #8, Batch 246/24958 loss = 1.4226957499980926, ppl = 4.1798584939032555\n","Train Epoch #8, Batch 247/24958 loss = 1.423120150566101, ppl = 4.1813362909118545\n","Train Epoch #8, Batch 248/24958 loss = 1.4234058713912965, ppl = 4.18245566583304\n","Train Epoch #8, Batch 249/24958 loss = 1.4225420582294463, ppl = 4.179355815641014\n","Train Epoch #8, Batch 250/24958 loss = 1.4218848419189454, ppl = 4.1766206919976785\n","Train Epoch #8, Batch 251/24958 loss = 1.4248011553287505, ppl = 4.188453981335298\n","Train Epoch #8, Batch 252/24958 loss = 1.424407320022583, ppl = 4.186855702350549\n","Train Epoch #8, Batch 253/24958 loss = 1.4254787421226502, ppl = 4.191682754553056\n","Train Epoch #8, Batch 254/24958 loss = 1.4267632722854615, ppl = 4.197257452599665\n","Train Epoch #8, Batch 255/24958 loss = 1.426554056406021, ppl = 4.196456041427637\n","Train Epoch #8, Batch 256/24958 loss = 1.4272458362579346, ppl = 4.199039781954585\n","Train Epoch #8, Batch 257/24958 loss = 1.4280628418922425, ppl = 4.202816312441742\n","Train Epoch #8, Batch 258/24958 loss = 1.4305042099952698, ppl = 4.213681112958542\n","Train Epoch #8, Batch 259/24958 loss = 1.4337413942813872, ppl = 4.225998213841589\n","Train Epoch #8, Batch 260/24958 loss = 1.4311547875404358, ppl = 4.215138963559404\n","Train Epoch #8, Batch 261/24958 loss = 1.4304629957675934, ppl = 4.212333489531875\n","Train Epoch #8, Batch 262/24958 loss = 1.4291213464736938, ppl = 4.206603727933359\n","Train Epoch #8, Batch 263/24958 loss = 1.429428017139435, ppl = 4.207931412811488\n","Train Epoch #8, Batch 264/24958 loss = 1.4310673260688782, ppl = 4.2147111044414265\n","Train Epoch #8, Batch 265/24958 loss = 1.429371691942215, ppl = 4.208027834276015\n","Train Epoch #8, Batch 266/24958 loss = 1.4309005272388458, ppl = 4.2142397357881665\n","Train Epoch #8, Batch 267/24958 loss = 1.4303230547904968, ppl = 4.212131168364609\n","Train Epoch #8, Batch 268/24958 loss = 1.429824779033661, ppl = 4.210338322927055\n","Train Epoch #8, Batch 269/24958 loss = 1.4273026490211487, ppl = 4.198516591586681\n","Train Epoch #8, Batch 270/24958 loss = 1.4272335648536683, ppl = 4.19822990289581\n","Train Epoch #8, Batch 271/24958 loss = 1.4251073598861694, ppl = 4.189720650072321\n","Train Epoch #8, Batch 272/24958 loss = 1.4257417345046997, ppl = 4.19195985023334\n","Train Epoch #8, Batch 273/24958 loss = 1.4285544419288636, ppl = 4.203996737033455\n","Train Epoch #8, Batch 274/24958 loss = 1.4305471456050873, ppl = 4.213263405020482\n","Train Epoch #8, Batch 275/24958 loss = 1.4297669541835785, ppl = 4.209444129688778\n","Train Epoch #8, Batch 276/24958 loss = 1.4291345036029817, ppl = 4.2069608185542675\n","Train Epoch #8, Batch 277/24958 loss = 1.4317000532150268, ppl = 4.21909007075477\n","Train Epoch #8, Batch 278/24958 loss = 1.4317824518680573, ppl = 4.219399603064223\n","Train Epoch #8, Batch 279/24958 loss = 1.4299005854129792, ppl = 4.21075333335879\n","Train Epoch #8, Batch 280/24958 loss = 1.430069991350174, ppl = 4.211406886920355\n","Train Epoch #8, Batch 281/24958 loss = 1.4253975999355317, ppl = 4.190372088567489\n","Train Epoch #8, Batch 282/24958 loss = 1.4262166929244995, ppl = 4.19389891498039\n","Train Epoch #8, Batch 283/24958 loss = 1.4227887201309204, ppl = 4.177810619152357\n","Train Epoch #8, Batch 284/24958 loss = 1.4237724840641022, ppl = 4.181866781683038\n","Train Epoch #8, Batch 285/24958 loss = 1.4248796153068541, ppl = 4.186132396199472\n","Train Epoch #8, Batch 286/24958 loss = 1.423854627609253, ppl = 4.182031588134618\n","Train Epoch #8, Batch 287/24958 loss = 1.423850804567337, ppl = 4.182015027139148\n","Train Epoch #8, Batch 288/24958 loss = 1.4217968273162842, ppl = 4.172709457487685\n","Train Epoch #8, Batch 289/24958 loss = 1.42093954205513, ppl = 4.168771812497434\n","Train Epoch #8, Batch 290/24958 loss = 1.4240005683898926, ppl = 4.182578097402865\n","Train Epoch #8, Batch 291/24958 loss = 1.4223324286937713, ppl = 4.17468232416718\n","Train Epoch #8, Batch 292/24958 loss = 1.423534197807312, ppl = 4.179592004332574\n","Train Epoch #8, Batch 293/24958 loss = 1.4239358627796173, ppl = 4.181413500350581\n","Train Epoch #8, Batch 294/24958 loss = 1.4236898922920227, ppl = 4.18026236696355\n","Train Epoch #8, Batch 295/24958 loss = 1.4191828513145446, ppl = 4.160790910620797\n","Train Epoch #8, Batch 296/24958 loss = 1.4189442014694214, ppl = 4.1598319073955174\n","Train Epoch #8, Batch 297/24958 loss = 1.418024218082428, ppl = 4.155847066819844\n","Train Epoch #8, Batch 298/24958 loss = 1.41834370136261, ppl = 4.15711666336585\n","Train Epoch #8, Batch 299/24958 loss = 1.4215945315361023, ppl = 4.170229873223864\n","Train Epoch #8, Batch 300/24958 loss = 1.4231333565711974, ppl = 4.177121757748228\n","Train Epoch #8, Batch 301/24958 loss = 1.4251095592975616, ppl = 4.185125634231472\n","Train Epoch #8, Batch 302/24958 loss = 1.42461133480072, ppl = 4.1831084064491595\n","Train Epoch #8, Batch 303/24958 loss = 1.4247687864303589, ppl = 4.1838421329981905\n","Train Epoch #8, Batch 304/24958 loss = 1.4253299224376679, ppl = 4.1865956814495755\n","Train Epoch #8, Batch 305/24958 loss = 1.4247136640548705, ppl = 4.1840530705437855\n","Train Epoch #8, Batch 306/24958 loss = 1.4269980227947234, ppl = 4.194700435659916\n","Train Epoch #8, Batch 307/24958 loss = 1.4275747334957123, ppl = 4.197035359244078\n","Train Epoch #8, Batch 308/24958 loss = 1.4291555571556092, ppl = 4.202675112248652\n","Train Epoch #8, Batch 309/24958 loss = 1.4286737024784089, ppl = 4.200330510409505\n","Train Epoch #8, Batch 310/24958 loss = 1.429409269094467, ppl = 4.2030165099417385\n","Train Epoch #8, Batch 311/24958 loss = 1.4292636620998382, ppl = 4.202330212769978\n","Train Epoch #8, Batch 312/24958 loss = 1.427754474878311, ppl = 4.196294414829169\n","Train Epoch #8, Batch 313/24958 loss = 1.4271975362300873, ppl = 4.1940103269963735\n","Train Epoch #8, Batch 314/24958 loss = 1.425915344953537, ppl = 4.189019475910776\n","Train Epoch #8, Batch 315/24958 loss = 1.4264392125606538, ppl = 4.191092141795289\n","Train Epoch #8, Batch 316/24958 loss = 1.4297953689098357, ppl = 4.204542044208444\n","Train Epoch #8, Batch 317/24958 loss = 1.4314338445663453, ppl = 4.210961455909348\n","Train Epoch #8, Batch 318/24958 loss = 1.4284266531467438, ppl = 4.197735887712026\n","Train Epoch #8, Batch 319/24958 loss = 1.4296070277690887, ppl = 4.2032329192912306\n","Train Epoch #8, Batch 320/24958 loss = 1.4303246986865998, ppl = 4.206297435041471\n","Train Epoch #8, Batch 321/24958 loss = 1.4296229708194732, ppl = 4.203358114425354\n","Train Epoch #8, Batch 322/24958 loss = 1.4318809521198272, ppl = 4.211782811997764\n","Train Epoch #8, Batch 323/24958 loss = 1.4328228509426117, ppl = 4.215835648287506\n","Train Epoch #8, Batch 324/24958 loss = 1.435816923379898, ppl = 4.228651724862761\n","Train Epoch #8, Batch 325/24958 loss = 1.4380256128311157, ppl = 4.236712474450809\n","Train Epoch #8, Batch 326/24958 loss = 1.4386375117301942, ppl = 4.239331223729753\n","Train Epoch #8, Batch 327/24958 loss = 1.4394356143474578, ppl = 4.242583265393172\n","Train Epoch #8, Batch 328/24958 loss = 1.438265471458435, ppl = 4.237131267595756\n","Train Epoch #8, Batch 329/24958 loss = 1.4394808030128479, ppl = 4.2425282170068215\n","Train Epoch #8, Batch 330/24958 loss = 1.4415093314647676, ppl = 4.2510391469246525\n","Train Epoch #8, Batch 331/24958 loss = 1.4394381392002105, ppl = 4.242392050574733\n","Train Epoch #8, Batch 332/24958 loss = 1.4412835550308227, ppl = 4.249388037091581\n","Train Epoch #8, Batch 333/24958 loss = 1.4420816898345947, ppl = 4.253296006918389\n","Train Epoch #8, Batch 334/24958 loss = 1.4435540235042572, ppl = 4.25988785173118\n","Train Epoch #8, Batch 335/24958 loss = 1.4440330839157105, ppl = 4.261852544120155\n","Train Epoch #8, Batch 336/24958 loss = 1.4426542973518373, ppl = 4.2561470300967335\n","Train Epoch #8, Batch 337/24958 loss = 1.4430155527591706, ppl = 4.257649490480285\n","Train Epoch #8, Batch 338/24958 loss = 1.4426870000362397, ppl = 4.256304486757466\n","Train Epoch #8, Batch 339/24958 loss = 1.4434886801242828, ppl = 4.259522524007227\n","Train Epoch #8, Batch 340/24958 loss = 1.4399567103385926, ppl = 4.246262162390872\n","Train Epoch #8, Batch 341/24958 loss = 1.4378638410568236, ppl = 4.238289128792365\n","Train Epoch #8, Batch 342/24958 loss = 1.4351356303691865, ppl = 4.227709866118427\n","Train Epoch #8, Batch 343/24958 loss = 1.4339161276817323, ppl = 4.2229654922276\n","Train Epoch #8, Batch 344/24958 loss = 1.4335253095626832, ppl = 4.221030037749594\n","Train Epoch #8, Batch 345/24958 loss = 1.4342722833156585, ppl = 4.2241738545521645\n","Train Epoch #8, Batch 346/24958 loss = 1.436406099796295, ppl = 4.233858335748046\n","Train Epoch #8, Batch 347/24958 loss = 1.437457593679428, ppl = 4.237801652640108\n","Train Epoch #8, Batch 348/24958 loss = 1.4387403178215026, ppl = 4.243240516943988\n","Train Epoch #8, Batch 349/24958 loss = 1.4413427519798279, ppl = 4.253453301305244\n","Train Epoch #8, Batch 350/24958 loss = 1.4418777859210967, ppl = 4.255666245433425\n","Train Epoch #8, Batch 351/24958 loss = 1.4418128883838655, ppl = 4.255363637677177\n","Train Epoch #8, Batch 352/24958 loss = 1.4459717786312103, ppl = 4.275883282880162\n","Train Epoch #8, Batch 353/24958 loss = 1.4432236659526825, ppl = 4.264467515955139\n","Train Epoch #8, Batch 354/24958 loss = 1.4401923024654388, ppl = 4.252374181125965\n","Train Epoch #8, Batch 355/24958 loss = 1.4394184100627898, ppl = 4.249551291768537\n","Train Epoch #8, Batch 356/24958 loss = 1.4383263599872589, ppl = 4.245552203673535\n","Train Epoch #8, Batch 357/24958 loss = 1.435388423204422, ppl = 4.233297721360274\n","Train Epoch #8, Batch 358/24958 loss = 1.433165395259857, ppl = 4.223300242692292\n","Train Epoch #8, Batch 359/24958 loss = 1.431576999425888, ppl = 4.216758934573677\n","Train Epoch #8, Batch 360/24958 loss = 1.4327623987197875, ppl = 4.221388620128712\n","Train Epoch #8, Batch 361/24958 loss = 1.434625382423401, ppl = 4.229409338945651\n","Train Epoch #8, Batch 362/24958 loss = 1.431478923559189, ppl = 4.21863660526281\n","Train Epoch #8, Batch 363/24958 loss = 1.4317133378982545, ppl = 4.219679281278056\n","Train Epoch #8, Batch 364/24958 loss = 1.4298473501205444, ppl = 4.212046560558649\n","Train Epoch #8, Batch 365/24958 loss = 1.431243917942047, ppl = 4.217467286882162\n","Train Epoch #8, Batch 366/24958 loss = 1.43444140791893, ppl = 4.233976620322829\n","Train Epoch #8, Batch 367/24958 loss = 1.4375779902935029, ppl = 4.247044398696115\n","Train Epoch #8, Batch 368/24958 loss = 1.4391415143013, ppl = 4.2529833063001\n","Train Epoch #8, Batch 369/24958 loss = 1.4389590203762055, ppl = 4.2522380813025435\n","Train Epoch #8, Batch 370/24958 loss = 1.438269933462143, ppl = 4.249484311595372\n","Train Epoch #8, Batch 371/24958 loss = 1.4434883284568787, ppl = 4.2740918487163535\n","Train Epoch #8, Batch 372/24958 loss = 1.444796893596649, ppl = 4.279184803965984\n","Train Epoch #8, Batch 373/24958 loss = 1.445136685371399, ppl = 4.2808816731493495\n","Train Epoch #8, Batch 374/24958 loss = 1.4427481198310852, ppl = 4.269983954141024\n","Train Epoch #8, Batch 375/24958 loss = 1.4409836077690124, ppl = 4.262370179581555\n","Train Epoch #8, Batch 376/24958 loss = 1.4421470534801484, ppl = 4.267063212630819\n","Train Epoch #8, Batch 377/24958 loss = 1.4417028057575225, ppl = 4.264734115456937\n","Train Epoch #8, Batch 378/24958 loss = 1.44360285282135, ppl = 4.272627265428272\n","Train Epoch #8, Batch 379/24958 loss = 1.4433103907108307, ppl = 4.271423700656035\n","Train Epoch #8, Batch 380/24958 loss = 1.4452707183361053, ppl = 4.279849629221945\n","Train Epoch #8, Batch 381/24958 loss = 1.4470641016960144, ppl = 4.286786984120963\n","Train Epoch #8, Batch 382/24958 loss = 1.444345989227295, ppl = 4.276113742987602\n","Train Epoch #8, Batch 383/24958 loss = 1.4457784914970397, ppl = 4.282173899463675\n","Train Epoch #8, Batch 384/24958 loss = 1.4440872752666474, ppl = 4.27543787284494\n","Train Epoch #8, Batch 385/24958 loss = 1.4444870817661286, ppl = 4.277098079799166\n","Train Epoch #8, Batch 386/24958 loss = 1.4458699309825898, ppl = 4.282732540686923\n","Train Epoch #8, Batch 387/24958 loss = 1.4465092134475708, ppl = 4.2855917302202\n","Train Epoch #8, Batch 388/24958 loss = 1.4478223955631255, ppl = 4.291318833082961\n","Train Epoch #8, Batch 389/24958 loss = 1.4478443109989165, ppl = 4.291415346699711\n","Train Epoch #8, Batch 390/24958 loss = 1.445075843334198, ppl = 4.278753592635814\n","Train Epoch #8, Batch 391/24958 loss = 1.4445688509941101, ppl = 4.2766034150024606\n","Train Epoch #8, Batch 392/24958 loss = 1.4431319808959961, ppl = 4.270800359289519\n","Train Epoch #8, Batch 393/24958 loss = 1.4412924480438232, ppl = 4.263026585891546\n","Train Epoch #8, Batch 394/24958 loss = 1.4381957936286927, ppl = 4.250716130603293\n","Train Epoch #8, Batch 395/24958 loss = 1.4411864757537842, ppl = 4.262636714671972\n","Train Epoch #8, Batch 396/24958 loss = 1.4420872676372527, ppl = 4.2663795276212095\n","Train Epoch #8, Batch 397/24958 loss = 1.4412818813323975, ppl = 4.263179648998903\n","Train Epoch #8, Batch 398/24958 loss = 1.4403043711185455, ppl = 4.259419505211063\n","Train Epoch #8, Batch 399/24958 loss = 1.4394313180446625, ppl = 4.2554693384955415\n","Train Epoch #8, Batch 400/24958 loss = 1.4376062202453612, ppl = 4.247408267722821\n","Train Epoch #8, Batch 401/24958 loss = 1.4358282005786895, ppl = 4.240137598643782\n","Train Epoch #8, Batch 402/24958 loss = 1.4366973543167114, ppl = 4.243723289678837\n","Train Epoch #8, Batch 403/24958 loss = 1.436228152513504, ppl = 4.241570445842233\n","Train Epoch #8, Batch 404/24958 loss = 1.4323419535160065, ppl = 4.225321721042333\n","Train Epoch #8, Batch 405/24958 loss = 1.4324566054344177, ppl = 4.22578297467962\n","Train Epoch #8, Batch 406/24958 loss = 1.4303482687473297, ppl = 4.215872367302905\n","Train Epoch #8, Batch 407/24958 loss = 1.4307193922996522, ppl = 4.217447727533128\n","Train Epoch #8, Batch 408/24958 loss = 1.4326966750621795, ppl = 4.225880373448949\n","Train Epoch #8, Batch 409/24958 loss = 1.4306828963756562, ppl = 4.217217452681701\n","Train Epoch #8, Batch 410/24958 loss = 1.4315835452079773, ppl = 4.220787041990132\n","Train Epoch #8, Batch 411/24958 loss = 1.4299271762371064, ppl = 4.213644543457175\n","Train Epoch #8, Batch 412/24958 loss = 1.4307413184642792, ppl = 4.216787272972469\n","Train Epoch #8, Batch 413/24958 loss = 1.4300599777698517, ppl = 4.214160583388098\n","Train Epoch #8, Batch 414/24958 loss = 1.4310446357727051, ppl = 4.217935647524384\n","Train Epoch #8, Batch 415/24958 loss = 1.4313738334178925, ppl = 4.21929476970728\n","Train Epoch #8, Batch 416/24958 loss = 1.4289246785640717, ppl = 4.209046818749417\n","Train Epoch #8, Batch 417/24958 loss = 1.4279249334335327, ppl = 4.205005626110696\n","Train Epoch #8, Batch 418/24958 loss = 1.4294086825847625, ppl = 4.211035326518254\n","Train Epoch #8, Batch 419/24958 loss = 1.4298185479640961, ppl = 4.213100989806485\n","Train Epoch #8, Batch 420/24958 loss = 1.4258790349960326, ppl = 4.198692143555295\n","Train Epoch #8, Batch 421/24958 loss = 1.4246428573131562, ppl = 4.193990329621606\n","Train Epoch #8, Batch 422/24958 loss = 1.4252203691005707, ppl = 4.196468350284689\n","Train Epoch #8, Batch 423/24958 loss = 1.42471257686615, ppl = 4.194236045457284\n","Train Epoch #8, Batch 424/24958 loss = 1.4232065820693969, ppl = 4.187311060620897\n","Train Epoch #8, Batch 425/24958 loss = 1.42237198472023, ppl = 4.184054197984524\n","Train Epoch #8, Batch 426/24958 loss = 1.4211395752429963, ppl = 4.178938532735588\n","Train Epoch #8, Batch 427/24958 loss = 1.420967756509781, ppl = 4.178216332633556\n","Train Epoch #8, Batch 428/24958 loss = 1.416620112657547, ppl = 4.162730989417299\n","Train Epoch #8, Batch 429/24958 loss = 1.4158811390399932, ppl = 4.159371617744868\n","Train Epoch #8, Batch 430/24958 loss = 1.4140538167953491, ppl = 4.151629854480001\n","Train Epoch #8, Batch 431/24958 loss = 1.4149218392372132, ppl = 4.155037188237611\n","Train Epoch #8, Batch 432/24958 loss = 1.4164360773563385, ppl = 4.16182455959759\n","Train Epoch #8, Batch 433/24958 loss = 1.4152802920341492, ppl = 4.156264079633339\n","Train Epoch #8, Batch 434/24958 loss = 1.414018347263336, ppl = 4.150555795903785\n","Train Epoch #8, Batch 435/24958 loss = 1.4130060303211212, ppl = 4.14651203784675\n","Train Epoch #8, Batch 436/24958 loss = 1.4142802047729492, ppl = 4.151756546399193\n","Train Epoch #8, Batch 437/24958 loss = 1.4137363612651825, ppl = 4.149515103523887\n","Train Epoch #8, Batch 438/24958 loss = 1.4144423007965088, ppl = 4.152460551867641\n","Train Epoch #8, Batch 439/24958 loss = 1.4165259170532227, ppl = 4.162137316046888\n","Train Epoch #8, Batch 440/24958 loss = 1.420381896495819, ppl = 4.176865223986648\n","Train Epoch #8, Batch 441/24958 loss = 1.4209652101993562, ppl = 4.178922408942182\n","Train Epoch #8, Batch 442/24958 loss = 1.4194328117370605, ppl = 4.174130483520818\n","Train Epoch #8, Batch 443/24958 loss = 1.4199668729305268, ppl = 4.176137197720322\n","Train Epoch #8, Batch 444/24958 loss = 1.4174289512634277, ppl = 4.1652522338816995\n","Train Epoch #8, Batch 445/24958 loss = 1.4167102313041686, ppl = 4.162223105885913\n","Train Epoch #8, Batch 446/24958 loss = 1.4173108911514283, ppl = 4.165343201976587\n","Train Epoch #8, Batch 447/24958 loss = 1.4170504593849182, ppl = 4.164327564306616\n","Train Epoch #8, Batch 448/24958 loss = 1.4158834874629975, ppl = 4.159351367014111\n","Train Epoch #8, Batch 449/24958 loss = 1.4149119770526886, ppl = 4.155224952573332\n","Train Epoch #8, Batch 450/24958 loss = 1.4152802157402038, ppl = 4.156818282023064\n","Train Epoch #8, Batch 451/24958 loss = 1.4143768596649169, ppl = 4.152803773852852\n","Train Epoch #8, Batch 452/24958 loss = 1.4092932105064393, ppl = 4.128769655502592\n","Train Epoch #8, Batch 453/24958 loss = 1.4123398554325104, ppl = 4.1416251132819175\n","Train Epoch #8, Batch 454/24958 loss = 1.4140510368347168, ppl = 4.147999008156474\n","Train Epoch #8, Batch 455/24958 loss = 1.4146026027202607, ppl = 4.149988442406383\n","Train Epoch #8, Batch 456/24958 loss = 1.4174634659290313, ppl = 4.161467045804621\n","Train Epoch #8, Batch 457/24958 loss = 1.418516801595688, ppl = 4.165453030981967\n","Train Epoch #8, Batch 458/24958 loss = 1.4182932019233703, ppl = 4.164565049231847\n","Train Epoch #8, Batch 459/24958 loss = 1.418546463251114, ppl = 4.1655396748425275\n","Train Epoch #8, Batch 460/24958 loss = 1.4174068617820739, ppl = 4.161078851193241\n","Train Epoch #8, Batch 461/24958 loss = 1.4145076918601989, ppl = 4.14920287141999\n","Train Epoch #8, Batch 462/24958 loss = 1.421517666578293, ppl = 4.178795358981535\n","Train Epoch #8, Batch 463/24958 loss = 1.420080019235611, ppl = 4.172769018011476\n","Train Epoch #8, Batch 464/24958 loss = 1.420857572555542, ppl = 4.1757774847322375\n","Train Epoch #8, Batch 465/24958 loss = 1.421395310163498, ppl = 4.178075051890621\n","Train Epoch #8, Batch 466/24958 loss = 1.4174337124824523, ppl = 4.1583423714341805\n","Train Epoch #8, Batch 467/24958 loss = 1.4170973598957062, ppl = 4.15673695498432\n","Train Epoch #8, Batch 468/24958 loss = 1.417259532213211, ppl = 4.157407787708267\n","Train Epoch #8, Batch 469/24958 loss = 1.4187878012657165, ppl = 4.164089357201425\n","Train Epoch #8, Batch 470/24958 loss = 1.4209184265136718, ppl = 4.173255751207098\n","Train Epoch #8, Batch 471/24958 loss = 1.4179959380626679, ppl = 4.157917818773644\n","Train Epoch #8, Batch 472/24958 loss = 1.4176845598220824, ppl = 4.15664483126356\n","Train Epoch #8, Batch 473/24958 loss = 1.4161921262741088, ppl = 4.149603037656174\n","Train Epoch #8, Batch 474/24958 loss = 1.4178176319599152, ppl = 4.156732609061404\n","Train Epoch #8, Batch 475/24958 loss = 1.4192946231365204, ppl = 4.163012343370457\n","Train Epoch #8, Batch 476/24958 loss = 1.42083913564682, ppl = 4.170148890831046\n","Train Epoch #8, Batch 477/24958 loss = 1.4196446883678435, ppl = 4.164376336864255\n","Train Epoch #8, Batch 478/24958 loss = 1.4154388308525085, ppl = 4.148715545794303\n","Train Epoch #8, Batch 479/24958 loss = 1.4152889275550842, ppl = 4.148112161794294\n","Train Epoch #8, Batch 480/24958 loss = 1.411677474975586, ppl = 4.133764546890222\n","Train Epoch #8, Batch 481/24958 loss = 1.4111976444721221, ppl = 4.131784881043672\n","Train Epoch #8, Batch 482/24958 loss = 1.4119765782356262, ppl = 4.134553061376592\n","Train Epoch #8, Batch 483/24958 loss = 1.4136648046970368, ppl = 4.142903885517369\n","Train Epoch #8, Batch 484/24958 loss = 1.4163482320308685, ppl = 4.154155760057299\n","Train Epoch #8, Batch 485/24958 loss = 1.4164481461048126, ppl = 4.154581126497203\n","Train Epoch #8, Batch 486/24958 loss = 1.4156247615814208, ppl = 4.151132822433138\n","Train Epoch #8, Batch 487/24958 loss = 1.4140002202987672, ppl = 4.144209894780236\n","Train Epoch #8, Batch 488/24958 loss = 1.4170809674263, ppl = 4.1610011487751155\n","Train Epoch #8, Batch 489/24958 loss = 1.4169361782073975, ppl = 4.160367410056846\n","Train Epoch #8, Batch 490/24958 loss = 1.418653427362442, ppl = 4.167804589684709\n","Train Epoch #8, Batch 491/24958 loss = 1.4199801778793335, ppl = 4.173670494375212\n","Train Epoch #8, Batch 492/24958 loss = 1.4210886371135711, ppl = 4.178072761437062\n","Train Epoch #8, Batch 493/24958 loss = 1.4231366443634033, ppl = 4.186821175824865\n","Train Epoch #8, Batch 494/24958 loss = 1.4250478518009186, ppl = 4.1939640742593145\n","Train Epoch #8, Batch 495/24958 loss = 1.4260882925987244, ppl = 4.199020666653496\n","Train Epoch #8, Batch 496/24958 loss = 1.4264409065246582, ppl = 4.200580097631298\n","Train Epoch #8, Batch 497/24958 loss = 1.4247234177589416, ppl = 4.1945592739338675\n","Train Epoch #8, Batch 498/24958 loss = 1.4262819182872772, ppl = 4.200734781980694\n","Train Epoch #8, Batch 499/24958 loss = 1.4258651876449584, ppl = 4.198967456973243\n","Train Epoch #8, Batch 500/24958 loss = 1.4257719802856446, ppl = 4.198593948629887\n","Train Epoch #8, Batch 501/24958 loss = 1.428061784505844, ppl = 4.208208430602755\n","Train Epoch #8, Batch 502/24958 loss = 1.427331222295761, ppl = 4.205173820994392\n","Train Epoch #8, Batch 503/24958 loss = 1.4255999994277955, ppl = 4.198049776913277\n","Train Epoch #8, Batch 504/24958 loss = 1.4281931900978089, ppl = 4.20817811283054\n","Train Epoch #8, Batch 505/24958 loss = 1.4282745969295503, ppl = 4.208508844294279\n","Train Epoch #8, Batch 506/24958 loss = 1.4271972072124481, ppl = 4.2041960184390135\n","Train Epoch #8, Batch 507/24958 loss = 1.4270553362369538, ppl = 4.203586885911524\n","Train Epoch #8, Batch 508/24958 loss = 1.4271220505237578, ppl = 4.203901510257419\n","Train Epoch #8, Batch 509/24958 loss = 1.4281175363063812, ppl = 4.207966144221575\n","Train Epoch #8, Batch 510/24958 loss = 1.4291580438613891, ppl = 4.21251088162645\n","Train Epoch #8, Batch 511/24958 loss = 1.4298941504955291, ppl = 4.215539553747936\n","Train Epoch #8, Batch 512/24958 loss = 1.4320059204101563, ppl = 4.224990503353976\n","Train Epoch #8, Batch 513/24958 loss = 1.4309584033489227, ppl = 4.221285587049462\n","Train Epoch #8, Batch 514/24958 loss = 1.4307129526138305, ppl = 4.22030949582505\n","Train Epoch #8, Batch 515/24958 loss = 1.4315835845470428, ppl = 4.224127249353329\n","Train Epoch #8, Batch 516/24958 loss = 1.4334052300453186, ppl = 4.231505847956343\n","Train Epoch #8, Batch 517/24958 loss = 1.4337921738624573, ppl = 4.233022226394832\n","Train Epoch #8, Batch 518/24958 loss = 1.4317266750335693, ppl = 4.224862020775949\n","Train Epoch #8, Batch 519/24958 loss = 1.4294401502609253, ppl = 4.214348254245351\n","Train Epoch #8, Batch 520/24958 loss = 1.4332552993297576, ppl = 4.22821018032703\n","Train Epoch #8, Batch 521/24958 loss = 1.4358461320400238, ppl = 4.2387778043763324\n","Train Epoch #8, Batch 522/24958 loss = 1.4355288636684418, ppl = 4.237398754962459\n","Train Epoch #8, Batch 523/24958 loss = 1.435692013502121, ppl = 4.23810365644145\n","Train Epoch #8, Batch 524/24958 loss = 1.4355052876472474, ppl = 4.237315452096156\n","Train Epoch #8, Batch 525/24958 loss = 1.436831409931183, ppl = 4.2426215039122805\n","Train Epoch #8, Batch 526/24958 loss = 1.4394342529773712, ppl = 4.254217394178392\n","Train Epoch #8, Batch 527/24958 loss = 1.4400124382972717, ppl = 4.256697860765337\n","Train Epoch #8, Batch 528/24958 loss = 1.4432931137084961, ppl = 4.267738443790245\n","Train Epoch #8, Batch 529/24958 loss = 1.443257555961609, ppl = 4.267582973991007\n","Train Epoch #8, Batch 530/24958 loss = 1.443837206363678, ppl = 4.269887357574097\n","Train Epoch #8, Batch 531/24958 loss = 1.4464197027683259, ppl = 4.2819632811374815\n","Train Epoch #8, Batch 532/24958 loss = 1.4440544855594635, ppl = 4.27178916489995\n","Train Epoch #8, Batch 533/24958 loss = 1.4447829556465148, ppl = 4.275218596285958\n","Train Epoch #8, Batch 534/24958 loss = 1.4454016637802125, ppl = 4.277927318410971\n","Train Epoch #8, Batch 535/24958 loss = 1.444956580400467, ppl = 4.27627492516673\n","Train Epoch #8, Batch 536/24958 loss = 1.443122730255127, ppl = 4.2689297664337404\n","Train Epoch #8, Batch 537/24958 loss = 1.4426091027259826, ppl = 4.266921905888459\n","Train Epoch #8, Batch 538/24958 loss = 1.4427768182754517, ppl = 4.267652781265624\n","Train Epoch #8, Batch 539/24958 loss = 1.4402956283092498, ppl = 4.256347864901603\n","Train Epoch #8, Batch 540/24958 loss = 1.4383403730392457, ppl = 4.2481728629879765\n","Train Epoch #8, Batch 541/24958 loss = 1.4379317998886108, ppl = 4.246719399707831\n","Train Epoch #8, Batch 542/24958 loss = 1.444190411567688, ppl = 4.271889503866064\n","Train Epoch #8, Batch 543/24958 loss = 1.4449040138721465, ppl = 4.274743700877068\n","Train Epoch #8, Batch 544/24958 loss = 1.4430554938316345, ppl = 4.268384891539717\n","Train Epoch #8, Batch 545/24958 loss = 1.444936203956604, ppl = 4.2767961014827\n","Train Epoch #8, Batch 546/24958 loss = 1.4403105700016021, ppl = 4.2569758533971624\n","Train Epoch #8, Batch 547/24958 loss = 1.4396679317951202, ppl = 4.254579979662892\n","Train Epoch #8, Batch 548/24958 loss = 1.4396178233623504, ppl = 4.2543790363808025\n","Train Epoch #8, Batch 549/24958 loss = 1.4391210198402404, ppl = 4.252418838555975\n","Train Epoch #8, Batch 550/24958 loss = 1.4391991293430328, ppl = 4.252764418824055\n","Train Epoch #8, Batch 551/24958 loss = 1.4399490833282471, ppl = 4.256071394653478\n","Train Epoch #8, Batch 552/24958 loss = 1.4445007967948913, ppl = 4.276981335830315\n","Train Epoch #8, Batch 553/24958 loss = 1.4435914146900177, ppl = 4.27272639552225\n","Train Epoch #8, Batch 554/24958 loss = 1.4429906725883483, ppl = 4.270363495397712\n","Train Epoch #8, Batch 555/24958 loss = 1.4442019748687744, ppl = 4.27513741773863\n","Train Epoch #8, Batch 556/24958 loss = 1.4442564380168914, ppl = 4.2753893714213165\n","Train Epoch #8, Batch 557/24958 loss = 1.4432583510875703, ppl = 4.271602186922082\n","Train Epoch #8, Batch 558/24958 loss = 1.4437367010116577, ppl = 4.2735263539854005\n","Train Epoch #8, Batch 559/24958 loss = 1.4432014203071595, ppl = 4.27149508800016\n","Train Epoch #8, Batch 560/24958 loss = 1.4443427336215973, ppl = 4.275963002117707\n","Train Epoch #8, Batch 561/24958 loss = 1.4456993329524994, ppl = 4.281093552430983\n","Train Epoch #8, Batch 562/24958 loss = 1.443591948747635, ppl = 4.269934829811766\n","Train Epoch #8, Batch 563/24958 loss = 1.4451905012130737, ppl = 4.276691156015648\n","Train Epoch #8, Batch 564/24958 loss = 1.4471199667453767, ppl = 4.2852496684597075\n","Train Epoch #8, Batch 565/24958 loss = 1.4471782445907593, ppl = 4.285506171130866\n","Train Epoch #8, Batch 566/24958 loss = 1.4466152811050415, ppl = 4.283284051545339\n","Train Epoch #8, Batch 567/24958 loss = 1.4440011644363404, ppl = 4.272488006596639\n","Train Epoch #8, Batch 568/24958 loss = 1.4435250425338746, ppl = 4.270549020880102\n","Train Epoch #8, Batch 569/24958 loss = 1.4419359254837036, ppl = 4.263621982849898\n","Train Epoch #8, Batch 570/24958 loss = 1.4398623299598694, ppl = 4.254676361156046\n","Train Epoch #8, Batch 571/24958 loss = 1.4386604118347168, ppl = 4.249559006774048\n","Train Epoch #8, Batch 572/24958 loss = 1.4409329771995545, ppl = 4.2598286537205565\n","Train Epoch #8, Batch 573/24958 loss = 1.4395420849323273, ppl = 4.254147739969133\n","Train Epoch #8, Batch 574/24958 loss = 1.4410297775268555, ppl = 4.26177050910806\n","Train Epoch #8, Batch 575/24958 loss = 1.4382018911838532, ppl = 4.250505217179502\n","Train Epoch #8, Batch 576/24958 loss = 1.437416889667511, ppl = 4.2467404362372125\n","Train Epoch #8, Batch 577/24958 loss = 1.436325877904892, ppl = 4.242037603113014\n","Train Epoch #8, Batch 578/24958 loss = 1.4401697051525115, ppl = 4.256076587380798\n","Train Epoch #8, Batch 579/24958 loss = 1.4378412079811096, ppl = 4.24777775195583\n","Train Epoch #8, Batch 580/24958 loss = 1.440742186307907, ppl = 4.258879177534779\n","Train Epoch #8, Batch 581/24958 loss = 1.4403999423980713, ppl = 4.257524087409984\n","Train Epoch #8, Batch 582/24958 loss = 1.443089497089386, ppl = 4.2689236951220675\n","Train Epoch #8, Batch 583/24958 loss = 1.4384731817245484, ppl = 4.249046950637389\n","Train Epoch #8, Batch 584/24958 loss = 1.4371711277961732, ppl = 4.243210287189619\n","Train Epoch #8, Batch 585/24958 loss = 1.4371585273742675, ppl = 4.243156408644975\n","Train Epoch #8, Batch 586/24958 loss = 1.4376146304607391, ppl = 4.245031426551912\n","Train Epoch #8, Batch 587/24958 loss = 1.4357953703403472, ppl = 4.238503219392829\n","Train Epoch #8, Batch 588/24958 loss = 1.431526381969452, ppl = 4.21649796375498\n","Train Epoch #8, Batch 589/24958 loss = 1.4326148986816407, ppl = 4.221494999933275\n","Train Epoch #8, Batch 590/24958 loss = 1.4331898617744445, ppl = 4.224284433387345\n","Train Epoch #8, Batch 591/24958 loss = 1.431533350944519, ppl = 4.217077387074848\n","Train Epoch #8, Batch 592/24958 loss = 1.431336967945099, ppl = 4.216261461217657\n","Train Epoch #8, Batch 593/24958 loss = 1.4304428470134736, ppl = 4.212220949480601\n","Train Epoch #8, Batch 594/24958 loss = 1.4299513876438141, ppl = 4.2102518546535075\n","Train Epoch #8, Batch 595/24958 loss = 1.427896044254303, ppl = 4.20074460425269\n","Train Epoch #8, Batch 596/24958 loss = 1.426377490758896, ppl = 4.1944033751680845\n","Train Epoch #8, Batch 597/24958 loss = 1.4265999519824981, ppl = 4.195126190780628\n","Train Epoch #8, Batch 598/24958 loss = 1.4260476911067963, ppl = 4.192826994855973\n","Train Epoch #8, Batch 599/24958 loss = 1.4276465058326722, ppl = 4.200027430852871\n","Train Epoch #8, Batch 600/24958 loss = 1.4281742537021638, ppl = 4.202188961241981\n","Train Epoch #8, Batch 601/24958 loss = 1.4259693288803101, ppl = 4.192892974860313\n","Train Epoch #8, Batch 602/24958 loss = 1.4248680722713472, ppl = 4.188717752863859\n","Train Epoch #8, Batch 603/24958 loss = 1.4269232177734374, ppl = 4.197317226925107\n","Train Epoch #8, Batch 604/24958 loss = 1.4249551916122436, ppl = 4.189395967343443\n","Train Epoch #8, Batch 605/24958 loss = 1.42302894115448, ppl = 4.182248747108565\n","Train Epoch #8, Batch 606/24958 loss = 1.424271559715271, ppl = 4.187265054966731\n","Train Epoch #8, Batch 607/24958 loss = 1.4236512565612793, ppl = 4.184700938144223\n","Train Epoch #8, Batch 608/24958 loss = 1.4231035268306733, ppl = 4.182178920289908\n","Train Epoch #8, Batch 609/24958 loss = 1.4195636355876922, ppl = 4.169390671059322\n","Train Epoch #8, Batch 610/24958 loss = 1.4183070516586305, ppl = 4.163960008526334\n","Train Epoch #8, Batch 611/24958 loss = 1.4159555852413177, ppl = 4.155017172116741\n","Train Epoch #8, Batch 612/24958 loss = 1.414120570421219, ppl = 4.14669415941368\n","Train Epoch #8, Batch 613/24958 loss = 1.4137196636199951, ppl = 4.145375783875496\n","Train Epoch #8, Batch 614/24958 loss = 1.4122979509830476, ppl = 4.1401699452763525\n","Train Epoch #8, Batch 615/24958 loss = 1.4118397295475007, ppl = 4.1381192321334925\n","Train Epoch #8, Batch 616/24958 loss = 1.4111569905281067, ppl = 4.135195215670527\n","Train Epoch #8, Batch 617/24958 loss = 1.412548668384552, ppl = 4.141160676586642\n","Train Epoch #8, Batch 618/24958 loss = 1.4124135184288025, ppl = 4.140683216420136\n","Train Epoch #8, Batch 619/24958 loss = 1.4124854505062103, ppl = 4.140978657597988\n","Train Epoch #8, Batch 620/24958 loss = 1.4124810540676116, ppl = 4.140959447400428\n","Train Epoch #8, Batch 621/24958 loss = 1.4093720412254334, ppl = 4.128587385209257\n","Train Epoch #8, Batch 622/24958 loss = 1.4094769036769867, ppl = 4.129038351930248\n","Train Epoch #8, Batch 623/24958 loss = 1.407873762845993, ppl = 4.12258619968605\n","Train Epoch #8, Batch 624/24958 loss = 1.4101950860023498, ppl = 4.133512937083563\n","Train Epoch #8, Batch 625/24958 loss = 1.4090963506698608, ppl = 4.129067454652582\n","Train Epoch #8, Batch 626/24958 loss = 1.4066278851032257, ppl = 4.117999229738475\n","Train Epoch #8, Batch 627/24958 loss = 1.4047681486606598, ppl = 4.110506253091374\n","Train Epoch #8, Batch 628/24958 loss = 1.406692417860031, ppl = 4.118882365424457\n","Train Epoch #8, Batch 629/24958 loss = 1.4053658187389373, ppl = 4.113459974419944\n","Train Epoch #8, Batch 630/24958 loss = 1.4055205333232879, ppl = 4.114097958662061\n","Train Epoch #8, Batch 631/24958 loss = 1.4032304418087005, ppl = 4.103238069467776\n","Train Epoch #8, Batch 632/24958 loss = 1.402891721725464, ppl = 4.101968196498271\n","Train Epoch #8, Batch 633/24958 loss = 1.4016709434986114, ppl = 4.096358615075432\n","Train Epoch #8, Batch 634/24958 loss = 1.4023364830017089, ppl = 4.099465680752296\n","Train Epoch #8, Batch 635/24958 loss = 1.402916761636734, ppl = 4.10163473006513\n","Train Epoch #8, Batch 636/24958 loss = 1.4036391401290893, ppl = 4.104368442868587\n","Train Epoch #8, Batch 637/24958 loss = 1.4040054416656493, ppl = 4.10578979404252\n","Train Epoch #8, Batch 638/24958 loss = 1.40369460105896, ppl = 4.104444825203256\n","Train Epoch #8, Batch 639/24958 loss = 1.405622810125351, ppl = 4.112981972319705\n","Train Epoch #8, Batch 640/24958 loss = 1.4074597179889679, ppl = 4.12061541988703\n","Train Epoch #8, Batch 641/24958 loss = 1.4095981633663177, ppl = 4.128925267906791\n","Train Epoch #8, Batch 642/24958 loss = 1.405885784626007, ppl = 4.112145885591306\n","Train Epoch #8, Batch 643/24958 loss = 1.405397380590439, ppl = 4.110170517267626\n","Train Epoch #8, Batch 644/24958 loss = 1.4097331535816193, ppl = 4.127168856720945\n","Train Epoch #8, Batch 645/24958 loss = 1.4080699133872985, ppl = 4.119651338461916\n","Train Epoch #8, Batch 646/24958 loss = 1.4101604449748992, ppl = 4.127486917832835\n","Train Epoch #8, Batch 647/24958 loss = 1.4123224639892578, ppl = 4.136198973016358\n","Train Epoch #8, Batch 648/24958 loss = 1.413306087255478, ppl = 4.140333607199864\n","Train Epoch #8, Batch 649/24958 loss = 1.415141555070877, ppl = 4.148087066902402\n","Train Epoch #8, Batch 650/24958 loss = 1.4117055833339691, ppl = 4.135171521750477\n","Train Epoch #8, Batch 651/24958 loss = 1.4088124084472655, ppl = 4.123672960597229\n","Train Epoch #8, Batch 652/24958 loss = 1.4054849934577942, ppl = 4.107487345834628\n","Train Epoch #8, Batch 653/24958 loss = 1.403503758907318, ppl = 4.099454407100015\n","Train Epoch #8, Batch 654/24958 loss = 1.4042001342773438, ppl = 4.102206732597605\n","Train Epoch #8, Batch 655/24958 loss = 1.4056796026229859, ppl = 4.108879229297174\n","Train Epoch #8, Batch 656/24958 loss = 1.4058762788772583, ppl = 4.109800590209142\n","Train Epoch #8, Batch 657/24958 loss = 1.4082640016078949, ppl = 4.119531612731566\n","Train Epoch #8, Batch 658/24958 loss = 1.4093210506439209, ppl = 4.1241245840549405\n","Train Epoch #8, Batch 659/24958 loss = 1.4095333445072173, ppl = 4.1249172047108145\n","Train Epoch #8, Batch 660/24958 loss = 1.4101330077648162, ppl = 4.127477214231437\n","Train Epoch #8, Batch 661/24958 loss = 1.4098922002315522, ppl = 4.126514961722388\n","Train Epoch #8, Batch 662/24958 loss = 1.4088385093212128, ppl = 4.1217578903129235\n","Train Epoch #8, Batch 663/24958 loss = 1.4086607229709625, ppl = 4.120951997872121\n","Train Epoch #8, Batch 664/24958 loss = 1.4097920358181, ppl = 4.126794058409458\n","Train Epoch #8, Batch 665/24958 loss = 1.4100736272335053, ppl = 4.128054729277716\n","Train Epoch #8, Batch 666/24958 loss = 1.4129168033599853, ppl = 4.140673283697697\n","Train Epoch #8, Batch 667/24958 loss = 1.4114587473869324, ppl = 4.1357705696785825\n","Train Epoch #8, Batch 668/24958 loss = 1.4130058360099793, ppl = 4.142423598383616\n","Train Epoch #8, Batch 669/24958 loss = 1.412884075641632, ppl = 4.141936863784679\n","Train Epoch #8, Batch 670/24958 loss = 1.4139224004745483, ppl = 4.146184588696602\n","Train Epoch #8, Batch 671/24958 loss = 1.412747745513916, ppl = 4.14174377478119\n","Train Epoch #8, Batch 672/24958 loss = 1.411862839460373, ppl = 4.137465423206866\n","Train Epoch #8, Batch 673/24958 loss = 1.4124038207530976, ppl = 4.139581611501816\n","Train Epoch #8, Batch 674/24958 loss = 1.4089373791217803, ppl = 4.123427343676743\n","Train Epoch #8, Batch 675/24958 loss = 1.4102680826187133, ppl = 4.128333316506403\n","Train Epoch #8, Batch 676/24958 loss = 1.4100920104980468, ppl = 4.127528708281985\n","Train Epoch #8, Batch 677/24958 loss = 1.4087047684192657, ppl = 4.122244248435483\n","Train Epoch #8, Batch 678/24958 loss = 1.4074829161167144, ppl = 4.117184536665662\n","Train Epoch #8, Batch 679/24958 loss = 1.409595892429352, ppl = 4.124631565165067\n","Train Epoch #8, Batch 680/24958 loss = 1.4089371013641356, ppl = 4.121820783070162\n","Train Epoch #8, Batch 681/24958 loss = 1.4122503423690795, ppl = 4.137109227847715\n","Train Epoch #8, Batch 682/24958 loss = 1.4091116726398467, ppl = 4.12408728684163\n","Train Epoch #8, Batch 683/24958 loss = 1.409925856590271, ppl = 4.126961246191648\n","Train Epoch #8, Batch 684/24958 loss = 1.410708385705948, ppl = 4.130377569080749\n","Train Epoch #8, Batch 685/24958 loss = 1.4104784333705902, ppl = 4.129406139850354\n","Train Epoch #8, Batch 686/24958 loss = 1.4139833068847656, ppl = 4.147058762854372\n","Train Epoch #8, Batch 687/24958 loss = 1.4168218302726745, ppl = 4.157798234184681\n","Train Epoch #8, Batch 688/24958 loss = 1.4138857305049897, ppl = 4.147283899353079\n","Train Epoch #8, Batch 689/24958 loss = 1.4127771580219268, ppl = 4.142199800883803\n","Train Epoch #8, Batch 690/24958 loss = 1.4124574184417724, ppl = 4.14062881158761\n","Train Epoch #8, Batch 691/24958 loss = 1.4147857773303985, ppl = 4.151116652282424\n","Train Epoch #8, Batch 692/24958 loss = 1.4156901013851166, ppl = 4.1550105508347395\n","Train Epoch #8, Batch 693/24958 loss = 1.415304901599884, ppl = 4.153378144602096\n","Train Epoch #8, Batch 694/24958 loss = 1.4188216364383697, ppl = 4.169852317136372\n","Train Epoch #8, Batch 695/24958 loss = 1.4189558625221252, ppl = 4.1704153451718895\n","Train Epoch #8, Batch 696/24958 loss = 1.4218149089813232, ppl = 4.183213104662911\n","Train Epoch #8, Batch 697/24958 loss = 1.424847390651703, ppl = 4.194851829679609\n","Train Epoch #8, Batch 698/24958 loss = 1.4235688269138336, ppl = 4.18999180113788\n","Train Epoch #8, Batch 699/24958 loss = 1.4227446568012239, ppl = 4.186136492459895\n","Train Epoch #8, Batch 700/24958 loss = 1.4214166820049285, ppl = 4.180907516363791\n","Train Epoch #8, Batch 701/24958 loss = 1.4197356832027435, ppl = 4.175076837026705\n","Train Epoch #8, Batch 702/24958 loss = 1.418661071062088, ppl = 4.1714227077446795\n","Train Epoch #8, Batch 703/24958 loss = 1.4172307026386262, ppl = 4.165253203954649\n","Train Epoch #8, Batch 704/24958 loss = 1.4199125742912293, ppl = 4.1764553807287\n","Train Epoch #8, Batch 705/24958 loss = 1.421896092891693, ppl = 4.183836882704009\n","Train Epoch #8, Batch 706/24958 loss = 1.4223858416080475, ppl = 4.185991655843338\n","Train Epoch #8, Batch 707/24958 loss = 1.4247789835929872, ppl = 4.196825067090555\n","Train Epoch #8, Batch 708/24958 loss = 1.425049263238907, ppl = 4.198052306698298\n","Train Epoch #8, Batch 709/24958 loss = 1.4273214876651763, ppl = 4.205733241350909\n","Train Epoch #8, Batch 710/24958 loss = 1.429450160264969, ppl = 4.215354708568021\n","Train Epoch #8, Batch 711/24958 loss = 1.4316904485225677, ppl = 4.2238256934687195\n","Train Epoch #8, Batch 712/24958 loss = 1.4324862444400788, ppl = 4.2272484954103335\n","Train Epoch #8, Batch 713/24958 loss = 1.434740912914276, ppl = 4.235399717948087\n","Train Epoch #8, Batch 714/24958 loss = 1.4359593439102172, ppl = 4.239815102358455\n","Train Epoch #8, Batch 715/24958 loss = 1.436778883934021, ppl = 4.243550433874744\n","Train Epoch #8, Batch 716/24958 loss = 1.4365018844604491, ppl = 4.2424198751788875\n","Train Epoch #8, Batch 717/24958 loss = 1.436607460975647, ppl = 4.2429072203644065\n","Train Epoch #8, Batch 718/24958 loss = 1.4386418771743774, ppl = 4.250823998447508\n","Train Epoch #8, Batch 719/24958 loss = 1.4376823902130127, ppl = 4.247052793517806\n","Train Epoch #8, Batch 720/24958 loss = 1.436600992679596, ppl = 4.24257514430845\n","Train Epoch #8, Batch 721/24958 loss = 1.4387909173965454, ppl = 4.250881505053378\n","Train Epoch #8, Batch 722/24958 loss = 1.4401333689689637, ppl = 4.257092700797494\n","Train Epoch #8, Batch 723/24958 loss = 1.4412214696407317, ppl = 4.261358174906061\n","Train Epoch #8, Batch 724/24958 loss = 1.4357994437217712, ppl = 4.239282307645144\n","Train Epoch #8, Batch 725/24958 loss = 1.4355090904235839, ppl = 4.238186874900482\n","Train Epoch #8, Batch 726/24958 loss = 1.4359773361682893, ppl = 4.240081957441276\n","Train Epoch #8, Batch 727/24958 loss = 1.438590806722641, ppl = 4.251031533577901\n","Train Epoch #8, Batch 728/24958 loss = 1.4361944127082824, ppl = 4.240835020717571\n","Train Epoch #8, Batch 729/24958 loss = 1.4379631507396697, ppl = 4.248230445330676\n","Train Epoch #8, Batch 730/24958 loss = 1.436776041984558, ppl = 4.243578852448752\n","Train Epoch #8, Batch 731/24958 loss = 1.4361698317527771, ppl = 4.241096740815163\n","Train Epoch #8, Batch 732/24958 loss = 1.4399982464313508, ppl = 4.25828944914195\n","Train Epoch #8, Batch 733/24958 loss = 1.440108906030655, ppl = 4.258770188219321\n","Train Epoch #8, Batch 734/24958 loss = 1.439362690448761, ppl = 4.255300346550029\n","Train Epoch #8, Batch 735/24958 loss = 1.441735841035843, ppl = 4.265605364449516\n","Train Epoch #8, Batch 736/24958 loss = 1.4455603098869323, ppl = 4.2838797113621805\n","Train Epoch #8, Batch 737/24958 loss = 1.444197702407837, ppl = 4.278845742082234\n","Train Epoch #8, Batch 738/24958 loss = 1.4433954119682313, ppl = 4.275561510722776\n","Train Epoch #8, Batch 739/24958 loss = 1.4406615710258484, ppl = 4.263917118291142\n","Train Epoch #8, Batch 740/24958 loss = 1.4403149807453155, ppl = 4.262367506581181\n","Train Epoch #8, Batch 741/24958 loss = 1.441324919462204, ppl = 4.266954346681417\n","Train Epoch #8, Batch 742/24958 loss = 1.4437901830673219, ppl = 4.277389875699613\n","Train Epoch #8, Batch 743/24958 loss = 1.4443123579025268, ppl = 4.27950543049664\n","Train Epoch #8, Batch 744/24958 loss = 1.442455450296402, ppl = 4.2713172869923035\n","Train Epoch #8, Batch 745/24958 loss = 1.4416233563423158, ppl = 4.268000395981347\n","Train Epoch #8, Batch 746/24958 loss = 1.4389102685451507, ppl = 4.258130780868515\n","Train Epoch #8, Batch 747/24958 loss = 1.4380603539943695, ppl = 4.254479766452557\n","Train Epoch #8, Batch 748/24958 loss = 1.435214443206787, ppl = 4.243548258642175\n","Train Epoch #8, Batch 749/24958 loss = 1.4349568092823028, ppl = 4.242372233548456\n","Train Epoch #8, Batch 750/24958 loss = 1.4373938763141632, ppl = 4.251065433371107\n","Train Epoch #8, Batch 751/24958 loss = 1.4398685526847839, ppl = 4.2606880598463786\n","Train Epoch #8, Batch 752/24958 loss = 1.4387722313404083, ppl = 4.256430941580939\n","Train Epoch #8, Batch 753/24958 loss = 1.4396194159984588, ppl = 4.259672179112691\n","Train Epoch #8, Batch 754/24958 loss = 1.4400614392757416, ppl = 4.261521316375732\n","Train Epoch #8, Batch 755/24958 loss = 1.4391535711288452, ppl = 4.2573104569953335\n","Train Epoch #8, Batch 756/24958 loss = 1.435355271100998, ppl = 4.242359830496838\n","Train Epoch #8, Batch 757/24958 loss = 1.4339482533931731, ppl = 4.23634675183758\n","Train Epoch #8, Batch 758/24958 loss = 1.4328444838523864, ppl = 4.231561765010185\n","Train Epoch #8, Batch 759/24958 loss = 1.431906567811966, ppl = 4.228183558138176\n","Train Epoch #8, Batch 760/24958 loss = 1.4326352620124816, ppl = 4.23150828048886\n","Train Epoch #8, Batch 761/24958 loss = 1.4349530947208404, ppl = 4.24180655181075\n","Train Epoch #8, Batch 762/24958 loss = 1.4366958630084992, ppl = 4.249956930515479\n","Train Epoch #8, Batch 763/24958 loss = 1.434354566335678, ppl = 4.2405787261653245\n","Train Epoch #8, Batch 764/24958 loss = 1.4303079986572265, ppl = 4.222402920005445\n","Train Epoch #8, Batch 765/24958 loss = 1.4293840289115907, ppl = 4.218395811380886\n","Train Epoch #8, Batch 766/24958 loss = 1.4284772741794587, ppl = 4.213975717438881\n","Train Epoch #8, Batch 767/24958 loss = 1.4340649521350861, ppl = 4.237354285719191\n","Train Epoch #8, Batch 768/24958 loss = 1.4320516741275788, ppl = 4.228890104152339\n","Train Epoch #8, Batch 769/24958 loss = 1.4319954681396485, ppl = 4.228667413365519\n","Train Epoch #8, Batch 770/24958 loss = 1.4307401823997496, ppl = 4.223586468061447\n","Train Epoch #8, Batch 771/24958 loss = 1.4327451300621032, ppl = 4.231496211274359\n","Train Epoch #8, Batch 772/24958 loss = 1.4312000679969787, ppl = 4.224876342938492\n","Train Epoch #8, Batch 773/24958 loss = 1.4322002267837524, ppl = 4.229103364741075\n","Train Epoch #8, Batch 774/24958 loss = 1.4341547143459321, ppl = 4.237519707902846\n","Train Epoch #8, Batch 775/24958 loss = 1.4345802879333496, ppl = 4.239231566812441\n","Train Epoch #8, Batch 776/24958 loss = 1.4321707463264466, ppl = 4.229532567984138\n","Train Epoch #8, Batch 777/24958 loss = 1.4316249632835387, ppl = 4.227646319089999\n","Train Epoch #8, Batch 778/24958 loss = 1.4301236808300017, ppl = 4.222219129339271\n","Train Epoch #8, Batch 779/24958 loss = 1.4321298432350158, ppl = 4.230905150334175\n","Train Epoch #8, Batch 780/24958 loss = 1.4319972956180573, ppl = 4.230361659346496\n","Train Epoch #8, Batch 781/24958 loss = 1.431533190011978, ppl = 4.227903275926633\n","Train Epoch #8, Batch 782/24958 loss = 1.4344922232627868, ppl = 4.240064611891763\n","Train Epoch #8, Batch 783/24958 loss = 1.434845689535141, ppl = 4.2413870151970325\n","Train Epoch #8, Batch 784/24958 loss = 1.433670244216919, ppl = 4.23635353969921\n","Train Epoch #8, Batch 785/24958 loss = 1.4362747311592101, ppl = 4.248777930913527\n","Train Epoch #8, Batch 786/24958 loss = 1.4344160664081573, ppl = 4.238650733686325\n","Train Epoch #8, Batch 787/24958 loss = 1.4344116246700287, ppl = 4.238631435004012\n","Train Epoch #8, Batch 788/24958 loss = 1.4376979887485504, ppl = 4.250618871523726\n","Train Epoch #8, Batch 789/24958 loss = 1.436920702457428, ppl = 4.2473757223316\n","Train Epoch #8, Batch 790/24958 loss = 1.435874547958374, ppl = 4.242572948148843\n","Train Epoch #8, Batch 791/24958 loss = 1.432498881816864, ppl = 4.228107457970833\n","Train Epoch #8, Batch 792/24958 loss = 1.433045550584793, ppl = 4.230637914154783\n","Train Epoch #8, Batch 793/24958 loss = 1.4304327523708344, ppl = 4.221080175247621\n","Train Epoch #8, Batch 794/24958 loss = 1.4287854862213134, ppl = 4.212641427411064\n","Train Epoch #8, Batch 795/24958 loss = 1.4293390655517577, ppl = 4.215045018940048\n","Train Epoch #8, Batch 796/24958 loss = 1.4268256306648255, ppl = 4.203607030909552\n","Train Epoch #8, Batch 797/24958 loss = 1.4259588098526002, ppl = 4.199912694411086\n","Train Epoch #8, Batch 798/24958 loss = 1.4273068392276764, ppl = 4.205054992253098\n","Train Epoch #8, Batch 799/24958 loss = 1.4275492489337922, ppl = 4.206156144216784\n","Train Epoch #8, Batch 800/24958 loss = 1.4284899389743806, ppl = 4.2097877996114645\n","Train Epoch #8, Batch 801/24958 loss = 1.4291633236408234, ppl = 4.212006536209469\n","Train Epoch #8, Batch 802/24958 loss = 1.4312884497642517, ppl = 4.219633232808407\n","Train Epoch #8, Batch 803/24958 loss = 1.431594842672348, ppl = 4.220881538741042\n","Train Epoch #8, Batch 804/24958 loss = 1.429719442129135, ppl = 4.212738128936851\n","Train Epoch #8, Batch 805/24958 loss = 1.4302304470539093, ppl = 4.21488911194439\n","Train Epoch #8, Batch 806/24958 loss = 1.4312771952152252, ppl = 4.219864075563993\n","Train Epoch #8, Batch 807/24958 loss = 1.4303724551200867, ppl = 4.215461030956822\n","Train Epoch #8, Batch 808/24958 loss = 1.426291949748993, ppl = 4.200040916420659\n","Train Epoch #8, Batch 809/24958 loss = 1.4293761622905732, ppl = 4.213693246457675\n","Train Epoch #8, Batch 810/24958 loss = 1.4239405131340026, ppl = 4.19265121834946\n","Train Epoch #8, Batch 811/24958 loss = 1.4206049513816834, ppl = 4.180680531830866\n","Train Epoch #8, Batch 812/24958 loss = 1.419903039932251, ppl = 4.1776475093968015\n","Train Epoch #8, Batch 813/24958 loss = 1.4215750420093536, ppl = 4.184996533861464\n","Train Epoch #8, Batch 814/24958 loss = 1.4252273857593536, ppl = 4.2019652644064704\n","Train Epoch #8, Batch 815/24958 loss = 1.425041366815567, ppl = 4.201090366003536\n","Train Epoch #8, Batch 816/24958 loss = 1.4277136993408204, ppl = 4.21342130884776\n","Train Epoch #8, Batch 817/24958 loss = 1.425215106010437, ppl = 4.203161758379\n","Train Epoch #8, Batch 818/24958 loss = 1.4248246300220488, ppl = 4.2015148114460565\n","Train Epoch #8, Batch 819/24958 loss = 1.4252353036403655, ppl = 4.203084756561833\n","Train Epoch #8, Batch 820/24958 loss = 1.4255014252662659, ppl = 4.204142164560329\n","Train Epoch #8, Batch 821/24958 loss = 1.4261810433864595, ppl = 4.207112284475082\n","Train Epoch #8, Batch 822/24958 loss = 1.4254389607906341, ppl = 4.203576064599418\n","Train Epoch #8, Batch 823/24958 loss = 1.425580801963806, ppl = 4.204167078656688\n","Train Epoch #8, Batch 824/24958 loss = 1.4282079493999482, ppl = 4.213382007799793\n","Train Epoch #8, Batch 825/24958 loss = 1.4279318714141847, ppl = 4.212369520998345\n","Train Epoch #8, Batch 826/24958 loss = 1.429639880657196, ppl = 4.220085470625657\n","Train Epoch #8, Batch 827/24958 loss = 1.428666068315506, ppl = 4.215667772691607\n","Train Epoch #8, Batch 828/24958 loss = 1.4319143998622894, ppl = 4.230119588355424\n","Train Epoch #8, Batch 829/24958 loss = 1.4324852526187897, ppl = 4.2327994987715485\n","Train Epoch #8, Batch 830/24958 loss = 1.4340149474143982, ppl = 4.238899409932318\n","Train Epoch #8, Batch 831/24958 loss = 1.434749653339386, ppl = 4.241927250582668\n","Train Epoch #8, Batch 832/24958 loss = 1.432664805650711, ppl = 4.23175544639257\n","Train Epoch #8, Batch 833/24958 loss = 1.4334785401821137, ppl = 4.235458786868565\n","Train Epoch #8, Batch 834/24958 loss = 1.4327258121967317, ppl = 4.232211385062822\n","Train Epoch #8, Batch 835/24958 loss = 1.4316287922859192, ppl = 4.227143253256685\n","Train Epoch #8, Batch 836/24958 loss = 1.4271107757091521, ppl = 4.206240556946198\n","Train Epoch #8, Batch 837/24958 loss = 1.4287696278095245, ppl = 4.212462732206533\n","Train Epoch #8, Batch 838/24958 loss = 1.4273263466358186, ppl = 4.207178869646606\n","Train Epoch #8, Batch 839/24958 loss = 1.4274612879753112, ppl = 4.207682029417426\n","Train Epoch #8, Batch 840/24958 loss = 1.4268617820739746, ppl = 4.205125215905126\n","Train Epoch #8, Batch 841/24958 loss = 1.4244802582263947, ppl = 4.195006364889621\n","Train Epoch #8, Batch 842/24958 loss = 1.4223281729221344, ppl = 4.18575832425686\n","Train Epoch #8, Batch 843/24958 loss = 1.4254900538921356, ppl = 4.2012219159777615\n","Train Epoch #8, Batch 844/24958 loss = 1.4265090572834014, ppl = 4.205526587598012\n","Train Epoch #8, Batch 845/24958 loss = 1.4295279419422149, ppl = 4.21899801300989\n","Train Epoch #8, Batch 846/24958 loss = 1.4353089761734008, ppl = 4.243781431361563\n","Train Epoch #8, Batch 847/24958 loss = 1.4370054984092713, ppl = 4.251391204077018\n","Train Epoch #8, Batch 848/24958 loss = 1.4410981369018554, ppl = 4.268182980596601\n","Train Epoch #8, Batch 849/24958 loss = 1.4400311672687531, ppl = 4.263622651630416\n","Train Epoch #8, Batch 850/24958 loss = 1.4393142080307006, ppl = 4.260841804521725\n","Train Epoch #8, Batch 851/24958 loss = 1.4397143566608428, ppl = 4.262633829021368\n","Train Epoch #8, Batch 852/24958 loss = 1.4427788770198822, ppl = 4.275809109338174\n","Train Epoch #8, Batch 853/24958 loss = 1.4439557492733002, ppl = 4.280792611717381\n","Train Epoch #8, Batch 854/24958 loss = 1.4424949753284455, ppl = 4.274980474681869\n","Train Epoch #8, Batch 855/24958 loss = 1.4425434708595275, ppl = 4.275195871819431\n","Train Epoch #8, Batch 856/24958 loss = 1.4454681038856507, ppl = 4.286188694756887\n","Train Epoch #8, Batch 857/24958 loss = 1.445119901895523, ppl = 4.284826691269171\n","Train Epoch #8, Batch 858/24958 loss = 1.4447674536705017, ppl = 4.28340672397188\n","Train Epoch #8, Batch 859/24958 loss = 1.4471595442295075, ppl = 4.292691099004495\n","Train Epoch #8, Batch 860/24958 loss = 1.4462196600437165, ppl = 4.288447227371752\n","Train Epoch #8, Batch 861/24958 loss = 1.4441136133670807, ppl = 4.278994008617065\n","Train Epoch #8, Batch 862/24958 loss = 1.4409974575042725, ppl = 4.2653500355904574\n","Train Epoch #8, Batch 863/24958 loss = 1.441130954027176, ppl = 4.265827788304669\n","Train Epoch #8, Batch 864/24958 loss = 1.4425634443759918, ppl = 4.271440164895651\n","Train Epoch #8, Batch 865/24958 loss = 1.442508076429367, ppl = 4.271211598797678\n","Train Epoch #8, Batch 866/24958 loss = 1.441439061164856, ppl = 4.26649009570756\n","Train Epoch #8, Batch 867/24958 loss = 1.43675124168396, ppl = 4.246052407796407\n","Train Epoch #8, Batch 868/24958 loss = 1.438436805009842, ppl = 4.253020130176216\n","Train Epoch #8, Batch 869/24958 loss = 1.4363551330566406, ppl = 4.245595209506232\n","Train Epoch #8, Batch 870/24958 loss = 1.4385014140605927, ppl = 4.254689825748588\n","Train Epoch #8, Batch 871/24958 loss = 1.4394387233257293, ppl = 4.258968057952085\n","Train Epoch #8, Batch 872/24958 loss = 1.4422244107723237, ppl = 4.27169567422866\n","Train Epoch #8, Batch 873/24958 loss = 1.4436560022830962, ppl = 4.2785313150348765\n","Train Epoch #8, Batch 874/24958 loss = 1.4430167961120606, ppl = 4.275595860538385\n","Train Epoch #8, Batch 875/24958 loss = 1.4437641835212707, ppl = 4.27878429801465\n","Train Epoch #8, Batch 876/24958 loss = 1.4443026161193848, ppl = 4.280753524022489\n","Train Epoch #8, Batch 877/24958 loss = 1.4443436980247497, ppl = 4.280891949648248\n","Train Epoch #8, Batch 878/24958 loss = 1.445353134870529, ppl = 4.284450622452911\n","Train Epoch #8, Batch 879/24958 loss = 1.4451930928230285, ppl = 4.283691951480524\n","Train Epoch #8, Batch 880/24958 loss = 1.4456123387813569, ppl = 4.285435939548447\n","Train Epoch #8, Batch 881/24958 loss = 1.443653553724289, ppl = 4.276230123660538\n","Train Epoch #8, Batch 882/24958 loss = 1.4420713686943054, ppl = 4.269282181229843\n","Train Epoch #8, Batch 883/24958 loss = 1.4426347780227662, ppl = 4.27148909066568\n","Train Epoch #8, Batch 884/24958 loss = 1.44308225274086, ppl = 4.273335859728238\n","Train Epoch #8, Batch 885/24958 loss = 1.44066455245018, ppl = 4.261698838024538\n","Train Epoch #8, Batch 886/24958 loss = 1.4387828850746154, ppl = 4.253194777545966\n","Train Epoch #8, Batch 887/24958 loss = 1.4379425251483917, ppl = 4.2496935270216785\n","Train Epoch #8, Batch 888/24958 loss = 1.4369742691516876, ppl = 4.245743910313348\n","Train Epoch #8, Batch 889/24958 loss = 1.4380792689323425, ppl = 4.250431784258007\n","Train Epoch #8, Batch 890/24958 loss = 1.437224076986313, ppl = 4.246862287133797\n","Train Epoch #8, Batch 891/24958 loss = 1.4383862471580506, ppl = 4.251302075355955\n","Train Epoch #8, Batch 892/24958 loss = 1.4367063438892365, ppl = 4.243946656066459\n","Train Epoch #8, Batch 893/24958 loss = 1.4380547642707824, ppl = 4.248567415114531\n","Train Epoch #8, Batch 894/24958 loss = 1.4377067518234252, ppl = 4.24695560790403\n","Train Epoch #8, Batch 895/24958 loss = 1.440133055448532, ppl = 4.259211433898312\n","Train Epoch #8, Batch 896/24958 loss = 1.4404956936836242, ppl = 4.260689632781211\n","Train Epoch #8, Batch 897/24958 loss = 1.4400174462795257, ppl = 4.258784359021022\n","Train Epoch #8, Batch 898/24958 loss = 1.4405807375907898, ppl = 4.261147139422253\n","Train Epoch #8, Batch 899/24958 loss = 1.4375681269168854, ppl = 4.249187541898315\n","Train Epoch #8, Batch 900/24958 loss = 1.4382239663600922, ppl = 4.251929378253319\n","Train Epoch #8, Batch 901/24958 loss = 1.4417355632781983, ppl = 4.266263463730511\n","Train Epoch #8, Batch 902/24958 loss = 1.4402079856395722, ppl = 4.260620127697765\n","Train Epoch #8, Batch 903/24958 loss = 1.4415966963768005, ppl = 4.266783164492639\n","Train Epoch #8, Batch 904/24958 loss = 1.44387122631073, ppl = 4.276865714988616\n","Train Epoch #8, Batch 905/24958 loss = 1.4426701986789703, ppl = 4.27197924786763\n","Train Epoch #8, Batch 906/24958 loss = 1.4426626014709472, ppl = 4.271941231698133\n","Train Epoch #8, Batch 907/24958 loss = 1.443614512681961, ppl = 4.276584949752075\n","Train Epoch #8, Batch 908/24958 loss = 1.4473861372470855, ppl = 4.290605242414303\n","Train Epoch #8, Batch 909/24958 loss = 1.4455086302757263, ppl = 4.281799518856645\n","Train Epoch #8, Batch 910/24958 loss = 1.449579700231552, ppl = 4.296440654755337\n","Train Epoch #8, Batch 911/24958 loss = 1.4503761041164398, ppl = 4.298947050522741\n","Train Epoch #8, Batch 912/24958 loss = 1.452227041721344, ppl = 4.307428429789922\n","Train Epoch #8, Batch 913/24958 loss = 1.4517671823501588, ppl = 4.305283210117091\n","Train Epoch #8, Batch 914/24958 loss = 1.4483144187927246, ppl = 4.289090396700119\n","Train Epoch #8, Batch 915/24958 loss = 1.447858076095581, ppl = 4.287011780679049\n","Train Epoch #8, Batch 916/24958 loss = 1.4426919841766357, ppl = 4.2657967401629096\n","Train Epoch #8, Batch 917/24958 loss = 1.4430313539505004, ppl = 4.267044441660164\n","Train Epoch #8, Batch 918/24958 loss = 1.4447385263442993, ppl = 4.274743790874773\n","Train Epoch #8, Batch 919/24958 loss = 1.4445306468009949, ppl = 4.273941040830355\n","Train Epoch #8, Batch 920/24958 loss = 1.4442829763889313, ppl = 4.272956042493262\n","Train Epoch #8, Batch 921/24958 loss = 1.4452160239219665, ppl = 4.2773768880269065\n","Train Epoch #8, Batch 922/24958 loss = 1.4443276810646057, ppl = 4.273474714864209\n","Train Epoch #8, Batch 923/24958 loss = 1.4465813100337983, ppl = 4.2840821382573795\n","Train Epoch #8, Batch 924/24958 loss = 1.4478986859321594, ppl = 4.289698269911035\n","Train Epoch #8, Batch 925/24958 loss = 1.4485109281539916, ppl = 4.291981946596845\n","Train Epoch #8, Batch 926/24958 loss = 1.446785763502121, ppl = 4.284194988354044\n","Train Epoch #8, Batch 927/24958 loss = 1.4473307836055755, ppl = 4.286614369665556\n","Train Epoch #8, Batch 928/24958 loss = 1.445975399017334, ppl = 4.280009654468793\n","Train Epoch #8, Batch 929/24958 loss = 1.444755892753601, ppl = 4.274464610500042\n","Train Epoch #8, Batch 930/24958 loss = 1.4453766965866088, ppl = 4.277218946916974\n","Train Epoch #8, Batch 931/24958 loss = 1.4466651499271392, ppl = 4.283096860618666\n","Train Epoch #8, Batch 932/24958 loss = 1.4477299857139587, ppl = 4.2880271898997275\n","Train Epoch #8, Batch 933/24958 loss = 1.4464796137809754, ppl = 4.282457491085472\n","Train Epoch #8, Batch 934/24958 loss = 1.446752768754959, ppl = 4.283607772915091\n","Train Epoch #8, Batch 935/24958 loss = 1.4453109085559845, ppl = 4.277738506155349\n","Train Epoch #8, Batch 936/24958 loss = 1.446258692741394, ppl = 4.281376922380478\n","Train Epoch #8, Batch 937/24958 loss = 1.4479325854778289, ppl = 4.2887941379058825\n","Train Epoch #8, Batch 938/24958 loss = 1.4509228920936585, ppl = 4.3006559088680625\n","Train Epoch #8, Batch 939/24958 loss = 1.4531163918972014, ppl = 4.309863095915375\n","Train Epoch #8, Batch 940/24958 loss = 1.4525621879100798, ppl = 4.307632025450004\n","Train Epoch #8, Batch 941/24958 loss = 1.4548730111122132, ppl = 4.317414478312511\n","Train Epoch #8, Batch 942/24958 loss = 1.4567582941055297, ppl = 4.325405061357285\n","Train Epoch #8, Batch 943/24958 loss = 1.4539087581634522, ppl = 4.311260736397104\n","Train Epoch #8, Batch 944/24958 loss = 1.4534288704395295, ppl = 4.309178813817661\n","Train Epoch #8, Batch 945/24958 loss = 1.4506527066230774, ppl = 4.296646577862446\n","Train Epoch #8, Batch 946/24958 loss = 1.445748724937439, ppl = 4.274765851779428\n","Train Epoch #8, Batch 947/24958 loss = 1.4446476578712464, ppl = 4.269681276214538\n","Train Epoch #8, Batch 948/24958 loss = 1.4436903345584868, ppl = 4.265116983487007\n","Train Epoch #8, Batch 949/24958 loss = 1.444720162153244, ppl = 4.269510254739434\n","Train Epoch #8, Batch 950/24958 loss = 1.4454385495185853, ppl = 4.272296842432909\n","Train Epoch #8, Batch 951/24958 loss = 1.4449273371696472, ppl = 4.270020012763526\n","Train Epoch #8, Batch 952/24958 loss = 1.4438123714923858, ppl = 4.264753541197534\n","Train Epoch #8, Batch 953/24958 loss = 1.4437832581996917, ppl = 4.264623053521945\n","Train Epoch #8, Batch 954/24958 loss = 1.4455187690258027, ppl = 4.271626387380025\n","Train Epoch #8, Batch 955/24958 loss = 1.445776445865631, ppl = 4.272788568006351\n","Train Epoch #8, Batch 956/24958 loss = 1.443643910884857, ppl = 4.264463071775526\n","Train Epoch #8, Batch 957/24958 loss = 1.4461599481105805, ppl = 4.275459736031009\n","Train Epoch #8, Batch 958/24958 loss = 1.4455672311782837, ppl = 4.2731817689676115\n","Train Epoch #8, Batch 959/24958 loss = 1.4447136449813842, ppl = 4.269611281418989\n","Train Epoch #8, Batch 960/24958 loss = 1.4445570027828216, ppl = 4.2689419665126085\n","Train Epoch #8, Batch 961/24958 loss = 1.4466500866413117, ppl = 4.278330700135605\n","Train Epoch #8, Batch 962/24958 loss = 1.4488446307182312, ppl = 4.287488029626987\n","Train Epoch #8, Batch 963/24958 loss = 1.4496261739730836, ppl = 4.29041665191876\n","Train Epoch #8, Batch 964/24958 loss = 1.4477608871459962, ppl = 4.283260808640092\n","Train Epoch #8, Batch 965/24958 loss = 1.445445259809494, ppl = 4.274751272679779\n","Train Epoch #8, Batch 966/24958 loss = 1.445884393453598, ppl = 4.276629912384431\n","Train Epoch #8, Batch 967/24958 loss = 1.4446586751937867, ppl = 4.272687671468585\n","Train Epoch #8, Batch 968/24958 loss = 1.4440588939189911, ppl = 4.270072698381515\n","Train Epoch #8, Batch 969/24958 loss = 1.44645268201828, ppl = 4.278750212034514\n","Train Epoch #8, Batch 970/24958 loss = 1.4451512944698335, ppl = 4.273004759524548\n","Train Epoch #8, Batch 971/24958 loss = 1.4436343240737914, ppl = 4.266274547665695\n","Train Epoch #8, Batch 972/24958 loss = 1.442443814277649, ppl = 4.26039911813717\n","Train Epoch #8, Batch 973/24958 loss = 1.4391660594940185, ppl = 4.246076604292659\n","Train Epoch #8, Batch 974/24958 loss = 1.4385106432437897, ppl = 4.243255344840848\n","Train Epoch #8, Batch 975/24958 loss = 1.4393274474143982, ppl = 4.247023560147924\n","Train Epoch #8, Batch 976/24958 loss = 1.440057406425476, ppl = 4.249868344970773\n","Train Epoch #8, Batch 977/24958 loss = 1.4404321992397309, ppl = 4.251157819866008\n","Train Epoch #8, Batch 978/24958 loss = 1.4420472383499146, ppl = 4.257654167307805\n","Train Epoch #8, Batch 979/24958 loss = 1.441205483675003, ppl = 4.253857743042367\n","Train Epoch #8, Batch 980/24958 loss = 1.439123088121414, ppl = 4.245872730155321\n","Train Epoch #8, Batch 981/24958 loss = 1.437362427711487, ppl = 4.239004401039954\n","Train Epoch #8, Batch 982/24958 loss = 1.4382275867462158, ppl = 4.242667152150268\n","Train Epoch #8, Batch 983/24958 loss = 1.4381391596794129, ppl = 4.242312499032703\n","Train Epoch #8, Batch 984/24958 loss = 1.438546018600464, ppl = 4.244064899139111\n","Train Epoch #8, Batch 985/24958 loss = 1.4413700163364411, ppl = 4.257948793469232\n","Train Epoch #8, Batch 986/24958 loss = 1.444061254262924, ppl = 4.2706336189002245\n","Train Epoch #8, Batch 987/24958 loss = 1.4421703326702118, ppl = 4.263752779910894\n","Train Epoch #8, Batch 988/24958 loss = 1.4437804973125459, ppl = 4.270539709210009\n","Train Epoch #8, Batch 989/24958 loss = 1.4418145847320556, ppl = 4.262542072768219\n","Train Epoch #8, Batch 990/24958 loss = 1.4420363843441009, ppl = 4.263438730802123\n","Train Epoch #8, Batch 991/24958 loss = 1.4434546434879303, ppl = 4.269604694717138\n","Train Epoch #8, Batch 992/24958 loss = 1.4421731662750243, ppl = 4.264768374389732\n","Train Epoch #8, Batch 993/24958 loss = 1.4421027541160583, ppl = 4.264511358959828\n","Train Epoch #8, Batch 994/24958 loss = 1.4415230607986451, ppl = 4.261947992912901\n","Train Epoch #8, Batch 995/24958 loss = 1.439787927865982, ppl = 4.2528861051015046\n","Train Epoch #8, Batch 996/24958 loss = 1.4408839428424836, ppl = 4.257693873879746\n","Train Epoch #8, Batch 997/24958 loss = 1.4410572171211242, ppl = 4.258373672850317\n","Train Epoch #8, Batch 998/24958 loss = 1.4402411770820618, ppl = 4.254993207513386\n","Train Epoch #8, Batch 999/24958 loss = 1.4405458176136017, ppl = 4.256045494314606\n","Train Epoch #8, Batch 1000/24958 loss = 1.4405470883846283, ppl = 4.25605098343099\n","Train Epoch #8, Batch 1001/24958 loss = 1.4395743262767793, ppl = 4.251564106522389\n","Train Epoch #8, Batch 1002/24958 loss = 1.4412194335460662, ppl = 4.257678401839149\n","Train Epoch #8, Batch 1003/24958 loss = 1.4403443372249602, ppl = 4.2536956663321694\n","Train Epoch #8, Batch 1004/24958 loss = 1.4389067959785462, ppl = 4.247059578013547\n","Train Epoch #8, Batch 1005/24958 loss = 1.4408220291137694, ppl = 4.255142622656936\n","Train Epoch #8, Batch 1006/24958 loss = 1.439671186208725, ppl = 4.249704928178727\n","Train Epoch #8, Batch 1007/24958 loss = 1.4377862203121186, ppl = 4.240918938684045\n","Train Epoch #8, Batch 1008/24958 loss = 1.4371375524997712, ppl = 4.238116280255201\n","Train Epoch #8, Batch 1009/24958 loss = 1.4341694033145904, ppl = 4.227166573785047\n","Train Epoch #8, Batch 1010/24958 loss = 1.430829107761383, ppl = 4.2147345492269235\n","Train Epoch #8, Batch 1011/24958 loss = 1.4300135672092438, ppl = 4.212170349359308\n","Train Epoch #8, Batch 1012/24958 loss = 1.4285010313987732, ppl = 4.205124671128518\n","Train Epoch #8, Batch 1013/24958 loss = 1.4293077492713928, ppl = 4.208954504135423\n","Train Epoch #8, Batch 1014/24958 loss = 1.430927392244339, ppl = 4.215858308908853\n","Train Epoch #8, Batch 1015/24958 loss = 1.4303485131263733, ppl = 4.213354423516887\n","Train Epoch #8, Batch 1016/24958 loss = 1.434869396686554, ppl = 4.231283914353892\n","Train Epoch #8, Batch 1017/24958 loss = 1.43553293466568, ppl = 4.2338492253109585\n","Train Epoch #8, Batch 1018/24958 loss = 1.4359786105155945, ppl = 4.236085128168179\n","Train Epoch #8, Batch 1019/24958 loss = 1.4360405373573304, ppl = 4.23632252289471\n","Train Epoch #8, Batch 1020/24958 loss = 1.436897212266922, ppl = 4.239835889563104\n","Train Epoch #8, Batch 1021/24958 loss = 1.4345666456222534, ppl = 4.229519178748773\n","Train Epoch #8, Batch 1022/24958 loss = 1.4345528316497802, ppl = 4.229461194282437\n","Train Epoch #8, Batch 1023/24958 loss = 1.4336171531677246, ppl = 4.224765359414366\n","Train Epoch #8, Batch 1024/24958 loss = 1.432458301782608, ppl = 4.219786537277799\n","Train Epoch #8, Batch 1025/24958 loss = 1.4335312271118164, ppl = 4.224141798933546\n","Train Epoch #8, Batch 1026/24958 loss = 1.4334836649894713, ppl = 4.223945568560031\n","Train Epoch #8, Batch 1027/24958 loss = 1.4337630546092988, ppl = 4.225237871314989\n","Train Epoch #8, Batch 1028/24958 loss = 1.4334618878364562, ppl = 4.223887941818937\n","Train Epoch #8, Batch 1029/24958 loss = 1.4354816341400147, ppl = 4.233456877284148\n","Train Epoch #8, Batch 1030/24958 loss = 1.4361074459552765, ppl = 4.236412012772227\n","Train Epoch #8, Batch 1031/24958 loss = 1.4342036437988281, ppl = 4.227983139989706\n","Train Epoch #8, Batch 1032/24958 loss = 1.431883099079132, ppl = 4.21787468707977\n","Train Epoch #8, Batch 1033/24958 loss = 1.4322978234291077, ppl = 4.219645425543034\n","Train Epoch #8, Batch 1034/24958 loss = 1.4319131934642793, ppl = 4.21803466537502\n","Train Epoch #8, Batch 1035/24958 loss = 1.4336599564552308, ppl = 4.225257229573382\n","Train Epoch #8, Batch 1036/24958 loss = 1.4350452470779418, ppl = 4.231235706491791\n","Train Epoch #8, Batch 1037/24958 loss = 1.432966606616974, ppl = 4.222203822647582\n","Train Epoch #8, Batch 1038/24958 loss = 1.4330991053581237, ppl = 4.222815951295589\n","Train Epoch #8, Batch 1039/24958 loss = 1.4321232509613038, ppl = 4.218469676090523\n","Train Epoch #8, Batch 1040/24958 loss = 1.4330458235740662, ppl = 4.222253593535107\n","Train Epoch #8, Batch 1041/24958 loss = 1.430263501405716, ppl = 4.2107380599135915\n","Train Epoch #8, Batch 1042/24958 loss = 1.4275749671459197, ppl = 4.199774809420527\n","Train Epoch #8, Batch 1043/24958 loss = 1.4276056158542634, ppl = 4.199906495761416\n","Train Epoch #8, Batch 1044/24958 loss = 1.4265990841388703, ppl = 4.195851253062136\n","Train Epoch #8, Batch 1045/24958 loss = 1.4287679660320283, ppl = 4.205337393739568\n","Train Epoch #8, Batch 1046/24958 loss = 1.4285366106033326, ppl = 4.204546812122921\n","Train Epoch #8, Batch 1047/24958 loss = 1.4246764886379242, ppl = 4.190557873898035\n","Train Epoch #8, Batch 1048/24958 loss = 1.4247590923309326, ppl = 4.19093471254048\n","Train Epoch #8, Batch 1049/24958 loss = 1.4241701591014861, ppl = 4.188367071439551\n","Train Epoch #8, Batch 1050/24958 loss = 1.4244227588176728, ppl = 4.1893954423099755\n","Train Epoch #8, Batch 1051/24958 loss = 1.423597651720047, ppl = 4.185957507642916\n","Train Epoch #8, Batch 1052/24958 loss = 1.4250385892391204, ppl = 4.1928779284922255\n","Train Epoch #8, Batch 1053/24958 loss = 1.423590785264969, ppl = 4.186845444603091\n","Train Epoch #8, Batch 1054/24958 loss = 1.4234301733970642, ppl = 4.18614509740111\n","Train Epoch #8, Batch 1055/24958 loss = 1.4222236716747283, ppl = 4.180952626365997\n","Train Epoch #8, Batch 1056/24958 loss = 1.4220785439014434, ppl = 4.180447980329628\n","Train Epoch #8, Batch 1057/24958 loss = 1.4204085552692414, ppl = 4.172844914586054\n","Train Epoch #8, Batch 1058/24958 loss = 1.422581729888916, ppl = 4.181900251757616\n","Train Epoch #8, Batch 1059/24958 loss = 1.4227476966381074, ppl = 4.182570819883623\n","Train Epoch #8, Batch 1060/24958 loss = 1.4224815547466279, ppl = 4.181457390434642\n","Train Epoch #8, Batch 1061/24958 loss = 1.4203296625614166, ppl = 4.171832206651192\n","Train Epoch #8, Batch 1062/24958 loss = 1.419899332523346, ppl = 4.1698747237076885\n","Train Epoch #8, Batch 1063/24958 loss = 1.4214649939537047, ppl = 4.176477248820328\n","Train Epoch #8, Batch 1064/24958 loss = 1.4247702360153198, ppl = 4.190146110916186\n","Train Epoch #8, Batch 1065/24958 loss = 1.4262306690216064, ppl = 4.1952813959047015\n","Train Epoch #8, Batch 1066/24958 loss = 1.4226046371459962, ppl = 4.181982440796627\n","Train Epoch #8, Batch 1067/24958 loss = 1.4257705879211426, ppl = 4.193242189534403\n","Train Epoch #8, Batch 1068/24958 loss = 1.4249727761745452, ppl = 4.189998222154806\n","Train Epoch #8, Batch 1069/24958 loss = 1.424084451198578, ppl = 4.18653341909154\n","Train Epoch #8, Batch 1070/24958 loss = 1.4243101143836976, ppl = 4.1874768759314485\n","Train Epoch #8, Batch 1071/24958 loss = 1.4255745494365692, ppl = 4.193014677102197\n","Train Epoch #8, Batch 1072/24958 loss = 1.4239867436885834, ppl = 4.186191709034644\n","Train Epoch #8, Batch 1073/24958 loss = 1.4256070601940154, ppl = 4.192686787756148\n","Train Epoch #8, Batch 1074/24958 loss = 1.4246653032302856, ppl = 4.188943396382323\n","Train Epoch #8, Batch 1075/24958 loss = 1.4230768525600432, ppl = 4.1818871916924625\n","Train Epoch #8, Batch 1076/24958 loss = 1.4241976845264435, ppl = 4.186680239498461\n","Train Epoch #8, Batch 1077/24958 loss = 1.4271518695354461, ppl = 4.198727819978127\n","Train Epoch #8, Batch 1078/24958 loss = 1.4280210733413696, ppl = 4.202683464725848\n","Train Epoch #8, Batch 1079/24958 loss = 1.4286717367172241, ppl = 4.205589791676637\n","Train Epoch #8, Batch 1080/24958 loss = 1.4311893689632416, ppl = 4.21546435049554\n","Train Epoch #8, Batch 1081/24958 loss = 1.43265119433403, ppl = 4.2210800995163815\n","Train Epoch #8, Batch 1082/24958 loss = 1.4319215929508209, ppl = 4.217970520538018\n","Train Epoch #8, Batch 1083/24958 loss = 1.4346685218811035, ppl = 4.2305933807557325\n","Train Epoch #8, Batch 1084/24958 loss = 1.4352472496032715, ppl = 4.233212143220113\n","Train Epoch #8, Batch 1085/24958 loss = 1.4341429090499878, ppl = 4.227311893905903\n","Train Epoch #8, Batch 1086/24958 loss = 1.431912716627121, ppl = 4.216565171282439\n","Train Epoch #8, Batch 1087/24958 loss = 1.4343833887577058, ppl = 4.225829827679766\n","Train Epoch #8, Batch 1088/24958 loss = 1.4342304456233979, ppl = 4.2251371816160175\n","Train Epoch #8, Batch 1089/24958 loss = 1.436273992061615, ppl = 4.233484059381161\n","Train Epoch #8, Batch 1090/24958 loss = 1.436700440645218, ppl = 4.235264933714096\n","Train Epoch #8, Batch 1091/24958 loss = 1.4329870355129242, ppl = 4.220800289915913\n","Train Epoch #8, Batch 1092/24958 loss = 1.4360141932964325, ppl = 4.23330593322011\n","Train Epoch #8, Batch 1093/24958 loss = 1.4382048892974852, ppl = 4.2422143847429705\n","Train Epoch #8, Batch 1094/24958 loss = 1.4372773349285126, ppl = 4.238409713731398\n","Train Epoch #8, Batch 1095/24958 loss = 1.4375954616069793, ppl = 4.239955643527702\n","Train Epoch #8, Batch 1096/24958 loss = 1.4379446351528167, ppl = 4.241601359932406\n","Train Epoch #8, Batch 1097/24958 loss = 1.4402677035331726, ppl = 4.251950076027482\n","Train Epoch #8, Batch 1098/24958 loss = 1.4409078931808472, ppl = 4.254578580913067\n","Train Epoch #8, Batch 1099/24958 loss = 1.4432494199275971, ppl = 4.263831552821538\n","Train Epoch #8, Batch 1100/24958 loss = 1.4430998599529266, ppl = 4.263190292297228\n","Train Epoch #8, Batch 1101/24958 loss = 1.4423564636707307, ppl = 4.260043842776225\n","Train Epoch #8, Batch 1102/24958 loss = 1.4426480412483216, ppl = 4.261236420381214\n","Train Epoch #8, Batch 1103/24958 loss = 1.4425873720645905, ppl = 4.260973008130102\n","Train Epoch #8, Batch 1104/24958 loss = 1.4421208381652832, ppl = 4.259016444025218\n","Train Epoch #8, Batch 1105/24958 loss = 1.4417243313789367, ppl = 4.257213643969133\n","Train Epoch #8, Batch 1106/24958 loss = 1.4406017982959747, ppl = 4.252479728143915\n","Train Epoch #8, Batch 1107/24958 loss = 1.440782734155655, ppl = 4.253253071660024\n","Train Epoch #8, Batch 1108/24958 loss = 1.4426436293125153, ppl = 4.261806559272256\n","Train Epoch #8, Batch 1109/24958 loss = 1.4442624068260193, ppl = 4.267374360525271\n","Train Epoch #8, Batch 1110/24958 loss = 1.447129831314087, ppl = 4.2777843516047005\n","Train Epoch #8, Batch 1111/24958 loss = 1.4509656035900116, ppl = 4.291892871499938\n","Train Epoch #8, Batch 1112/24958 loss = 1.4507491195201874, ppl = 4.290968827888765\n","Train Epoch #8, Batch 1113/24958 loss = 1.449761233329773, ppl = 4.286320573597488\n","Train Epoch #8, Batch 1114/24958 loss = 1.4475367307662963, ppl = 4.277112087215537\n","Train Epoch #8, Batch 1115/24958 loss = 1.4449733734130858, ppl = 4.267611932929729\n","Train Epoch #8, Batch 1116/24958 loss = 1.4452156686782838, ppl = 4.268820968641844\n","Train Epoch #8, Batch 1117/24958 loss = 1.4435775482654571, ppl = 4.262783386243844\n","Train Epoch #8, Batch 1118/24958 loss = 1.4409762060642242, ppl = 4.25103415341333\n","Train Epoch #8, Batch 1119/24958 loss = 1.441145759820938, ppl = 4.251691706162689\n","Train Epoch #8, Batch 1120/24958 loss = 1.4403547930717469, ppl = 4.248437291393472\n","Train Epoch #8, Batch 1121/24958 loss = 1.439037836790085, ppl = 4.243586891907222\n","Train Epoch #8, Batch 1122/24958 loss = 1.4403277003765107, ppl = 4.249361824442808\n","Train Epoch #8, Batch 1123/24958 loss = 1.4391892504692079, ppl = 4.244210284562849\n","Train Epoch #8, Batch 1124/24958 loss = 1.4403463768959046, ppl = 4.249181258659653\n","Train Epoch #8, Batch 1125/24958 loss = 1.4388529133796693, ppl = 4.243242403343021\n","Train Epoch #8, Batch 1126/24958 loss = 1.4388667345046997, ppl = 4.243299329956576\n","Train Epoch #8, Batch 1127/24958 loss = 1.4366321539878846, ppl = 4.233906798537937\n","Train Epoch #8, Batch 1128/24958 loss = 1.4341962003707887, ppl = 4.224361400161203\n","Train Epoch #8, Batch 1129/24958 loss = 1.430388367176056, ppl = 4.207792274380601\n","Train Epoch #8, Batch 1130/24958 loss = 1.4308922827243804, ppl = 4.210309940860345\n","Train Epoch #8, Batch 1131/24958 loss = 1.4322848308086396, ppl = 4.21631547063863\n","Train Epoch #8, Batch 1132/24958 loss = 1.4349422824382783, ppl = 4.228096388550981\n","Train Epoch #8, Batch 1133/24958 loss = 1.4341451859474181, ppl = 4.224756849541861\n","Train Epoch #8, Batch 1134/24958 loss = 1.43221431016922, ppl = 4.217543961224271\n","Train Epoch #8, Batch 1135/24958 loss = 1.4336869537830352, ppl = 4.2246939274267525\n","Train Epoch #8, Batch 1136/24958 loss = 1.4315492391586304, ppl = 4.215799046695724\n","Train Epoch #8, Batch 1137/24958 loss = 1.4291939926147461, ppl = 4.2075959759192845\n","Train Epoch #8, Batch 1138/24958 loss = 1.4250556647777557, ppl = 4.191835773418054\n","Train Epoch #8, Batch 1139/24958 loss = 1.4234184622764587, ppl = 4.185432450382369\n","Train Epoch #8, Batch 1140/24958 loss = 1.421551855802536, ppl = 4.178121552344383\n","Train Epoch #8, Batch 1141/24958 loss = 1.4222181987762452, ppl = 4.1805950242297545\n","Train Epoch #8, Batch 1142/24958 loss = 1.4248706519603729, ppl = 4.191390782918586\n","Train Epoch #8, Batch 1143/24958 loss = 1.4254173195362092, ppl = 4.193808703544029\n","Train Epoch #8, Batch 1144/24958 loss = 1.425518296957016, ppl = 4.194197362188921\n","Train Epoch #8, Batch 1145/24958 loss = 1.4229371309280396, ppl = 4.183129314907083\n","Train Epoch #8, Batch 1146/24958 loss = 1.4255197525024415, ppl = 4.193082944981983\n","Train Epoch #8, Batch 1147/24958 loss = 1.4276224172115326, ppl = 4.20003155273996\n","Train Epoch #8, Batch 1148/24958 loss = 1.4280083084106445, ppl = 4.201833822472785\n","Train Epoch #8, Batch 1149/24958 loss = 1.430926994085312, ppl = 4.216179569837007\n","Train Epoch #8, Batch 1150/24958 loss = 1.43116637468338, ppl = 4.217178391368245\n","Train Epoch #8, Batch 1151/24958 loss = 1.4329734241962433, ppl = 4.225095151877813\n","Train Epoch #8, Batch 1152/24958 loss = 1.4309035968780517, ppl = 4.215453207524406\n","Train Epoch #8, Batch 1153/24958 loss = 1.4290889525413513, ppl = 4.209027052036083\n","Train Epoch #8, Batch 1154/24958 loss = 1.4303413951396942, ppl = 4.214798456929885\n","Train Epoch #8, Batch 1155/24958 loss = 1.4296516585350036, ppl = 4.21209962507813\n","Train Epoch #8, Batch 1156/24958 loss = 1.4281681048870087, ppl = 4.207340056263865\n","Train Epoch #8, Batch 1157/24958 loss = 1.4309716880321504, ppl = 4.220877018501362\n","Train Epoch #8, Batch 1158/24958 loss = 1.4301112735271453, ppl = 4.217054904457409\n","Train Epoch #8, Batch 1159/24958 loss = 1.429764769077301, ppl = 4.215667423438326\n","Train Epoch #8, Batch 1160/24958 loss = 1.4309884750843047, ppl = 4.221041179150733\n","Train Epoch #8, Batch 1161/24958 loss = 1.4312214064598083, ppl = 4.22198593373518\n","Train Epoch #8, Batch 1162/24958 loss = 1.4293404567241668, ppl = 4.21435300458556\n","Train Epoch #8, Batch 1163/24958 loss = 1.4271235978603363, ppl = 4.205294528701125\n","Train Epoch #8, Batch 1164/24958 loss = 1.427794064283371, ppl = 4.208662309358358\n","Train Epoch #8, Batch 1165/24958 loss = 1.429272335767746, ppl = 4.214683186288185\n","Train Epoch #8, Batch 1166/24958 loss = 1.430792397260666, ppl = 4.219678444015191\n","Train Epoch #8, Batch 1167/24958 loss = 1.4297309374809266, ppl = 4.215499965871874\n","Train Epoch #8, Batch 1168/24958 loss = 1.4299646711349487, ppl = 4.216423691968505\n","Train Epoch #8, Batch 1169/24958 loss = 1.4306186830997467, ppl = 4.2189444951835045\n","Train Epoch #8, Batch 1170/24958 loss = 1.4316142833232879, ppl = 4.2233707442132\n","Train Epoch #8, Batch 1171/24958 loss = 1.4303660821914672, ppl = 4.2178996960277315\n","Train Epoch #8, Batch 1172/24958 loss = 1.4312984621524811, ppl = 4.221774392541273\n","Train Epoch #8, Batch 1173/24958 loss = 1.43031604886055, ppl = 4.217711546777712\n","Train Epoch #8, Batch 1174/24958 loss = 1.4315008544921874, ppl = 4.2224796401374505\n","Train Epoch #8, Batch 1175/24958 loss = 1.430246161222458, ppl = 4.217646545866931\n","Train Epoch #8, Batch 1176/24958 loss = 1.4275102365016936, ppl = 4.2068264661448005\n","Train Epoch #8, Batch 1177/24958 loss = 1.4271086573600769, ppl = 4.2049724499952115\n","Train Epoch #8, Batch 1178/24958 loss = 1.4255091834068299, ppl = 4.197949147773249\n","Train Epoch #8, Batch 1179/24958 loss = 1.4239830875396728, ppl = 4.191419272286798\n","Train Epoch #8, Batch 1180/24958 loss = 1.4226682269573212, ppl = 4.185953023521261\n","Train Epoch #8, Batch 1181/24958 loss = 1.4217105746269225, ppl = 4.1821821031396516\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"yqipisyjN0v2","executionInfo":{"status":"ok","timestamp":1622351874599,"user_tz":-540,"elapsed":1884,"user":{"displayName":"최석웅","photoUrl":"","userId":"05234760535644650462"}}},"source":["  ## load_model \n","SAVE_PATH = './model_checkpoints/cur_epoch_11_train_loss_0_train_ppl_0_valid_loss_1_valid_ppl_4.pt'\n","checkpoint = torch.load(SAVE_PATH)\n","\n","## Hyper Parameter for Data \n","train_src_fn = checkpoint['hyper_params']['train_src_fn']\n","train_tgt_fn = checkpoint['hyper_params']['train_tgt_fn']\n","valid_src_fn = checkpoint['hyper_params']['valid_src_fn']\n","valid_tgt_fn = checkpoint['hyper_params']['valid_tgt_fn']\n","max_len = checkpoint['hyper_params']['max_len']\n","init_token = checkpoint['hyper_params']['init_token']\n","eos_token= checkpoint['hyper_params']['eos_token']\n","batch_size= checkpoint['hyper_params']['batch_size']\n","device = checkpoint['hyper_params']['device']\n","max_vocab = checkpoint['hyper_params']['max_vocab']\n","\n","num_epochs =checkpoint['hyper_params']['num_epochs']\n","\n","train_src_vocab = checkpoint['hyper_params']['train_src_vocab']\n","train_tgt_vocab = checkpoint['hyper_params']['train_tgt_vocab']\n","\n","input_size = checkpoint['hyper_params']['input_size']\n","output_size = checkpoint['hyper_params']['output_size']\n","\n","\n","embed_size = checkpoint['hyper_params']['embed_size']\n","hidden_size = checkpoint['hyper_params']['hidden_size']\n","num_layer = checkpoint['hyper_params']['num_layer']\n","enc_bidirectional = checkpoint['hyper_params']['enc_bidirectional']\n","drop_out = checkpoint['hyper_params']['drop_out']\n","max_clip_norm = checkpoint['hyper_params']['max_clip_norm']\n","\n","\n","beam_size = checkpoint['hyper_params']['beam_size']\n","lp_alpha = checkpoint['hyper_params']['lp_alpha']\n","lp_length = checkpoint['hyper_params']['lp_length']\n","cp_beta = checkpoint['hyper_params']['cp_beta']\n","cp_min_val = checkpoint['hyper_params']['cp_min_val']\n","\n","learning_rate = checkpoint['hyper_params']['learning_rate']\n","grad_update_period = checkpoint['hyper_params']['grad_update_period'] \n","\n","##metric \n","train_loss_sum = checkpoint['train_loss_sum']\n","train_ppl_sum = checkpoint['train_ppl_sum']\n","\n","valid_loss_sum = checkpoint['valid_loss_sum']\n","valid_ppl_sum = checkpoint['valid_ppl_sum']"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"L2ADqX0gwI2p","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1622351956818,"user_tz":-540,"elapsed":78156,"user":{"displayName":"최석웅","photoUrl":"","userId":"05234760535644650462"}},"outputId":"7c3cb518-e384-4fa0-c790-8917c43fd810"},"source":["train_dl =  DataLoader(train_src_fn, train_tgt_fn, max_len, init_token, eos_token, batch_size, -1, max_vocab)   ## device = -1 because gpu memory leakage -> batchwise loading \n","test_valid_dl =  DataLoader(valid_src_fn, valid_tgt_fn, max_len, init_token, eos_token, batch_size, -1, max_vocab)   ## device = -1 because gpu memory leakage -> batchwise loading \n","\n","train_dl.set_vocab_for_reproduction(train_src_vocab, train_tgt_vocab)\n","test_valid_dl.set_vocab_for_reproduction(train_src_vocab, train_tgt_vocab)\n","\n","tl_model = TranslationModel(input_size, output_size, embed_size, hidden_size, beam_size, num_layer, enc_bidirectional, drop_out, lp_alpha, lp_length, cp_beta, cp_min_val, max_len)\n","tl_model.load_state_dict(checkpoint['model_state_dict'])\n","tl_model.to(device)\n","\n","## LogSoftmax + NLLLoss \n","loss_weight = torch.ones(tl_model.output_size)\n","loss_weight[train_dl.PAD_ID] = 0.\n","crit = nn.NLLLoss(loss_weight, reduction='sum').to(device)\n","optimizer = optim.Adam(tl_model.parameters(), lr = learning_rate, )\n","optimizer.load_state_dict(checkpoint['optim_state_dict'])\n","\n","## for amp \n","scaler = GradScaler()"],"execution_count":18,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torchtext/data/field.py:150: UserWarning: Field class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n","  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n","/usr/local/lib/python3.7/dist-packages/torchtext/data/example.py:78: UserWarning: Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n","  warnings.warn('Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.', UserWarning)\n","/usr/local/lib/python3.7/dist-packages/torchtext/data/iterator.py:48: UserWarning: BucketIterator class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n","  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"YWqaFC321c_q","executionInfo":{"status":"ok","timestamp":1622366063010,"user_tz":-540,"elapsed":249,"user":{"displayName":"최석웅","photoUrl":"","userId":"05234760535644650462"}}},"source":["## to save \n","## Hyper Parameters \n","hyper_params = {'train_src_fn' : train_src_fn, 'train_tgt_fn' : train_tgt_fn, 'valid_src_fn' : valid_src_fn,\n","                'valid_tgt_fn' : valid_tgt_fn, 'max_len' : max_len, 'init_token' : init_token,\n","                'eos_token' : eos_token, 'batch_size' : batch_size, 'device' : device, 'max_vocab' : max_vocab,\n","                'num_epochs' : num_epochs, 'train_src_vocab' : train_dl.src.vocab, 'train_tgt_vocab':train_dl.tgt.vocab , \n","                'input_size' : input_size, 'output_size' : output_size, 'embed_size' : embed_size, 'hidden_size' : hidden_size,\n","                'num_layer' : num_layer, 'enc_bidirectional' : enc_bidirectional, 'drop_out' : drop_out, 'max_clip_norm': max_clip_norm, 'beam_size' : beam_size,\n","                'lp_alpha' : lp_alpha, 'lp_length' : lp_length, 'cp_beta' : cp_beta, 'cp_min_val' : cp_min_val, 'learning_rate' : learning_rate,\n","                'grad_update_period' : grad_update_period\n","                }\n","\n"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"2ra00GXSuM_B","colab":{"base_uri":"https://localhost:8080/"},"outputId":"85101eee-3750-4e9c-b245-82650a2fb5f4"},"source":["#loss/ ppl \n","train_loss_sum = 0\n","train_ppl_sum = 0\n","\n","valid_loss_sum = 0\n","valid_ppl_sum = 0\n","\n","train_loss_list = list()\n","train_ppl_list = list() \n","\n","valid_loss_list = list()\n","valid_ppl_list = list()\n","\n","train_loss_sum_list = list() \n","train_ppl_sum_list = list()\n","valid_loss_sum_list = list()\n","valid_ppl_sum_list = list()\n","\n","for cur_epoch in range(12,num_epochs) :\n","  tl_model.train()\n","\n","  train_loss_sum = 0.; train_ppl_sum = 0.; valid_loss_sum = 0.; valid_ppl_sum =0.\n","  for i, train_batch in enumerate(train_dl.data_iter) :\n","    src = train_batch.src; tgt = train_batch.tgt\n","    ## |src|\n","    ##  |src[0]| = (batch_size, length, )\n","    ##  |src[1]| = (batch_size) \n","    ## |tgt|\n","    ##  |tgt[0]| = (batch_size, length, ) \n","    ##  |tgt[1]| = (batch_size)\n","\n","    ## this is for gpu memory leakage \n","    src = (src[0].to(device), src[1]);\n","    tgt = (tgt[0].to(device), tgt[1]);\n","\n","    \n","    with autocast() :\n","      ## FeedForward \n","      log_probs = tl_model(src, tgt[0][:,:-1])  ## extract <EOS> from target \n","      ## |log_probs| = (batch_size, length, output_size)\n","\n","      log_probs = log_probs.view(-1, log_probs.size(-1))\n","      ## |log_probs| = (batch_size * length, output_size)\n","\n","      loss = crit(log_probs, tgt[0][:,1:].contiguous().view(-1))\n","      loss_for_gradient = loss / (src[0].size(0) * grad_update_period)\n","    \n","    ## Scale loss. Calls backward() on scaled loss to create scaled gradients. \n","    ## Backward passes under autocast are not recommended. \n","    ## Backward ops run in the same dtype autocast chose for corresponding forward ops.\n","    ## Accumulates scaled gradients \n","    scaler.scale(loss_for_gradient).backward()\n","\n","    ## update for every periods\n","    if (i+1) % grad_update_period == 0 :\n","      ## Gradient Clipping because Gradient Explood or Vanish in RNN based Models \n","      tc_utils.clip_grad_norm_(tl_model.parameters(), max_clip_norm)\n","\n","      ## scaler.step() first unscale the gradients of the optimizer's assigned params. \n","      ## If these gradients do not contain infs or NaNs, optimizer.step() is then called, \n","      ## otherwise optimizer.step() is skipped \n","      scaler.step(optimizer)\n","\n","      ## Gradient Descent\n","\n","      ## Updates the scale for next iteration. \n","      scaler.update()  \n","\n","      ## Clear Gradient for next period \n","      optimizer.zero_grad()\n","\n","    ## Calculate loss and perplexity \n","\n","    all_words_num = int(train_batch.tgt[1].sum())\n","    ## tgt[1] is length of each instance \n","\n","    ## loss mean for each word in mini batch \n","    loss = float(loss / all_words_num)\n","    ppl = np.exp(loss)\n","    \n","    train_loss_list.append(loss)\n","    train_ppl_list.append(ppl)\n","    print_st = max(0, len(train_loss_list) - 100)\n","    print(f'Train Epoch #{cur_epoch+1}, Batch {i+1}/{len(train_dl.data_iter)} loss = {sum(train_loss_list[print_st:])/len(train_loss_list[print_st:])}, ppl = {sum(train_ppl_list[print_st:])/len(train_ppl_list[print_st:])}')  \n","    \n","  train_loss_sum_list.append(train_loss_sum)\n","  train_ppl_sum_list.append(train_ppl_sum)\n","\n","  tl_model.eval()\n","  for i, valid_batch in enumerate(test_valid_dl.data_iter) :\n","    src = valid_batch.src;  tgt = valid_batch.tgt\n","    ## |src| \n","    ##   |src[0]| = (batch_size, length, )\n","    ##   |src[1]| = (batch_size, )\n","    ## |tgt| \n","    ##   |tgt[0]| = (batch_size, length, )\n","    ##   |tgt[1]| = (batch_size,)\n","\n","    with torch.no_grad() :\n","      src = (src[0].to(device), src[1])\n","      tgt = (tgt[0].to(device), tgt[1])\n","      ## |src[0]| = (length, batch_size)\n","      ## |tgt[0]| = (length, batch_size)\n","      \n","      with autocast() : \n","      ## FeedForward \n","       log_probs = tl_model(src, tgt[0][:,:-1]) ## extract <EOS> from target \n","       ## |log_probs| = (batch_size * length, output_size)\n","       \n","       log_probs = log_probs.view(-1, log_probs.size(-1))\n","       ## |log_probs| = (batch_size * length, output_size)\n","       \n","       loss = crit(log_probs, tgt[0][:,1:].contiguous().view(-1)) \n","       loss_for_gradient = loss / (src[0].size(0) * grad_update_period)\n","    \n","    \n","    ## Calculate loss and perplexity \n","    ## loss mean for each word in mini batch  \n","    all_words_num = int(tgt[1].sum())\n","    loss = float(loss/all_words_num)\n","    ppl = np.exp(loss) \n","    \n","    valid_loss_list.append(float(loss))\n","    valid_ppl_list.append(float(ppl))\n","    \n","    print_st = max(0, len(valid_loss_list) - 100)\n","    print(f'Valid Epoch #{cur_epoch+1}, Batch {i+1}/{len(test_valid_dl.data_iter)} loss = {sum(valid_loss_list[print_st:])/len(valid_loss_list[print_st:])}, ppl = {sum(valid_ppl_list[print_st:])/len(valid_ppl_list[print_st:])}')\n","\n","    valid_loss_sum += loss\n","    valid_ppl_sum += ppl\n","    \n","  valid_loss_sum_list.append(valid_loss_sum)\n","  valid_ppl_sum_list.append(valid_ppl_sum)\n","\n","  ## Save Model for each iteration \n","  SAVE_PATH = f'./model_checkpoints/cur_epoch_{cur_epoch+1}_train_loss_{int(train_loss_sum/len(train_dl.data_iter))}_train_ppl_{int(train_ppl_sum/len(train_dl.data_iter))}_valid_loss_{int(valid_loss_sum/len(test_valid_dl.data_iter))}_valid_ppl_{int(valid_ppl_sum/len(test_valid_dl.data_iter))}.pt'\n","  torch.save({'hyper_params' : hyper_params, 'train_loss_sum' : train_loss_sum, 'train_ppl_sum' : train_ppl_sum, 'valid_loss_sum' : valid_loss_sum, 'valid_ppl_sum' : valid_ppl_sum,\n","              'model_state_dict' : tl_model.state_dict(), 'optim_state_dict' : optimizer.state_dict(), 'grad_scaler_state_dict' : scaler.state_dict()}, SAVE_PATH)\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torchtext/data/batch.py:23: UserWarning: Batch class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n","  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\u001b[1;30;43m스트리밍 출력 내용이 길어서 마지막 5000줄이 삭제되었습니다.\u001b[0m\n","Train Epoch #17, Batch 3999/24958 loss = 1.2438573920726776, ppl = 3.4923436927872324\n","Train Epoch #17, Batch 4000/24958 loss = 1.2436955642700196, ppl = 3.491793963830811\n","Train Epoch #17, Batch 4001/24958 loss = 1.2427750408649445, ppl = 3.48882126261266\n","Train Epoch #17, Batch 4002/24958 loss = 1.242962054014206, ppl = 3.48950904361222\n","Train Epoch #17, Batch 4003/24958 loss = 1.2417497885227204, ppl = 3.485440927672621\n","Train Epoch #17, Batch 4004/24958 loss = 1.2412441551685334, ppl = 3.4837914917827857\n","Train Epoch #17, Batch 4005/24958 loss = 1.2417908883094788, ppl = 3.4856116075581793\n","Train Epoch #17, Batch 4006/24958 loss = 1.2416067230701446, ppl = 3.4849972720913365\n","Train Epoch #17, Batch 4007/24958 loss = 1.240616512298584, ppl = 3.481924121856646\n","Train Epoch #17, Batch 4008/24958 loss = 1.2396324396133422, ppl = 3.4783748275531257\n","Train Epoch #17, Batch 4009/24958 loss = 1.2388035178184509, ppl = 3.4750870103915177\n","Train Epoch #17, Batch 4010/24958 loss = 1.2406733465194701, ppl = 3.4813561091938907\n","Train Epoch #17, Batch 4011/24958 loss = 1.2384122967720033, ppl = 3.4730307888386474\n","Train Epoch #17, Batch 4012/24958 loss = 1.2418032228946685, ppl = 3.4840323944879983\n","Train Epoch #17, Batch 4013/24958 loss = 1.2403590214252471, ppl = 3.4783020956950192\n","Train Epoch #17, Batch 4014/24958 loss = 1.2395957750082016, ppl = 3.47623964627376\n","Train Epoch #17, Batch 4015/24958 loss = 1.2408217138051987, ppl = 3.4801488411011117\n","Train Epoch #17, Batch 4016/24958 loss = 1.2388325315713882, ppl = 3.4728790724454\n","Train Epoch #17, Batch 4017/24958 loss = 1.2375835293531419, ppl = 3.468346050918417\n","Train Epoch #17, Batch 4018/24958 loss = 1.2375684541463852, ppl = 3.4682908434621154\n","Train Epoch #17, Batch 4019/24958 loss = 1.2371351212263106, ppl = 3.4667282501605188\n","Train Epoch #17, Batch 4020/24958 loss = 1.234673975110054, ppl = 3.459180137825558\n","Train Epoch #17, Batch 4021/24958 loss = 1.2367110651731492, ppl = 3.4666110835560513\n","Train Epoch #17, Batch 4022/24958 loss = 1.2345635694265367, ppl = 3.45909806482242\n","Train Epoch #17, Batch 4023/24958 loss = 1.2348070019483566, ppl = 3.459923302495907\n","Train Epoch #17, Batch 4024/24958 loss = 1.2362809759378433, ppl = 3.4650684095645334\n","Train Epoch #17, Batch 4025/24958 loss = 1.2386914139986038, ppl = 3.4735820346975235\n","Train Epoch #17, Batch 4026/24958 loss = 1.240111032128334, ppl = 3.4784555687597134\n","Train Epoch #17, Batch 4027/24958 loss = 1.2393754810094832, ppl = 3.4759807012569484\n","Train Epoch #17, Batch 4028/24958 loss = 1.2407690876722335, ppl = 3.4813220534016422\n","Train Epoch #17, Batch 4029/24958 loss = 1.2407825237512589, ppl = 3.4813640397100274\n","Train Epoch #17, Batch 4030/24958 loss = 1.2401350039243697, ppl = 3.47915697726763\n","Train Epoch #17, Batch 4031/24958 loss = 1.2418575149774551, ppl = 3.4846076006513558\n","Train Epoch #17, Batch 4032/24958 loss = 1.2396163600683212, ppl = 3.476839735241437\n","Train Epoch #17, Batch 4033/24958 loss = 1.2379970651865007, ppl = 3.4710546469027572\n","Train Epoch #17, Batch 4034/24958 loss = 1.2396031361818314, ppl = 3.476701758088737\n","Train Epoch #17, Batch 4035/24958 loss = 1.2421528726816178, ppl = 3.487043425102195\n","Train Epoch #17, Batch 4036/24958 loss = 1.2407632511854172, ppl = 3.4822156846768952\n","Train Epoch #17, Batch 4037/24958 loss = 1.2403364533185959, ppl = 3.4804842962327944\n","Train Epoch #17, Batch 4038/24958 loss = 1.2399523574113847, ppl = 3.4791860599240825\n","Train Epoch #17, Batch 4039/24958 loss = 1.2426092785596847, ppl = 3.4884402026393286\n","Train Epoch #17, Batch 4040/24958 loss = 1.2437721878290176, ppl = 3.4928146873966903\n","Train Epoch #17, Batch 4041/24958 loss = 1.2439034551382064, ppl = 3.4933001466704003\n","Train Epoch #17, Batch 4042/24958 loss = 1.2440355604887008, ppl = 3.4937794301833858\n","Train Epoch #17, Batch 4043/24958 loss = 1.245923632979393, ppl = 3.5003484071403146\n","Train Epoch #17, Batch 4044/24958 loss = 1.244031565785408, ppl = 3.493911800117869\n","Train Epoch #17, Batch 4045/24958 loss = 1.2468014734983444, ppl = 3.5036716276412165\n","Train Epoch #17, Batch 4046/24958 loss = 1.247327999472618, ppl = 3.5053392179863305\n","Train Epoch #17, Batch 4047/24958 loss = 1.248138273358345, ppl = 3.5083089395347393\n","Train Epoch #17, Batch 4048/24958 loss = 1.248337225317955, ppl = 3.508969984396096\n","Train Epoch #17, Batch 4049/24958 loss = 1.2475894993543626, ppl = 3.5067117602476863\n","Train Epoch #17, Batch 4050/24958 loss = 1.2455929845571518, ppl = 3.4997787386150025\n","Train Epoch #17, Batch 4051/24958 loss = 1.2473223668336868, ppl = 3.505758808548797\n","Train Epoch #17, Batch 4052/24958 loss = 1.2462626272439956, ppl = 3.5017853765763793\n","Train Epoch #17, Batch 4053/24958 loss = 1.2455578345060347, ppl = 3.4994909837737844\n","Train Epoch #17, Batch 4054/24958 loss = 1.2441770499944687, ppl = 3.494914766847869\n","Train Epoch #17, Batch 4055/24958 loss = 1.2464875930547714, ppl = 3.5039268545192077\n","Train Epoch #17, Batch 4056/24958 loss = 1.2482019072771073, ppl = 3.509651812055808\n","Train Epoch #17, Batch 4057/24958 loss = 1.2464758414030075, ppl = 3.5040998877360727\n","Train Epoch #17, Batch 4058/24958 loss = 1.25044608771801, ppl = 3.519013648128604\n","Train Epoch #17, Batch 4059/24958 loss = 1.251642012000084, ppl = 3.522966904256701\n","Train Epoch #17, Batch 4060/24958 loss = 1.2521580666303636, ppl = 3.52496336541814\n","Train Epoch #17, Batch 4061/24958 loss = 1.250759451985359, ppl = 3.5207665801834365\n","Train Epoch #17, Batch 4062/24958 loss = 1.2520259445905686, ppl = 3.524883318304086\n","Train Epoch #17, Batch 4063/24958 loss = 1.253045421242714, ppl = 3.5278173316197035\n","Train Epoch #17, Batch 4064/24958 loss = 1.2521530824899674, ppl = 3.524901755514861\n","Train Epoch #17, Batch 4065/24958 loss = 1.2526925188302993, ppl = 3.526663833092426\n","Train Epoch #17, Batch 4066/24958 loss = 1.2527671355009078, ppl = 3.5269141048122528\n","Train Epoch #17, Batch 4067/24958 loss = 1.2542200046777725, ppl = 3.531177767206271\n","Train Epoch #17, Batch 4068/24958 loss = 1.2518342357873917, ppl = 3.5225397971542383\n","Train Epoch #17, Batch 4069/24958 loss = 1.2484755927324296, ppl = 3.5107232318809127\n","Train Epoch #17, Batch 4070/24958 loss = 1.2479314035177231, ppl = 3.508972533050888\n","Train Epoch #17, Batch 4071/24958 loss = 1.249368478655815, ppl = 3.5143179161450346\n","Train Epoch #17, Batch 4072/24958 loss = 1.2478453677892685, ppl = 3.509261328052216\n","Train Epoch #17, Batch 4073/24958 loss = 1.2445699948072433, ppl = 3.4982503860214154\n","Train Epoch #17, Batch 4074/24958 loss = 1.2436334067583084, ppl = 3.4950965277131076\n","Train Epoch #17, Batch 4075/24958 loss = 1.2419293272495269, ppl = 3.490280070374817\n","Train Epoch #17, Batch 4076/24958 loss = 1.2434019839763641, ppl = 3.4956446373800247\n","Train Epoch #17, Batch 4077/24958 loss = 1.2416758275032043, ppl = 3.4897876889600714\n","Train Epoch #17, Batch 4078/24958 loss = 1.2397463428974151, ppl = 3.4827394284058033\n","Train Epoch #17, Batch 4079/24958 loss = 1.2380051338672637, ppl = 3.477165800330688\n","Train Epoch #17, Batch 4080/24958 loss = 1.2400527000427246, ppl = 3.484038966849933\n","Train Epoch #17, Batch 4081/24958 loss = 1.2418220019340516, ppl = 3.4908123639546558\n","Train Epoch #17, Batch 4082/24958 loss = 1.2422513258457184, ppl = 3.4923700655852805\n","Train Epoch #17, Batch 4083/24958 loss = 1.2413922441005707, ppl = 3.488715603370707\n","Train Epoch #17, Batch 4084/24958 loss = 1.237661966085434, ppl = 3.4708070155491964\n","Train Epoch #17, Batch 4085/24958 loss = 1.23821803689003, ppl = 3.472837306814063\n","Train Epoch #17, Batch 4086/24958 loss = 1.238799409866333, ppl = 3.474801207686644\n","Train Epoch #17, Batch 4087/24958 loss = 1.2384908664226533, ppl = 3.473747562889018\n","Train Epoch #17, Batch 4088/24958 loss = 1.239557933807373, ppl = 3.4777799653352326\n","Train Epoch #17, Batch 4089/24958 loss = 1.2413004958629608, ppl = 3.484467088743666\n","Train Epoch #17, Batch 4090/24958 loss = 1.2431794822216033, ppl = 3.4918775786563323\n","Train Epoch #17, Batch 4091/24958 loss = 1.243797814846039, ppl = 3.4941352564524446\n","Train Epoch #17, Batch 4092/24958 loss = 1.2430490255355835, ppl = 3.4914638346259195\n","Train Epoch #17, Batch 4093/24958 loss = 1.2437844240665437, ppl = 3.493936020558938\n","Train Epoch #17, Batch 4094/24958 loss = 1.2459502518177032, ppl = 3.5015678954627343\n","Train Epoch #17, Batch 4095/24958 loss = 1.2444894623756408, ppl = 3.496096443072368\n","Train Epoch #17, Batch 4096/24958 loss = 1.242884259223938, ppl = 3.491424809778901\n","Train Epoch #17, Batch 4097/24958 loss = 1.2432368087768555, ppl = 3.4925809171251645\n","Train Epoch #17, Batch 4098/24958 loss = 1.2439689671993255, ppl = 3.495370260203048\n","Train Epoch #17, Batch 4099/24958 loss = 1.2421010947227478, ppl = 3.48869227041616\n","Train Epoch #17, Batch 4100/24958 loss = 1.2419956648349761, ppl = 3.48833888138436\n","Train Epoch #17, Batch 4101/24958 loss = 1.24102410197258, ppl = 3.485484456145317\n","Train Epoch #17, Batch 4102/24958 loss = 1.2409286522865295, ppl = 3.4851318124451502\n","Train Epoch #17, Batch 4103/24958 loss = 1.244247509241104, ppl = 3.497555589169467\n","Train Epoch #17, Batch 4104/24958 loss = 1.2455077493190765, ppl = 3.5018270869332455\n","Train Epoch #17, Batch 4105/24958 loss = 1.2471967685222625, ppl = 3.508121698899417\n","Train Epoch #17, Batch 4106/24958 loss = 1.24551952958107, ppl = 3.503018108849371\n","Train Epoch #17, Batch 4107/24958 loss = 1.2483620595932008, ppl = 3.5127247176484446\n","Train Epoch #17, Batch 4108/24958 loss = 1.2492172563076018, ppl = 3.515789075392032\n","Train Epoch #17, Batch 4109/24958 loss = 1.2476468801498413, ppl = 3.510260419880967\n","Train Epoch #17, Batch 4110/24958 loss = 1.2471214592456819, ppl = 3.5083788447927766\n","Train Epoch #17, Batch 4111/24958 loss = 1.247762326002121, ppl = 3.5105506774318824\n","Train Epoch #17, Batch 4112/24958 loss = 1.2471614134311677, ppl = 3.508319572280247\n","Train Epoch #17, Batch 4113/24958 loss = 1.2447270715236665, ppl = 3.500350568662285\n","Train Epoch #17, Batch 4114/24958 loss = 1.2486784917116165, ppl = 3.512951956575185\n","Train Epoch #17, Batch 4115/24958 loss = 1.2491253405809402, ppl = 3.514500300784799\n","Train Epoch #17, Batch 4116/24958 loss = 1.2496854203939438, ppl = 3.516403149919424\n","Train Epoch #17, Batch 4117/24958 loss = 1.250174407362938, ppl = 3.518110723187915\n","Train Epoch #17, Batch 4118/24958 loss = 1.249917258620262, ppl = 3.517181715042144\n","Train Epoch #17, Batch 4119/24958 loss = 1.2498402935266495, ppl = 3.516911192045706\n","Train Epoch #17, Batch 4120/24958 loss = 1.2543383318185806, ppl = 3.5322755397759398\n","Train Epoch #17, Batch 4121/24958 loss = 1.2536284440755845, ppl = 3.529512520618178\n","Train Epoch #17, Batch 4122/24958 loss = 1.2537305444478988, ppl = 3.5298343768882394\n","Train Epoch #17, Batch 4123/24958 loss = 1.2545110863447189, ppl = 3.5326200586904064\n","Train Epoch #17, Batch 4124/24958 loss = 1.2549200278520585, ppl = 3.5341871343626474\n","Train Epoch #17, Batch 4125/24958 loss = 1.2544788724184037, ppl = 3.5324717677944824\n","Train Epoch #17, Batch 4126/24958 loss = 1.2520248824357987, ppl = 3.5244585173624845\n","Train Epoch #17, Batch 4127/24958 loss = 1.2529927963018417, ppl = 3.52775380337218\n","Train Epoch #17, Batch 4128/24958 loss = 1.2516158789396286, ppl = 3.5224721133112165\n","Train Epoch #17, Batch 4129/24958 loss = 1.2524436765909195, ppl = 3.5251707874680607\n","Train Epoch #17, Batch 4130/24958 loss = 1.2526607555150986, ppl = 3.5258948314745977\n","Train Epoch #17, Batch 4131/24958 loss = 1.2510718601942061, ppl = 3.5208342450741816\n","Train Epoch #17, Batch 4132/24958 loss = 1.2528519552946091, ppl = 3.526858813813734\n","Train Epoch #17, Batch 4133/24958 loss = 1.2548479837179185, ppl = 3.5341295396242094\n","Train Epoch #17, Batch 4134/24958 loss = 1.2550596088171004, ppl = 3.534943570688303\n","Train Epoch #17, Batch 4135/24958 loss = 1.2526732224225998, ppl = 3.5251883442180447\n","Train Epoch #17, Batch 4136/24958 loss = 1.2527203792333603, ppl = 3.525341414748427\n","Train Epoch #17, Batch 4137/24958 loss = 1.2520308297872544, ppl = 3.5226956599650325\n","Train Epoch #17, Batch 4138/24958 loss = 1.2510085254907608, ppl = 3.51947372276585\n","Train Epoch #17, Batch 4139/24958 loss = 1.2494206672906876, ppl = 3.513650503568526\n","Train Epoch #17, Batch 4140/24958 loss = 1.248018301129341, ppl = 3.5084367093696107\n","Train Epoch #17, Batch 4141/24958 loss = 1.2464490455389023, ppl = 3.503030326593436\n","Train Epoch #17, Batch 4142/24958 loss = 1.2447554343938827, ppl = 3.497340567544551\n","Train Epoch #17, Batch 4143/24958 loss = 1.2448862093687056, ppl = 3.4978431422717517\n","Train Epoch #17, Batch 4144/24958 loss = 1.2476360446214676, ppl = 3.507623914634834\n","Train Epoch #17, Batch 4145/24958 loss = 1.2443857353925705, ppl = 3.496429734504437\n","Train Epoch #17, Batch 4146/24958 loss = 1.245143535733223, ppl = 3.498989303879349\n","Train Epoch #17, Batch 4147/24958 loss = 1.2442004853487014, ppl = 3.495555482497398\n","Train Epoch #17, Batch 4148/24958 loss = 1.24356851875782, ppl = 3.4935003532281854\n","Train Epoch #17, Batch 4149/24958 loss = 1.2451725369691848, ppl = 3.4985608405536355\n","Train Epoch #17, Batch 4150/24958 loss = 1.2441299253702163, ppl = 3.495454461800152\n","Train Epoch #17, Batch 4151/24958 loss = 1.242043088078499, ppl = 3.488362138786055\n","Train Epoch #17, Batch 4152/24958 loss = 1.2417124766111374, ppl = 3.4872062660438736\n","Train Epoch #17, Batch 4153/24958 loss = 1.242172036767006, ppl = 3.488683917120803\n","Train Epoch #17, Batch 4154/24958 loss = 1.2468266767263412, ppl = 3.5070039474306367\n","Train Epoch #17, Batch 4155/24958 loss = 1.245600135922432, ppl = 3.501961530824918\n","Train Epoch #17, Batch 4156/24958 loss = 1.2461523467302322, ppl = 3.504024663758454\n","Train Epoch #17, Batch 4157/24958 loss = 1.2477672106027604, ppl = 3.5091893051550933\n","Train Epoch #17, Batch 4158/24958 loss = 1.246210487484932, ppl = 3.502628156664169\n","Train Epoch #17, Batch 4159/24958 loss = 1.2472764712572098, ppl = 3.506573323717215\n","Train Epoch #17, Batch 4160/24958 loss = 1.2460420662164688, ppl = 3.5019638472673917\n","Train Epoch #17, Batch 4161/24958 loss = 1.250333724617958, ppl = 3.5169482473609786\n","Train Epoch #17, Batch 4162/24958 loss = 1.248374289870262, ppl = 3.5107902618485913\n","Train Epoch #17, Batch 4163/24958 loss = 1.250453503727913, ppl = 3.517786508701008\n","Train Epoch #17, Batch 4164/24958 loss = 1.2519893258810044, ppl = 3.5229720164362486\n","Train Epoch #17, Batch 4165/24958 loss = 1.2517642253637313, ppl = 3.522225148961476\n","Train Epoch #17, Batch 4166/24958 loss = 1.2501849871873856, ppl = 3.517307004217658\n","Train Epoch #17, Batch 4167/24958 loss = 1.2516504842042924, ppl = 3.5222834516477377\n","Train Epoch #17, Batch 4168/24958 loss = 1.2503993302583694, ppl = 3.5185131766196243\n","Train Epoch #17, Batch 4169/24958 loss = 1.2517116063833236, ppl = 3.522664519061105\n","Train Epoch #17, Batch 4170/24958 loss = 1.2516018468141556, ppl = 3.5223228133950615\n","Train Epoch #17, Batch 4171/24958 loss = 1.249787535071373, ppl = 3.5156969644050107\n","Train Epoch #17, Batch 4172/24958 loss = 1.250300104022026, ppl = 3.517313415408811\n","Train Epoch #17, Batch 4173/24958 loss = 1.2513748878240585, ppl = 3.520537222725764\n","Train Epoch #17, Batch 4174/24958 loss = 1.251242225766182, ppl = 3.520113905162739\n","Train Epoch #17, Batch 4175/24958 loss = 1.2543658924102783, ppl = 3.529619238370748\n","Train Epoch #17, Batch 4176/24958 loss = 1.2531365430355073, ppl = 3.525087415800373\n","Train Epoch #17, Batch 4177/24958 loss = 1.2546828258037568, ppl = 3.530285792874369\n","Train Epoch #17, Batch 4178/24958 loss = 1.2541915774345398, ppl = 3.528698173466018\n","Train Epoch #17, Batch 4179/24958 loss = 1.2568718600273132, ppl = 3.5377057942281853\n","Train Epoch #17, Batch 4180/24958 loss = 1.256269931793213, ppl = 3.535537279248708\n","Train Epoch #17, Batch 4181/24958 loss = 1.2547019457817077, ppl = 3.529475546569986\n","Train Epoch #17, Batch 4182/24958 loss = 1.2547296702861785, ppl = 3.529578455830081\n","Train Epoch #17, Batch 4183/24958 loss = 1.2547357964515686, ppl = 3.5296034203071347\n","Train Epoch #17, Batch 4184/24958 loss = 1.2534226548671723, ppl = 3.5247291217154584\n","Train Epoch #17, Batch 4185/24958 loss = 1.2525869774818421, ppl = 3.521719819992334\n","Train Epoch #17, Batch 4186/24958 loss = 1.2528635370731354, ppl = 3.5226948902197144\n","Train Epoch #17, Batch 4187/24958 loss = 1.2533061552047728, ppl = 3.524216617141986\n","Train Epoch #17, Batch 4188/24958 loss = 1.253734894990921, ppl = 3.525961933223322\n","Train Epoch #17, Batch 4189/24958 loss = 1.2502170884609223, ppl = 3.5135607885773146\n","Train Epoch #17, Batch 4190/24958 loss = 1.2496473824977874, ppl = 3.5111651309148098\n","Train Epoch #17, Batch 4191/24958 loss = 1.2504294097423554, ppl = 3.514227881203411\n","Train Epoch #17, Batch 4192/24958 loss = 1.250164178609848, ppl = 3.5133285918855317\n","Train Epoch #17, Batch 4193/24958 loss = 1.2506599879264833, ppl = 3.5151009644520292\n","Train Epoch #17, Batch 4194/24958 loss = 1.2484777402877807, ppl = 3.507417311920108\n","Train Epoch #17, Batch 4195/24958 loss = 1.2507955968379973, ppl = 3.516491299969796\n","Train Epoch #17, Batch 4196/24958 loss = 1.2548231089115143, ppl = 3.529797084937648\n","Train Epoch #17, Batch 4197/24958 loss = 1.2551893067359925, ppl = 3.5310418945364894\n","Train Epoch #17, Batch 4198/24958 loss = 1.2516908395290374, ppl = 3.5193786182338647\n","Train Epoch #17, Batch 4199/24958 loss = 1.2522883713245392, ppl = 3.521380820251868\n","Train Epoch #17, Batch 4200/24958 loss = 1.2524216532707215, ppl = 3.521828190038495\n","Train Epoch #17, Batch 4201/24958 loss = 1.253915512561798, ppl = 3.5263356505893855\n","Train Epoch #17, Batch 4202/24958 loss = 1.2536385679244995, ppl = 3.5253313114773177\n","Train Epoch #17, Batch 4203/24958 loss = 1.2511945652961731, ppl = 3.515793407146747\n","Train Epoch #17, Batch 4204/24958 loss = 1.2507240986824035, ppl = 3.514135507979182\n","Train Epoch #17, Batch 4205/24958 loss = 1.249839997291565, ppl = 3.5107083009175875\n","Train Epoch #17, Batch 4206/24958 loss = 1.251638307571411, ppl = 3.5162144835044327\n","Train Epoch #17, Batch 4207/24958 loss = 1.2492031240463257, ppl = 3.5077353591394207\n","Train Epoch #17, Batch 4208/24958 loss = 1.2503504681587219, ppl = 3.512280607325161\n","Train Epoch #17, Batch 4209/24958 loss = 1.2518085896968842, ppl = 3.517384605250775\n","Train Epoch #17, Batch 4210/24958 loss = 1.251672705411911, ppl = 3.5169138699504985\n","Train Epoch #17, Batch 4211/24958 loss = 1.2521473777294159, ppl = 3.518614628225318\n","Train Epoch #17, Batch 4212/24958 loss = 1.2505776631832122, ppl = 3.5133813321268264\n","Train Epoch #17, Batch 4213/24958 loss = 1.2539682400226593, ppl = 3.525051225298457\n","Train Epoch #17, Batch 4214/24958 loss = 1.254047976732254, ppl = 3.5253602821364693\n","Train Epoch #17, Batch 4215/24958 loss = 1.253042813539505, ppl = 3.5219721021791037\n","Train Epoch #17, Batch 4216/24958 loss = 1.2530447888374328, ppl = 3.521979003546621\n","Train Epoch #17, Batch 4217/24958 loss = 1.2520362210273743, ppl = 3.518546228083724\n","Train Epoch #17, Batch 4218/24958 loss = 1.2536254489421845, ppl = 3.5246893905657863\n","Train Epoch #17, Batch 4219/24958 loss = 1.2522128117084503, ppl = 3.5200766959126883\n","Train Epoch #17, Batch 4220/24958 loss = 1.2512576115131377, ppl = 3.516212784023716\n","Train Epoch #17, Batch 4221/24958 loss = 1.2487237095832824, ppl = 3.507806267485263\n","Train Epoch #17, Batch 4222/24958 loss = 1.2491319036483766, ppl = 3.5091263786428395\n","Train Epoch #17, Batch 4223/24958 loss = 1.2486622107028962, ppl = 3.5074241064557428\n","Train Epoch #17, Batch 4224/24958 loss = 1.2484236884117126, ppl = 3.506502302882213\n","Train Epoch #17, Batch 4225/24958 loss = 1.2469884479045867, ppl = 3.5014174072298077\n","Train Epoch #17, Batch 4226/24958 loss = 1.2499067056179047, ppl = 3.5111805986769964\n","Train Epoch #17, Batch 4227/24958 loss = 1.2496407914161682, ppl = 3.510243285023768\n","Train Epoch #17, Batch 4228/24958 loss = 1.24967817902565, ppl = 3.5103773028123384\n","Train Epoch #17, Batch 4229/24958 loss = 1.2489165985584259, ppl = 3.5078863763722152\n","Train Epoch #17, Batch 4230/24958 loss = 1.2463214749097824, ppl = 3.5001795381838634\n","Train Epoch #17, Batch 4231/24958 loss = 1.2479211050271988, ppl = 3.5052771225783914\n","Train Epoch #17, Batch 4232/24958 loss = 1.2494060403108598, ppl = 3.5111915840831442\n","Train Epoch #17, Batch 4233/24958 loss = 1.2478506690263749, ppl = 3.505403553268867\n","Train Epoch #17, Batch 4234/24958 loss = 1.2475306516885758, ppl = 3.504179207649534\n","Train Epoch #17, Batch 4235/24958 loss = 1.2473396581411362, ppl = 3.5034944691188095\n","Train Epoch #17, Batch 4236/24958 loss = 1.248270909190178, ppl = 3.506669999772344\n","Train Epoch #17, Batch 4237/24958 loss = 1.245875479578972, ppl = 3.4987754034459897\n","Train Epoch #17, Batch 4238/24958 loss = 1.2459668511152266, ppl = 3.4990501582361877\n","Train Epoch #17, Batch 4239/24958 loss = 1.2446467572450637, ppl = 3.494865403506944\n","Train Epoch #17, Batch 4240/24958 loss = 1.2457254034280778, ppl = 3.4988099464106774\n","Train Epoch #17, Batch 4241/24958 loss = 1.2463132148981095, ppl = 3.5007363903381337\n","Train Epoch #17, Batch 4242/24958 loss = 1.247424940466881, ppl = 3.5043617157291953\n","Train Epoch #17, Batch 4243/24958 loss = 1.2478833156824112, ppl = 3.5061760833480817\n","Train Epoch #17, Batch 4244/24958 loss = 1.2480731266736984, ppl = 3.5069556630181737\n","Train Epoch #17, Batch 4245/24958 loss = 1.2515417796373367, ppl = 3.519040330555108\n","Train Epoch #17, Batch 4246/24958 loss = 1.2502055305242539, ppl = 3.5146534295670273\n","Train Epoch #17, Batch 4247/24958 loss = 1.2516469651460647, ppl = 3.5200370573118853\n","Train Epoch #17, Batch 4248/24958 loss = 1.2514632827043533, ppl = 3.519463687382971\n","Train Epoch #17, Batch 4249/24958 loss = 1.2494511395692824, ppl = 3.5132400180000163\n","Train Epoch #17, Batch 4250/24958 loss = 1.2512750607728957, ppl = 3.51889601250446\n","Train Epoch #17, Batch 4251/24958 loss = 1.2532261699438094, ppl = 3.5254806986840213\n","Train Epoch #17, Batch 4252/24958 loss = 1.2558189541101457, ppl = 3.5356590386729145\n","Train Epoch #17, Batch 4253/24958 loss = 1.2548549097776414, ppl = 3.532635595951331\n","Train Epoch #17, Batch 4254/24958 loss = 1.2520291060209274, ppl = 3.5205177538357733\n","Train Epoch #17, Batch 4255/24958 loss = 1.2513465803861619, ppl = 3.5179683834466404\n","Train Epoch #17, Batch 4256/24958 loss = 1.251565664410591, ppl = 3.518819002253529\n","Train Epoch #17, Batch 4257/24958 loss = 1.2529092890024185, ppl = 3.5237995808933458\n","Train Epoch #17, Batch 4258/24958 loss = 1.2520830672979355, ppl = 3.520710671386604\n","Train Epoch #17, Batch 4259/24958 loss = 1.251947038769722, ppl = 3.52018351888899\n","Train Epoch #17, Batch 4260/24958 loss = 1.251750606894493, ppl = 3.5195010750267075\n","Train Epoch #17, Batch 4261/24958 loss = 1.2493253201246262, ppl = 3.5102532178486867\n","Train Epoch #17, Batch 4262/24958 loss = 1.251224201321602, ppl = 3.5162022798677572\n","Train Epoch #17, Batch 4263/24958 loss = 1.250651951432228, ppl = 3.514129504548253\n","Train Epoch #17, Batch 4264/24958 loss = 1.2494908672571183, ppl = 3.5101367871449214\n","Train Epoch #17, Batch 4265/24958 loss = 1.2496291774511337, ppl = 3.5105936974035474\n","Train Epoch #17, Batch 4266/24958 loss = 1.2508672732114792, ppl = 3.514382711616611\n","Train Epoch #17, Batch 4267/24958 loss = 1.2497231358289718, ppl = 3.510435965579133\n","Train Epoch #17, Batch 4268/24958 loss = 1.2513211411237717, ppl = 3.5153377142826696\n","Train Epoch #17, Batch 4269/24958 loss = 1.2517685610055924, ppl = 3.5168823091026673\n","Train Epoch #17, Batch 4270/24958 loss = 1.2524437195062637, ppl = 3.519044894728763\n","Train Epoch #17, Batch 4271/24958 loss = 1.2551173394918442, ppl = 3.5292539650702723\n","Train Epoch #17, Batch 4272/24958 loss = 1.256050519347191, ppl = 3.5324182797825294\n","Train Epoch #17, Batch 4273/24958 loss = 1.2587524396181107, ppl = 3.5422321839163944\n","Train Epoch #17, Batch 4274/24958 loss = 1.2616013675928115, ppl = 3.5526805534750836\n","Train Epoch #17, Batch 4275/24958 loss = 1.260817170739174, ppl = 3.5500083115691075\n","Train Epoch #17, Batch 4276/24958 loss = 1.2607975333929062, ppl = 3.5499403465262866\n","Train Epoch #17, Batch 4277/24958 loss = 1.259623834490776, ppl = 3.5459220425271103\n","Train Epoch #17, Batch 4278/24958 loss = 1.262041751742363, ppl = 3.554546614270076\n","Train Epoch #17, Batch 4279/24958 loss = 1.2596759074926376, ppl = 3.546475067216123\n","Train Epoch #17, Batch 4280/24958 loss = 1.2587154561281204, ppl = 3.5432741989626346\n","Train Epoch #17, Batch 4281/24958 loss = 1.2574007135629655, ppl = 3.538875081012884\n","Train Epoch #17, Batch 4282/24958 loss = 1.255553212761879, ppl = 3.5326049488733537\n","Train Epoch #17, Batch 4283/24958 loss = 1.2525592523813247, ppl = 3.5220581504464996\n","Train Epoch #17, Batch 4284/24958 loss = 1.251752547621727, ppl = 3.519366063478247\n","Train Epoch #17, Batch 4285/24958 loss = 1.2554267150163652, ppl = 3.534695873074499\n","Train Epoch #17, Batch 4286/24958 loss = 1.2560856825113296, ppl = 3.5371308262337697\n","Train Epoch #17, Batch 4287/24958 loss = 1.2568542236089706, ppl = 3.539938496062642\n","Train Epoch #17, Batch 4288/24958 loss = 1.2532225471735001, ppl = 3.527274017064648\n","Train Epoch #17, Batch 4289/24958 loss = 1.2550764507055283, ppl = 3.5332654472154768\n","Train Epoch #17, Batch 4290/24958 loss = 1.2539873987436294, ppl = 3.5290488803462137\n","Train Epoch #17, Batch 4291/24958 loss = 1.2509018522500992, ppl = 3.51823921373944\n","Train Epoch #17, Batch 4292/24958 loss = 1.2508332592248916, ppl = 3.51801049902052\n","Train Epoch #17, Batch 4293/24958 loss = 1.2525179320573807, ppl = 3.5247336590329237\n","Train Epoch #17, Batch 4294/24958 loss = 1.254026340842247, ppl = 3.5298634628434713\n","Train Epoch #17, Batch 4295/24958 loss = 1.2517372101545334, ppl = 3.5208895451141085\n","Train Epoch #17, Batch 4296/24958 loss = 1.2505786782503128, ppl = 3.5164989609357646\n","Train Epoch #17, Batch 4297/24958 loss = 1.248854359984398, ppl = 3.5110158501712196\n","Train Epoch #17, Batch 4298/24958 loss = 1.2502198737859727, ppl = 3.515090095756593\n","Train Epoch #17, Batch 4299/24958 loss = 1.2501163738965988, ppl = 3.5147346675761257\n","Train Epoch #17, Batch 4300/24958 loss = 1.251886116862297, ppl = 3.5212763969027345\n","Train Epoch #17, Batch 4301/24958 loss = 1.2524816447496414, ppl = 3.5232696169063273\n","Train Epoch #17, Batch 4302/24958 loss = 1.2520367449522019, ppl = 3.5217133040350177\n","Train Epoch #17, Batch 4303/24958 loss = 1.2523954159021378, ppl = 3.5229713833831595\n","Train Epoch #17, Batch 4304/24958 loss = 1.251937980055809, ppl = 3.5214324913028863\n","Train Epoch #17, Batch 4305/24958 loss = 1.252190951704979, ppl = 3.5223823859968797\n","Train Epoch #17, Batch 4306/24958 loss = 1.2512183314561844, ppl = 3.519281790947754\n","Train Epoch #17, Batch 4307/24958 loss = 1.2537118655443191, ppl = 3.5279904978331085\n","Train Epoch #17, Batch 4308/24958 loss = 1.2512152606248856, ppl = 3.51872638059166\n","Train Epoch #17, Batch 4309/24958 loss = 1.2501149886846543, ppl = 3.5148069607751062\n","Train Epoch #17, Batch 4310/24958 loss = 1.249270321726799, ppl = 3.512020028623377\n","Train Epoch #17, Batch 4311/24958 loss = 1.2485295730829238, ppl = 3.5094006378380675\n","Train Epoch #17, Batch 4312/24958 loss = 1.2474835258722305, ppl = 3.506342496398854\n","Train Epoch #17, Batch 4313/24958 loss = 1.246417469382286, ppl = 3.5022387815542664\n","Train Epoch #17, Batch 4314/24958 loss = 1.243947769999504, ppl = 3.493722916418672\n","Train Epoch #17, Batch 4315/24958 loss = 1.2464480370283126, ppl = 3.502824770466109\n","Train Epoch #17, Batch 4316/24958 loss = 1.2472676366567612, ppl = 3.5058092329331982\n","Train Epoch #17, Batch 4317/24958 loss = 1.247665519118309, ppl = 3.507122275540725\n","Train Epoch #17, Batch 4318/24958 loss = 1.2469770413637162, ppl = 3.5043407432476568\n","Train Epoch #17, Batch 4319/24958 loss = 1.24831495821476, ppl = 3.5086927891757114\n","Train Epoch #17, Batch 4320/24958 loss = 1.2495777529478074, ppl = 3.513881605938956\n","Train Epoch #17, Batch 4321/24958 loss = 1.2523253136873245, ppl = 3.5230991892728243\n","Train Epoch #17, Batch 4322/24958 loss = 1.2534993594884873, ppl = 3.5272107433319735\n","Train Epoch #17, Batch 4323/24958 loss = 1.2548970085382463, ppl = 3.532520528087088\n","Train Epoch #17, Batch 4324/24958 loss = 1.2537768977880477, ppl = 3.5284739795305757\n","Train Epoch #17, Batch 4325/24958 loss = 1.252070750594139, ppl = 3.5233060875783195\n","Train Epoch #17, Batch 4326/24958 loss = 1.2517130118608475, ppl = 3.5219505290339885\n","Train Epoch #17, Batch 4327/24958 loss = 1.2521837216615677, ppl = 3.523626903470228\n","Train Epoch #17, Batch 4328/24958 loss = 1.2532927960157394, ppl = 3.527839140737888\n","Train Epoch #17, Batch 4329/24958 loss = 1.255114033818245, ppl = 3.534127205800836\n","Train Epoch #17, Batch 4330/24958 loss = 1.2578279042243958, ppl = 3.54223681244354\n","Train Epoch #17, Batch 4331/24958 loss = 1.2584179902076722, ppl = 3.544332899444373\n","Train Epoch #17, Batch 4332/24958 loss = 1.2564225935935973, ppl = 3.5365798294799693\n","Train Epoch #17, Batch 4333/24958 loss = 1.2561692690849304, ppl = 3.5357194846123754\n","Train Epoch #17, Batch 4334/24958 loss = 1.255350284576416, ppl = 3.5327589105163586\n","Train Epoch #17, Batch 4335/24958 loss = 1.2559619224071503, ppl = 3.534998640572175\n","Train Epoch #17, Batch 4336/24958 loss = 1.2566839051246643, ppl = 3.5376723441254194\n","Train Epoch #17, Batch 4337/24958 loss = 1.2591020596027374, ppl = 3.5456512583297304\n","Train Epoch #17, Batch 4338/24958 loss = 1.2607899475097657, ppl = 3.5512055410220023\n","Train Epoch #17, Batch 4339/24958 loss = 1.262409770488739, ppl = 3.5564198970590803\n","Train Epoch #17, Batch 4340/24958 loss = 1.2620973181724549, ppl = 3.5552331825336463\n","Train Epoch #17, Batch 4341/24958 loss = 1.2606043827533722, ppl = 3.550553185814226\n","Train Epoch #17, Batch 4342/24958 loss = 1.2608684134483337, ppl = 3.5514750500640218\n","Train Epoch #17, Batch 4343/24958 loss = 1.2584395706653595, ppl = 3.542742433934645\n","Train Epoch #17, Batch 4344/24958 loss = 1.2554670453071595, ppl = 3.5320806455896574\n","Train Epoch #17, Batch 4345/24958 loss = 1.2535100078582764, ppl = 3.524752144746653\n","Train Epoch #17, Batch 4346/24958 loss = 1.252757387161255, ppl = 3.5225274687774504\n","Train Epoch #17, Batch 4347/24958 loss = 1.2523068583011627, ppl = 3.5207606957892676\n","Train Epoch #17, Batch 4348/24958 loss = 1.2541592693328858, ppl = 3.5270551091839684\n","Train Epoch #17, Batch 4349/24958 loss = 1.255358099937439, ppl = 3.5306115226934804\n","Train Epoch #17, Batch 4350/24958 loss = 1.2544221019744872, ppl = 3.527580316194336\n","Train Epoch #17, Batch 4351/24958 loss = 1.2536641335487366, ppl = 3.5248686972733667\n","Train Epoch #17, Batch 4352/24958 loss = 1.2494938278198242, ppl = 3.509671980317713\n","Train Epoch #17, Batch 4353/24958 loss = 1.2512653744220734, ppl = 3.5154621541949274\n","Train Epoch #17, Batch 4354/24958 loss = 1.251540402173996, ppl = 3.5164969153024357\n","Train Epoch #17, Batch 4355/24958 loss = 1.2518412458896637, ppl = 3.5175992129489013\n","Train Epoch #17, Batch 4356/24958 loss = 1.2545403218269349, ppl = 3.5297614984580634\n","Train Epoch #17, Batch 4357/24958 loss = 1.2508719313144683, ppl = 3.5175967943558386\n","Train Epoch #17, Batch 4358/24958 loss = 1.2509818744659424, ppl = 3.517993256424231\n","Train Epoch #17, Batch 4359/24958 loss = 1.2490902650356293, ppl = 3.511359613447372\n","Train Epoch #17, Batch 4360/24958 loss = 1.2493864941596984, ppl = 3.5123939424214297\n","Train Epoch #17, Batch 4361/24958 loss = 1.2487038588523864, ppl = 3.5101706348416495\n","Train Epoch #17, Batch 4362/24958 loss = 1.2492056810855865, ppl = 3.511940843644169\n","Train Epoch #17, Batch 4363/24958 loss = 1.2467258834838868, ppl = 3.5042111670693656\n","Train Epoch #17, Batch 4364/24958 loss = 1.2474966394901275, ppl = 3.506809587892829\n","Train Epoch #17, Batch 4365/24958 loss = 1.2463236224651337, ppl = 3.503127805128725\n","Train Epoch #17, Batch 4366/24958 loss = 1.2476446735858917, ppl = 3.507722971032803\n","Train Epoch #17, Batch 4367/24958 loss = 1.2488558959960938, ppl = 3.5119154435333355\n","Train Epoch #17, Batch 4368/24958 loss = 1.2500338053703308, ppl = 3.516064525124092\n","Train Epoch #17, Batch 4369/24958 loss = 1.2488628399372101, ppl = 3.5121638152875416\n","Train Epoch #17, Batch 4370/24958 loss = 1.246996089220047, ppl = 3.5065231968330295\n","Train Epoch #17, Batch 4371/24958 loss = 1.245127902030945, ppl = 3.4991077848421566\n","Train Epoch #17, Batch 4372/24958 loss = 1.2451830804347992, ppl = 3.4993042965170473\n","Train Epoch #17, Batch 4373/24958 loss = 1.2424818456172944, ppl = 3.4894925609380443\n","Train Epoch #17, Batch 4374/24958 loss = 1.2408880925178527, ppl = 3.483283360261833\n","Train Epoch #17, Batch 4375/24958 loss = 1.241959228515625, ppl = 3.486986946102681\n","Train Epoch #17, Batch 4376/24958 loss = 1.2410760271549224, ppl = 3.48406414873467\n","Train Epoch #17, Batch 4377/24958 loss = 1.2417382037639617, ppl = 3.4862730812742018\n","Train Epoch #17, Batch 4378/24958 loss = 1.2405485963821412, ppl = 3.481769367254226\n","Train Epoch #17, Batch 4379/24958 loss = 1.2444018530845642, ppl = 3.495985071891294\n","Train Epoch #17, Batch 4380/24958 loss = 1.2455655586719514, ppl = 3.499903638757821\n","Train Epoch #17, Batch 4381/24958 loss = 1.2446378076076507, ppl = 3.497129653113348\n","Train Epoch #17, Batch 4382/24958 loss = 1.248020316362381, ppl = 3.5095666120674434\n","Train Epoch #17, Batch 4383/24958 loss = 1.2496637153625487, ppl = 3.5149636853222344\n","Train Epoch #17, Batch 4384/24958 loss = 1.2502841079235076, ppl = 3.5170145982402743\n","Train Epoch #17, Batch 4385/24958 loss = 1.246878297328949, ppl = 3.5026238784924377\n","Train Epoch #17, Batch 4386/24958 loss = 1.2453408229351044, ppl = 3.497182523443289\n","Train Epoch #17, Batch 4387/24958 loss = 1.2444313645362854, ppl = 3.4938830504332152\n","Train Epoch #17, Batch 4388/24958 loss = 1.2484497547149658, ppl = 3.508187254577666\n","Train Epoch #17, Batch 4389/24958 loss = 1.24826921582222, ppl = 3.50755377162459\n","Train Epoch #17, Batch 4390/24958 loss = 1.245726981163025, ppl = 3.4993270287905154\n","Train Epoch #17, Batch 4391/24958 loss = 1.248960441350937, ppl = 3.510743410490982\n","Train Epoch #17, Batch 4392/24958 loss = 1.2502269399166108, ppl = 3.515230042128628\n","Train Epoch #17, Batch 4393/24958 loss = 1.2478075456619262, ppl = 3.5059113385447644\n","Train Epoch #17, Batch 4394/24958 loss = 1.2461772787570953, ppl = 3.5003999188734114\n","Train Epoch #17, Batch 4395/24958 loss = 1.2474502825737, ppl = 3.505136027737087\n","Train Epoch #17, Batch 4396/24958 loss = 1.2469752144813537, ppl = 3.5034776059794566\n","Train Epoch #17, Batch 4397/24958 loss = 1.2496999633312225, ppl = 3.512603278455023\n","Train Epoch #17, Batch 4398/24958 loss = 1.2507746982574464, ppl = 3.516224986442319\n","Train Epoch #17, Batch 4399/24958 loss = 1.2521648859977723, ppl = 3.5213203270846787\n","Train Epoch #17, Batch 4400/24958 loss = 1.2530489182472229, ppl = 3.525048115774871\n","Train Epoch #17, Batch 4401/24958 loss = 1.2523483979701995, ppl = 3.522715632246695\n","Train Epoch #17, Batch 4402/24958 loss = 1.2534369134902954, ppl = 3.526649536949276\n","Train Epoch #17, Batch 4403/24958 loss = 1.2550894331932068, ppl = 3.533066088593291\n","Train Epoch #17, Batch 4404/24958 loss = 1.2547890830039978, ppl = 3.5320932759074624\n","Train Epoch #17, Batch 4405/24958 loss = 1.254373871088028, ppl = 3.530546704302996\n","Train Epoch #17, Batch 4406/24958 loss = 1.255833375453949, ppl = 3.535316435686996\n","Train Epoch #17, Batch 4407/24958 loss = 1.2537026274204255, ppl = 3.527743836777075\n","Train Epoch #17, Batch 4408/24958 loss = 1.2543122124671937, ppl = 3.5297971364112466\n","Train Epoch #17, Batch 4409/24958 loss = 1.2549472618103028, ppl = 3.5320065700877747\n","Train Epoch #17, Batch 4410/24958 loss = 1.2548458790779113, ppl = 3.531687611399602\n","Train Epoch #17, Batch 4411/24958 loss = 1.2557104468345641, ppl = 3.5347640845385992\n","Train Epoch #17, Batch 4412/24958 loss = 1.2567261004447936, ppl = 3.5377287833054107\n","Train Epoch #17, Batch 4413/24958 loss = 1.2576342689990998, ppl = 3.541196778828697\n","Train Epoch #17, Batch 4414/24958 loss = 1.2578381836414336, ppl = 3.5418230127119856\n","Train Epoch #17, Batch 4415/24958 loss = 1.2564972031116486, ppl = 3.5366596307239586\n","Train Epoch #17, Batch 4416/24958 loss = 1.2582616341114043, ppl = 3.5439781331353313\n","Train Epoch #17, Batch 4417/24958 loss = 1.2573831653594971, ppl = 3.541147226598858\n","Train Epoch #17, Batch 4418/24958 loss = 1.2568820250034332, ppl = 3.5392396542574875\n","Train Epoch #17, Batch 4419/24958 loss = 1.257714775800705, ppl = 3.542257635016306\n","Train Epoch #17, Batch 4420/24958 loss = 1.2560099148750306, ppl = 3.5354017663175976\n","Train Epoch #17, Batch 4421/24958 loss = 1.2548622500896454, ppl = 3.5312417096347013\n","Train Epoch #17, Batch 4422/24958 loss = 1.2526999342441558, ppl = 3.5240243817335255\n","Train Epoch #17, Batch 4423/24958 loss = 1.2506963121891022, ppl = 3.5166332859769778\n","Train Epoch #17, Batch 4424/24958 loss = 1.2522741806507112, ppl = 3.5224685173837353\n","Train Epoch #17, Batch 4425/24958 loss = 1.2532365942001342, ppl = 3.525274917943008\n","Train Epoch #17, Batch 4426/24958 loss = 1.2567638731002808, ppl = 3.541016331072541\n","Train Epoch #17, Batch 4427/24958 loss = 1.2554721295833589, ppl = 3.53659831423458\n","Train Epoch #17, Batch 4428/24958 loss = 1.2525970935821533, ppl = 3.526572486402384\n","Train Epoch #17, Batch 4429/24958 loss = 1.2522248792648316, ppl = 3.5251926308941637\n","Train Epoch #17, Batch 4430/24958 loss = 1.2502412045001983, ppl = 3.5190533566932776\n","Train Epoch #17, Batch 4431/24958 loss = 1.247310402393341, ppl = 3.5097606395521455\n","Train Epoch #17, Batch 4432/24958 loss = 1.2469294834136964, ppl = 3.508448493898375\n","Train Epoch #17, Batch 4433/24958 loss = 1.2482564175128936, ppl = 3.513206936267149\n","Train Epoch #17, Batch 4434/24958 loss = 1.2478767848014831, ppl = 3.5119147029179785\n","Train Epoch #17, Batch 4435/24958 loss = 1.2490192329883576, ppl = 3.5164834362256645\n","Train Epoch #17, Batch 4436/24958 loss = 1.2502061903476716, ppl = 3.521321084265611\n","Train Epoch #17, Batch 4437/24958 loss = 1.2495937108993531, ppl = 3.5191142421186514\n","Train Epoch #17, Batch 4438/24958 loss = 1.2478577280044556, ppl = 3.5134150245809725\n","Train Epoch #17, Batch 4439/24958 loss = 1.248035465478897, ppl = 3.514040307669725\n","Train Epoch #17, Batch 4440/24958 loss = 1.2484668850898744, ppl = 3.5156887044139635\n","Train Epoch #17, Batch 4441/24958 loss = 1.2511778628826142, ppl = 3.524739896797154\n","Train Epoch #17, Batch 4442/24958 loss = 1.25223482131958, ppl = 3.5286839694116328\n","Train Epoch #17, Batch 4443/24958 loss = 1.2540804636478424, ppl = 3.5351223659002318\n","Train Epoch #17, Batch 4444/24958 loss = 1.2555357897281647, ppl = 3.5399474478584825\n","Train Epoch #17, Batch 4445/24958 loss = 1.256763768196106, ppl = 3.5443769553268965\n","Train Epoch #17, Batch 4446/24958 loss = 1.258741031885147, ppl = 3.5505992806940596\n","Train Epoch #17, Batch 4447/24958 loss = 1.2578329372406005, ppl = 3.5472711559368384\n","Train Epoch #17, Batch 4448/24958 loss = 1.2563031470775605, ppl = 3.541990862811878\n","Train Epoch #17, Batch 4449/24958 loss = 1.2572387373447418, ppl = 3.545078219676858\n","Train Epoch #17, Batch 4450/24958 loss = 1.2585430538654327, ppl = 3.5493822055242203\n","Train Epoch #17, Batch 4451/24958 loss = 1.2568543231487275, ppl = 3.5440313833319874\n","Train Epoch #17, Batch 4452/24958 loss = 1.2602484118938446, ppl = 3.555899717977377\n","Train Epoch #17, Batch 4453/24958 loss = 1.2607319712638856, ppl = 3.557666701027855\n","Train Epoch #17, Batch 4454/24958 loss = 1.2621002805233001, ppl = 3.5632598644909232\n","Train Epoch #17, Batch 4455/24958 loss = 1.2609389793872834, ppl = 3.5591818775797237\n","Train Epoch #17, Batch 4456/24958 loss = 1.2559584021568297, ppl = 3.539012164939022\n","Train Epoch #17, Batch 4457/24958 loss = 1.255852832198143, ppl = 3.538723904243968\n","Train Epoch #17, Batch 4458/24958 loss = 1.254850408434868, ppl = 3.5352654305580695\n","Train Epoch #17, Batch 4459/24958 loss = 1.2550397235155106, ppl = 3.535874266336977\n","Train Epoch #17, Batch 4460/24958 loss = 1.2524532002210618, ppl = 3.5277980436497653\n","Train Epoch #17, Batch 4461/24958 loss = 1.252714987397194, ppl = 3.5286327786996274\n","Train Epoch #17, Batch 4462/24958 loss = 1.253979063630104, ppl = 3.5335062386531497\n","Train Epoch #17, Batch 4463/24958 loss = 1.254479997754097, ppl = 3.5349171133222863\n","Train Epoch #17, Batch 4464/24958 loss = 1.2547175091505052, ppl = 3.535759039446355\n","Train Epoch #17, Batch 4465/24958 loss = 1.2578650587797164, ppl = 3.5467022603701865\n","Train Epoch #17, Batch 4466/24958 loss = 1.25735070168972, ppl = 3.544840620978559\n","Train Epoch #17, Batch 4467/24958 loss = 1.2572965747117997, ppl = 3.5446422303277374\n","Train Epoch #17, Batch 4468/24958 loss = 1.2559818977117538, ppl = 3.5400423030706456\n","Train Epoch #17, Batch 4469/24958 loss = 1.2556577926874162, ppl = 3.539040940835607\n","Train Epoch #17, Batch 4470/24958 loss = 1.2582706958055496, ppl = 3.547247678008426\n","Train Epoch #17, Batch 4471/24958 loss = 1.2601177614927292, ppl = 3.5545712743056557\n","Train Epoch #17, Batch 4472/24958 loss = 1.259146539568901, ppl = 3.5512659338804666\n","Train Epoch #17, Batch 4473/24958 loss = 1.2594556993246078, ppl = 3.552259326487051\n","Train Epoch #17, Batch 4474/24958 loss = 1.260077617764473, ppl = 3.5545653058404327\n","Train Epoch #17, Batch 4475/24958 loss = 1.259175128340721, ppl = 3.551418848741802\n","Train Epoch #17, Batch 4476/24958 loss = 1.2601010411977769, ppl = 3.554489641740089\n","Train Epoch #17, Batch 4477/24958 loss = 1.2604289835691451, ppl = 3.555638976202688\n","Train Epoch #17, Batch 4478/24958 loss = 1.2603490847349166, ppl = 3.5553552589647133\n","Train Epoch #17, Batch 4479/24958 loss = 1.2565681582689285, ppl = 3.541359075322067\n","Train Epoch #17, Batch 4480/24958 loss = 1.2569308358430862, ppl = 3.5426765085433596\n","Train Epoch #17, Batch 4481/24958 loss = 1.2597674804925918, ppl = 3.5520354802760035\n","Train Epoch #17, Batch 4482/24958 loss = 1.258038586974144, ppl = 3.5451549222958567\n","Train Epoch #17, Batch 4483/24958 loss = 1.256868845820427, ppl = 3.5412235028877563\n","Train Epoch #17, Batch 4484/24958 loss = 1.2569072061777116, ppl = 3.5413545412755614\n","Train Epoch #17, Batch 4485/24958 loss = 1.2569842427968978, ppl = 3.5416288122954933\n","Train Epoch #17, Batch 4486/24958 loss = 1.255803411602974, ppl = 3.537982243939256\n","Train Epoch #17, Batch 4487/24958 loss = 1.2560247796773911, ppl = 3.538757944748267\n","Train Epoch #17, Batch 4488/24958 loss = 1.2537816125154495, ppl = 3.5300720651095445\n","Train Epoch #17, Batch 4489/24958 loss = 1.2550409132242202, ppl = 3.5347386551729847\n","Train Epoch #17, Batch 4490/24958 loss = 1.2568202286958694, ppl = 3.5402734627775576\n","Train Epoch #17, Batch 4491/24958 loss = 1.2551812261343003, ppl = 3.534026635419731\n","Train Epoch #17, Batch 4492/24958 loss = 1.2543284946680069, ppl = 3.530943772629472\n","Train Epoch #17, Batch 4493/24958 loss = 1.2551167708635331, ppl = 3.533736070326376\n","Train Epoch #17, Batch 4494/24958 loss = 1.2549044889211656, ppl = 3.5330822856999564\n","Train Epoch #17, Batch 4495/24958 loss = 1.2530875664949417, ppl = 3.526499324185989\n","Train Epoch #17, Batch 4496/24958 loss = 1.2514191776514054, ppl = 3.5212614560029083\n","Train Epoch #17, Batch 4497/24958 loss = 1.249171614050865, ppl = 3.5135598122753318\n","Train Epoch #17, Batch 4498/24958 loss = 1.250601492524147, ppl = 3.519023163262147\n","Train Epoch #17, Batch 4499/24958 loss = 1.2517458504438401, ppl = 3.5237829324275127\n","Train Epoch #17, Batch 4500/24958 loss = 1.2513356059789658, ppl = 3.522011995379438\n","Train Epoch #17, Batch 4501/24958 loss = 1.253134564757347, ppl = 3.5283473078582954\n","Train Epoch #17, Batch 4502/24958 loss = 1.2518636196851731, ppl = 3.523794991289243\n","Train Epoch #17, Batch 4503/24958 loss = 1.2512902814149856, ppl = 3.521447707809987\n","Train Epoch #17, Batch 4504/24958 loss = 1.252352380156517, ppl = 3.5250228651071076\n","Train Epoch #17, Batch 4505/24958 loss = 1.2519409674406052, ppl = 3.523552492375191\n","Train Epoch #17, Batch 4506/24958 loss = 1.2513750046491623, ppl = 3.521619847864954\n","Train Epoch #17, Batch 4507/24958 loss = 1.2522484880685807, ppl = 3.524530452254147\n","Train Epoch #17, Batch 4508/24958 loss = 1.2540337890386581, ppl = 3.531316909580815\n","Train Epoch #17, Batch 4509/24958 loss = 1.2562921530008315, ppl = 3.5404149246388035\n","Train Epoch #17, Batch 4510/24958 loss = 1.255605760216713, ppl = 3.538338480666096\n","Train Epoch #17, Batch 4511/24958 loss = 1.2538882452249527, ppl = 3.532476673510402\n","Train Epoch #17, Batch 4512/24958 loss = 1.25381123483181, ppl = 3.532241178831386\n","Train Epoch #17, Batch 4513/24958 loss = 1.2523813873529435, ppl = 3.5269189404054155\n","Train Epoch #17, Batch 4514/24958 loss = 1.2548805969953536, ppl = 3.5357276153509476\n","Train Epoch #17, Batch 4515/24958 loss = 1.2552336293458939, ppl = 3.5370205318168644\n","Train Epoch #17, Batch 4516/24958 loss = 1.2510848838090896, ppl = 3.5216564513289397\n","Train Epoch #17, Batch 4517/24958 loss = 1.2527495843172074, ppl = 3.527240765579242\n","Train Epoch #17, Batch 4518/24958 loss = 1.2517430919408798, ppl = 3.523686645034418\n","Train Epoch #17, Batch 4519/24958 loss = 1.249951999783516, ppl = 3.5174927463627137\n","Train Epoch #17, Batch 4520/24958 loss = 1.2487678903341293, ppl = 3.513374047425648\n","Train Epoch #17, Batch 4521/24958 loss = 1.2480897527933121, ppl = 3.511131198190358\n","Train Epoch #17, Batch 4522/24958 loss = 1.2508149522542953, ppl = 3.5204976648156765\n","Train Epoch #17, Batch 4523/24958 loss = 1.2503272312879563, ppl = 3.5189117404823027\n","Train Epoch #17, Batch 4524/24958 loss = 1.2504404550790786, ppl = 3.519366936521675\n","Train Epoch #17, Batch 4525/24958 loss = 1.254821143746376, ppl = 3.536180269021803\n","Train Epoch #17, Batch 4526/24958 loss = 1.2511212784051895, ppl = 3.5198020231940643\n","Train Epoch #17, Batch 4527/24958 loss = 1.251039885878563, ppl = 3.5195422958745906\n","Train Epoch #17, Batch 4528/24958 loss = 1.2536934703588485, ppl = 3.5286893205094936\n","Train Epoch #17, Batch 4529/24958 loss = 1.2530590397119523, ppl = 3.526452591161059\n","Train Epoch #17, Batch 4530/24958 loss = 1.25676986515522, ppl = 3.539024430384691\n","Train Epoch #17, Batch 4531/24958 loss = 1.2572760742902755, ppl = 3.5404413002812167\n","Train Epoch #17, Batch 4532/24958 loss = 1.256991154551506, ppl = 3.5394920037348756\n","Train Epoch #17, Batch 4533/24958 loss = 1.2564657455682755, ppl = 3.5375320346098005\n","Train Epoch #17, Batch 4534/24958 loss = 1.2554790598154069, ppl = 3.534394149611434\n","Train Epoch #17, Batch 4535/24958 loss = 1.2560709971189499, ppl = 3.536974768991203\n","Train Epoch #17, Batch 4536/24958 loss = 1.2535740333795546, ppl = 3.5274240143033535\n","Train Epoch #17, Batch 4537/24958 loss = 1.2524220341444015, ppl = 3.5236222165252\n","Train Epoch #17, Batch 4538/24958 loss = 1.2541824501752854, ppl = 3.5294089185121633\n","Train Epoch #17, Batch 4539/24958 loss = 1.254826620221138, ppl = 3.5317705659777836\n","Train Epoch #17, Batch 4540/24958 loss = 1.2514457589387893, ppl = 3.520571659272615\n","Train Epoch #17, Batch 4541/24958 loss = 1.2506445187330246, ppl = 3.5176367204387424\n","Train Epoch #17, Batch 4542/24958 loss = 1.250067645907402, ppl = 3.5154325251010494\n","Train Epoch #17, Batch 4543/24958 loss = 1.2479298228025437, ppl = 3.5080794704986364\n","Train Epoch #17, Batch 4544/24958 loss = 1.247174933552742, ppl = 3.5054891271262245\n","Train Epoch #17, Batch 4545/24958 loss = 1.2475572711229324, ppl = 3.5069830660684937\n","Train Epoch #17, Batch 4546/24958 loss = 1.247006556391716, ppl = 3.50512466440105\n","Train Epoch #17, Batch 4547/24958 loss = 1.2455696946382522, ppl = 3.500438821687619\n","Train Epoch #17, Batch 4548/24958 loss = 1.2473492151498795, ppl = 3.506660412892085\n","Train Epoch #17, Batch 4549/24958 loss = 1.2488408571481704, ppl = 3.5122209479833595\n","Train Epoch #17, Batch 4550/24958 loss = 1.2477992004156113, ppl = 3.508739141965987\n","Train Epoch #17, Batch 4551/24958 loss = 1.2507714182138443, ppl = 3.5188059732431607\n","Train Epoch #17, Batch 4552/24958 loss = 1.248842849135399, ppl = 3.511573024406856\n","Train Epoch #17, Batch 4553/24958 loss = 1.249477395415306, ppl = 3.514025223829253\n","Train Epoch #17, Batch 4554/24958 loss = 1.2479994100332261, ppl = 3.5080160015577944\n","Train Epoch #17, Batch 4555/24958 loss = 1.2470536440610887, ppl = 3.505027536963877\n","Train Epoch #17, Batch 4556/24958 loss = 1.2504616731405258, ppl = 3.5177156198682993\n","Train Epoch #17, Batch 4557/24958 loss = 1.253670128583908, ppl = 3.52799054285879\n","Train Epoch #17, Batch 4558/24958 loss = 1.2560113954544068, ppl = 3.536643534715101\n","Train Epoch #17, Batch 4559/24958 loss = 1.2557054674625396, ppl = 3.5356653690719226\n","Train Epoch #17, Batch 4560/24958 loss = 1.2574003219604493, ppl = 3.540718629803235\n","Train Epoch #17, Batch 4561/24958 loss = 1.2591291797161102, ppl = 3.546815601536079\n","Train Epoch #17, Batch 4562/24958 loss = 1.258277337551117, ppl = 3.5434642729640715\n","Train Epoch #17, Batch 4563/24958 loss = 1.2577096116542816, ppl = 3.5418705637821155\n","Train Epoch #17, Batch 4564/24958 loss = 1.2590834045410155, ppl = 3.547152961316721\n","Train Epoch #17, Batch 4565/24958 loss = 1.25763063788414, ppl = 3.5416732110227724\n","Train Epoch #17, Batch 4566/24958 loss = 1.2582678484916687, ppl = 3.543993847719206\n","Train Epoch #17, Batch 4567/24958 loss = 1.2587245094776154, ppl = 3.545701814631067\n","Train Epoch #17, Batch 4568/24958 loss = 1.2600163459777831, ppl = 3.5502165542150306\n","Train Epoch #17, Batch 4569/24958 loss = 1.2625707244873048, ppl = 3.559063258926579\n","Train Epoch #17, Batch 4570/24958 loss = 1.2633388686180114, ppl = 3.5619128364550385\n","Train Epoch #17, Batch 4571/24958 loss = 1.2598275315761567, ppl = 3.549054434302217\n","Train Epoch #17, Batch 4572/24958 loss = 1.2595320558547973, ppl = 3.5481108979208047\n","Train Epoch #17, Batch 4573/24958 loss = 1.2607500731945038, ppl = 3.552337630775469\n","Train Epoch #17, Batch 4574/24958 loss = 1.2596180641651153, ppl = 3.5482444844805823\n","Train Epoch #17, Batch 4575/24958 loss = 1.2589136958122253, ppl = 3.5459786433623193\n","Train Epoch #17, Batch 4576/24958 loss = 1.2595730328559875, ppl = 3.5483452970154383\n","Train Epoch #17, Batch 4577/24958 loss = 1.2587209796905519, ppl = 3.545435608006672\n","Train Epoch #17, Batch 4578/24958 loss = 1.257495744228363, ppl = 3.5413571624437084\n","Train Epoch #17, Batch 4579/24958 loss = 1.259220095872879, ppl = 3.5470895221706513\n","Train Epoch #17, Batch 4580/24958 loss = 1.2573762953281402, ppl = 3.540861489630001\n","Train Epoch #17, Batch 4581/24958 loss = 1.2546948683261872, ppl = 3.5319488797927674\n","Train Epoch #17, Batch 4582/24958 loss = 1.2514161735773086, ppl = 3.5217577870751198\n","Train Epoch #17, Batch 4583/24958 loss = 1.2532344979047776, ppl = 3.528075579017289\n","Train Epoch #17, Batch 4584/24958 loss = 1.2548474568128585, ppl = 3.5340661408734495\n","Train Epoch #17, Batch 4585/24958 loss = 1.2550305610895156, ppl = 3.534726583468419\n","Train Epoch #17, Batch 4586/24958 loss = 1.2581051844358444, ppl = 3.54519952393962\n","Train Epoch #17, Batch 4587/24958 loss = 1.2560833507776261, ppl = 3.5387137969937883\n","Train Epoch #17, Batch 4588/24958 loss = 1.2558582693338394, ppl = 3.5379450321087678\n","Train Epoch #17, Batch 4589/24958 loss = 1.2571831279993058, ppl = 3.5435321097974493\n","Train Epoch #17, Batch 4590/24958 loss = 1.2583825582265853, ppl = 3.547859188090688\n","Train Epoch #17, Batch 4591/24958 loss = 1.2581781405210495, ppl = 3.5471494623105615\n","Train Epoch #17, Batch 4592/24958 loss = 1.2594649118185044, ppl = 3.5519054019583467\n","Train Epoch #17, Batch 4593/24958 loss = 1.2594189316034317, ppl = 3.551736411959474\n","Train Epoch #17, Batch 4594/24958 loss = 1.261313117146492, ppl = 3.558091289005329\n","Train Epoch #17, Batch 4595/24958 loss = 1.2616652983427048, ppl = 3.5592756112270956\n","Train Epoch #17, Batch 4596/24958 loss = 1.2639995366334915, ppl = 3.5668603941812274\n","Train Epoch #17, Batch 4597/24958 loss = 1.2641213339567186, ppl = 3.5672348820140996\n","Train Epoch #17, Batch 4598/24958 loss = 1.2629688745737075, ppl = 3.562771335316063\n","Train Epoch #17, Batch 4599/24958 loss = 1.26365857899189, ppl = 3.565914465051678\n","Train Epoch #17, Batch 4600/24958 loss = 1.260486482977867, ppl = 3.554419543331678\n","Train Epoch #17, Batch 4601/24958 loss = 1.2598115211725236, ppl = 3.5519080600902715\n","Train Epoch #17, Batch 4602/24958 loss = 1.2597337931394577, ppl = 3.5516479805903898\n","Train Epoch #17, Batch 4603/24958 loss = 1.2578670018911362, ppl = 3.5448741461472952\n","Train Epoch #17, Batch 4604/24958 loss = 1.25916031062603, ppl = 3.5497728142834895\n","Train Epoch #17, Batch 4605/24958 loss = 1.2592210954427718, ppl = 3.5499862667086024\n","Train Epoch #17, Batch 4606/24958 loss = 1.2599500340223313, ppl = 3.5524960267109806\n","Train Epoch #17, Batch 4607/24958 loss = 1.259209241271019, ppl = 3.5500113618202356\n","Train Epoch #17, Batch 4608/24958 loss = 1.2566357678174973, ppl = 3.540593385655285\n","Train Epoch #17, Batch 4609/24958 loss = 1.2542642599344254, ppl = 3.5310913838701\n","Train Epoch #17, Batch 4610/24958 loss = 1.2552990716695787, ppl = 3.5342776583127478\n","Train Epoch #17, Batch 4611/24958 loss = 1.2551031142473221, ppl = 3.5336706208868622\n","Train Epoch #17, Batch 4612/24958 loss = 1.2555787962675096, ppl = 3.535154660215893\n","Train Epoch #17, Batch 4613/24958 loss = 1.2582391005754472, ppl = 3.5457073938605332\n","Train Epoch #17, Batch 4614/24958 loss = 1.2568192511796952, ppl = 3.540434812915085\n","Train Epoch #17, Batch 4615/24958 loss = 1.2555803245306014, ppl = 3.536091513446\n","Train Epoch #17, Batch 4616/24958 loss = 1.2574536508321763, ppl = 3.5422477851894882\n","Train Epoch #17, Batch 4617/24958 loss = 1.257269555926323, ppl = 3.541583535700422\n","Train Epoch #17, Batch 4618/24958 loss = 1.2578383439779282, ppl = 3.5435479936796237\n","Train Epoch #17, Batch 4619/24958 loss = 1.2589624279737472, ppl = 3.5473047177903525\n","Train Epoch #17, Batch 4620/24958 loss = 1.258423429131508, ppl = 3.5455854715217026\n","Train Epoch #17, Batch 4621/24958 loss = 1.2589267247915268, ppl = 3.547235424090197\n","Train Epoch #17, Batch 4622/24958 loss = 1.2566562575101852, ppl = 3.5392599504945927\n","Train Epoch #17, Batch 4623/24958 loss = 1.258245548605919, ppl = 3.544725687188302\n","Train Epoch #17, Batch 4624/24958 loss = 1.2573043352365494, ppl = 3.5410938424129186\n","Train Epoch #17, Batch 4625/24958 loss = 1.2549008375406265, ppl = 3.5309671636137274\n","Train Epoch #17, Batch 4626/24958 loss = 1.2564291459321977, ppl = 3.5370078459582\n","Train Epoch #17, Batch 4627/24958 loss = 1.2574238556623458, ppl = 3.540331683075818\n","Train Epoch #17, Batch 4628/24958 loss = 1.2574782449007034, ppl = 3.540545720584796\n","Train Epoch #17, Batch 4629/24958 loss = 1.258721575140953, ppl = 3.5450668270214765\n","Train Epoch #17, Batch 4630/24958 loss = 1.2572670406103135, ppl = 3.5395772246685606\n","Train Epoch #17, Batch 4631/24958 loss = 1.262028174996376, ppl = 3.557081222080601\n","Train Epoch #17, Batch 4632/24958 loss = 1.2638962680101395, ppl = 3.563827630858751\n","Train Epoch #17, Batch 4633/24958 loss = 1.2647340565919876, ppl = 3.5670026508286834\n","Train Epoch #17, Batch 4634/24958 loss = 1.2685710793733598, ppl = 3.581155099177163\n","Train Epoch #17, Batch 4635/24958 loss = 1.2638365679979324, ppl = 3.564221322021968\n","Train Epoch #17, Batch 4636/24958 loss = 1.2652564913034439, ppl = 3.569358680143957\n","Train Epoch #17, Batch 4637/24958 loss = 1.2638470804691315, ppl = 3.5652653818684645\n","Train Epoch #17, Batch 4638/24958 loss = 1.2630589318275451, ppl = 3.5625483908540287\n","Train Epoch #17, Batch 4639/24958 loss = 1.2626500165462493, ppl = 3.5610316494328402\n","Train Epoch #17, Batch 4640/24958 loss = 1.2643456768989563, ppl = 3.5661761976008894\n","Train Epoch #17, Batch 4641/24958 loss = 1.265135073661804, ppl = 3.5690660194896884\n","Train Epoch #17, Batch 4642/24958 loss = 1.2643001234531404, ppl = 3.566092716583426\n","Train Epoch #17, Batch 4643/24958 loss = 1.2678473663330079, ppl = 3.5792280160941217\n","Train Epoch #17, Batch 4644/24958 loss = 1.2685159039497376, ppl = 3.581512050297691\n","Train Epoch #17, Batch 4645/24958 loss = 1.2665822219848633, ppl = 3.5745098608293078\n","Train Epoch #17, Batch 4646/24958 loss = 1.265838931798935, ppl = 3.5721585100576116\n","Train Epoch #17, Batch 4647/24958 loss = 1.2660384631156922, ppl = 3.5727696619676568\n","Train Epoch #17, Batch 4648/24958 loss = 1.2654130029678345, ppl = 3.570455700483022\n","Train Epoch #17, Batch 4649/24958 loss = 1.2616453886032104, ppl = 3.5578589250314616\n","Train Epoch #17, Batch 4650/24958 loss = 1.2630878603458404, ppl = 3.5627801245633344\n","Train Epoch #17, Batch 4651/24958 loss = 1.2624171924591066, ppl = 3.560240431821382\n","Train Epoch #17, Batch 4652/24958 loss = 1.2624424469470978, ppl = 3.560326415513669\n","Train Epoch #17, Batch 4653/24958 loss = 1.2613128876686097, ppl = 3.5560664072772754\n","Train Epoch #17, Batch 4654/24958 loss = 1.258625934123993, ppl = 3.5471768887685813\n","Train Epoch #17, Batch 4655/24958 loss = 1.2585887277126313, ppl = 3.5470650027958435\n","Train Epoch #17, Batch 4656/24958 loss = 1.2557599139213562, ppl = 3.5362401513831143\n","Train Epoch #17, Batch 4657/24958 loss = 1.2552679526805877, ppl = 3.5344430028665035\n","Train Epoch #17, Batch 4658/24958 loss = 1.2541961669921875, ppl = 3.5302298603721884\n","Train Epoch #17, Batch 4659/24958 loss = 1.2531862592697143, ppl = 3.5272052496991817\n","Train Epoch #17, Batch 4660/24958 loss = 1.2538390588760375, ppl = 3.529391778817549\n","Train Epoch #17, Batch 4661/24958 loss = 1.253902224302292, ppl = 3.5296351155250263\n","Train Epoch #17, Batch 4662/24958 loss = 1.252181829214096, ppl = 3.523678016742527\n","Train Epoch #17, Batch 4663/24958 loss = 1.2558498668670655, ppl = 3.5357672900350483\n","Train Epoch #17, Batch 4664/24958 loss = 1.2529393923282623, ppl = 3.525375381595217\n","Train Epoch #17, Batch 4665/24958 loss = 1.2542286121845245, ppl = 3.5301977389954833\n","Train Epoch #17, Batch 4666/24958 loss = 1.255173671245575, ppl = 3.533923626965548\n","Train Epoch #17, Batch 4667/24958 loss = 1.254617612361908, ppl = 3.531854123570741\n","Train Epoch #17, Batch 4668/24958 loss = 1.2523867797851562, ppl = 3.5244050833219536\n","Train Epoch #17, Batch 4669/24958 loss = 1.2506258845329286, ppl = 3.518068707070755\n","Train Epoch #17, Batch 4670/24958 loss = 1.2506803250312806, ppl = 3.5182790925785095\n","Train Epoch #17, Batch 4671/24958 loss = 1.2512172198295592, ppl = 3.5199650159963785\n","Train Epoch #17, Batch 4672/24958 loss = 1.2517978608608247, ppl = 3.52184598684701\n","Train Epoch #17, Batch 4673/24958 loss = 1.2495856809616088, ppl = 3.5145312186388757\n","Train Epoch #17, Batch 4674/24958 loss = 1.2498431527614593, ppl = 3.5154219091918093\n","Train Epoch #17, Batch 4675/24958 loss = 1.2497394704818725, ppl = 3.515101651381658\n","Train Epoch #17, Batch 4676/24958 loss = 1.2498349857330322, ppl = 3.515457622160091\n","Train Epoch #17, Batch 4677/24958 loss = 1.2520871126651765, ppl = 3.5237210650304656\n","Train Epoch #17, Batch 4678/24958 loss = 1.253179622888565, ppl = 3.527333190901521\n","Train Epoch #17, Batch 4679/24958 loss = 1.2509706044197082, ppl = 3.5201597539519103\n","Train Epoch #17, Batch 4680/24958 loss = 1.253472764492035, ppl = 3.528904867547195\n","Train Epoch #17, Batch 4681/24958 loss = 1.2534099638462066, ppl = 3.5287234357971626\n","Train Epoch #17, Batch 4682/24958 loss = 1.2581461590528489, ppl = 3.544634771395406\n","Train Epoch #17, Batch 4683/24958 loss = 1.2563677245378495, ppl = 3.538443610415574\n","Train Epoch #17, Batch 4684/24958 loss = 1.2552353626489638, ppl = 3.534138078087669\n","Train Epoch #17, Batch 4685/24958 loss = 1.2552470248937606, ppl = 3.534180553929935\n","Train Epoch #17, Batch 4686/24958 loss = 1.253941360116005, ppl = 3.5293374921910736\n","Train Epoch #17, Batch 4687/24958 loss = 1.257776179909706, ppl = 3.5428658501974173\n","Train Epoch #17, Batch 4688/24958 loss = 1.2563292962312698, ppl = 3.538316485065471\n","Train Epoch #17, Batch 4689/24958 loss = 1.2519887739419937, ppl = 3.522461743425952\n","Train Epoch #17, Batch 4690/24958 loss = 1.2516664296388627, ppl = 3.521247393233292\n","Train Epoch #17, Batch 4691/24958 loss = 1.251312739253044, ppl = 3.520053154264426\n","Train Epoch #17, Batch 4692/24958 loss = 1.2512737637758256, ppl = 3.5198999317284723\n","Train Epoch #17, Batch 4693/24958 loss = 1.251130228638649, ppl = 3.5193773715572614\n","Train Epoch #17, Batch 4694/24958 loss = 1.2510360568761825, ppl = 3.5190321923115926\n","Train Epoch #17, Batch 4695/24958 loss = 1.2524695020914078, ppl = 3.5243070228586277\n","Train Epoch #17, Batch 4696/24958 loss = 1.2530286592245101, ppl = 3.526402255131776\n","Train Epoch #17, Batch 4697/24958 loss = 1.2518871396780014, ppl = 3.5230651228533225\n","Train Epoch #17, Batch 4698/24958 loss = 1.2515407699346541, ppl = 3.5218210977662427\n","Train Epoch #17, Batch 4699/24958 loss = 1.2500710397958756, ppl = 3.5153749004644386\n","Train Epoch #17, Batch 4700/24958 loss = 1.2511830240488053, ppl = 3.5189967300583107\n","Train Epoch #17, Batch 4701/24958 loss = 1.251603748202324, ppl = 3.5205422600116725\n","Train Epoch #17, Batch 4702/24958 loss = 1.2548273223638535, ppl = 3.5332203830843043\n","Train Epoch #17, Batch 4703/24958 loss = 1.2555751734972, ppl = 3.535783257173145\n","Train Epoch #17, Batch 4704/24958 loss = 1.254820550084114, ppl = 3.5328482856283348\n","Train Epoch #17, Batch 4705/24958 loss = 1.2544633108377456, ppl = 3.531612195480967\n","Train Epoch #17, Batch 4706/24958 loss = 1.2534384912252425, ppl = 3.528134771881584\n","Train Epoch #17, Batch 4707/24958 loss = 1.252162340283394, ppl = 3.5242633444116636\n","Train Epoch #17, Batch 4708/24958 loss = 1.2533585947752, ppl = 3.5283410578184995\n","Train Epoch #17, Batch 4709/24958 loss = 1.253795136809349, ppl = 3.529925281891057\n","Train Epoch #17, Batch 4710/24958 loss = 1.2542062455415726, ppl = 3.53128551432684\n","Train Epoch #17, Batch 4711/24958 loss = 1.2565080708265304, ppl = 3.5392252464770535\n","Train Epoch #17, Batch 4712/24958 loss = 1.2577854365110397, ppl = 3.543578010675081\n","Train Epoch #17, Batch 4713/24958 loss = 1.2551388889551163, ppl = 3.533072942144934\n","Train Epoch #17, Batch 4714/24958 loss = 1.255578859448433, ppl = 3.5346274646473144\n","Train Epoch #17, Batch 4715/24958 loss = 1.2563128405809403, ppl = 3.537135386990555\n","Train Epoch #17, Batch 4716/24958 loss = 1.256302563548088, ppl = 3.5370983707027532\n","Train Epoch #17, Batch 4717/24958 loss = 1.2556478172540664, ppl = 3.5348325854772344\n","Train Epoch #17, Batch 4718/24958 loss = 1.2553356879949569, ppl = 3.5337407451693745\n","Train Epoch #17, Batch 4719/24958 loss = 1.2548240274190903, ppl = 3.5319783234124373\n","Train Epoch #17, Batch 4720/24958 loss = 1.2561659926176072, ppl = 3.5364369485866805\n","Train Epoch #17, Batch 4721/24958 loss = 1.2566185253858566, ppl = 3.53799307572716\n","Train Epoch #17, Batch 4722/24958 loss = 1.2566061514616012, ppl = 3.5379543816034493\n","Train Epoch #17, Batch 4723/24958 loss = 1.2542070478200913, ppl = 3.530020358364461\n","Train Epoch #17, Batch 4724/24958 loss = 1.2540722912549973, ppl = 3.529527788627884\n","Train Epoch #17, Batch 4725/24958 loss = 1.2531986743211747, ppl = 3.5264097895502022\n","Train Epoch #17, Batch 4726/24958 loss = 1.2524341851472856, ppl = 3.5232727814804923\n","Train Epoch #17, Batch 4727/24958 loss = 1.2519332891702653, ppl = 3.5215577175681223\n","Train Epoch #17, Batch 4728/24958 loss = 1.2524850708246231, ppl = 3.5237962405584033\n","Train Epoch #17, Batch 4729/24958 loss = 1.250172535777092, ppl = 3.5158123116476196\n","Train Epoch #17, Batch 4730/24958 loss = 1.249702369570732, ppl = 3.514201921366253\n","Train Epoch #17, Batch 4731/24958 loss = 1.2476439148187637, ppl = 3.50560529031631\n","Train Epoch #17, Batch 4732/24958 loss = 1.246153054833412, ppl = 3.5001215946551967\n","Train Epoch #17, Batch 4733/24958 loss = 1.2438620656728745, ppl = 3.4920324693752467\n","Train Epoch #17, Batch 4734/24958 loss = 1.2421420234441758, ppl = 3.4850143575288057\n","Train Epoch #17, Batch 4735/24958 loss = 1.2443200570344926, ppl = 3.491819534715388\n","Train Epoch #17, Batch 4736/24958 loss = 1.244281674027443, ppl = 3.49167085586189\n","Train Epoch #17, Batch 4737/24958 loss = 1.2470598208904267, ppl = 3.5003314772549654\n","Train Epoch #17, Batch 4738/24958 loss = 1.2477045118808747, ppl = 3.5025378522949207\n","Train Epoch #17, Batch 4739/24958 loss = 1.24776673078537, ppl = 3.50276465205643\n","Train Epoch #17, Batch 4740/24958 loss = 1.2482935571670533, ppl = 3.5045489469140874\n","Train Epoch #17, Batch 4741/24958 loss = 1.248490296602249, ppl = 3.5053053879464087\n","Train Epoch #17, Batch 4742/24958 loss = 1.2494460678100585, ppl = 3.508729872894754\n","Train Epoch #17, Batch 4743/24958 loss = 1.246953648328781, ppl = 3.4990264633564903\n","Train Epoch #17, Batch 4744/24958 loss = 1.2479607117176057, ppl = 3.502768615216646\n","Train Epoch #17, Batch 4745/24958 loss = 1.2478473818302154, ppl = 3.502398728369593\n","Train Epoch #17, Batch 4746/24958 loss = 1.248162304162979, ppl = 3.503373669896518\n","Train Epoch #17, Batch 4747/24958 loss = 1.2483079659938812, ppl = 3.5038275867190913\n","Train Epoch #17, Batch 4748/24958 loss = 1.249505798816681, ppl = 3.508389745794657\n","Train Epoch #17, Batch 4749/24958 loss = 1.2521570539474487, ppl = 3.516747866370659\n","Train Epoch #17, Batch 4750/24958 loss = 1.250007952451706, ppl = 3.5096629405023965\n","Train Epoch #17, Batch 4751/24958 loss = 1.2500832104682922, ppl = 3.509939518041541\n","Train Epoch #17, Batch 4752/24958 loss = 1.2528063333034516, ppl = 3.5206095550840253\n","Train Epoch #17, Batch 4753/24958 loss = 1.2529690563678741, ppl = 3.521193981553686\n","Train Epoch #17, Batch 4754/24958 loss = 1.255048702955246, ppl = 3.5278604647537675\n","Train Epoch #17, Batch 4755/24958 loss = 1.2577407264709473, ppl = 3.5371329398143034\n","Train Epoch #17, Batch 4756/24958 loss = 1.2600891041755675, ppl = 3.5458969607643267\n","Train Epoch #17, Batch 4757/24958 loss = 1.2597975158691406, ppl = 3.544872771516695\n","Train Epoch #17, Batch 4758/24958 loss = 1.2590822291374206, ppl = 3.5423020365216393\n","Train Epoch #17, Batch 4759/24958 loss = 1.2610332298278808, ppl = 3.5484337918049893\n","Train Epoch #17, Batch 4760/24958 loss = 1.2611961555480957, ppl = 3.549002128861348\n","Train Epoch #17, Batch 4761/24958 loss = 1.2595631992816925, ppl = 3.5431797981039677\n","Train Epoch #17, Batch 4762/24958 loss = 1.259296990633011, ppl = 3.5423461791393662\n","Train Epoch #17, Batch 4763/24958 loss = 1.2577112007141114, ppl = 3.536572528396943\n","Train Epoch #17, Batch 4764/24958 loss = 1.257667554616928, ppl = 3.536438561474775\n","Train Epoch #17, Batch 4765/24958 loss = 1.2566712033748626, ppl = 3.5326577646813297\n","Train Epoch #17, Batch 4766/24958 loss = 1.2571203112602234, ppl = 3.534555651739763\n","Train Epoch #17, Batch 4767/24958 loss = 1.257934763431549, ppl = 3.5376266951897457\n","Train Epoch #17, Batch 4768/24958 loss = 1.2593667030334472, ppl = 3.5422153047496834\n","Train Epoch #17, Batch 4769/24958 loss = 1.2587952303886414, ppl = 3.540387396905921\n","Train Epoch #17, Batch 4770/24958 loss = 1.2565888154506684, ppl = 3.5327149934001385\n","Train Epoch #17, Batch 4771/24958 loss = 1.2577733302116394, ppl = 3.5367707395297994\n","Train Epoch #17, Batch 4772/24958 loss = 1.2578390729427338, ppl = 3.5369906763315715\n","Train Epoch #17, Batch 4773/24958 loss = 1.2579614233970642, ppl = 3.537354359465965\n","Train Epoch #17, Batch 4774/24958 loss = 1.2578639996051788, ppl = 3.537014634607731\n","Train Epoch #17, Batch 4775/24958 loss = 1.2602046573162078, ppl = 3.54511859683392\n","Train Epoch #17, Batch 4776/24958 loss = 1.2588392794132233, ppl = 3.540339394422062\n","Train Epoch #17, Batch 4777/24958 loss = 1.2572051787376404, ppl = 3.5341616077756974\n","Train Epoch #17, Batch 4778/24958 loss = 1.2571814501285552, ppl = 3.5340788893836463\n","Train Epoch #17, Batch 4779/24958 loss = 1.2604635739326477, ppl = 3.545352161559991\n","Train Epoch #17, Batch 4780/24958 loss = 1.259366878271103, ppl = 3.5412487881074015\n","Train Epoch #17, Batch 4781/24958 loss = 1.2624903011322022, ppl = 3.551807325205901\n","Train Epoch #17, Batch 4782/24958 loss = 1.2596138167381286, ppl = 3.5412642613410634\n","Train Epoch #17, Batch 4783/24958 loss = 1.2614247572422028, ppl = 3.5475791451053578\n","Train Epoch #17, Batch 4784/24958 loss = 1.2603922605514526, ppl = 3.5440563948267596\n","Train Epoch #17, Batch 4785/24958 loss = 1.2583811831474305, ppl = 3.537417382464873\n","Train Epoch #17, Batch 4786/24958 loss = 1.2552548193931579, ppl = 3.52809458268203\n","Train Epoch #17, Batch 4787/24958 loss = 1.2520889639854431, ppl = 3.516568761762842\n","Train Epoch #17, Batch 4788/24958 loss = 1.2522545278072357, ppl = 3.5170566106432597\n","Train Epoch #17, Batch 4789/24958 loss = 1.254550940990448, ppl = 3.5245872162025496\n","Train Epoch #17, Batch 4790/24958 loss = 1.253897956609726, ppl = 3.5222440337880148\n","Train Epoch #17, Batch 4791/24958 loss = 1.2550901341438294, ppl = 3.526444049910516\n","Train Epoch #17, Batch 4792/24958 loss = 1.2550517296791077, ppl = 3.5262936551769006\n","Train Epoch #17, Batch 4793/24958 loss = 1.2527950417995453, ppl = 3.5189915712954956\n","Train Epoch #17, Batch 4794/24958 loss = 1.2544593918323517, ppl = 3.5255979607528776\n","Train Epoch #17, Batch 4795/24958 loss = 1.252594667673111, ppl = 3.5188785036396335\n","Train Epoch #17, Batch 4796/24958 loss = 1.2523906862735747, ppl = 3.518100552414038\n","Train Epoch #17, Batch 4797/24958 loss = 1.2538218367099763, ppl = 3.5223467422719184\n","Train Epoch #17, Batch 4798/24958 loss = 1.2537268590927124, ppl = 3.522013080349656\n","Train Epoch #17, Batch 4799/24958 loss = 1.2511357319355012, ppl = 3.512719185400528\n","Train Epoch #17, Batch 4800/24958 loss = 1.250888879299164, ppl = 3.5118800335898537\n","Train Epoch #17, Batch 4801/24958 loss = 1.250016256570816, ppl = 3.5087453089165668\n","Train Epoch #17, Batch 4802/24958 loss = 1.2454751706123353, ppl = 3.4919528600386593\n","Train Epoch #17, Batch 4803/24958 loss = 1.2448960161209106, ppl = 3.4899514815026276\n","Train Epoch #17, Batch 4804/24958 loss = 1.2442288196086884, ppl = 3.4875347385128124\n","Train Epoch #17, Batch 4805/24958 loss = 1.2449867129325867, ppl = 3.490210700856606\n","Train Epoch #17, Batch 4806/24958 loss = 1.2450870871543884, ppl = 3.490535765753431\n","Train Epoch #17, Batch 4807/24958 loss = 1.247492847442627, ppl = 3.498271521389345\n","Train Epoch #17, Batch 4808/24958 loss = 1.2470619034767152, ppl = 3.496746039302762\n","Train Epoch #17, Batch 4809/24958 loss = 1.2480509281158447, ppl = 3.500601674584707\n","Train Epoch #17, Batch 4810/24958 loss = 1.249715087413788, ppl = 3.5067165222099272\n","Train Epoch #17, Batch 4811/24958 loss = 1.24885373711586, ppl = 3.50352962017595\n","Train Epoch #17, Batch 4812/24958 loss = 1.2482454192638397, ppl = 3.501387319680311\n","Train Epoch #17, Batch 4813/24958 loss = 1.2493289744853973, ppl = 3.505355359411941\n","Train Epoch #17, Batch 4814/24958 loss = 1.2509760081768035, ppl = 3.5118215784074285\n","Train Epoch #17, Batch 4815/24958 loss = 1.2489326548576356, ppl = 3.5052722344355947\n","Train Epoch #17, Batch 4816/24958 loss = 1.2492574167251587, ppl = 3.5064605674586153\n","Train Epoch #17, Batch 4817/24958 loss = 1.249841697216034, ppl = 3.5084753173153196\n","Train Epoch #17, Batch 4818/24958 loss = 1.247572649717331, ppl = 3.5014844296279106\n","Train Epoch #17, Batch 4819/24958 loss = 1.2485374009609223, ppl = 3.504884618285802\n","Train Epoch #17, Batch 4820/24958 loss = 1.2476766204833984, ppl = 3.501956361536829\n","Train Epoch #17, Batch 4821/24958 loss = 1.2455636084079742, ppl = 3.4952573495775705\n","Train Epoch #17, Batch 4822/24958 loss = 1.2485163402557373, ppl = 3.505991981248778\n","Train Epoch #17, Batch 4823/24958 loss = 1.2498346424102784, ppl = 3.5101154577739675\n","Train Epoch #17, Batch 4824/24958 loss = 1.2486404418945312, ppl = 3.5060285780342952\n","Train Epoch #17, Batch 4825/24958 loss = 1.248450174331665, ppl = 3.5053848740627673\n","Train Epoch #17, Batch 4826/24958 loss = 1.2479816615581512, ppl = 3.5035775942334753\n","Train Epoch #17, Batch 4827/24958 loss = 1.2497782289981842, ppl = 3.5101488738021818\n","Train Epoch #17, Batch 4828/24958 loss = 1.2481735146045685, ppl = 3.503966735811368\n","Train Epoch #17, Batch 4829/24958 loss = 1.2503190171718597, ppl = 3.51131011031483\n","Train Epoch #17, Batch 4830/24958 loss = 1.2515241539478301, ppl = 3.515594594389355\n","Train Epoch #17, Batch 4831/24958 loss = 1.249154189825058, ppl = 3.507658327511677\n","Train Epoch #17, Batch 4832/24958 loss = 1.248174147605896, ppl = 3.504474144857333\n","Train Epoch #17, Batch 4833/24958 loss = 1.2483074069023132, ppl = 3.50489562332402\n","Train Epoch #17, Batch 4834/24958 loss = 1.2503451585769654, ppl = 3.513347386524286\n","Train Epoch #17, Batch 4835/24958 loss = 1.252991052865982, ppl = 3.523879259713325\n","Train Epoch #17, Batch 4836/24958 loss = 1.2513258361816406, ppl = 3.5179487890357546\n","Train Epoch #17, Batch 4837/24958 loss = 1.2509146118164063, ppl = 3.516510306407349\n","Train Epoch #17, Batch 4838/24958 loss = 1.2518790566921234, ppl = 3.5200883051411473\n","Train Epoch #17, Batch 4839/24958 loss = 1.2529439115524292, ppl = 3.524196861187985\n","Train Epoch #17, Batch 4840/24958 loss = 1.2526284837722779, ppl = 3.5231172750676016\n","Train Epoch #17, Batch 4841/24958 loss = 1.251702972650528, ppl = 3.5196849515920166\n","Train Epoch #17, Batch 4842/24958 loss = 1.250912160873413, ppl = 3.516828384915216\n","Train Epoch #17, Batch 4843/24958 loss = 1.251741305589676, ppl = 3.519791966314979\n","Train Epoch #17, Batch 4844/24958 loss = 1.249724428653717, ppl = 3.5126573846519142\n","Train Epoch #17, Batch 4845/24958 loss = 1.2510583841800689, ppl = 3.5172885571626824\n","Train Epoch #17, Batch 4846/24958 loss = 1.2537053275108336, ppl = 3.5268183837234535\n","Train Epoch #17, Batch 4847/24958 loss = 1.2557423448562621, ppl = 3.5339103764956143\n","Train Epoch #17, Batch 4848/24958 loss = 1.2520712280273438, ppl = 3.5214926478659265\n","Train Epoch #17, Batch 4849/24958 loss = 1.251308444738388, ppl = 3.51885692354767\n","Train Epoch #17, Batch 4850/24958 loss = 1.253144804239273, ppl = 3.5248138136342306\n","Train Epoch #17, Batch 4851/24958 loss = 1.2508123707771301, ppl = 3.5171394489022334\n","Train Epoch #17, Batch 4852/24958 loss = 1.2496372640132904, ppl = 3.5121769596480705\n","Train Epoch #17, Batch 4853/24958 loss = 1.2511342585086822, ppl = 3.5180240786057606\n","Train Epoch #17, Batch 4854/24958 loss = 1.2511338901519775, ppl = 3.5180227707963945\n","Train Epoch #17, Batch 4855/24958 loss = 1.2500069987773896, ppl = 3.5138357562927918\n","Train Epoch #17, Batch 4856/24958 loss = 1.2485797011852264, ppl = 3.508266181028804\n","Train Epoch #17, Batch 4857/24958 loss = 1.2494374907016754, ppl = 3.5113664794577413\n","Train Epoch #17, Batch 4858/24958 loss = 1.2508081424236297, ppl = 3.516459584734034\n","Train Epoch #17, Batch 4859/24958 loss = 1.249381629228592, ppl = 3.5118604949908216\n","Train Epoch #17, Batch 4860/24958 loss = 1.2502211225032807, ppl = 3.5149403020844154\n","Train Epoch #17, Batch 4861/24958 loss = 1.2526160657405854, ppl = 3.5238224680581\n","Train Epoch #17, Batch 4862/24958 loss = 1.254491493701935, ppl = 3.5301964821488285\n","Train Epoch #17, Batch 4863/24958 loss = 1.257028352022171, ppl = 3.5398985038844732\n","Train Epoch #17, Batch 4864/24958 loss = 1.2585931825637817, ppl = 3.5450864355830793\n","Train Epoch #17, Batch 4865/24958 loss = 1.2577416801452637, ppl = 3.542140775055336\n","Train Epoch #17, Batch 4866/24958 loss = 1.2558145999908448, ppl = 3.534566152401406\n","Train Epoch #17, Batch 4867/24958 loss = 1.2540908288955688, ppl = 3.528349280912894\n","Train Epoch #17, Batch 4868/24958 loss = 1.2534903049468995, ppl = 3.5263446474462468\n","Train Epoch #17, Batch 4869/24958 loss = 1.25525053024292, ppl = 3.532326586400974\n","Train Epoch #17, Batch 4870/24958 loss = 1.2582698702812194, ppl = 3.543280682581923\n","Train Epoch #17, Batch 4871/24958 loss = 1.2578584194183349, ppl = 3.5418171179675024\n","Train Epoch #17, Batch 4872/24958 loss = 1.2581661498546601, ppl = 3.542866048765662\n","Train Epoch #17, Batch 4873/24958 loss = 1.2598924815654755, ppl = 3.5485014117179903\n","Train Epoch #17, Batch 4874/24958 loss = 1.2597576463222504, ppl = 3.548036656952652\n","Train Epoch #17, Batch 4875/24958 loss = 1.2597794210910798, ppl = 3.548121305938614\n","Train Epoch #17, Batch 4876/24958 loss = 1.2611547243595123, ppl = 3.5529376940635\n","Train Epoch #17, Batch 4877/24958 loss = 1.2632059526443482, ppl = 3.5608609542793968\n","Train Epoch #17, Batch 4878/24958 loss = 1.2626730918884277, ppl = 3.5590541603125674\n","Train Epoch #17, Batch 4879/24958 loss = 1.2616820287704469, ppl = 3.555252474274992\n","Train Epoch #17, Batch 4880/24958 loss = 1.2614370691776275, ppl = 3.554395813397989\n","Train Epoch #17, Batch 4881/24958 loss = 1.2600764584541322, ppl = 3.549389052555904\n","Train Epoch #17, Batch 4882/24958 loss = 1.2633592224121093, ppl = 3.561680947031962\n","Train Epoch #17, Batch 4883/24958 loss = 1.2616949367523194, ppl = 3.5558359884250836\n","Train Epoch #17, Batch 4884/24958 loss = 1.262550152540207, ppl = 3.558727725109552\n","Train Epoch #17, Batch 4885/24958 loss = 1.2639386475086212, ppl = 3.563167050613296\n","Train Epoch #17, Batch 4886/24958 loss = 1.266471209526062, ppl = 3.5704879671287246\n","Train Epoch #17, Batch 4887/24958 loss = 1.2667282152175903, ppl = 3.571293639501338\n","Train Epoch #17, Batch 4888/24958 loss = 1.2666445004940032, ppl = 3.571045956982362\n","Train Epoch #17, Batch 4889/24958 loss = 1.2652258706092834, ppl = 3.5661917302727586\n","Train Epoch #17, Batch 4890/24958 loss = 1.265418221950531, ppl = 3.5668661426716786\n","Train Epoch #17, Batch 4891/24958 loss = 1.2657126200199127, ppl = 3.5679827078612836\n","Train Epoch #17, Batch 4892/24958 loss = 1.265027174949646, ppl = 3.565393361626282\n","Train Epoch #17, Batch 4893/24958 loss = 1.2664385068416595, ppl = 3.569765430856547\n","Train Epoch #17, Batch 4894/24958 loss = 1.2649450159072877, ppl = 3.5637877233749946\n","Train Epoch #17, Batch 4895/24958 loss = 1.2639279985427856, ppl = 3.5606179380637637\n","Train Epoch #17, Batch 4896/24958 loss = 1.2611327683925628, ppl = 3.551412218513409\n","Train Epoch #17, Batch 4897/24958 loss = 1.2643557226657867, ppl = 3.563522056697542\n","Train Epoch #17, Batch 4898/24958 loss = 1.2643688642978668, ppl = 3.563568035328394\n","Train Epoch #17, Batch 4899/24958 loss = 1.2658788061141968, ppl = 3.568689448842936\n","Train Epoch #17, Batch 4900/24958 loss = 1.265030277967453, ppl = 3.5659579414420084\n","Train Epoch #17, Batch 4901/24958 loss = 1.2655905258655549, ppl = 3.56793896206659\n","Train Epoch #17, Batch 4902/24958 loss = 1.2689062094688415, ppl = 3.579425271210535\n","Train Epoch #17, Batch 4903/24958 loss = 1.2702355980873108, ppl = 3.584197672448908\n","Train Epoch #17, Batch 4904/24958 loss = 1.2713721334934234, ppl = 3.588413709343214\n","Train Epoch #17, Batch 4905/24958 loss = 1.271949951648712, ppl = 3.590594551251133\n","Train Epoch #17, Batch 4906/24958 loss = 1.2732464599609374, ppl = 3.5951002112441266\n","Train Epoch #17, Batch 4907/24958 loss = 1.2730085444450379, ppl = 3.59424963991597\n","Train Epoch #17, Batch 4908/24958 loss = 1.2724989116191865, ppl = 3.5925284344022606\n","Train Epoch #17, Batch 4909/24958 loss = 1.2706962215900421, ppl = 3.5857745710022244\n","Train Epoch #17, Batch 4910/24958 loss = 1.2680687713623047, ppl = 3.5765583023246283\n","Train Epoch #17, Batch 4911/24958 loss = 1.2682529258728028, ppl = 3.577216775420746\n","Train Epoch #17, Batch 4912/24958 loss = 1.265058718919754, ppl = 3.567877356438661\n","Train Epoch #17, Batch 4913/24958 loss = 1.2663425958156587, ppl = 3.573170848662099\n","Train Epoch #17, Batch 4914/24958 loss = 1.2644613552093507, ppl = 3.565868610619038\n","Train Epoch #17, Batch 4915/24958 loss = 1.2663789355754853, ppl = 3.571975030910596\n","Train Epoch #17, Batch 4916/24958 loss = 1.26415811419487, ppl = 3.5645689681408586\n","Train Epoch #17, Batch 4917/24958 loss = 1.263265870809555, ppl = 3.5615387211311376\n","Train Epoch #17, Batch 4918/24958 loss = 1.2649503684043883, ppl = 3.566574282275267\n","Train Epoch #17, Batch 4919/24958 loss = 1.265053517818451, ppl = 3.5669576160760403\n","Train Epoch #17, Batch 4920/24958 loss = 1.2654487931728362, ppl = 3.5682710322754914\n","Train Epoch #17, Batch 4921/24958 loss = 1.2682991480827333, ppl = 3.577661353767469\n","Train Epoch #17, Batch 4922/24958 loss = 1.2654482793807984, ppl = 3.5672466850744926\n","Train Epoch #17, Batch 4923/24958 loss = 1.2644495642185212, ppl = 3.5640734957397497\n","Train Epoch #17, Batch 4924/24958 loss = 1.2669243502616883, ppl = 3.573120598060454\n","Train Epoch #17, Batch 4925/24958 loss = 1.2664819025993348, ppl = 3.571670247543474\n","Train Epoch #17, Batch 4926/24958 loss = 1.2633196806907654, ppl = 3.561455581367272\n","Train Epoch #17, Batch 4927/24958 loss = 1.2616482508182525, ppl = 3.5553047557293422\n","Train Epoch #17, Batch 4928/24958 loss = 1.2619552600383759, ppl = 3.5564120530004852\n","Train Epoch #17, Batch 4929/24958 loss = 1.2596297204494475, ppl = 3.5485211544232236\n","Train Epoch #17, Batch 4930/24958 loss = 1.2598164141178132, ppl = 3.549232300016582\n","Train Epoch #17, Batch 4931/24958 loss = 1.259761505126953, ppl = 3.5490698023446496\n","Train Epoch #17, Batch 4932/24958 loss = 1.2611859798431397, ppl = 3.553804061100209\n","Train Epoch #17, Batch 4933/24958 loss = 1.26388028383255, ppl = 3.563649471599673\n","Train Epoch #17, Batch 4934/24958 loss = 1.2600881850719452, ppl = 3.5491808076560094\n","Train Epoch #17, Batch 4935/24958 loss = 1.2572927725315095, ppl = 3.5381329178534986\n","Train Epoch #17, Batch 4936/24958 loss = 1.2577475571632386, ppl = 3.5396558331628416\n","Train Epoch #17, Batch 4937/24958 loss = 1.2571098434925079, ppl = 3.537538851491344\n","Train Epoch #17, Batch 4938/24958 loss = 1.2554008913040162, ppl = 3.531425407086684\n","Train Epoch #17, Batch 4939/24958 loss = 1.25462122797966, ppl = 3.528374678422276\n","Train Epoch #17, Batch 4940/24958 loss = 1.2569464933872223, ppl = 3.5371939539837256\n","Train Epoch #17, Batch 4941/24958 loss = 1.2555591440200806, ppl = 3.5326087091702307\n","Train Epoch #17, Batch 4942/24958 loss = 1.2562778091430664, ppl = 3.5351952030588074\n","Train Epoch #17, Batch 4943/24958 loss = 1.2558409976959228, ppl = 3.5336033239895266\n","Train Epoch #17, Batch 4944/24958 loss = 1.254979555606842, ppl = 3.530968135219788\n","Train Epoch #17, Batch 4945/24958 loss = 1.256284898519516, ppl = 3.536139107381676\n","Train Epoch #17, Batch 4946/24958 loss = 1.2541558349132538, ppl = 3.5282808281175018\n","Train Epoch #17, Batch 4947/24958 loss = 1.2548447132110596, ppl = 3.5310252027440434\n","Train Epoch #17, Batch 4948/24958 loss = 1.2563480651378631, ppl = 3.5355667628623224\n","Train Epoch #17, Batch 4949/24958 loss = 1.256045285463333, ppl = 3.534575021486106\n","Train Epoch #17, Batch 4950/24958 loss = 1.256730580329895, ppl = 3.5370936917534253\n","Train Epoch #17, Batch 4951/24958 loss = 1.2582938480377197, ppl = 3.5420370540283987\n","Train Epoch #17, Batch 4952/24958 loss = 1.2561585891246796, ppl = 3.5343852472389274\n","Train Epoch #17, Batch 4953/24958 loss = 1.2535303616523743, ppl = 3.5246652963913356\n","Train Epoch #17, Batch 4954/24958 loss = 1.2545727932453155, ppl = 3.5285660468236797\n","Train Epoch #17, Batch 4955/24958 loss = 1.2564232242107392, ppl = 3.535701087042769\n","Train Epoch #17, Batch 4956/24958 loss = 1.2555387210845947, ppl = 3.5326279651592434\n","Train Epoch #17, Batch 4957/24958 loss = 1.2569161868095398, ppl = 3.5381979199757496\n","Train Epoch #17, Batch 4958/24958 loss = 1.2557472252845765, ppl = 3.533811171458309\n","Train Epoch #17, Batch 4959/24958 loss = 1.2567914807796479, ppl = 3.537112824072106\n","Train Epoch #17, Batch 4960/24958 loss = 1.2576525366306306, ppl = 3.5405521331454737\n","Train Epoch #17, Batch 4961/24958 loss = 1.2544915616512298, ppl = 3.52924949840436\n","Train Epoch #17, Batch 4962/24958 loss = 1.254478657245636, ppl = 3.529201430125176\n","Train Epoch #17, Batch 4963/24958 loss = 1.2509767663478852, ppl = 3.5164086150111133\n","Train Epoch #17, Batch 4964/24958 loss = 1.2514744329452514, ppl = 3.5182360998635485\n","Train Epoch #17, Batch 4965/24958 loss = 1.2529235315322875, ppl = 3.5234040712872594\n","Train Epoch #17, Batch 4966/24958 loss = 1.2529358601570129, ppl = 3.52344803818118\n","Train Epoch #17, Batch 4967/24958 loss = 1.251942673921585, ppl = 3.520323643170307\n","Train Epoch #17, Batch 4968/24958 loss = 1.2529876720905304, ppl = 3.5238914730906283\n","Train Epoch #17, Batch 4969/24958 loss = 1.251652420759201, ppl = 3.5192588498607016\n","Train Epoch #17, Batch 4970/24958 loss = 1.250372828245163, ppl = 3.514210351931343\n","Train Epoch #17, Batch 4971/24958 loss = 1.2501016807556153, ppl = 3.513278257858693\n","Train Epoch #17, Batch 4972/24958 loss = 1.2496514797210694, ppl = 3.5117545254558142\n","Train Epoch #17, Batch 4973/24958 loss = 1.2504541528224946, ppl = 3.51472503136965\n","Train Epoch #17, Batch 4974/24958 loss = 1.2525976479053498, ppl = 3.52290945728368\n","Train Epoch #17, Batch 4975/24958 loss = 1.2520692658424377, ppl = 3.5209065268335387\n","Train Epoch #17, Batch 4976/24958 loss = 1.250604956150055, ppl = 3.515800666756472\n","Train Epoch #17, Batch 4977/24958 loss = 1.2475955283641815, ppl = 3.5046975905570803\n","Train Epoch #17, Batch 4978/24958 loss = 1.248156532049179, ppl = 3.5066025129866665\n","Train Epoch #17, Batch 4979/24958 loss = 1.248341567516327, ppl = 3.507283997075216\n","Train Epoch #17, Batch 4980/24958 loss = 1.247914925813675, ppl = 3.5058411635379993\n","Train Epoch #17, Batch 4981/24958 loss = 1.2486082935333251, ppl = 3.508307484680958\n","Train Epoch #17, Batch 4982/24958 loss = 1.2483991718292236, ppl = 3.5073984485370335\n","Train Epoch #17, Batch 4983/24958 loss = 1.2477385890483856, ppl = 3.5053350895355986\n","Train Epoch #17, Batch 4984/24958 loss = 1.2475544154644012, ppl = 3.504691282576939\n","Train Epoch #17, Batch 4985/24958 loss = 1.247846587896347, ppl = 3.505706534401595\n","Train Epoch #17, Batch 4986/24958 loss = 1.2507049345970154, ppl = 3.5165333262860003\n","Train Epoch #17, Batch 4987/24958 loss = 1.2511968410015106, ppl = 3.5181343304440422\n","Train Epoch #17, Batch 4988/24958 loss = 1.2523989033699037, ppl = 3.521897599710402\n","Train Epoch #17, Batch 4989/24958 loss = 1.251764906644821, ppl = 3.5199411244372807\n","Train Epoch #17, Batch 4990/24958 loss = 1.2519686067104339, ppl = 3.520669612528093\n","Train Epoch #17, Batch 4991/24958 loss = 1.250257898569107, ppl = 3.51461782007331\n","Train Epoch #17, Batch 4992/24958 loss = 1.251252965927124, ppl = 3.518436273128139\n","Train Epoch #17, Batch 4993/24958 loss = 1.2521448934078216, ppl = 3.5215350166362667\n","Train Epoch #17, Batch 4994/24958 loss = 1.2508544874191285, ppl = 3.5170423456882527\n","Train Epoch #17, Batch 4995/24958 loss = 1.2501711118221284, ppl = 3.5150864993323228\n","Train Epoch #17, Batch 4996/24958 loss = 1.2512023639678955, ppl = 3.5181873454702592\n","Train Epoch #17, Batch 4997/24958 loss = 1.2503248846530914, ppl = 3.5144949032985324\n","Train Epoch #17, Batch 4998/24958 loss = 1.2502468812465668, ppl = 3.5142228757335014\n","Train Epoch #17, Batch 4999/24958 loss = 1.2480820631980896, ppl = 3.507109663047727\n","Train Epoch #17, Batch 5000/24958 loss = 1.2499867796897888, ppl = 3.513581496444548\n","Train Epoch #17, Batch 5001/24958 loss = 1.2485770440101625, ppl = 3.5088006716548454\n","Train Epoch #17, Batch 5002/24958 loss = 1.2474945819377898, ppl = 3.504624884641282\n","Train Epoch #17, Batch 5003/24958 loss = 1.2461252403259278, ppl = 3.499718645236338\n","Train Epoch #17, Batch 5004/24958 loss = 1.2466075432300567, ppl = 3.501657754636403\n","Train Epoch #17, Batch 5005/24958 loss = 1.2454123878479004, ppl = 3.4972820288714455\n","Train Epoch #17, Batch 5006/24958 loss = 1.244238452911377, ppl = 3.493177777013823\n","Train Epoch #17, Batch 5007/24958 loss = 1.2460673439502716, ppl = 3.500267320286493\n","Train Epoch #17, Batch 5008/24958 loss = 1.2461976647377013, ppl = 3.500699145950679\n","Train Epoch #17, Batch 5009/24958 loss = 1.246883934736252, ppl = 3.503127884718985\n","Train Epoch #17, Batch 5010/24958 loss = 1.247040889263153, ppl = 3.5036130662823024\n","Train Epoch #17, Batch 5011/24958 loss = 1.2462171936035156, ppl = 3.5007597387757277\n","Train Epoch #17, Batch 5012/24958 loss = 1.2506494796276093, ppl = 3.5146009316714726\n","Train Epoch #17, Batch 5013/24958 loss = 1.246620810031891, ppl = 3.5000324973211523\n","Train Epoch #17, Batch 5014/24958 loss = 1.2473909616470338, ppl = 3.502856908883574\n","Train Epoch #17, Batch 5015/24958 loss = 1.246685733795166, ppl = 3.5004739679579804\n","Train Epoch #17, Batch 5016/24958 loss = 1.2484173417091369, ppl = 3.506104514114656\n","Train Epoch #17, Batch 5017/24958 loss = 1.2474893188476563, ppl = 3.5032268601198537\n","Train Epoch #17, Batch 5018/24958 loss = 1.2471730184555054, ppl = 3.5022155322158914\n","Train Epoch #17, Batch 5019/24958 loss = 1.2468225502967833, ppl = 3.500929035270474\n","Train Epoch #17, Batch 5020/24958 loss = 1.2470843970775605, ppl = 3.501828125402008\n","Train Epoch #17, Batch 5021/24958 loss = 1.2461108481884002, ppl = 3.4983157904842592\n","Train Epoch #17, Batch 5022/24958 loss = 1.248878300189972, ppl = 3.5083816826503016\n","Train Epoch #17, Batch 5023/24958 loss = 1.2502508103847503, ppl = 3.5128264305146324\n","Train Epoch #17, Batch 5024/24958 loss = 1.2491000294685364, ppl = 3.5083405592894126\n","Train Epoch #17, Batch 5025/24958 loss = 1.2506026422977448, ppl = 3.513538752603701\n","Train Epoch #17, Batch 5026/24958 loss = 1.254192932844162, ppl = 3.52540132533588\n","Train Epoch #17, Batch 5027/24958 loss = 1.2521159720420838, ppl = 3.5190603919101333\n","Train Epoch #17, Batch 5028/24958 loss = 1.251833758354187, ppl = 3.518041268753907\n","Train Epoch #17, Batch 5029/24958 loss = 1.253003579378128, ppl = 3.5217814741245137\n","Train Epoch #17, Batch 5030/24958 loss = 1.2524272561073304, ppl = 3.5196282552104545\n","Train Epoch #17, Batch 5031/24958 loss = 1.2535480511188508, ppl = 3.5231285291581527\n","Train Epoch #17, Batch 5032/24958 loss = 1.2525097346305847, ppl = 3.5196117891165004\n","Train Epoch #17, Batch 5033/24958 loss = 1.2491832304000854, ppl = 3.5078157828571737\n","Train Epoch #17, Batch 5034/24958 loss = 1.250998306274414, ppl = 3.5140604605075954\n","Train Epoch #17, Batch 5035/24958 loss = 1.2487196838855743, ppl = 3.5070805392240754\n","Train Epoch #17, Batch 5036/24958 loss = 1.2480472218990326, ppl = 3.5048528463918647\n","Train Epoch #17, Batch 5037/24958 loss = 1.2469969713687896, ppl = 3.5016476356033945\n","Train Epoch #17, Batch 5038/24958 loss = 1.246328617334366, ppl = 3.4995268705782774\n","Train Epoch #17, Batch 5039/24958 loss = 1.2460047709941864, ppl = 3.4983279730974264\n","Train Epoch #17, Batch 5040/24958 loss = 1.244758585691452, ppl = 3.493347415641868\n","Train Epoch #17, Batch 5041/24958 loss = 1.2469692206382752, ppl = 3.500970081042334\n","Train Epoch #17, Batch 5042/24958 loss = 1.2460679924488067, ppl = 3.4977556148887636\n","Train Epoch #17, Batch 5043/24958 loss = 1.242603536248207, ppl = 3.487316314172824\n","Train Epoch #17, Batch 5044/24958 loss = 1.2456893402338027, ppl = 3.4979050189577507\n","Train Epoch #17, Batch 5045/24958 loss = 1.2421463185548782, ppl = 3.4852986011650984\n","Train Epoch #17, Batch 5046/24958 loss = 1.2435273987054825, ppl = 3.490203619111699\n","Train Epoch #17, Batch 5047/24958 loss = 1.2429497689008713, ppl = 3.4878897396990465\n","Train Epoch #17, Batch 5048/24958 loss = 1.2438596719503403, ppl = 3.4909891823650163\n","Train Epoch #17, Batch 5049/24958 loss = 1.2442755597829818, ppl = 3.4923591766362447\n","Train Epoch #17, Batch 5050/24958 loss = 1.2442478102445602, ppl = 3.492253800280251\n","Train Epoch #17, Batch 5051/24958 loss = 1.2457191759347916, ppl = 3.497668264481571\n","Train Epoch #17, Batch 5052/24958 loss = 1.247154489159584, ppl = 3.5026297189903426\n","Train Epoch #17, Batch 5053/24958 loss = 1.2479865926504135, ppl = 3.505435489602098\n","Train Epoch #17, Batch 5054/24958 loss = 1.2462588602304459, ppl = 3.4991831958525186\n","Train Epoch #17, Batch 5055/24958 loss = 1.242955726981163, ppl = 3.4873020662975898\n","Train Epoch #17, Batch 5056/24958 loss = 1.2440015655755996, ppl = 3.4909656387055805\n","Train Epoch #17, Batch 5057/24958 loss = 1.2401497334241867, ppl = 3.477128502707566\n","Train Epoch #17, Batch 5058/24958 loss = 1.2406880575418473, ppl = 3.4790850819254997\n","Train Epoch #17, Batch 5059/24958 loss = 1.240959149003029, ppl = 3.4800000771584108\n","Train Epoch #17, Batch 5060/24958 loss = 1.237794857621193, ppl = 3.46869226909453\n","Train Epoch #17, Batch 5061/24958 loss = 1.2390353792905808, ppl = 3.4727077054410547\n","Train Epoch #17, Batch 5062/24958 loss = 1.237714849114418, ppl = 3.468102709929436\n","Train Epoch #17, Batch 5063/24958 loss = 1.2390685838460922, ppl = 3.472525182928118\n","Train Epoch #17, Batch 5064/24958 loss = 1.2384786826372147, ppl = 3.4703688794598473\n","Train Epoch #17, Batch 5065/24958 loss = 1.2378983563184738, ppl = 3.4682089448305464\n","Train Epoch #17, Batch 5066/24958 loss = 1.2381446224451065, ppl = 3.4690986417619634\n","Train Epoch #17, Batch 5067/24958 loss = 1.2386907535791396, ppl = 3.470778219028601\n","Train Epoch #17, Batch 5068/24958 loss = 1.2390998047590256, ppl = 3.4722795388957355\n","Train Epoch #17, Batch 5069/24958 loss = 1.2411664110422134, ppl = 3.4797243359401877\n","Train Epoch #17, Batch 5070/24958 loss = 1.2410650306940079, ppl = 3.479351289898375\n","Train Epoch #17, Batch 5071/24958 loss = 1.243389019370079, ppl = 3.488223434921882\n","Train Epoch #17, Batch 5072/24958 loss = 1.2451364940404892, ppl = 3.4945417140216066\n","Train Epoch #17, Batch 5073/24958 loss = 1.2440257340669632, ppl = 3.4904928930907597\n","Train Epoch #17, Batch 5074/24958 loss = 1.2434118670225143, ppl = 3.487967130127709\n","Train Epoch #17, Batch 5075/24958 loss = 1.2426602858304978, ppl = 3.4852944231303273\n","Train Epoch #17, Batch 5076/24958 loss = 1.2424537271261216, ppl = 3.4846324858972535\n","Train Epoch #17, Batch 5077/24958 loss = 1.2418013697862624, ppl = 3.48263552445884\n","Train Epoch #17, Batch 5078/24958 loss = 1.2421105188131332, ppl = 3.483731838397472\n","Train Epoch #17, Batch 5079/24958 loss = 1.2420076197385788, ppl = 3.4833513061222616\n","Train Epoch #17, Batch 5080/24958 loss = 1.2421575230360031, ppl = 3.483851255395296\n","Train Epoch #17, Batch 5081/24958 loss = 1.2427245086431504, ppl = 3.485999073231581\n","Train Epoch #17, Batch 5082/24958 loss = 1.2404448753595352, ppl = 3.47723034798588\n","Train Epoch #17, Batch 5083/24958 loss = 1.2415273493528367, ppl = 3.4806846421915933\n","Train Epoch #17, Batch 5084/24958 loss = 1.242658390402794, ppl = 3.4848322051418346\n","Train Epoch #17, Batch 5085/24958 loss = 1.2422080439329148, ppl = 3.4832795755732993\n","Train Epoch #17, Batch 5086/24958 loss = 1.2396922224760056, ppl = 3.473593009577241\n","Train Epoch #17, Batch 5087/24958 loss = 1.2401420670747756, ppl = 3.475127680231404\n","Train Epoch #17, Batch 5088/24958 loss = 1.2396760922670365, ppl = 3.473614946407853\n","Train Epoch #17, Batch 5089/24958 loss = 1.241448866724968, ppl = 3.4794127686067786\n","Train Epoch #17, Batch 5090/24958 loss = 1.2408947545289992, ppl = 3.477465311304074\n","Train Epoch #17, Batch 5091/24958 loss = 1.2426673406362534, ppl = 3.483755998506077\n","Train Epoch #17, Batch 5092/24958 loss = 1.2400202006101608, ppl = 3.47437982337696\n","Train Epoch #17, Batch 5093/24958 loss = 1.2408909791707992, ppl = 3.4776837754821157\n","Train Epoch #17, Batch 5094/24958 loss = 1.2411479955911637, ppl = 3.4785329755480507\n","Train Epoch #17, Batch 5095/24958 loss = 1.243899045586586, ppl = 3.4872900066046126\n","Train Epoch #17, Batch 5096/24958 loss = 1.2445004159212112, ppl = 3.48925147950995\n","Train Epoch #17, Batch 5097/24958 loss = 1.245230101943016, ppl = 3.492299097816854\n","Train Epoch #17, Batch 5098/24958 loss = 1.2448423141241074, ppl = 3.490977786695429\n","Train Epoch #17, Batch 5099/24958 loss = 1.2485276490449906, ppl = 3.504092118473417\n","Train Epoch #17, Batch 5100/24958 loss = 1.2465301746129989, ppl = 3.4973354990122654\n","Train Epoch #17, Batch 5101/24958 loss = 1.247800768017769, ppl = 3.5016139132411093\n","Train Epoch #17, Batch 5102/24958 loss = 1.2466692858934403, ppl = 3.497706244008304\n","Train Epoch #17, Batch 5103/24958 loss = 1.2449764651060105, ppl = 3.49249989741032\n","Train Epoch #17, Batch 5104/24958 loss = 1.2439908856153488, ppl = 3.4886346326439384\n","Train Epoch #17, Batch 5105/24958 loss = 1.2442679709196092, ppl = 3.489603042109471\n","Train Epoch #17, Batch 5106/24958 loss = 1.245143956542015, ppl = 3.4926195645724762\n","Train Epoch #17, Batch 5107/24958 loss = 1.2417026656866073, ppl = 3.4802693430919645\n","Train Epoch #17, Batch 5108/24958 loss = 1.2415352123975754, ppl = 3.4797155033513314\n","Train Epoch #17, Batch 5109/24958 loss = 1.241497728228569, ppl = 3.4795784981933515\n","Train Epoch #17, Batch 5110/24958 loss = 1.2410229510068893, ppl = 3.4781338728907754\n","Train Epoch #17, Batch 5111/24958 loss = 1.2420879966020584, ppl = 3.481868750453505\n","Train Epoch #17, Batch 5112/24958 loss = 1.239466077685356, ppl = 3.4729527357439047\n","Train Epoch #17, Batch 5113/24958 loss = 1.2417367666959762, ppl = 3.4804384708047102\n","Train Epoch #17, Batch 5114/24958 loss = 1.2407448464632034, ppl = 3.4768402852306703\n","Train Epoch #17, Batch 5115/24958 loss = 1.240693318247795, ppl = 3.4766726726321013\n","Train Epoch #17, Batch 5116/24958 loss = 1.240741052031517, ppl = 3.4768421152658617\n","Train Epoch #17, Batch 5117/24958 loss = 1.2424395149946212, ppl = 3.482320240209903\n","Train Epoch #17, Batch 5118/24958 loss = 1.2453734058141708, ppl = 3.4930506142387743\n","Train Epoch #17, Batch 5119/24958 loss = 1.246724370121956, ppl = 3.4982678150454816\n","Train Epoch #17, Batch 5120/24958 loss = 1.2477996844053267, ppl = 3.5022171530327335\n","Train Epoch #17, Batch 5121/24958 loss = 1.249171250462532, ppl = 3.507266864703108\n","Train Epoch #17, Batch 5122/24958 loss = 1.2462729686498641, ppl = 3.4967906157912605\n","Train Epoch #17, Batch 5123/24958 loss = 1.246786325573921, ppl = 3.4986162296242305\n","Train Epoch #17, Batch 5124/24958 loss = 1.2451387852430345, ppl = 3.493029252503409\n","Train Epoch #17, Batch 5125/24958 loss = 1.2425915008783341, ppl = 3.484650814832503\n","Train Epoch #17, Batch 5126/24958 loss = 1.241361945271492, ppl = 3.4801008959420923\n","Train Epoch #17, Batch 5127/24958 loss = 1.243485843539238, ppl = 3.4866008979726315\n","Train Epoch #17, Batch 5128/24958 loss = 1.2454248601198197, ppl = 3.494219457526744\n","Train Epoch #17, Batch 5129/24958 loss = 1.2443416565656662, ppl = 3.49074144075649\n","Train Epoch #17, Batch 5130/24958 loss = 1.2459180110692978, ppl = 3.4969384306106575\n","Train Epoch #17, Batch 5131/24958 loss = 1.2447906583547592, ppl = 3.4934188093723195\n","Train Epoch #17, Batch 5132/24958 loss = 1.2457219165563584, ppl = 3.496555832605401\n","Train Epoch #17, Batch 5133/24958 loss = 1.2471050602197646, ppl = 3.500989470773136\n","Train Epoch #17, Batch 5134/24958 loss = 1.2448866361379622, ppl = 3.4935044085721194\n","Train Epoch #17, Batch 5135/24958 loss = 1.2459258669614792, ppl = 3.4964913961322988\n","Train Epoch #17, Batch 5136/24958 loss = 1.2475641983747483, ppl = 3.5021926015551674\n","Train Epoch #17, Batch 5137/24958 loss = 1.249763475060463, ppl = 3.5093124321542017\n","Train Epoch #17, Batch 5138/24958 loss = 1.2502716428041458, ppl = 3.510911918623182\n","Train Epoch #17, Batch 5139/24958 loss = 1.2505315619707107, ppl = 3.5118710684355223\n","Train Epoch #17, Batch 5140/24958 loss = 1.251777841448784, ppl = 3.5168520262174074\n","Train Epoch #17, Batch 5141/24958 loss = 1.2476050579547882, ppl = 3.5037399798388837\n","Train Epoch #17, Batch 5142/24958 loss = 1.2476274752616883, ppl = 3.5038164738646054\n","Train Epoch #17, Batch 5143/24958 loss = 1.2510371977090835, ppl = 3.5140611653040144\n","Train Epoch #17, Batch 5144/24958 loss = 1.250632076859474, ppl = 3.5124778137198778\n","Train Epoch #17, Batch 5145/24958 loss = 1.2530217307806015, ppl = 3.520481158220991\n","Train Epoch #17, Batch 5146/24958 loss = 1.2515248376131058, ppl = 3.5151947832065877\n","Train Epoch #17, Batch 5147/24958 loss = 1.250514970421791, ppl = 3.5114570570007335\n","Train Epoch #17, Batch 5148/24958 loss = 1.249795851111412, ppl = 3.5089843308571136\n","Train Epoch #17, Batch 5149/24958 loss = 1.2496920269727707, ppl = 3.508636964381262\n","Train Epoch #17, Batch 5150/24958 loss = 1.2474200707674026, ppl = 3.5009299990063782\n","Train Epoch #17, Batch 5151/24958 loss = 1.2461467987298966, ppl = 3.49619893026263\n","Train Epoch #17, Batch 5152/24958 loss = 1.247602419257164, ppl = 3.5020132237150174\n","Train Epoch #17, Batch 5153/24958 loss = 1.2473772484064103, ppl = 3.5012307851456814\n","Train Epoch #17, Batch 5154/24958 loss = 1.2486764460802078, ppl = 3.505830151217515\n","Train Epoch #17, Batch 5155/24958 loss = 1.2517623203992843, ppl = 3.516803556053024\n","Train Epoch #17, Batch 5156/24958 loss = 1.2498967736959457, ppl = 3.5105247337818883\n","Train Epoch #17, Batch 5157/24958 loss = 1.2519905465841292, ppl = 3.5173834714718684\n","Train Epoch #17, Batch 5158/24958 loss = 1.2519357401132583, ppl = 3.517179423165677\n","Train Epoch #17, Batch 5159/24958 loss = 1.2540553814172746, ppl = 3.525256958752635\n","Train Epoch #17, Batch 5160/24958 loss = 1.2574111658334732, ppl = 3.5373707410405406\n","Train Epoch #17, Batch 5161/24958 loss = 1.2574605470895768, ppl = 3.537541122531623\n","Train Epoch #17, Batch 5162/24958 loss = 1.2587058979272843, ppl = 3.541867308683963\n","Train Epoch #17, Batch 5163/24958 loss = 1.2602080231904984, ppl = 3.5475287712573293\n","Train Epoch #17, Batch 5164/24958 loss = 1.2604099327325822, ppl = 3.5482525514875167\n","Train Epoch #17, Batch 5165/24958 loss = 1.2597300332784653, ppl = 3.54587642101668\n","Train Epoch #17, Batch 5166/24958 loss = 1.2593077212572097, ppl = 3.5443640116196944\n","Train Epoch #17, Batch 5167/24958 loss = 1.258518550992012, ppl = 3.5419659797035132\n","Train Epoch #17, Batch 5168/24958 loss = 1.2573863345384597, ppl = 3.5379561735581406\n","Train Epoch #17, Batch 5169/24958 loss = 1.2566199415922166, ppl = 3.535014367028361\n","Train Epoch #17, Batch 5170/24958 loss = 1.257061385512352, ppl = 3.536666716809108\n","Train Epoch #17, Batch 5171/24958 loss = 1.2530839020013809, ppl = 3.522626301126715\n","Train Epoch #17, Batch 5172/24958 loss = 1.2516598159074783, ppl = 3.517395587571492\n","Train Epoch #17, Batch 5173/24958 loss = 1.2494462209939956, ppl = 3.5105520267423604\n","Train Epoch #17, Batch 5174/24958 loss = 1.2455078917741775, ppl = 3.4975648274848403\n","Train Epoch #17, Batch 5175/24958 loss = 1.245620658993721, ppl = 3.4979531447844083\n","Train Epoch #17, Batch 5176/24958 loss = 1.248590663075447, ppl = 3.5089210860612674\n","Train Epoch #17, Batch 5177/24958 loss = 1.251647098660469, ppl = 3.5195115601684135\n","Train Epoch #17, Batch 5178/24958 loss = 1.2504038113355636, ppl = 3.5153012277356805\n","Train Epoch #17, Batch 5179/24958 loss = 1.2505513900518417, ppl = 3.515848213455602\n","Train Epoch #17, Batch 5180/24958 loss = 1.2518998461961746, ppl = 3.5206990089541166\n","Train Epoch #17, Batch 5181/24958 loss = 1.2510824459791183, ppl = 3.5176406729212597\n","Train Epoch #17, Batch 5182/24958 loss = 1.2512996691465377, ppl = 3.518392748548666\n","Train Epoch #17, Batch 5183/24958 loss = 1.2525021582841873, ppl = 3.5226949423649825\n","Train Epoch #17, Batch 5184/24958 loss = 1.2510406213998795, ppl = 3.5174213958804343\n","Train Epoch #17, Batch 5185/24958 loss = 1.2512853997945785, ppl = 3.5182566227569056\n","Train Epoch #17, Batch 5186/24958 loss = 1.2511915129423141, ppl = 3.5179401891723883\n","Train Epoch #17, Batch 5187/24958 loss = 1.2493650549650193, ppl = 3.5121159867880114\n","Train Epoch #17, Batch 5188/24958 loss = 1.2524214500188828, ppl = 3.5234532866648585\n","Train Epoch #17, Batch 5189/24958 loss = 1.2519843465089797, ppl = 3.521926896873396\n","Train Epoch #17, Batch 5190/24958 loss = 1.2527049726247788, ppl = 3.524480976565513\n","Train Epoch #17, Batch 5191/24958 loss = 1.2515192073583603, ppl = 3.5201506753945666\n","Train Epoch #17, Batch 5192/24958 loss = 1.251909299492836, ppl = 3.521381411865625\n","Train Epoch #17, Batch 5193/24958 loss = 1.2506814306974412, ppl = 3.516803584131945\n","Train Epoch #17, Batch 5194/24958 loss = 1.2511912876367568, ppl = 3.518554176426063\n","Train Epoch #17, Batch 5195/24958 loss = 1.25059075653553, ppl = 3.5164319660641596\n","Train Epoch #17, Batch 5196/24958 loss = 1.251710403561592, ppl = 3.5204135350527577\n","Train Epoch #17, Batch 5197/24958 loss = 1.248683332800865, ppl = 3.5091020255590144\n","Train Epoch #17, Batch 5198/24958 loss = 1.2487959581613541, ppl = 3.5094805092133408\n","Train Epoch #17, Batch 5199/24958 loss = 1.247833598256111, ppl = 3.5055770644381097\n","Train Epoch #17, Batch 5200/24958 loss = 1.2482486134767532, ppl = 3.506872032328729\n","Train Epoch #17, Batch 5201/24958 loss = 1.2487401658296584, ppl = 3.508678632912806\n","Train Epoch #17, Batch 5202/24958 loss = 1.250087463259697, ppl = 3.513383168179703\n","Train Epoch #17, Batch 5203/24958 loss = 1.2507019966840744, ppl = 3.515172137094906\n","Train Epoch #17, Batch 5204/24958 loss = 1.2490531462430954, ppl = 3.509499577975735\n","Train Epoch #17, Batch 5205/24958 loss = 1.2475869888067246, ppl = 3.5046669786304796\n","Train Epoch #17, Batch 5206/24958 loss = 1.2469731360673904, ppl = 3.502525591126647\n","Train Epoch #17, Batch 5207/24958 loss = 1.2495368307828902, ppl = 3.51131198658717\n","Train Epoch #17, Batch 5208/24958 loss = 1.2519110649824143, ppl = 3.520101161801065\n","Train Epoch #17, Batch 5209/24958 loss = 1.2501141303777694, ppl = 3.51410088485291\n","Train Epoch #17, Batch 5210/24958 loss = 1.2528083389997482, ppl = 3.5232876547435934\n","Train Epoch #17, Batch 5211/24958 loss = 1.2524269562959671, ppl = 3.5219042929073883\n","Train Epoch #17, Batch 5212/24958 loss = 1.2535540658235549, ppl = 3.5254527933339173\n","Train Epoch #17, Batch 5213/24958 loss = 1.25291381418705, ppl = 3.523167333724248\n","Train Epoch #17, Batch 5214/24958 loss = 1.2524431890249252, ppl = 3.5215810340599374\n","Train Epoch #17, Batch 5215/24958 loss = 1.2539311617612838, ppl = 3.526786368302672\n","Train Epoch #17, Batch 5216/24958 loss = 1.2522679263353347, ppl = 3.521334185018089\n","Train Epoch #17, Batch 5217/24958 loss = 1.253311122059822, ppl = 3.5251903093591737\n","Train Epoch #17, Batch 5218/24958 loss = 1.2551780194044113, ppl = 3.533852208897516\n","Train Epoch #17, Batch 5219/24958 loss = 1.254656005501747, ppl = 3.5317523250536857\n","Train Epoch #17, Batch 5220/24958 loss = 1.2519755166769029, ppl = 3.5226440289151513\n","Train Epoch #17, Batch 5221/24958 loss = 1.2515453511476518, ppl = 3.5209851265164747\n","Train Epoch #17, Batch 5222/24958 loss = 1.2565742260217667, ppl = 3.541348465419235\n","Train Epoch #17, Batch 5223/24958 loss = 1.2559103602170945, ppl = 3.5390051346545577\n","Train Epoch #17, Batch 5224/24958 loss = 1.2583953899145126, ppl = 3.5478051634706826\n","Train Epoch #17, Batch 5225/24958 loss = 1.2604451674222945, ppl = 3.5543753185652065\n","Train Epoch #17, Batch 5226/24958 loss = 1.2590639561414718, ppl = 3.549888948014788\n","Train Epoch #17, Batch 5227/24958 loss = 1.2617852479219436, ppl = 3.5605129981569665\n","Train Epoch #17, Batch 5228/24958 loss = 1.2562520837783813, ppl = 3.5421448700830536\n","Train Epoch #17, Batch 5229/24958 loss = 1.25820969581604, ppl = 3.548718673418541\n","Train Epoch #17, Batch 5230/24958 loss = 1.2551028251647949, ppl = 3.5373708892228324\n","Train Epoch #17, Batch 5231/24958 loss = 1.2580610132217407, ppl = 3.5475233283030376\n","Train Epoch #17, Batch 5232/24958 loss = 1.2601518762111663, ppl = 3.5557274407681665\n","Train Epoch #17, Batch 5233/24958 loss = 1.2589076912403108, ppl = 3.551712036187136\n","Train Epoch #17, Batch 5234/24958 loss = 1.2617767095565795, ppl = 3.5617260900188548\n","Train Epoch #17, Batch 5235/24958 loss = 1.2649688720703125, ppl = 3.5731059487947334\n","Train Epoch #17, Batch 5236/24958 loss = 1.2654117095470427, ppl = 3.574814197860012\n","Train Epoch #17, Batch 5237/24958 loss = 1.2654392385482789, ppl = 3.5749136147000473\n","Train Epoch #17, Batch 5238/24958 loss = 1.2677160823345184, ppl = 3.583167784792618\n","Train Epoch #17, Batch 5239/24958 loss = 1.2669399285316467, ppl = 3.580375994340987\n","Train Epoch #17, Batch 5240/24958 loss = 1.2648071181774139, ppl = 3.572211285676776\n","Train Epoch #17, Batch 5241/24958 loss = 1.269473108649254, ppl = 3.587266419210634\n","Train Epoch #17, Batch 5242/24958 loss = 1.2682665830850601, ppl = 3.583383741703883\n","Train Epoch #17, Batch 5243/24958 loss = 1.2671641308069228, ppl = 3.5796823972591723\n","Train Epoch #17, Batch 5244/24958 loss = 1.264509294629097, ppl = 3.5707528522629373\n","Train Epoch #17, Batch 5245/24958 loss = 1.2632629615068436, ppl = 3.566340748299412\n","Train Epoch #17, Batch 5246/24958 loss = 1.2658054858446122, ppl = 3.575818419352401\n","Train Epoch #17, Batch 5247/24958 loss = 1.2669312363862992, ppl = 3.5800096980202545\n","Train Epoch #17, Batch 5248/24958 loss = 1.2670982509851456, ppl = 3.5805682353137307\n","Train Epoch #17, Batch 5249/24958 loss = 1.2673117798566818, ppl = 3.5812865829693354\n","Train Epoch #17, Batch 5250/24958 loss = 1.266856122612953, ppl = 3.5799407341652327\n","Train Epoch #17, Batch 5251/24958 loss = 1.26512413918972, ppl = 3.5743999293088353\n","Train Epoch #17, Batch 5252/24958 loss = 1.2632949131727218, ppl = 3.5672248719016215\n","Train Epoch #17, Batch 5253/24958 loss = 1.2623922628164292, ppl = 3.5642593197399095\n","Train Epoch #17, Batch 5254/24958 loss = 1.2603094762563705, ppl = 3.557161394817576\n","Train Epoch #17, Batch 5255/24958 loss = 1.257842990756035, ppl = 3.5481276029830013\n","Train Epoch #17, Batch 5256/24958 loss = 1.258070588707924, ppl = 3.548832381390223\n","Train Epoch #17, Batch 5257/24958 loss = 1.2590949136018752, ppl = 3.552748517983649\n","Train Epoch #17, Batch 5258/24958 loss = 1.256265464425087, ppl = 3.5435985531675875\n","Train Epoch #17, Batch 5259/24958 loss = 1.2543105393648148, ppl = 3.53608920874775\n","Train Epoch #17, Batch 5260/24958 loss = 1.253696157336235, ppl = 3.533557082095509\n","Train Epoch #17, Batch 5261/24958 loss = 1.2537656313180923, ppl = 3.5337982190733146\n","Train Epoch #17, Batch 5262/24958 loss = 1.2528464466333389, ppl = 3.5305535445101146\n","Train Epoch #17, Batch 5263/24958 loss = 1.25212728202343, ppl = 3.527736861788629\n","Train Epoch #17, Batch 5264/24958 loss = 1.2517120450735093, ppl = 3.526264083605321\n","Train Epoch #17, Batch 5265/24958 loss = 1.2528613728284836, ppl = 3.5303776485088205\n","Train Epoch #17, Batch 5266/24958 loss = 1.251830102801323, ppl = 3.52694203465\n","Train Epoch #17, Batch 5267/24958 loss = 1.2533373075723648, ppl = 3.531692615669977\n","Train Epoch #17, Batch 5268/24958 loss = 1.2530685514211655, ppl = 3.5308056399742873\n","Train Epoch #17, Batch 5269/24958 loss = 1.2538036853075027, ppl = 3.533622996290275\n","Train Epoch #17, Batch 5270/24958 loss = 1.254393568634987, ppl = 3.5359479550654114\n","Train Epoch #17, Batch 5271/24958 loss = 1.256945863366127, ppl = 3.544305407992709\n","Train Epoch #17, Batch 5272/24958 loss = 1.2574021464586258, ppl = 3.5459009720556383\n","Train Epoch #17, Batch 5273/24958 loss = 1.2597584062814713, ppl = 3.553239736766418\n","Train Epoch #17, Batch 5274/24958 loss = 1.262388862967491, ppl = 3.5613359666301663\n","Train Epoch #17, Batch 5275/24958 loss = 1.2639020496606828, ppl = 3.5669933483343557\n","Train Epoch #17, Batch 5276/24958 loss = 1.2629699999094008, ppl = 3.5631947537769877\n","Train Epoch #17, Batch 5277/24958 loss = 1.2609810310602187, ppl = 3.555941475040628\n","Train Epoch #17, Batch 5278/24958 loss = 1.2601324373483658, ppl = 3.553354032628527\n","Train Epoch #17, Batch 5279/24958 loss = 1.2580674749612808, ppl = 3.54638782615953\n","Train Epoch #17, Batch 5280/24958 loss = 1.2554603415727614, ppl = 3.537562965404801\n","Train Epoch #17, Batch 5281/24958 loss = 1.2549550074338913, ppl = 3.5357935427203016\n","Train Epoch #17, Batch 5282/24958 loss = 1.2544693583250046, ppl = 3.5341344016514005\n","Train Epoch #17, Batch 5283/24958 loss = 1.2525062257051467, ppl = 3.5273661449915243\n","Train Epoch #17, Batch 5284/24958 loss = 1.2523277217149735, ppl = 3.5267732917643393\n","Train Epoch #17, Batch 5285/24958 loss = 1.2535769778490067, ppl = 3.531369470882089\n","Train Epoch #17, Batch 5286/24958 loss = 1.253931866288185, ppl = 3.532581347529939\n","Train Epoch #17, Batch 5287/24958 loss = 1.2575269204378128, ppl = 3.5451552339224794\n","Train Epoch #17, Batch 5288/24958 loss = 1.2558275026082992, ppl = 3.5384270154445945\n","Train Epoch #17, Batch 5289/24958 loss = 1.2557955461740493, ppl = 3.5383180171814286\n","Train Epoch #17, Batch 5290/24958 loss = 1.2562818568944931, ppl = 3.540148625446584\n","Train Epoch #17, Batch 5291/24958 loss = 1.259678722023964, ppl = 3.5540623273804615\n","Train Epoch #17, Batch 5292/24958 loss = 1.2608948785066605, ppl = 3.5582224549950556\n","Train Epoch #17, Batch 5293/24958 loss = 1.261640928387642, ppl = 3.5609366479039135\n","Train Epoch #17, Batch 5294/24958 loss = 1.2604270738363266, ppl = 3.556911000148611\n","Train Epoch #17, Batch 5295/24958 loss = 1.2576111626625062, ppl = 3.548496013399394\n","Train Epoch #17, Batch 5296/24958 loss = 1.2565743255615234, ppl = 3.544793901602712\n","Train Epoch #17, Batch 5297/24958 loss = 1.258821895122528, ppl = 3.552857731214333\n","Train Epoch #17, Batch 5298/24958 loss = 1.257452439069748, ppl = 3.5485325498737814\n","Train Epoch #17, Batch 5299/24958 loss = 1.255768404006958, ppl = 3.542543727943816\n","Train Epoch #17, Batch 5300/24958 loss = 1.257639354467392, ppl = 3.5490976074795832\n","Train Epoch #17, Batch 5301/24958 loss = 1.2584248185157776, ppl = 3.5521752392099177\n","Train Epoch #17, Batch 5302/24958 loss = 1.2591379940509797, ppl = 3.5549342658637086\n","Train Epoch #17, Batch 5303/24958 loss = 1.2609962272644042, ppl = 3.561063543300229\n","Train Epoch #17, Batch 5304/24958 loss = 1.2631205797195435, ppl = 3.5685534119868367\n","Train Epoch #17, Batch 5305/24958 loss = 1.2641686034202575, ppl = 3.5719348501330335\n","Train Epoch #17, Batch 5306/24958 loss = 1.2645666074752808, ppl = 3.5733082340191693\n","Train Epoch #17, Batch 5307/24958 loss = 1.2638187789916993, ppl = 3.5705086727208624\n","Train Epoch #17, Batch 5308/24958 loss = 1.262007910013199, ppl = 3.563620269132709\n","Train Epoch #17, Batch 5309/24958 loss = 1.2629360949993134, ppl = 3.56658496840649\n","Train Epoch #17, Batch 5310/24958 loss = 1.2611597883701324, ppl = 3.5602544447906537\n","Train Epoch #17, Batch 5311/24958 loss = 1.2633017885684967, ppl = 3.5687546467717595\n","Train Epoch #17, Batch 5312/24958 loss = 1.263315908908844, ppl = 3.5688016876667077\n","Train Epoch #17, Batch 5313/24958 loss = 1.2639255905151368, ppl = 3.5709746650813243\n","Train Epoch #17, Batch 5314/24958 loss = 1.2633179771900176, ppl = 3.5690340006132795\n","Train Epoch #17, Batch 5315/24958 loss = 1.264264361858368, ppl = 3.572771182445934\n","Train Epoch #17, Batch 5316/24958 loss = 1.2656856393814087, ppl = 3.5773727580450427\n","Train Epoch #17, Batch 5317/24958 loss = 1.2630607903003692, ppl = 3.5683861968576776\n","Train Epoch #17, Batch 5318/24958 loss = 1.2579089283943177, ppl = 3.547908240478813\n","Train Epoch #17, Batch 5319/24958 loss = 1.2575309562683106, ppl = 3.546454768812304\n","Train Epoch #17, Batch 5320/24958 loss = 1.2589095115661622, ppl = 3.550834229654845\n","Train Epoch #17, Batch 5321/24958 loss = 1.2558792412281037, ppl = 3.5409680032781194\n","Train Epoch #17, Batch 5322/24958 loss = 1.2543419098854065, ppl = 3.5336258333152886\n","Train Epoch #17, Batch 5323/24958 loss = 1.2538250160217286, ppl = 3.5319060117106584\n","Train Epoch #17, Batch 5324/24958 loss = 1.2536714637279511, ppl = 3.5312965820627435\n","Train Epoch #17, Batch 5325/24958 loss = 1.2536064112186431, ppl = 3.5310667178103636\n","Train Epoch #17, Batch 5326/24958 loss = 1.2539922094345093, ppl = 3.53225812958928\n","Train Epoch #17, Batch 5327/24958 loss = 1.2514561474323274, ppl = 3.522269151351031\n","Train Epoch #17, Batch 5328/24958 loss = 1.2560745614767075, ppl = 3.5368588898167563\n","Train Epoch #17, Batch 5329/24958 loss = 1.2553556829690933, ppl = 3.5342941423940335\n","Train Epoch #17, Batch 5330/24958 loss = 1.2564477628469468, ppl = 3.5378880107681647\n","Train Epoch #17, Batch 5331/24958 loss = 1.2553506761789321, ppl = 3.5337686079724837\n","Train Epoch #17, Batch 5332/24958 loss = 1.2532215267419815, ppl = 3.5254296840898562\n","Train Epoch #17, Batch 5333/24958 loss = 1.2541203337907791, ppl = 3.528279895902262\n","Train Epoch #17, Batch 5334/24958 loss = 1.2532135504484176, ppl = 3.5247993302465073\n","Train Epoch #17, Batch 5335/24958 loss = 1.252545639872551, ppl = 3.522108898398851\n","Train Epoch #17, Batch 5336/24958 loss = 1.249105378985405, ppl = 3.510629633661964\n","Train Epoch #17, Batch 5337/24958 loss = 1.248189178109169, ppl = 3.507463606116948\n","Train Epoch #17, Batch 5338/24958 loss = 1.248140954375267, ppl = 3.5072685957814276\n","Train Epoch #17, Batch 5339/24958 loss = 1.2463343554735185, ppl = 3.501551250170378\n","Train Epoch #17, Batch 5340/24958 loss = 1.2442683583498002, ppl = 3.4951407562669203\n","Train Epoch #17, Batch 5341/24958 loss = 1.2416471391916275, ppl = 3.4858306253650193\n","Train Epoch #17, Batch 5342/24958 loss = 1.2419915157556534, ppl = 3.486891502590518\n","Train Epoch #17, Batch 5343/24958 loss = 1.2409878891706467, ppl = 3.4838589992914746\n","Train Epoch #17, Batch 5344/24958 loss = 1.2425016802549362, ppl = 3.4886587645913267\n","Train Epoch #17, Batch 5345/24958 loss = 1.2424387508630752, ppl = 3.488450241321435\n","Train Epoch #17, Batch 5346/24958 loss = 1.2394201570749284, ppl = 3.477450513824549\n","Train Epoch #17, Batch 5347/24958 loss = 1.24091795027256, ppl = 3.4838111759805996\n","Train Epoch #17, Batch 5348/24958 loss = 1.2414706736803054, ppl = 3.485727569725502\n","Train Epoch #17, Batch 5349/24958 loss = 1.2406637912988663, ppl = 3.4830917642562884\n","Train Epoch #17, Batch 5350/24958 loss = 1.2425677806138993, ppl = 3.4891464396088123\n","Train Epoch #17, Batch 5351/24958 loss = 1.245582146048546, ppl = 3.4994543800782845\n","Train Epoch #17, Batch 5352/24958 loss = 1.2449556416273118, ppl = 3.497283567428568\n","Train Epoch #17, Batch 5353/24958 loss = 1.2471636265516282, ppl = 3.5050399907330285\n","Train Epoch #17, Batch 5354/24958 loss = 1.248259705901146, ppl = 3.508590864461989\n","Train Epoch #17, Batch 5355/24958 loss = 1.2487012141942977, ppl = 3.510048649645621\n","Train Epoch #17, Batch 5356/24958 loss = 1.2508440119028092, ppl = 3.5175330857379516\n","Train Epoch #17, Batch 5357/24958 loss = 1.2495576125383376, ppl = 3.512677802108181\n","Train Epoch #17, Batch 5358/24958 loss = 1.2525581043958665, ppl = 3.5224682894958774\n","Train Epoch #17, Batch 5359/24958 loss = 1.2528795510530473, ppl = 3.523604444650746\n","Train Epoch #17, Batch 5360/24958 loss = 1.2509323698282242, ppl = 3.5165339917548057\n","Train Epoch #17, Batch 5361/24958 loss = 1.2527438682317733, ppl = 3.52345098180511\n","Train Epoch #17, Batch 5362/24958 loss = 1.2515312868356705, ppl = 3.519602391240827\n","Train Epoch #17, Batch 5363/24958 loss = 1.2499889189004898, ppl = 3.5142032354442305\n","Train Epoch #17, Batch 5364/24958 loss = 1.2500285786390304, ppl = 3.514341275372664\n","Train Epoch #17, Batch 5365/24958 loss = 1.249018606543541, ppl = 3.510701660232476\n","Train Epoch #17, Batch 5366/24958 loss = 1.2493802815675736, ppl = 3.5118664341474237\n","Train Epoch #17, Batch 5367/24958 loss = 1.2482166665792465, ppl = 3.5081366927067568\n","Train Epoch #17, Batch 5368/24958 loss = 1.2498870307207108, ppl = 3.5140562836415343\n","Train Epoch #17, Batch 5369/24958 loss = 1.2480102330446243, ppl = 3.5072542105256694\n","Train Epoch #17, Batch 5370/24958 loss = 1.2458931797742843, ppl = 3.499510187955205\n","Train Epoch #17, Batch 5371/24958 loss = 1.2465950399637222, ppl = 3.502207727322226\n","Train Epoch #17, Batch 5372/24958 loss = 1.2467922919988632, ppl = 3.5029203539807474\n","Train Epoch #17, Batch 5373/24958 loss = 1.249135656952858, ppl = 3.512152014292499\n","Train Epoch #17, Batch 5374/24958 loss = 1.250263585448265, ppl = 3.516331514628131\n","Train Epoch #17, Batch 5375/24958 loss = 1.249666833281517, ppl = 3.5139976950844725\n","Train Epoch #17, Batch 5376/24958 loss = 1.2498417180776595, ppl = 3.5146837243141142\n","Train Epoch #17, Batch 5377/24958 loss = 1.249384290575981, ppl = 3.513209959875507\n","Train Epoch #17, Batch 5378/24958 loss = 1.2516218346357346, ppl = 3.520536154461567\n","Train Epoch #17, Batch 5379/24958 loss = 1.2526681977510452, ppl = 3.523886385732293\n","Train Epoch #17, Batch 5380/24958 loss = 1.2548483091592788, ppl = 3.5311037905908655\n","Train Epoch #17, Batch 5381/24958 loss = 1.2540825778245925, ppl = 3.5285873399047887\n","Train Epoch #17, Batch 5382/24958 loss = 1.2555929285287857, ppl = 3.5340230922857843\n","Train Epoch #17, Batch 5383/24958 loss = 1.2568603557348252, ppl = 3.538239442114974\n","Train Epoch #17, Batch 5384/24958 loss = 1.2571190696954728, ppl = 3.5391021568339505\n","Train Epoch #17, Batch 5385/24958 loss = 1.2544517797231673, ppl = 3.5299393666821923\n","Train Epoch #17, Batch 5386/24958 loss = 1.2545587259531021, ppl = 3.5303130811713426\n","Train Epoch #17, Batch 5387/24958 loss = 1.2561431533098222, ppl = 3.537461753351947\n","Train Epoch #17, Batch 5388/24958 loss = 1.2554787248373032, ppl = 3.535126815727224\n","Train Epoch #17, Batch 5389/24958 loss = 1.2553367739915848, ppl = 3.5346468321690936\n","Train Epoch #17, Batch 5390/24958 loss = 1.2539407616853715, ppl = 3.529621940454321\n","Train Epoch #17, Batch 5391/24958 loss = 1.2514151459932328, ppl = 3.5188394702774626\n","Train Epoch #17, Batch 5392/24958 loss = 1.250163717865944, ppl = 3.5145660762609467\n","Train Epoch #17, Batch 5393/24958 loss = 1.248188539147377, ppl = 3.5077991089825975\n","Train Epoch #17, Batch 5394/24958 loss = 1.2517876201868057, ppl = 3.5213114361941784\n","Train Epoch #17, Batch 5395/24958 loss = 1.2557636070251466, ppl = 3.5339440467507375\n","Train Epoch #17, Batch 5396/24958 loss = 1.2557247054576874, ppl = 3.533812478078904\n","Train Epoch #17, Batch 5397/24958 loss = 1.2539856386184693, ppl = 3.527417782408195\n","Train Epoch #17, Batch 5398/24958 loss = 1.2565445184707642, ppl = 3.5360114597102053\n","Train Epoch #17, Batch 5399/24958 loss = 1.2568590998649598, ppl = 3.5370549558261994\n","Train Epoch #17, Batch 5400/24958 loss = 1.2556777966022492, ppl = 3.5327754628773875\n","Train Epoch #17, Batch 5401/24958 loss = 1.2557326924800873, ppl = 3.5329997308034944\n","Train Epoch #17, Batch 5402/24958 loss = 1.2544886660575867, ppl = 3.5283110597860685\n","Train Epoch #17, Batch 5403/24958 loss = 1.2545961117744446, ppl = 3.528701504697307\n","Train Epoch #17, Batch 5404/24958 loss = 1.2546367526054383, ppl = 3.5288608746398906\n","Train Epoch #17, Batch 5405/24958 loss = 1.2547245180606843, ppl = 3.529160459567504\n","Train Epoch #17, Batch 5406/24958 loss = 1.2544818639755249, ppl = 3.528316644200781\n","Train Epoch #17, Batch 5407/24958 loss = 1.2550891745090484, ppl = 3.5305740676316555\n","Train Epoch #17, Batch 5408/24958 loss = 1.2537806880474092, ppl = 3.5263182659091465\n","Train Epoch #17, Batch 5409/24958 loss = 1.2551713359355927, ppl = 3.531308375825798\n","Train Epoch #17, Batch 5410/24958 loss = 1.2564980292320251, ppl = 3.5359287446459735\n","Train Epoch #17, Batch 5411/24958 loss = 1.2533590912818908, ppl = 3.524052044601336\n","Train Epoch #17, Batch 5412/24958 loss = 1.2528207838535308, ppl = 3.522304892942708\n","Train Epoch #17, Batch 5413/24958 loss = 1.2517179822921753, ppl = 3.518468754094692\n","Train Epoch #17, Batch 5414/24958 loss = 1.2544697046279907, ppl = 3.528281465692956\n","Train Epoch #17, Batch 5415/24958 loss = 1.2524227380752564, ppl = 3.5206204854636893\n","Train Epoch #17, Batch 5416/24958 loss = 1.2523219990730285, ppl = 3.5202723591835094\n","Train Epoch #17, Batch 5417/24958 loss = 1.2566919195652009, ppl = 3.5366805435199478\n","Train Epoch #17, Batch 5418/24958 loss = 1.258993891477585, ppl = 3.544545639433084\n","Train Epoch #17, Batch 5419/24958 loss = 1.2586682522296906, ppl = 3.543336717798011\n","Train Epoch #17, Batch 5420/24958 loss = 1.2585401737689972, ppl = 3.542903919597647\n","Train Epoch #17, Batch 5421/24958 loss = 1.2615417337417603, ppl = 3.5526619462263835\n","Train Epoch #17, Batch 5422/24958 loss = 1.2579546749591828, ppl = 3.539344559509857\n","Train Epoch #17, Batch 5423/24958 loss = 1.2586768996715545, ppl = 3.54177261780046\n","Train Epoch #17, Batch 5424/24958 loss = 1.2551913142204285, ppl = 3.5301818519115\n","Train Epoch #17, Batch 5425/24958 loss = 1.255606460571289, ppl = 3.531674788013045\n","Train Epoch #17, Batch 5426/24958 loss = 1.2564916503429413, ppl = 3.5345885365110017\n","Train Epoch #17, Batch 5427/24958 loss = 1.2580943059921266, ppl = 3.5406035170797088\n","Train Epoch #17, Batch 5428/24958 loss = 1.2583057153224946, ppl = 3.5414462932604778\n","Train Epoch #17, Batch 5429/24958 loss = 1.2591000878810883, ppl = 3.544291234749\n","Train Epoch #17, Batch 5430/24958 loss = 1.2577434659004212, ppl = 3.539884272365596\n","Train Epoch #17, Batch 5431/24958 loss = 1.2585920631885528, ppl = 3.5430306555201256\n","Train Epoch #17, Batch 5432/24958 loss = 1.2579885530471802, ppl = 3.5409724185174154\n","Train Epoch #17, Batch 5433/24958 loss = 1.2584123849868774, ppl = 3.5424079456898867\n","Train Epoch #17, Batch 5434/24958 loss = 1.2567150175571442, ppl = 3.5366833320208233\n","Train Epoch #17, Batch 5435/24958 loss = 1.2542333233356475, ppl = 3.528122966192715\n","Train Epoch #17, Batch 5436/24958 loss = 1.2571271026134492, ppl = 3.5375049803372125\n","Train Epoch #17, Batch 5437/24958 loss = 1.256449818611145, ppl = 3.5353441342460585\n","Train Epoch #17, Batch 5438/24958 loss = 1.2553872203826903, ppl = 3.5312773739905907\n","Train Epoch #17, Batch 5439/24958 loss = 1.257757853269577, ppl = 3.5390018830464616\n","Train Epoch #17, Batch 5440/24958 loss = 1.260765163898468, ppl = 3.5488022794646326\n","Train Epoch #17, Batch 5441/24958 loss = 1.2621564733982087, ppl = 3.553439702161918\n","Train Epoch #17, Batch 5442/24958 loss = 1.2668765544891358, ppl = 3.5723438423264637\n","Train Epoch #17, Batch 5443/24958 loss = 1.267124947309494, ppl = 3.573066275000912\n","Train Epoch #17, Batch 5444/24958 loss = 1.2682176434993744, ppl = 3.577011339277816\n","Train Epoch #17, Batch 5445/24958 loss = 1.2687036657333375, ppl = 3.578656417302227\n","Train Epoch #17, Batch 5446/24958 loss = 1.2701037991046906, ppl = 3.583347891332098\n","Train Epoch #17, Batch 5447/24958 loss = 1.266759396791458, ppl = 3.5703495894400303\n","Train Epoch #17, Batch 5448/24958 loss = 1.2686729073524474, ppl = 3.5778652720675517\n","Train Epoch #17, Batch 5449/24958 loss = 1.2686325216293335, ppl = 3.5777388522145714\n","Train Epoch #17, Batch 5450/24958 loss = 1.268477635383606, ppl = 3.577202105938344\n","Train Epoch #17, Batch 5451/24958 loss = 1.2688579428195954, ppl = 3.5787374594229333\n","Train Epoch #17, Batch 5452/24958 loss = 1.2688744521141053, ppl = 3.578792936026895\n","Train Epoch #17, Batch 5453/24958 loss = 1.2686801338195801, ppl = 3.5780395279031887\n","Train Epoch #17, Batch 5454/24958 loss = 1.2683218133449554, ppl = 3.5768356264333065\n","Train Epoch #17, Batch 5455/24958 loss = 1.2676105511188507, ppl = 3.5745183222463344\n","Train Epoch #17, Batch 5456/24958 loss = 1.2685142326354981, ppl = 3.5781883045970773\n","Train Epoch #17, Batch 5457/24958 loss = 1.2671221911907196, ppl = 3.5735922991167435\n","Train Epoch #17, Batch 5458/24958 loss = 1.2676607477664947, ppl = 3.575682159238499\n","Train Epoch #17, Batch 5459/24958 loss = 1.2669762992858886, ppl = 3.573306122889544\n","Train Epoch #17, Batch 5460/24958 loss = 1.2691620767116547, ppl = 3.5813414981194533\n","Train Epoch #17, Batch 5461/24958 loss = 1.267569637298584, ppl = 3.575195901486508\n","Train Epoch #17, Batch 5462/24958 loss = 1.267135623693466, ppl = 3.5739279377108555\n","Train Epoch #17, Batch 5463/24958 loss = 1.26732879281044, ppl = 3.5745594102185083\n","Train Epoch #17, Batch 5464/24958 loss = 1.268493757247925, ppl = 3.57886835470501\n","Train Epoch #17, Batch 5465/24958 loss = 1.2692548549175262, ppl = 3.5815766903818957\n","Train Epoch #17, Batch 5466/24958 loss = 1.269805371761322, ppl = 3.583432497744998\n","Train Epoch #17, Batch 5467/24958 loss = 1.2711334073543548, ppl = 3.5877251291322456\n","Train Epoch #17, Batch 5468/24958 loss = 1.2696744751930238, ppl = 3.5825013218556365\n","Train Epoch #17, Batch 5469/24958 loss = 1.2709096658229828, ppl = 3.586833081481324\n","Train Epoch #17, Batch 5470/24958 loss = 1.2730667877197266, ppl = 3.5947400599742854\n","Train Epoch #17, Batch 5471/24958 loss = 1.2732862365245818, ppl = 3.595623090974379\n","Train Epoch #17, Batch 5472/24958 loss = 1.2717774713039398, ppl = 3.5905134793171136\n","Train Epoch #17, Batch 5473/24958 loss = 1.267485625743866, ppl = 3.575092636540175\n","Train Epoch #17, Batch 5474/24958 loss = 1.2661082863807678, ppl = 3.5700508911952293\n","Train Epoch #17, Batch 5475/24958 loss = 1.2665460681915284, ppl = 3.571749327345279\n","Train Epoch #17, Batch 5476/24958 loss = 1.2651275074481965, ppl = 3.566515842546455\n","Train Epoch #17, Batch 5477/24958 loss = 1.2654925310611724, ppl = 3.5676864370582226\n","Train Epoch #17, Batch 5478/24958 loss = 1.2655263257026672, ppl = 3.567810137371585\n","Train Epoch #17, Batch 5479/24958 loss = 1.2667043602466583, ppl = 3.5720261855203446\n","Train Epoch #17, Batch 5480/24958 loss = 1.265098853111267, ppl = 3.566561079239366\n","Train Epoch #17, Batch 5481/24958 loss = 1.2665151929855347, ppl = 3.5713723978231138\n","Train Epoch #17, Batch 5482/24958 loss = 1.265895733833313, ppl = 3.5690432517552466\n","Train Epoch #17, Batch 5483/24958 loss = 1.2663581573963165, ppl = 3.5707196023386456\n","Train Epoch #17, Batch 5484/24958 loss = 1.2670488703250884, ppl = 3.573135261666767\n","Train Epoch #17, Batch 5485/24958 loss = 1.2705664622783661, ppl = 3.5857714808176637\n","Train Epoch #17, Batch 5486/24958 loss = 1.2700252366065978, ppl = 3.583920621020623\n","Train Epoch #17, Batch 5487/24958 loss = 1.2659082317352295, ppl = 3.567456108954151\n","Train Epoch #17, Batch 5488/24958 loss = 1.2661554324626922, ppl = 3.568306753227446\n","Train Epoch #17, Batch 5489/24958 loss = 1.2677733552455903, ppl = 3.5742028747347776\n","Train Epoch #17, Batch 5490/24958 loss = 1.2674805462360381, ppl = 3.5732350147767793\n","Train Epoch #17, Batch 5491/24958 loss = 1.2665986406803131, ppl = 3.570067149042336\n","Train Epoch #17, Batch 5492/24958 loss = 1.267084481716156, ppl = 3.571663013734284\n","Train Epoch #17, Batch 5493/24958 loss = 1.2690507376194, ppl = 3.578396308109421\n","Train Epoch #17, Batch 5494/24958 loss = 1.2661732137203217, ppl = 3.5672178546550155\n","Train Epoch #17, Batch 5495/24958 loss = 1.266181266307831, ppl = 3.567248874460646\n","Train Epoch #17, Batch 5496/24958 loss = 1.2657934474945067, ppl = 3.5659648446994394\n","Train Epoch #17, Batch 5497/24958 loss = 1.2657413852214814, ppl = 3.5657900266738056\n","Train Epoch #17, Batch 5498/24958 loss = 1.2648856437206268, ppl = 3.5626682401934047\n","Train Epoch #17, Batch 5499/24958 loss = 1.2650690627098085, ppl = 3.56329198109111\n","Train Epoch #17, Batch 5500/24958 loss = 1.2636024940013886, ppl = 3.5586364185960333\n","Train Epoch #17, Batch 5501/24958 loss = 1.263155561685562, ppl = 3.5568458464381507\n","Train Epoch #17, Batch 5502/24958 loss = 1.2645373332500458, ppl = 3.5620904532759585\n","Train Epoch #17, Batch 5503/24958 loss = 1.2627417588233947, ppl = 3.5560856609266143\n","Train Epoch #17, Batch 5504/24958 loss = 1.2630038022994996, ppl = 3.5571289436641718\n","Train Epoch #17, Batch 5505/24958 loss = 1.2639611566066742, ppl = 3.560573457847557\n","Train Epoch #17, Batch 5506/24958 loss = 1.2621361088752747, ppl = 3.554842510982884\n","Train Epoch #17, Batch 5507/24958 loss = 1.2619265794754029, ppl = 3.5540481350160604\n","Train Epoch #17, Batch 5508/24958 loss = 1.2637487018108369, ppl = 3.5601327625666914\n","Train Epoch #17, Batch 5509/24958 loss = 1.2624530899524689, ppl = 3.555462026314916\n","Train Epoch #17, Batch 5510/24958 loss = 1.2613416993618012, ppl = 3.551550438367142\n","Train Epoch #17, Batch 5511/24958 loss = 1.2625084936618804, ppl = 3.5555365333448377\n","Train Epoch #17, Batch 5512/24958 loss = 1.2630810987949372, ppl = 3.55739822232656\n","Train Epoch #17, Batch 5513/24958 loss = 1.262707350254059, ppl = 3.5561911902840615\n","Train Epoch #17, Batch 5514/24958 loss = 1.2611769700050355, ppl = 3.5504027803384726\n","Train Epoch #17, Batch 5515/24958 loss = 1.2605634498596192, ppl = 3.548395810503719\n","Train Epoch #17, Batch 5516/24958 loss = 1.2604171538352966, ppl = 3.547896455475122\n","Train Epoch #17, Batch 5517/24958 loss = 1.2598644244670867, ppl = 3.5454041918722816\n","Train Epoch #17, Batch 5518/24958 loss = 1.2588376772403718, ppl = 3.5416717679355982\n","Train Epoch #17, Batch 5519/24958 loss = 1.2586708462238312, ppl = 3.5410674991024407\n","Train Epoch #17, Batch 5520/24958 loss = 1.2575851273536682, ppl = 3.537613042208448\n","Train Epoch #17, Batch 5521/24958 loss = 1.2566383373737335, ppl = 3.534213499411133\n","Train Epoch #17, Batch 5522/24958 loss = 1.259292997121811, ppl = 3.543597568898288\n","Train Epoch #17, Batch 5523/24958 loss = 1.2591033256053925, ppl = 3.5429428343588905\n","Train Epoch #17, Batch 5524/24958 loss = 1.2612122249603273, ppl = 3.54946821909042\n","Train Epoch #17, Batch 5525/24958 loss = 1.2619788122177125, ppl = 3.5523932991580467\n","Train Epoch #17, Batch 5526/24958 loss = 1.2635148441791535, ppl = 3.5581038390788904\n","Train Epoch #17, Batch 5527/24958 loss = 1.2632969498634339, ppl = 3.557228344370671\n","Train Epoch #17, Batch 5528/24958 loss = 1.262248021364212, ppl = 3.5532165516969796\n","Train Epoch #17, Batch 5529/24958 loss = 1.2611096060276032, ppl = 3.5492078904372817\n","Train Epoch #17, Batch 5530/24958 loss = 1.2602066719532012, ppl = 3.546589192312428\n","Train Epoch #17, Batch 5531/24958 loss = 1.2585752665996552, ppl = 3.5407678304869385\n","Train Epoch #17, Batch 5532/24958 loss = 1.258796730041504, ppl = 3.541508730810211\n","Train Epoch #17, Batch 5533/24958 loss = 1.2592377507686614, ppl = 3.5430684968620194\n","Train Epoch #17, Batch 5534/24958 loss = 1.2607776093482972, ppl = 3.5482200557319787\n","Train Epoch #17, Batch 5535/24958 loss = 1.2611432373523712, ppl = 3.549351788789725\n","Train Epoch #17, Batch 5536/24958 loss = 1.2616340219974518, ppl = 3.5512300061186095\n","Train Epoch #17, Batch 5537/24958 loss = 1.2625746154785156, ppl = 3.5542712395334735\n","Train Epoch #17, Batch 5538/24958 loss = 1.2616789400577546, ppl = 3.5511634784360426\n","Train Epoch #17, Batch 5539/24958 loss = 1.262481005191803, ppl = 3.5542198799565763\n","Train Epoch #17, Batch 5540/24958 loss = 1.261118370294571, ppl = 3.549413045527136\n","Train Epoch #17, Batch 5541/24958 loss = 1.2638409745693207, ppl = 3.560585799925467\n","Train Epoch #17, Batch 5542/24958 loss = 1.259646453857422, ppl = 3.5433727746631667\n","Train Epoch #17, Batch 5543/24958 loss = 1.2620353698730469, ppl = 3.5513187772735364\n","Train Epoch #17, Batch 5544/24958 loss = 1.2610768854618073, ppl = 3.5478353698471126\n","Train Epoch #17, Batch 5545/24958 loss = 1.2622822856903075, ppl = 3.5522776971807546\n","Train Epoch #17, Batch 5546/24958 loss = 1.2617202770709992, ppl = 3.5503153086166623\n","Train Epoch #17, Batch 5547/24958 loss = 1.260937260389328, ppl = 3.547850392295603\n","Train Epoch #17, Batch 5548/24958 loss = 1.2582678270339966, ppl = 3.537739992497602\n","Train Epoch #17, Batch 5549/24958 loss = 1.260072648525238, ppl = 3.5439190878178537\n","Train Epoch #17, Batch 5550/24958 loss = 1.2605777537822724, ppl = 3.5457005836486992\n","Train Epoch #17, Batch 5551/24958 loss = 1.259681693315506, ppl = 3.5421741919008114\n","Train Epoch #17, Batch 5552/24958 loss = 1.2587589263916015, ppl = 3.5392097137017196\n","Train Epoch #17, Batch 5553/24958 loss = 1.2585861611366271, ppl = 3.5385520551611824\n","Train Epoch #17, Batch 5554/24958 loss = 1.2606417310237885, ppl = 3.5460829741003637\n","Train Epoch #17, Batch 5555/24958 loss = 1.2626360189914703, ppl = 3.5530208996806594\n","Train Epoch #17, Batch 5556/24958 loss = 1.2613600444793702, ppl = 3.5479328288743517\n","Train Epoch #17, Batch 5557/24958 loss = 1.2635197961330413, ppl = 3.5553509847210485\n","Train Epoch #17, Batch 5558/24958 loss = 1.2615143251419068, ppl = 3.548107897908129\n","Train Epoch #17, Batch 5559/24958 loss = 1.263576372861862, ppl = 3.5557887536114485\n","Train Epoch #17, Batch 5560/24958 loss = 1.262115740776062, ppl = 3.5502270327428533\n","Train Epoch #17, Batch 5561/24958 loss = 1.261704798936844, ppl = 3.548793688855953\n","Train Epoch #17, Batch 5562/24958 loss = 1.2619255292415619, ppl = 3.549431671417937\n","Train Epoch #17, Batch 5563/24958 loss = 1.2618116652965545, ppl = 3.5490579735127863\n","Train Epoch #17, Batch 5564/24958 loss = 1.2591968417167663, ppl = 3.5400420893328386\n","Train Epoch #17, Batch 5565/24958 loss = 1.2586532413959504, ppl = 3.5380867895502446\n","Train Epoch #17, Batch 5566/24958 loss = 1.2583762526512146, ppl = 3.5371402842851847\n","Train Epoch #17, Batch 5567/24958 loss = 1.2580483520030976, ppl = 3.5360268254491802\n","Train Epoch #17, Batch 5568/24958 loss = 1.2577106440067292, ppl = 3.534922453440945\n","Train Epoch #17, Batch 5569/24958 loss = 1.2569352722167968, ppl = 3.532141088776836\n","Train Epoch #17, Batch 5570/24958 loss = 1.2553896307945251, ppl = 3.5263051157831296\n","Train Epoch #17, Batch 5571/24958 loss = 1.2534489846229553, ppl = 3.519129051242331\n","Train Epoch #17, Batch 5572/24958 loss = 1.2532138407230378, ppl = 3.518399879884098\n","Train Epoch #17, Batch 5573/24958 loss = 1.25415806889534, ppl = 3.5212488088096503\n","Train Epoch #17, Batch 5574/24958 loss = 1.2533815753459931, ppl = 3.5186980242407655\n","Train Epoch #17, Batch 5575/24958 loss = 1.2522873842716218, ppl = 3.5145882981083254\n","Train Epoch #17, Batch 5576/24958 loss = 1.2530736792087556, ppl = 3.517397266318919\n","Train Epoch #17, Batch 5577/24958 loss = 1.2520212697982789, ppl = 3.5141349944918105\n","Train Epoch #17, Batch 5578/24958 loss = 1.254202468395233, ppl = 3.5230716806497866\n","Train Epoch #17, Batch 5579/24958 loss = 1.256189478635788, ppl = 3.5314111580859757\n","Train Epoch #17, Batch 5580/24958 loss = 1.2563398551940919, ppl = 3.5318866098950132\n","Train Epoch #17, Batch 5581/24958 loss = 1.2548939454555512, ppl = 3.526981925978246\n","Train Epoch #17, Batch 5582/24958 loss = 1.2551698994636535, ppl = 3.528001704785367\n","Train Epoch #17, Batch 5583/24958 loss = 1.2547711634635925, ppl = 3.5265516534560435\n","Train Epoch #17, Batch 5584/24958 loss = 1.2540196883678436, ppl = 3.5239313649206854\n","Train Epoch #17, Batch 5585/24958 loss = 1.2515094363689423, ppl = 3.51447191143582\n","Train Epoch #17, Batch 5586/24958 loss = 1.2538952934741974, ppl = 3.5234394198095016\n","Train Epoch #17, Batch 5587/24958 loss = 1.2530460798740386, ppl = 3.5208078674426972\n","Train Epoch #17, Batch 5588/24958 loss = 1.2541003620624542, ppl = 3.5246813937343346\n","Train Epoch #17, Batch 5589/24958 loss = 1.2524350166320801, ppl = 3.51862643264342\n","Train Epoch #17, Batch 5590/24958 loss = 1.2530924308300018, ppl = 3.520839767675801\n","Train Epoch #17, Batch 5591/24958 loss = 1.252072672843933, ppl = 3.517508610428566\n","Train Epoch #17, Batch 5592/24958 loss = 1.252863997220993, ppl = 3.520279762165803\n","Train Epoch #17, Batch 5593/24958 loss = 1.251990600824356, ppl = 3.517124984561392\n","Train Epoch #17, Batch 5594/24958 loss = 1.2523754012584687, ppl = 3.5184402064231075\n","Train Epoch #17, Batch 5595/24958 loss = 1.2516877889633178, ppl = 3.515879402396203\n","Train Epoch #17, Batch 5596/24958 loss = 1.2521843016147614, ppl = 3.5175323313446096\n","Train Epoch #17, Batch 5597/24958 loss = 1.2527475512027741, ppl = 3.5194728649865805\n","Train Epoch #17, Batch 5598/24958 loss = 1.2526059758663177, ppl = 3.5189816598884516\n","Train Epoch #17, Batch 5599/24958 loss = 1.2536274361610413, ppl = 3.522672521300238\n","Train Epoch #17, Batch 5600/24958 loss = 1.2567326188087464, ppl = 3.533404831553846\n","Train Epoch #17, Batch 5601/24958 loss = 1.2552803313732148, ppl = 3.528109330414334\n","Train Epoch #17, Batch 5602/24958 loss = 1.2518532824516297, ppl = 3.516318019121674\n","Train Epoch #17, Batch 5603/24958 loss = 1.252094703912735, ppl = 3.517064037864844\n","Train Epoch #17, Batch 5604/24958 loss = 1.2524975311756135, ppl = 3.5187221043747576\n","Train Epoch #17, Batch 5605/24958 loss = 1.2504566478729249, ppl = 3.5117569212329642\n","Train Epoch #17, Batch 5606/24958 loss = 1.2522126400470734, ppl = 3.517251450404002\n","Train Epoch #17, Batch 5607/24958 loss = 1.2507912755012511, ppl = 3.5122806105801114\n","Train Epoch #17, Batch 5608/24958 loss = 1.2490367460250855, ppl = 3.5064024536950678\n","Train Epoch #17, Batch 5609/24958 loss = 1.2490678322315216, ppl = 3.5065075810635973\n","Train Epoch #17, Batch 5610/24958 loss = 1.2480139243602753, ppl = 3.50317908801378\n","Train Epoch #17, Batch 5611/24958 loss = 1.2502919721603394, ppl = 3.512439116243954\n","Train Epoch #17, Batch 5612/24958 loss = 1.2512019157409668, ppl = 3.5156258808460454\n","Train Epoch #17, Batch 5613/24958 loss = 1.2501329112052917, ppl = 3.512412432296844\n","Train Epoch #17, Batch 5614/24958 loss = 1.2499193167686462, ppl = 3.51167271723061\n","Train Epoch #17, Batch 5615/24958 loss = 1.249497526884079, ppl = 3.5103626584338126\n","Train Epoch #17, Batch 5616/24958 loss = 1.2518666470050812, ppl = 3.51942088765878\n","Train Epoch #17, Batch 5617/24958 loss = 1.2501535892486573, ppl = 3.5125164531712363\n","Train Epoch #17, Batch 5618/24958 loss = 1.248157081604004, ppl = 3.5062693371789515\n","Train Epoch #17, Batch 5619/24958 loss = 1.2503287947177888, ppl = 3.5149817689964022\n","Train Epoch #17, Batch 5620/24958 loss = 1.2507694685459136, ppl = 3.516338814865463\n","Train Epoch #17, Batch 5621/24958 loss = 1.251727693080902, ppl = 3.5197814134501653\n","Train Epoch #17, Batch 5622/24958 loss = 1.2497292649745941, ppl = 3.5124907218768397\n","Train Epoch #17, Batch 5623/24958 loss = 1.2491500675678253, ppl = 3.5105665309546454\n","Train Epoch #17, Batch 5624/24958 loss = 1.2495149636268617, ppl = 3.5118419615304526\n","Train Epoch #17, Batch 5625/24958 loss = 1.2494864749908448, ppl = 3.511729197850798\n","Train Epoch #17, Batch 5626/24958 loss = 1.2472131979465484, ppl = 3.5035741204056112\n","Train Epoch #17, Batch 5627/24958 loss = 1.2468432021141052, ppl = 3.50213049417297\n","Train Epoch #17, Batch 5628/24958 loss = 1.2452716147899627, ppl = 3.496854854749219\n","Train Epoch #17, Batch 5629/24958 loss = 1.245195826292038, ppl = 3.4966038381929168\n","Train Epoch #17, Batch 5630/24958 loss = 1.2456718707084655, ppl = 3.4979549788571496\n","Train Epoch #17, Batch 5631/24958 loss = 1.244656481742859, ppl = 3.4947830328274407\n","Train Epoch #17, Batch 5632/24958 loss = 1.2457290768623352, ppl = 3.4986129816243268\n","Train Epoch #17, Batch 5633/24958 loss = 1.246273488998413, ppl = 3.5006357450828496\n","Train Epoch #17, Batch 5634/24958 loss = 1.2440150892734527, ppl = 3.4933386622124702\n","Train Epoch #17, Batch 5635/24958 loss = 1.2468129229545593, ppl = 3.5035154689978056\n","Train Epoch #17, Batch 5636/24958 loss = 1.2457721388339997, ppl = 3.4996391022387923\n","Train Epoch #17, Batch 5637/24958 loss = 1.247664498090744, ppl = 3.506696683652929\n","Train Epoch #17, Batch 5638/24958 loss = 1.2487020599842071, ppl = 3.5103227991816306\n","Train Epoch #17, Batch 5639/24958 loss = 1.247987253665924, ppl = 3.5075871525136773\n","Train Epoch #17, Batch 5640/24958 loss = 1.2514985871315003, ppl = 3.5214388496960147\n","Train Epoch #17, Batch 5641/24958 loss = 1.2477566075325013, ppl = 3.506805894599134\n","Train Epoch #17, Batch 5642/24958 loss = 1.2490364873409272, ppl = 3.511315834177048\n","Train Epoch #17, Batch 5643/24958 loss = 1.2483571481704712, ppl = 3.5088599450017983\n","Train Epoch #17, Batch 5644/24958 loss = 1.2488648176193238, ppl = 3.5106633419563043\n","Train Epoch #17, Batch 5645/24958 loss = 1.246896277666092, ppl = 3.5036731313291996\n","Train Epoch #17, Batch 5646/24958 loss = 1.2447207105159759, ppl = 3.4970361926035913\n","Train Epoch #17, Batch 5647/24958 loss = 1.246123697757721, ppl = 3.501594384101146\n","Train Epoch #17, Batch 5648/24958 loss = 1.2462080252170562, ppl = 3.5018742152031597\n","Train Epoch #17, Batch 5649/24958 loss = 1.2465353882312775, ppl = 3.5031194468790807\n","Train Epoch #17, Batch 5650/24958 loss = 1.2471586918830873, ppl = 3.50544555455877\n","Train Epoch #17, Batch 5651/24958 loss = 1.2460432744026184, ppl = 3.5014751768213563\n","Train Epoch #17, Batch 5652/24958 loss = 1.249524040222168, ppl = 3.5142428988829164\n","Train Epoch #17, Batch 5653/24958 loss = 1.2487264108657836, ppl = 3.5113496682375143\n","Train Epoch #17, Batch 5654/24958 loss = 1.2465822899341583, ppl = 3.503527819971591\n","Train Epoch #17, Batch 5655/24958 loss = 1.2465688335895537, ppl = 3.503476218432375\n","Train Epoch #17, Batch 5656/24958 loss = 1.2454385542869568, ppl = 3.4994806151595412\n","Train Epoch #17, Batch 5657/24958 loss = 1.2420229315757751, ppl = 3.488430763150666\n","Train Epoch #17, Batch 5658/24958 loss = 1.2421636116504668, ppl = 3.4888928488324025\n","Train Epoch #17, Batch 5659/24958 loss = 1.241942391395569, ppl = 3.487990969282606\n","Train Epoch #17, Batch 5660/24958 loss = 1.241878982782364, ppl = 3.4877674385610518\n","Train Epoch #17, Batch 5661/24958 loss = 1.2407160675525666, ppl = 3.4840163582854813\n","Train Epoch #17, Batch 5662/24958 loss = 1.2430237352848053, ppl = 3.4916017496962\n","Train Epoch #17, Batch 5663/24958 loss = 1.2420891904830933, ppl = 3.4886901991047043\n","Train Epoch #17, Batch 5664/24958 loss = 1.2421513283252716, ppl = 3.488878241331017\n","Train Epoch #17, Batch 5665/24958 loss = 1.2410154819488526, ppl = 3.4851201746111786\n","Train Epoch #17, Batch 5666/24958 loss = 1.241721420288086, ppl = 3.487585183530902\n","Train Epoch #17, Batch 5667/24958 loss = 1.2415169894695282, ppl = 3.4869092454192927\n","Train Epoch #17, Batch 5668/24958 loss = 1.2427752637863159, ppl = 3.4912205136749304\n","Train Epoch #17, Batch 5669/24958 loss = 1.2419451951980591, ppl = 3.4884725175894253\n","Train Epoch #17, Batch 5670/24958 loss = 1.2431533086299895, ppl = 3.4929559927908547\n","Train Epoch #17, Batch 5671/24958 loss = 1.2450615096092223, ppl = 3.500000278609662\n","Train Epoch #17, Batch 5672/24958 loss = 1.248195195198059, ppl = 3.5112789479916655\n","Train Epoch #17, Batch 5673/24958 loss = 1.2475514817237854, ppl = 3.509307721570577\n","Train Epoch #17, Batch 5674/24958 loss = 1.248933424949646, ppl = 3.513989487870554\n","Train Epoch #17, Batch 5675/24958 loss = 1.249913387298584, ppl = 3.517648853402495\n","Train Epoch #17, Batch 5676/24958 loss = 1.2500225126743316, ppl = 3.5180564412107547\n","Train Epoch #17, Batch 5677/24958 loss = 1.2515079820156096, ppl = 3.522764064665182\n","Train Epoch #17, Batch 5678/24958 loss = 1.2503252267837524, ppl = 3.517677206503826\n","Train Epoch #17, Batch 5679/24958 loss = 1.2493725037574768, ppl = 3.513471735175986\n","Train Epoch #17, Batch 5680/24958 loss = 1.2500622367858887, ppl = 3.5157464770662297\n","Train Epoch #17, Batch 5681/24958 loss = 1.2512935388088227, ppl = 3.5198776212246\n","Train Epoch #17, Batch 5682/24958 loss = 1.2493626141548158, ppl = 3.513298648704013\n","Train Epoch #17, Batch 5683/24958 loss = 1.2470514130592347, ppl = 3.5059428890517155\n","Train Epoch #17, Batch 5684/24958 loss = 1.2488036930561066, ppl = 3.5123730749226536\n","Train Epoch #17, Batch 5685/24958 loss = 1.248623594045639, ppl = 3.511781368860534\n","Train Epoch #17, Batch 5686/24958 loss = 1.2473142099380494, ppl = 3.5065963496081314\n","Train Epoch #17, Batch 5687/24958 loss = 1.2486275589466096, ppl = 3.510763463701517\n","Train Epoch #17, Batch 5688/24958 loss = 1.2507783901691436, ppl = 3.5200529094368256\n","Train Epoch #17, Batch 5689/24958 loss = 1.2518156826496125, ppl = 3.523705182194368\n","Train Epoch #17, Batch 5690/24958 loss = 1.2516650867462158, ppl = 3.5231852430021404\n","Train Epoch #17, Batch 5691/24958 loss = 1.2551202630996705, ppl = 3.5359915133778874\n","Train Epoch #17, Batch 5692/24958 loss = 1.2552586770057679, ppl = 3.5364991636885788\n","Train Epoch #17, Batch 5693/24958 loss = 1.254978485107422, ppl = 3.535544084782343\n","Train Epoch #17, Batch 5694/24958 loss = 1.2548696041107177, ppl = 3.535166788592717\n","Train Epoch #17, Batch 5695/24958 loss = 1.2547970461845397, ppl = 3.5349066971382728\n","Train Epoch #17, Batch 5696/24958 loss = 1.2552710282802582, ppl = 3.5365630614806656\n","Train Epoch #17, Batch 5697/24958 loss = 1.2536238360404968, ppl = 3.5311820920442973\n","Train Epoch #17, Batch 5698/24958 loss = 1.254040834903717, ppl = 3.532649053553531\n","Train Epoch #17, Batch 5699/24958 loss = 1.2507523000240326, ppl = 3.521996684760934\n","Train Epoch #17, Batch 5700/24958 loss = 1.2498422276973724, ppl = 3.5184992095257916\n","Train Epoch #17, Batch 5701/24958 loss = 1.250406287908554, ppl = 3.5204651407483976\n","Train Epoch #17, Batch 5702/24958 loss = 1.2527818977832794, ppl = 3.5282005406711465\n","Train Epoch #17, Batch 5703/24958 loss = 1.255747331380844, ppl = 3.538996907212791\n","Train Epoch #17, Batch 5704/24958 loss = 1.253100142478943, ppl = 3.529229702331268\n","Train Epoch #17, Batch 5705/24958 loss = 1.25392094373703, ppl = 3.531861346001202\n","Train Epoch #17, Batch 5706/24958 loss = 1.2546225595474243, ppl = 3.534341078261859\n","Train Epoch #17, Batch 5707/24958 loss = 1.2550181603431703, ppl = 3.535654396785643\n","Train Epoch #17, Batch 5708/24958 loss = 1.254648185968399, ppl = 3.5345411614169513\n","Train Epoch #17, Batch 5709/24958 loss = 1.2584042978286742, ppl = 3.549982124035007\n","Train Epoch #17, Batch 5710/24958 loss = 1.2596934235095978, ppl = 3.5541026026295532\n","Train Epoch #17, Batch 5711/24958 loss = 1.2555152690410614, ppl = 3.5385791123408734\n","Train Epoch #17, Batch 5712/24958 loss = 1.2559670329093933, ppl = 3.540272292707744\n","Train Epoch #17, Batch 5713/24958 loss = 1.2571637856960296, ppl = 3.5438932435940336\n","Train Epoch #17, Batch 5714/24958 loss = 1.2599210965633392, ppl = 3.554771592906101\n","Train Epoch #17, Batch 5715/24958 loss = 1.26170330286026, ppl = 3.5607040702281374\n","Train Epoch #17, Batch 5716/24958 loss = 1.2608620536327362, ppl = 3.557239326868731\n","Train Epoch #17, Batch 5717/24958 loss = 1.2597283017635346, ppl = 3.553278753024463\n","Train Epoch #17, Batch 5718/24958 loss = 1.2638935613632203, ppl = 3.5678856648393475\n","Train Epoch #17, Batch 5719/24958 loss = 1.2605553340911866, ppl = 3.555218370757016\n","Train Epoch #17, Batch 5720/24958 loss = 1.260346723794937, ppl = 3.55456850307585\n","Train Epoch #17, Batch 5721/24958 loss = 1.25842777967453, ppl = 3.5479901123468682\n","Train Epoch #17, Batch 5722/24958 loss = 1.2581604254245757, ppl = 3.5471206376688293\n","Train Epoch #17, Batch 5723/24958 loss = 1.2595357191562653, ppl = 3.5518782115036807\n","Train Epoch #17, Batch 5724/24958 loss = 1.2576663446426393, ppl = 3.5458091335189277\n","Train Epoch #17, Batch 5725/24958 loss = 1.2557857537269592, ppl = 3.5390330863811164\n","Train Epoch #17, Batch 5726/24958 loss = 1.2570911347866058, ppl = 3.543488304845553\n","Train Epoch #17, Batch 5727/24958 loss = 1.2547500717639923, ppl = 3.5354942400913534\n","Train Epoch #17, Batch 5728/24958 loss = 1.2547536265850068, ppl = 3.5355052620324745\n","Train Epoch #17, Batch 5729/24958 loss = 1.2567429745197296, ppl = 3.5427676105895376\n","Train Epoch #17, Batch 5730/24958 loss = 1.260500499010086, ppl = 3.556023125413796\n","Train Epoch #17, Batch 5731/24958 loss = 1.2625666749477387, ppl = 3.5628349567759106\n","Train Epoch #17, Batch 5732/24958 loss = 1.2634593892097472, ppl = 3.5663512235260164\n","Train Epoch #17, Batch 5733/24958 loss = 1.2625012695789337, ppl = 3.562863307918777\n","Train Epoch #17, Batch 5734/24958 loss = 1.2638453900814057, ppl = 3.567006524889517\n","Train Epoch #17, Batch 5735/24958 loss = 1.2638780438899995, ppl = 3.567142911377951\n","Train Epoch #17, Batch 5736/24958 loss = 1.2640121829509736, ppl = 3.567620153946096\n","Train Epoch #17, Batch 5737/24958 loss = 1.2640719377994538, ppl = 3.5678654936902627\n","Train Epoch #17, Batch 5738/24958 loss = 1.263126665353775, ppl = 3.5645468887639082\n","Train Epoch #17, Batch 5739/24958 loss = 1.2619097423553467, ppl = 3.5603166659732195\n","Train Epoch #17, Batch 5740/24958 loss = 1.2587037408351898, ppl = 3.5474858466538985\n","Train Epoch #17, Batch 5741/24958 loss = 1.2606350135803224, ppl = 3.5543549347835697\n","Train Epoch #17, Batch 5742/24958 loss = 1.2593504691123962, ppl = 3.549829591274235\n","Train Epoch #17, Batch 5743/24958 loss = 1.2601194953918458, ppl = 3.552622355830774\n","Train Epoch #17, Batch 5744/24958 loss = 1.259421045780182, ppl = 3.5501645686150214\n","Train Epoch #17, Batch 5745/24958 loss = 1.2593334186077119, ppl = 3.5498842602173375\n","Train Epoch #17, Batch 5746/24958 loss = 1.2601183378696441, ppl = 3.55211412282033\n","Train Epoch #17, Batch 5747/24958 loss = 1.2610147416591644, ppl = 3.5553797186718343\n","Train Epoch #17, Batch 5748/24958 loss = 1.2614965379238128, ppl = 3.557024561226293\n","Train Epoch #17, Batch 5749/24958 loss = 1.261598117351532, ppl = 3.55741931214756\n","Train Epoch #17, Batch 5750/24958 loss = 1.260965437889099, ppl = 3.5550593098902787\n","Train Epoch #17, Batch 5751/24958 loss = 1.2614521861076355, ppl = 3.556737592635646\n","Train Epoch #17, Batch 5752/24958 loss = 1.2580209255218506, ppl = 3.54412206231723\n","Train Epoch #17, Batch 5753/24958 loss = 1.2596686673164368, ppl = 3.550363823029877\n","Train Epoch #17, Batch 5754/24958 loss = 1.2594442093372344, ppl = 3.549637817956239\n","Train Epoch #17, Batch 5755/24958 loss = 1.2597408282756806, ppl = 3.550791534493713\n","Train Epoch #17, Batch 5756/24958 loss = 1.2631493270397187, ppl = 3.5643527860374133\n","Train Epoch #17, Batch 5757/24958 loss = 1.266117390394211, ppl = 3.573731104633514\n","Train Epoch #17, Batch 5758/24958 loss = 1.2662543487548827, ppl = 3.5741872540519326\n","Train Epoch #17, Batch 5759/24958 loss = 1.2640689241886138, ppl = 3.5662721814187988\n","Train Epoch #17, Batch 5760/24958 loss = 1.2636238241195679, ppl = 3.5647423639253066\n","Train Epoch #17, Batch 5761/24958 loss = 1.2660517621040344, ppl = 3.5731010306367765\n","Train Epoch #17, Batch 5762/24958 loss = 1.2659480321407317, ppl = 3.5727211863779336\n","Train Epoch #17, Batch 5763/24958 loss = 1.2665098810195923, ppl = 3.5744388963425604\n","Train Epoch #17, Batch 5764/24958 loss = 1.268820641040802, ppl = 3.5823301497689646\n","Train Epoch #17, Batch 5765/24958 loss = 1.270290629863739, ppl = 3.5872774953732836\n","Train Epoch #17, Batch 5766/24958 loss = 1.2688768744468688, ppl = 3.5825095925252937\n","Train Epoch #17, Batch 5767/24958 loss = 1.269490760564804, ppl = 3.584581642461851\n","Train Epoch #17, Batch 5768/24958 loss = 1.2674642872810364, ppl = 3.577892880119303\n","Train Epoch #17, Batch 5769/24958 loss = 1.2683967542648316, ppl = 3.5809959517550514\n","Train Epoch #17, Batch 5770/24958 loss = 1.2672060632705688, ppl = 3.576573359607291\n","Train Epoch #17, Batch 5771/24958 loss = 1.2638979208469392, ppl = 3.5651520066448206\n","Train Epoch #17, Batch 5772/24958 loss = 1.2619814848899842, ppl = 3.5578403151052163\n","Train Epoch #17, Batch 5773/24958 loss = 1.2643860495090484, ppl = 3.5658994338163366\n","Train Epoch #17, Batch 5774/24958 loss = 1.2641500401496888, ppl = 3.5650533820354298\n","Train Epoch #17, Batch 5775/24958 loss = 1.263822774887085, ppl = 3.56379122013112\n","Train Epoch #17, Batch 5776/24958 loss = 1.263806359767914, ppl = 3.5637296244099534\n","Train Epoch #17, Batch 5777/24958 loss = 1.265745677947998, ppl = 3.571028173554688\n","Train Epoch #17, Batch 5778/24958 loss = 1.2636609268188477, ppl = 3.5634040655231645\n","Train Epoch #17, Batch 5779/24958 loss = 1.2608635759353637, ppl = 3.5531377645681674\n","Train Epoch #17, Batch 5780/24958 loss = 1.2610964143276215, ppl = 3.5539417770763584\n","Train Epoch #17, Batch 5781/24958 loss = 1.2593594527244567, ppl = 3.548256034185319\n","Train Epoch #17, Batch 5782/24958 loss = 1.2605886995792388, ppl = 3.5522961520002503\n","Train Epoch #17, Batch 5783/24958 loss = 1.264820212125778, ppl = 3.567198462603725\n","Train Epoch #17, Batch 5784/24958 loss = 1.2645726585388184, ppl = 3.5662202808117547\n","Train Epoch #17, Batch 5785/24958 loss = 1.2647153759002685, ppl = 3.566688293453402\n","Train Epoch #17, Batch 5786/24958 loss = 1.2661488902568818, ppl = 3.5724010063812375\n","Train Epoch #17, Batch 5787/24958 loss = 1.2672912752628327, ppl = 3.5764984913383904\n","Train Epoch #17, Batch 5788/24958 loss = 1.2654260551929475, ppl = 3.568330634909718\n","Train Epoch #17, Batch 5789/24958 loss = 1.264842084646225, ppl = 3.566228000827321\n","Train Epoch #17, Batch 5790/24958 loss = 1.2663315498828889, ppl = 3.5717315166668904\n","Train Epoch #17, Batch 5791/24958 loss = 1.263547775745392, ppl = 3.5610800600862715\n","Train Epoch #17, Batch 5792/24958 loss = 1.2621052861213684, ppl = 3.5561192456522623\n","Train Epoch #17, Batch 5793/24958 loss = 1.2624453818798065, ppl = 3.5572820118950097\n","Train Epoch #17, Batch 5794/24958 loss = 1.262470601797104, ppl = 3.557369039149372\n","Train Epoch #17, Batch 5795/24958 loss = 1.2624480438232422, ppl = 3.557288561545951\n","Train Epoch #17, Batch 5796/24958 loss = 1.2614858758449554, ppl = 3.554006317488369\n","Train Epoch #17, Batch 5797/24958 loss = 1.2640118730068206, ppl = 3.562641971654068\n","Train Epoch #17, Batch 5798/24958 loss = 1.2620498847961426, ppl = 3.5562432074506694\n","Train Epoch #17, Batch 5799/24958 loss = 1.2630598115921021, ppl = 3.559150466023421\n","Train Epoch #17, Batch 5800/24958 loss = 1.2643714869022369, ppl = 3.5642954876766986\n","Train Epoch #17, Batch 5801/24958 loss = 1.2649507892131806, ppl = 3.5664333467363427\n","Train Epoch #17, Batch 5802/24958 loss = 1.2638574767112731, ppl = 3.5626446291897067\n","Train Epoch #17, Batch 5803/24958 loss = 1.2625017273426056, ppl = 3.557310480627166\n","Train Epoch #17, Batch 5804/24958 loss = 1.2622205913066864, ppl = 3.556417049486231\n","Train Epoch #17, Batch 5805/24958 loss = 1.2625145423412323, ppl = 3.557413290306048\n","Train Epoch #17, Batch 5806/24958 loss = 1.2635199236869812, ppl = 3.5612840573888764\n","Train Epoch #17, Batch 5807/24958 loss = 1.264733395576477, ppl = 3.5656524464539086\n","Train Epoch #17, Batch 5808/24958 loss = 1.2667597842216491, ppl = 3.5722871985553515\n","Train Epoch #17, Batch 5809/24958 loss = 1.2629232549667357, ppl = 3.5565749496463765\n","Train Epoch #17, Batch 5810/24958 loss = 1.2627034962177277, ppl = 3.5558344452452566\n","Train Epoch #17, Batch 5811/24958 loss = 1.2638847935199737, ppl = 3.559587512041188\n","Train Epoch #17, Batch 5812/24958 loss = 1.2642987656593323, ppl = 3.561207665463618\n","Train Epoch #17, Batch 5813/24958 loss = 1.2654620456695556, ppl = 3.5651680341813177\n","Train Epoch #17, Batch 5814/24958 loss = 1.262417379617691, ppl = 3.553319125138036\n","Train Epoch #17, Batch 5815/24958 loss = 1.2613149511814117, ppl = 3.549525669586341\n","Train Epoch #17, Batch 5816/24958 loss = 1.2603431749343872, ppl = 3.545869838333004\n","Train Epoch #17, Batch 5817/24958 loss = 1.2602718329429627, ppl = 3.545635315359204\n","Train Epoch #17, Batch 5818/24958 loss = 1.2554544883966445, ppl = 3.529243744764234\n","Train Epoch #17, Batch 5819/24958 loss = 1.2566599696874619, ppl = 3.5333388465945017\n","Train Epoch #17, Batch 5820/24958 loss = 1.2581137889623641, ppl = 3.53816291565269\n","Train Epoch #17, Batch 5821/24958 loss = 1.2613538855314255, ppl = 3.550062606311276\n","Train Epoch #17, Batch 5822/24958 loss = 1.2621288281679153, ppl = 3.552648182114454\n","Train Epoch #17, Batch 5823/24958 loss = 1.2610100346803665, ppl = 3.548729012117282\n","Train Epoch #17, Batch 5824/24958 loss = 1.264060029387474, ppl = 3.5592586196673848\n","Train Epoch #17, Batch 5825/24958 loss = 1.2646467381715774, ppl = 3.561237551730768\n","Train Epoch #17, Batch 5826/24958 loss = 1.2642894619703293, ppl = 3.559959823735062\n","Train Epoch #17, Batch 5827/24958 loss = 1.2656812435388565, ppl = 3.564485374356402\n","Train Epoch #17, Batch 5828/24958 loss = 1.2665580624341966, ppl = 3.567327258901993\n","Train Epoch #17, Batch 5829/24958 loss = 1.2651571124792098, ppl = 3.5620646019427387\n","Train Epoch #17, Batch 5830/24958 loss = 1.2643156856298448, ppl = 3.5586494534363333\n","Train Epoch #17, Batch 5831/24958 loss = 1.2624720579385758, ppl = 3.5525055407987765\n","Train Epoch #17, Batch 5832/24958 loss = 1.2605343633890151, ppl = 3.545252865834754\n","Train Epoch #17, Batch 5833/24958 loss = 1.2607634395360947, ppl = 3.5460566482741758\n","Train Epoch #17, Batch 5834/24958 loss = 1.2615867227315902, ppl = 3.548883539271991\n","Train Epoch #17, Batch 5835/24958 loss = 1.2624073189496994, ppl = 3.5524613450163596\n","Train Epoch #17, Batch 5836/24958 loss = 1.260001135468483, ppl = 3.5448015039403997\n","Train Epoch #17, Batch 5837/24958 loss = 1.2575771719217301, ppl = 3.53593719748074\n","Train Epoch #17, Batch 5838/24958 loss = 1.256764481663704, ppl = 3.533324387881963\n","Train Epoch #17, Batch 5839/24958 loss = 1.2584218031167984, ppl = 3.5392168798702572\n","Train Epoch #17, Batch 5840/24958 loss = 1.2577899116277695, ppl = 3.537138101074543\n","Train Epoch #17, Batch 5841/24958 loss = 1.2566066211462021, ppl = 3.5327732674491856\n","Train Epoch #17, Batch 5842/24958 loss = 1.2560727769136428, ppl = 3.531057003115413\n","Train Epoch #17, Batch 5843/24958 loss = 1.255712440609932, ppl = 3.5297216619555876\n","Train Epoch #17, Batch 5844/24958 loss = 1.2567866796255112, ppl = 3.533574589253371\n","Train Epoch #17, Batch 5845/24958 loss = 1.2566706901788711, ppl = 3.533207310882408\n","Train Epoch #17, Batch 5846/24958 loss = 1.2573651534318924, ppl = 3.535331545869344\n","Train Epoch #17, Batch 5847/24958 loss = 1.2566174799203873, ppl = 3.5325877225645756\n","Train Epoch #17, Batch 5848/24958 loss = 1.2569507819414139, ppl = 3.533772881470327\n","Train Epoch #17, Batch 5849/24958 loss = 1.255987965464592, ppl = 3.530187583557299\n","Train Epoch #17, Batch 5850/24958 loss = 1.2561099904775619, ppl = 3.530631211697618\n","Train Epoch #17, Batch 5851/24958 loss = 1.255435398221016, ppl = 3.528326786567792\n","Train Epoch #17, Batch 5852/24958 loss = 1.2553025192022325, ppl = 3.5279199793019593\n","Train Epoch #17, Batch 5853/24958 loss = 1.2540177589654922, ppl = 3.522966281133356\n","Train Epoch #17, Batch 5854/24958 loss = 1.255283095240593, ppl = 3.527280414033685\n","Train Epoch #17, Batch 5855/24958 loss = 1.2574924629926683, ppl = 3.537040464959945\n","Train Epoch #17, Batch 5856/24958 loss = 1.2522112268209458, ppl = 3.517776689796394\n","Train Epoch #17, Batch 5857/24958 loss = 1.2507490330934525, ppl = 3.5128090494355853\n","Train Epoch #17, Batch 5858/24958 loss = 1.2504961556196212, ppl = 3.5119716749066456\n","Train Epoch #17, Batch 5859/24958 loss = 1.2508261638879776, ppl = 3.5130588759042056\n","Train Epoch #17, Batch 5860/24958 loss = 1.2523172265291214, ppl = 3.518463394664035\n","Train Epoch #17, Batch 5861/24958 loss = 1.253474914431572, ppl = 3.5232225304667417\n","Train Epoch #17, Batch 5862/24958 loss = 1.2527867978811265, ppl = 3.520800094252349\n","Train Epoch #17, Batch 5863/24958 loss = 1.2539898878335953, ppl = 3.5248194675519033\n","Train Epoch #17, Batch 5864/24958 loss = 1.2532357174158095, ppl = 3.5220410426327295\n","Train Epoch #17, Batch 5865/24958 loss = 1.2521837967634202, ppl = 3.5184275373135763\n","Train Epoch #17, Batch 5866/24958 loss = 1.2518932682275772, ppl = 3.5175284797239432\n","Train Epoch #17, Batch 5867/24958 loss = 1.2515834945440292, ppl = 3.5164670046144755\n","Train Epoch #17, Batch 5868/24958 loss = 1.2510531455278397, ppl = 3.514929012895522\n","Train Epoch #17, Batch 5869/24958 loss = 1.2508156925439835, ppl = 3.514111149293892\n","Train Epoch #17, Batch 5870/24958 loss = 1.2502062565088272, ppl = 3.512043259557114\n","Train Epoch #17, Batch 5871/24958 loss = 1.2530642074346543, ppl = 3.5216795707282937\n","Train Epoch #17, Batch 5872/24958 loss = 1.2530187267065047, ppl = 3.521522503906533\n","Train Epoch #17, Batch 5873/24958 loss = 1.252187929749489, ppl = 3.5185164341833968\n","Train Epoch #17, Batch 5874/24958 loss = 1.252984955906868, ppl = 3.521455622987432\n","Train Epoch #17, Batch 5875/24958 loss = 1.2524112075567246, ppl = 3.5193401302838994\n","Train Epoch #17, Batch 5876/24958 loss = 1.2516781920194626, ppl = 3.5166901467138327\n","Train Epoch #17, Batch 5877/24958 loss = 1.2490911227464676, ppl = 3.507252583231155\n","Train Epoch #17, Batch 5878/24958 loss = 1.2496654742956161, ppl = 3.509196994898309\n","Train Epoch #17, Batch 5879/24958 loss = 1.252663281559944, ppl = 3.5203151704555005\n","Train Epoch #17, Batch 5880/24958 loss = 1.2538783794641495, ppl = 3.5248287214561684\n","Train Epoch #17, Batch 5881/24958 loss = 1.254795759320259, ppl = 3.5277084773297904\n","Train Epoch #17, Batch 5882/24958 loss = 1.2529072469472886, ppl = 3.5216976981252293\n","Train Epoch #17, Batch 5883/24958 loss = 1.2495744341611863, ppl = 3.509455575412018\n","Train Epoch #17, Batch 5884/24958 loss = 1.2487433129549026, ppl = 3.506343103147178\n","Train Epoch #17, Batch 5885/24958 loss = 1.2468518286943435, ppl = 3.5006512583774736\n","Train Epoch #17, Batch 5886/24958 loss = 1.2454473930597305, ppl = 3.4950464766720306\n","Train Epoch #17, Batch 5887/24958 loss = 1.247124076485634, ppl = 3.501975048202309\n","Train Epoch #17, Batch 5888/24958 loss = 1.2450503879785537, ppl = 3.494515067280162\n","Train Epoch #17, Batch 5889/24958 loss = 1.2448438602685927, ppl = 3.493800354341247\n","Train Epoch #17, Batch 5890/24958 loss = 1.243213033080101, ppl = 3.487815853362978\n","Train Epoch #17, Batch 5891/24958 loss = 1.2447328358888625, ppl = 3.4932625345560133\n","Train Epoch #17, Batch 5892/24958 loss = 1.2462271624803543, ppl = 3.4984152833739226\n","Train Epoch #17, Batch 5893/24958 loss = 1.2451894038915634, ppl = 3.494987511494724\n","Train Epoch #17, Batch 5894/24958 loss = 1.2457616478204727, ppl = 3.497022330194722\n","Train Epoch #17, Batch 5895/24958 loss = 1.2461014240980148, ppl = 3.4982539512547532\n","Train Epoch #17, Batch 5896/24958 loss = 1.2480407804250717, ppl = 3.505209154559235\n","Train Epoch #17, Batch 5897/24958 loss = 1.2470740514993668, ppl = 3.5016443044614936\n","Train Epoch #17, Batch 5898/24958 loss = 1.2479804116487503, ppl = 3.504444769389453\n","Train Epoch #17, Batch 5899/24958 loss = 1.249930929541588, ppl = 3.5109630435738173\n","Train Epoch #17, Batch 5900/24958 loss = 1.2509238463640213, ppl = 3.515332067391644\n","Train Epoch #17, Batch 5901/24958 loss = 1.2500011545419694, ppl = 3.511984208113978\n","Train Epoch #17, Batch 5902/24958 loss = 1.2490438228845597, ppl = 3.5089903534547817\n","Train Epoch #17, Batch 5903/24958 loss = 1.2488089889287948, ppl = 3.5081376756965024\n","Train Epoch #17, Batch 5904/24958 loss = 1.2504630810022355, ppl = 3.5137740301326637\n","Train Epoch #17, Batch 5905/24958 loss = 1.2516377931833267, ppl = 3.518060960937998\n","Train Epoch #17, Batch 5906/24958 loss = 1.2506976407766341, ppl = 3.5144296959174954\n","Train Epoch #17, Batch 5907/24958 loss = 1.2506103163957596, ppl = 3.514097330337951\n","Train Epoch #17, Batch 5908/24958 loss = 1.2503963488340377, ppl = 3.513331607488789\n","Train Epoch #17, Batch 5909/24958 loss = 1.2496689528226852, ppl = 3.510974377869758\n","Train Epoch #17, Batch 5910/24958 loss = 1.2491673523187636, ppl = 3.509343910521821\n","Train Epoch #17, Batch 5911/24958 loss = 1.2479032653570175, ppl = 3.5053440678905248\n","Train Epoch #17, Batch 5912/24958 loss = 1.246336904168129, ppl = 3.4995515683994314\n","Train Epoch #17, Batch 5913/24958 loss = 1.2468085235357285, ppl = 3.5012931337648068\n","Train Epoch #17, Batch 5914/24958 loss = 1.2479425650835037, ppl = 3.5052910667459205\n","Train Epoch #17, Batch 5915/24958 loss = 1.2493190425634384, ppl = 3.5100942316994743\n","Train Epoch #17, Batch 5916/24958 loss = 1.249918504357338, ppl = 3.5123072796213877\n","Train Epoch #17, Batch 5917/24958 loss = 1.2499773734807968, ppl = 3.5125006796772125\n","Train Epoch #17, Batch 5918/24958 loss = 1.253668200969696, ppl = 3.5243241647312584\n","Train Epoch #17, Batch 5919/24958 loss = 1.2524029695987702, ppl = 3.520038645651307\n","Train Epoch #17, Batch 5920/24958 loss = 1.2509123361110688, ppl = 3.5151012928050522\n","Train Epoch #17, Batch 5921/24958 loss = 1.247131826877594, ppl = 3.5015656699166153\n","Train Epoch #17, Batch 5922/24958 loss = 1.2455636262893677, ppl = 3.4965329795203854\n","Train Epoch #17, Batch 5923/24958 loss = 1.2465311515331268, ppl = 3.4998962719577293\n","Train Epoch #17, Batch 5924/24958 loss = 1.2446365916728974, ppl = 3.492983079191914\n","Train Epoch #17, Batch 5925/24958 loss = 1.2469200611114502, ppl = 3.5018916795212136\n","Train Epoch #17, Batch 5926/24958 loss = 1.248015785217285, ppl = 3.5059595289497305\n","Train Epoch #17, Batch 5927/24958 loss = 1.2507632553577424, ppl = 3.516973163860742\n","Train Epoch #17, Batch 5928/24958 loss = 1.2509398865699768, ppl = 3.5175764257522126\n","Train Epoch #17, Batch 5929/24958 loss = 1.2483903098106384, ppl = 3.5097007744989175\n","Train Epoch #17, Batch 5930/24958 loss = 1.2467695152759553, ppl = 3.5038797170295157\n","Train Epoch #17, Batch 5931/24958 loss = 1.2492673575878144, ppl = 3.5124907740630844\n","Train Epoch #17, Batch 5932/24958 loss = 1.251112575531006, ppl = 3.519364452255131\n","Train Epoch #17, Batch 5933/24958 loss = 1.2507387244701385, ppl = 3.5180620974730776\n","Train Epoch #17, Batch 5934/24958 loss = 1.2496707713603974, ppl = 3.514438976977122\n","Train Epoch #17, Batch 5935/24958 loss = 1.2468799686431884, ppl = 3.503379858151376\n","Train Epoch #17, Batch 5936/24958 loss = 1.2504317927360535, ppl = 3.5153873694695057\n","Train Epoch #17, Batch 5937/24958 loss = 1.2514332473278045, ppl = 3.518791289223556\n","Train Epoch #17, Batch 5938/24958 loss = 1.2531514823436738, ppl = 3.52457682430265\n","Train Epoch #17, Batch 5939/24958 loss = 1.2518035566806793, ppl = 3.519711537530226\n","Train Epoch #17, Batch 5940/24958 loss = 1.2520425486564637, ppl = 3.520482361963245\n","Train Epoch #17, Batch 5941/24958 loss = 1.252245329618454, ppl = 3.521194175280138\n","Train Epoch #17, Batch 5942/24958 loss = 1.2530317866802216, ppl = 3.5237550622203098\n","Train Epoch #17, Batch 5943/24958 loss = 1.2512823688983916, ppl = 3.5179139547406364\n","Train Epoch #17, Batch 5944/24958 loss = 1.250860217809677, ppl = 3.516350298932313\n","Train Epoch #17, Batch 5945/24958 loss = 1.252385401725769, ppl = 3.521537317279303\n","Train Epoch #17, Batch 5946/24958 loss = 1.2552514636516572, ppl = 3.5320461099542557\n","Train Epoch #17, Batch 5947/24958 loss = 1.2554094457626344, ppl = 3.5326089052207608\n","Train Epoch #17, Batch 5948/24958 loss = 1.2564409947395325, ppl = 3.5365375095195226\n","Train Epoch #17, Batch 5949/24958 loss = 1.2563144075870514, ppl = 3.536091288083434\n","Train Epoch #17, Batch 5950/24958 loss = 1.256039603948593, ppl = 3.535099803130229\n","Train Epoch #17, Batch 5951/24958 loss = 1.2577985119819641, ppl = 3.5414500022819793\n","Train Epoch #17, Batch 5952/24958 loss = 1.2600680243968965, ppl = 3.5491980040129945\n","Train Epoch #17, Batch 5953/24958 loss = 1.259538652896881, ppl = 3.547334944607564\n","Train Epoch #17, Batch 5954/24958 loss = 1.2599315655231476, ppl = 3.5487894998285276\n","Train Epoch #17, Batch 5955/24958 loss = 1.2553397059440612, ppl = 3.5306609366694284\n","Train Epoch #17, Batch 5956/24958 loss = 1.2576905477046967, ppl = 3.537998648300564\n","Train Epoch #17, Batch 5957/24958 loss = 1.2599371218681334, ppl = 3.5459460414333166\n","Train Epoch #17, Batch 5958/24958 loss = 1.2592914593219757, ppl = 3.543901633720544\n","Train Epoch #17, Batch 5959/24958 loss = 1.2603204500675202, ppl = 3.5475313999424083\n","Train Epoch #17, Batch 5960/24958 loss = 1.257600884437561, ppl = 3.5382413216391644\n","Train Epoch #17, Batch 5961/24958 loss = 1.2542538344860077, ppl = 3.525857912533337\n","Train Epoch #17, Batch 5962/24958 loss = 1.254604412317276, ppl = 3.527071250526439\n","Train Epoch #17, Batch 5963/24958 loss = 1.25364581823349, ppl = 3.523830030396598\n","Train Epoch #17, Batch 5964/24958 loss = 1.252862455844879, ppl = 3.5211575599660447\n","Train Epoch #17, Batch 5965/24958 loss = 1.2539744806289672, ppl = 3.524989236672422\n","Train Epoch #17, Batch 5966/24958 loss = 1.2550383484363556, ppl = 3.5284127241844225\n","Train Epoch #17, Batch 5967/24958 loss = 1.254067988395691, ppl = 3.52529273234242\n","Train Epoch #17, Batch 5968/24958 loss = 1.2559582006931305, ppl = 3.5311679954400805\n","Train Epoch #17, Batch 5969/24958 loss = 1.2545107626914977, ppl = 3.5265814560811863\n","Train Epoch #17, Batch 5970/24958 loss = 1.2571618783473968, ppl = 3.5365714750894277\n","Train Epoch #17, Batch 5971/24958 loss = 1.2557534885406494, ppl = 3.531478898181413\n","Train Epoch #17, Batch 5972/24958 loss = 1.2558984184265136, ppl = 3.531981909705068\n","Train Epoch #17, Batch 5973/24958 loss = 1.2552726531028748, ppl = 3.529877003436436\n","Train Epoch #17, Batch 5974/24958 loss = 1.2579306769371033, ppl = 3.5415585948210646\n","Train Epoch #17, Batch 5975/24958 loss = 1.2575963020324707, ppl = 3.5403805419643497\n","Train Epoch #17, Batch 5976/24958 loss = 1.2582992279529572, ppl = 3.542917880140396\n","Train Epoch #17, Batch 5977/24958 loss = 1.25755384683609, ppl = 3.5406219585284937\n","Train Epoch #17, Batch 5978/24958 loss = 1.2605798840522766, ppl = 3.5529320754263125\n","Train Epoch #17, Batch 5979/24958 loss = 1.2577855336666106, ppl = 3.542467641484434\n","Train Epoch #17, Batch 5980/24958 loss = 1.2557870495319365, ppl = 3.5353218207611428\n","Train Epoch #17, Batch 5981/24958 loss = 1.2539326393604278, ppl = 3.5297610532282366\n","Train Epoch #17, Batch 5982/24958 loss = 1.2547894465923308, ppl = 3.5323479465673855\n","Train Epoch #17, Batch 5983/24958 loss = 1.254215716123581, ppl = 3.5306222054736933\n","Train Epoch #17, Batch 5984/24958 loss = 1.2525130796432495, ppl = 3.5249995343628626\n","Train Epoch #17, Batch 5985/24958 loss = 1.2555114316940308, ppl = 3.53455708595469\n","Train Epoch #17, Batch 5986/24958 loss = 1.2554261839389802, ppl = 3.5342415591945087\n","Train Epoch #17, Batch 5987/24958 loss = 1.2542565739154816, ppl = 3.5292872444348693\n","Train Epoch #17, Batch 5988/24958 loss = 1.25587996840477, ppl = 3.5349933417771\n","Train Epoch #17, Batch 5989/24958 loss = 1.2568350183963775, ppl = 3.5384256849077667\n","Train Epoch #17, Batch 5990/24958 loss = 1.257867817878723, ppl = 3.5421015693027282\n","Train Epoch #17, Batch 5991/24958 loss = 1.256208848953247, ppl = 3.5361962820572734\n","Train Epoch #17, Batch 5992/24958 loss = 1.2560664880275727, ppl = 3.5356715453113243\n","Train Epoch #17, Batch 5993/24958 loss = 1.2568812203407287, ppl = 3.538332348856258\n","Train Epoch #17, Batch 5994/24958 loss = 1.2570272755622864, ppl = 3.5388706234569076\n","Train Epoch #17, Batch 5995/24958 loss = 1.2576228737831117, ppl = 3.54113314197502\n","Train Epoch #17, Batch 5996/24958 loss = 1.2576394951343537, ppl = 3.5411987733842425\n","Train Epoch #17, Batch 5997/24958 loss = 1.2586036026477814, ppl = 3.5447534834782237\n","Train Epoch #17, Batch 5998/24958 loss = 1.2613683176040649, ppl = 3.555046193132434\n","Train Epoch #17, Batch 5999/24958 loss = 1.260709855556488, ppl = 3.5527021786406743\n","Train Epoch #17, Batch 6000/24958 loss = 1.2569762146472931, ppl = 3.5382998985626517\n","Train Epoch #17, Batch 6001/24958 loss = 1.2566280817985536, ppl = 3.537114872769277\n","Train Epoch #17, Batch 6002/24958 loss = 1.2588854038715362, ppl = 3.544661390455238\n","Train Epoch #17, Batch 6003/24958 loss = 1.258480520248413, ppl = 3.543237480109355\n","Train Epoch #17, Batch 6004/24958 loss = 1.2573009300231934, ppl = 3.5391238027241423\n","Train Epoch #17, Batch 6005/24958 loss = 1.2565067136287689, ppl = 3.5361706856387025\n","Train Epoch #17, Batch 6006/24958 loss = 1.2571318125724793, ppl = 3.5385468579082078\n","Train Epoch #17, Batch 6007/24958 loss = 1.2562333536148071, ppl = 3.5352906101717902\n","Train Epoch #17, Batch 6008/24958 loss = 1.2567627382278443, ppl = 3.537215414577777\n","Train Epoch #17, Batch 6009/24958 loss = 1.2587883055210114, ppl = 3.5442301861880896\n","Train Epoch #17, Batch 6010/24958 loss = 1.2579854094982148, ppl = 3.541784741840671\n","Train Epoch #17, Batch 6011/24958 loss = 1.2617293214797973, ppl = 3.5552645796709426\n","Train Epoch #17, Batch 6012/24958 loss = 1.2599695611000061, ppl = 3.5497524660178783\n","Train Epoch #17, Batch 6013/24958 loss = 1.2601934051513672, ppl = 3.5506082503283376\n","Train Epoch #17, Batch 6014/24958 loss = 1.2602963721752167, ppl = 3.5509942040458413\n","Train Epoch #17, Batch 6015/24958 loss = 1.2594871413707733, ppl = 3.548090688907934\n","Train Epoch #17, Batch 6016/24958 loss = 1.2577868604660034, ppl = 3.5421436060695357\n","Train Epoch #17, Batch 6017/24958 loss = 1.2565523874759674, ppl = 3.5383171405407343\n","Train Epoch #17, Batch 6018/24958 loss = 1.2556947541236878, ppl = 3.5351685490753573\n","Train Epoch #17, Batch 6019/24958 loss = 1.2565260136127472, ppl = 3.537922663070264\n","Train Epoch #17, Batch 6020/24958 loss = 1.257495014667511, ppl = 3.5410479387102005\n","Train Epoch #17, Batch 6021/24958 loss = 1.2587166357040405, ppl = 3.544876060239241\n","Train Epoch #17, Batch 6022/24958 loss = 1.2590584444999695, ppl = 3.5459067484122797\n","Train Epoch #17, Batch 6023/24958 loss = 1.257299292087555, ppl = 3.5400236475654445\n","Train Epoch #17, Batch 6024/24958 loss = 1.2586347329616547, ppl = 3.544758726607425\n","Train Epoch #17, Batch 6025/24958 loss = 1.2572504270076752, ppl = 3.53911748085201\n","Train Epoch #17, Batch 6026/24958 loss = 1.2544473278522492, ppl = 3.529536044764999\n","Train Epoch #17, Batch 6027/24958 loss = 1.2522872376441956, ppl = 3.520629622493425\n","Train Epoch #17, Batch 6028/24958 loss = 1.250753322839737, ppl = 3.51572972850808\n","Train Epoch #17, Batch 6029/24958 loss = 1.2542130196094512, ppl = 3.526939779384599\n","Train Epoch #17, Batch 6030/24958 loss = 1.253638288974762, ppl = 3.5250920109029322\n","Train Epoch #17, Batch 6031/24958 loss = 1.2523987364768983, ppl = 3.5205501968166595\n","Train Epoch #17, Batch 6032/24958 loss = 1.2509854972362517, ppl = 3.515173903973076\n","Train Epoch #17, Batch 6033/24958 loss = 1.2512139785289764, ppl = 3.5159640526734837\n","Train Epoch #17, Batch 6034/24958 loss = 1.252273577451706, ppl = 3.519557303024369\n","Train Epoch #17, Batch 6035/24958 loss = 1.2528643000125885, ppl = 3.5216478285652513\n","Train Epoch #17, Batch 6036/24958 loss = 1.2517465186119079, ppl = 3.5174000817584443\n","Train Epoch #17, Batch 6037/24958 loss = 1.251635571718216, ppl = 3.5170059684621036\n","Train Epoch #17, Batch 6038/24958 loss = 1.254487497806549, ppl = 3.5291001286040915\n","Train Epoch #17, Batch 6039/24958 loss = 1.255997393131256, ppl = 3.534595413353322\n","Train Epoch #17, Batch 6040/24958 loss = 1.2592250907421112, ppl = 3.5470295729467263\n","Train Epoch #17, Batch 6041/24958 loss = 1.2592092370986938, ppl = 3.546973400971562\n","Train Epoch #17, Batch 6042/24958 loss = 1.258648580312729, ppl = 3.545127278009885\n","Train Epoch #17, Batch 6043/24958 loss = 1.2608117830753327, ppl = 3.5525059277078874\n","Train Epoch #17, Batch 6044/24958 loss = 1.2592653441429138, ppl = 3.547310048433922\n","Train Epoch #17, Batch 6045/24958 loss = 1.2592658007144928, ppl = 3.5473117226536215\n","Train Epoch #17, Batch 6046/24958 loss = 1.2605590546131134, ppl = 3.5531339162325564\n","Train Epoch #17, Batch 6047/24958 loss = 1.260144945383072, ppl = 3.5516773768928815\n","Train Epoch #17, Batch 6048/24958 loss = 1.2598599565029145, ppl = 3.550551191588101\n","Train Epoch #17, Batch 6049/24958 loss = 1.2592197132110596, ppl = 3.5483788625983435\n","Train Epoch #17, Batch 6050/24958 loss = 1.259146056175232, ppl = 3.5481177075196917\n","Train Epoch #17, Batch 6051/24958 loss = 1.2587256455421447, ppl = 3.546496810963757\n","Train Epoch #17, Batch 6052/24958 loss = 1.2575683724880218, ppl = 3.5423266229650765\n","Train Epoch #17, Batch 6053/24958 loss = 1.2581210660934448, ppl = 3.5442740517547087\n","Train Epoch #17, Batch 6054/24958 loss = 1.2585572302341461, ppl = 3.5459570894671053\n","Train Epoch #17, Batch 6055/24958 loss = 1.2582568752765655, ppl = 3.545036673767448\n","Train Epoch #17, Batch 6056/24958 loss = 1.258831307888031, ppl = 3.5471075682926734\n","Train Epoch #17, Batch 6057/24958 loss = 1.2572117006778718, ppl = 3.541201619173629\n","Train Epoch #17, Batch 6058/24958 loss = 1.2605578124523162, ppl = 3.5533828344006486\n","Train Epoch #17, Batch 6059/24958 loss = 1.2603661549091338, ppl = 3.5526781565422216\n","Train Epoch #17, Batch 6060/24958 loss = 1.2631041526794433, ppl = 3.562040215036228\n","Train Epoch #17, Batch 6061/24958 loss = 1.2639421224594116, ppl = 3.5647630677126823\n","Train Epoch #17, Batch 6062/24958 loss = 1.2622096359729766, ppl = 3.559160589160231\n","Train Epoch #17, Batch 6063/24958 loss = 1.2640685999393464, ppl = 3.565742544458095\n","Train Epoch #17, Batch 6064/24958 loss = 1.2679311740398407, ppl = 3.5812049347527823\n","Train Epoch #17, Batch 6065/24958 loss = 1.2674627721309661, ppl = 3.579538896012902\n","Train Epoch #17, Batch 6066/24958 loss = 1.2675635719299316, ppl = 3.5798825554161198\n","Train Epoch #17, Batch 6067/24958 loss = 1.2675783050060272, ppl = 3.579927698630068\n","Train Epoch #17, Batch 6068/24958 loss = 1.2686377656459809, ppl = 3.5837401968218514\n","Train Epoch #17, Batch 6069/24958 loss = 1.2715486180782318, ppl = 3.5936904951928046\n","Train Epoch #17, Batch 6070/24958 loss = 1.2700172400474548, ppl = 3.587599503085529\n","Train Epoch #17, Batch 6071/24958 loss = 1.2707126760482788, ppl = 3.59002454322517\n","Train Epoch #17, Batch 6072/24958 loss = 1.2690093553066253, ppl = 3.584549374941871\n","Train Epoch #17, Batch 6073/24958 loss = 1.2691739463806153, ppl = 3.585090312730061\n","Train Epoch #17, Batch 6074/24958 loss = 1.265690757036209, ppl = 3.570369983754963\n","Train Epoch #17, Batch 6075/24958 loss = 1.2658497846126557, ppl = 3.5709253510067986\n","Train Epoch #17, Batch 6076/24958 loss = 1.2649172604084016, ppl = 3.567597137446155\n","Train Epoch #17, Batch 6077/24958 loss = 1.2663519299030304, ppl = 3.5721740235088335\n","Train Epoch #17, Batch 6078/24958 loss = 1.2627065527439116, ppl = 3.557771855368441\n","Train Epoch #17, Batch 6079/24958 loss = 1.2636158132553101, ppl = 3.560861628136311\n","Train Epoch #17, Batch 6080/24958 loss = 1.2628519690036775, ppl = 3.558486122225048\n","Train Epoch #17, Batch 6081/24958 loss = 1.2677111530303955, ppl = 3.5755619717675633\n","Train Epoch #17, Batch 6082/24958 loss = 1.2693249237537385, ppl = 3.5810792319972733\n","Train Epoch #17, Batch 6083/24958 loss = 1.271558074951172, ppl = 3.5883916700763496\n","Train Epoch #17, Batch 6084/24958 loss = 1.2751359164714813, ppl = 3.60142186432021\n","Train Epoch #17, Batch 6085/24958 loss = 1.2757632398605347, ppl = 3.6038103996000217\n","Train Epoch #17, Batch 6086/24958 loss = 1.275879898071289, ppl = 3.604242865406817\n","Train Epoch #17, Batch 6087/24958 loss = 1.2747717094421387, ppl = 3.6000542631490378\n","Train Epoch #17, Batch 6088/24958 loss = 1.2737994527816772, ppl = 3.5965262551052875\n","Train Epoch #17, Batch 6089/24958 loss = 1.272494684457779, ppl = 3.5919168281351976\n","Train Epoch #17, Batch 6090/24958 loss = 1.2714516973495484, ppl = 3.588206542218123\n","Train Epoch #17, Batch 6091/24958 loss = 1.2728400707244873, ppl = 3.5930805249630895\n","Train Epoch #17, Batch 6092/24958 loss = 1.2707616257667542, ppl = 3.586212327310762\n","Train Epoch #17, Batch 6093/24958 loss = 1.2705200612545013, ppl = 3.585400679479331\n","Train Epoch #17, Batch 6094/24958 loss = 1.2705689072608948, ppl = 3.5855824588767713\n","Train Epoch #17, Batch 6095/24958 loss = 1.2704717814922333, ppl = 3.585204247203942\n","Train Epoch #17, Batch 6096/24958 loss = 1.2692340922355652, ppl = 3.5806035994027683\n","Train Epoch #17, Batch 6097/24958 loss = 1.267653740644455, ppl = 3.5749498763938665\n","Train Epoch #17, Batch 6098/24958 loss = 1.2641354620456695, ppl = 3.5623112028885995\n","Train Epoch #17, Batch 6099/24958 loss = 1.2640265679359437, ppl = 3.561938215028563\n","Train Epoch #17, Batch 6100/24958 loss = 1.2654814660549163, ppl = 3.5669214614992466\n","Train Epoch #17, Batch 6101/24958 loss = 1.2647837889194489, ppl = 3.564667253633268\n","Train Epoch #17, Batch 6102/24958 loss = 1.2648676562309265, ppl = 3.5649817847888654\n","Train Epoch #17, Batch 6103/24958 loss = 1.265005234479904, ppl = 3.565459172803533\n","Train Epoch #17, Batch 6104/24958 loss = 1.2656634628772736, ppl = 3.5676947058317525\n","Train Epoch #17, Batch 6105/24958 loss = 1.2663164281845092, ppl = 3.5701053200318937\n","Train Epoch #17, Batch 6106/24958 loss = 1.2647787034511566, ppl = 3.5645161484963226\n","Train Epoch #17, Batch 6107/24958 loss = 1.2643493139743804, ppl = 3.5630602736908794\n","Train Epoch #17, Batch 6108/24958 loss = 1.2625471425056458, ppl = 3.5569041118709674\n","Train Epoch #17, Batch 6109/24958 loss = 1.2611093497276307, ppl = 3.551780710965292\n","Train Epoch #17, Batch 6110/24958 loss = 1.263800482749939, ppl = 3.5608136540047566\n","Train Epoch #17, Batch 6111/24958 loss = 1.2619341897964478, ppl = 3.553465005981871\n","Train Epoch #17, Batch 6112/24958 loss = 1.263090102672577, ppl = 3.5569754242836154\n","Train Epoch #17, Batch 6113/24958 loss = 1.2615012264251708, ppl = 3.5512958575967413\n","Train Epoch #17, Batch 6114/24958 loss = 1.2614170324802398, ppl = 3.5509799755497307\n","Train Epoch #17, Batch 6115/24958 loss = 1.2608743214607239, ppl = 3.5491602827041944\n","Train Epoch #17, Batch 6116/24958 loss = 1.2612704455852508, ppl = 3.5504568664789646\n","Train Epoch #17, Batch 6117/24958 loss = 1.2634305739402771, ppl = 3.5574789248356353\n","Train Epoch #17, Batch 6118/24958 loss = 1.2655593490600585, ppl = 3.565820221457218\n","Train Epoch #17, Batch 6119/24958 loss = 1.2663850009441375, ppl = 3.5687920241001736\n","Train Epoch #17, Batch 6120/24958 loss = 1.26538143992424, ppl = 3.5655607802399647\n","Train Epoch #17, Batch 6121/24958 loss = 1.2655321621894837, ppl = 3.566066326353294\n","Train Epoch #17, Batch 6122/24958 loss = 1.266441558599472, ppl = 3.568986410514301\n","Train Epoch #17, Batch 6123/24958 loss = 1.2674274122714997, ppl = 3.572155535207442\n","Train Epoch #17, Batch 6124/24958 loss = 1.2648874139785766, ppl = 3.5636593588420316\n","Train Epoch #17, Batch 6125/24958 loss = 1.2658185374736786, ppl = 3.5673671874497987\n","Train Epoch #17, Batch 6126/24958 loss = 1.2700518667697906, ppl = 3.5829752300347333\n","Train Epoch #17, Batch 6127/24958 loss = 1.2690516090393067, ppl = 3.579459186448355\n","Train Epoch #17, Batch 6128/24958 loss = 1.272261769771576, ppl = 3.5906470955834333\n","Train Epoch #17, Batch 6129/24958 loss = 1.2706850385665893, ppl = 3.58505594396902\n","Train Epoch #17, Batch 6130/24958 loss = 1.2705761444568635, ppl = 3.5847176570156165\n","Train Epoch #17, Batch 6131/24958 loss = 1.2699979150295257, ppl = 3.582784022078306\n","Train Epoch #17, Batch 6132/24958 loss = 1.2706919145584106, ppl = 3.5853292935531766\n","Train Epoch #17, Batch 6133/24958 loss = 1.2697254931926727, ppl = 3.5821070372015584\n","Train Epoch #17, Batch 6134/24958 loss = 1.2691564440727234, ppl = 3.5801300524305044\n","Train Epoch #17, Batch 6135/24958 loss = 1.2690958666801453, ppl = 3.579909946384067\n","Train Epoch #17, Batch 6136/24958 loss = 1.2663117218017579, ppl = 3.5711814382460387\n","Train Epoch #17, Batch 6137/24958 loss = 1.2669144248962403, ppl = 3.573376017221891\n","Train Epoch #17, Batch 6138/24958 loss = 1.2628757166862488, ppl = 3.557180826183299\n","Train Epoch #17, Batch 6139/24958 loss = 1.262241872549057, ppl = 3.554772533400594\n","Train Epoch #17, Batch 6140/24958 loss = 1.2601094436645508, ppl = 3.546116466969138\n","Train Epoch #17, Batch 6141/24958 loss = 1.2619440174102783, ppl = 3.5532454504630424\n","Train Epoch #17, Batch 6142/24958 loss = 1.2647067165374757, ppl = 3.5634322383801766\n","Train Epoch #17, Batch 6143/24958 loss = 1.2632643139362336, ppl = 3.558337192353457\n","Train Epoch #17, Batch 6144/24958 loss = 1.264111531972885, ppl = 3.561084044568763\n","Train Epoch #17, Batch 6145/24958 loss = 1.2633067560195923, ppl = 3.558248541092894\n","Train Epoch #17, Batch 6146/24958 loss = 1.2618492722511292, ppl = 3.5517394239598614\n","Train Epoch #17, Batch 6147/24958 loss = 1.2633538699150086, ppl = 3.557332952902247\n","Train Epoch #17, Batch 6148/24958 loss = 1.26246129155159, ppl = 3.554006455343516\n","Train Epoch #17, Batch 6149/24958 loss = 1.2630707228183746, ppl = 3.5560710236258415\n","Train Epoch #17, Batch 6150/24958 loss = 1.2616489446163177, ppl = 3.551389277313084\n","Train Epoch #17, Batch 6151/24958 loss = 1.261280974149704, ppl = 3.550025424159802\n","Train Epoch #17, Batch 6152/24958 loss = 1.262507905960083, ppl = 3.554462357318932\n","Train Epoch #17, Batch 6153/24958 loss = 1.262050668001175, ppl = 3.5528436259885026\n","Train Epoch #17, Batch 6154/24958 loss = 1.2615174531936646, ppl = 3.550795976172286\n","Train Epoch #17, Batch 6155/24958 loss = 1.2629583489894867, ppl = 3.555474486849655\n","Train Epoch #17, Batch 6156/24958 loss = 1.2624877381324768, ppl = 3.5537691284570996\n","Train Epoch #17, Batch 6157/24958 loss = 1.262571976184845, ppl = 3.5540532962905638\n","Train Epoch #17, Batch 6158/24958 loss = 1.2616189563274383, ppl = 3.55015963999244\n","Train Epoch #17, Batch 6159/24958 loss = 1.2602154779434205, ppl = 3.5453911350878853\n","Train Epoch #17, Batch 6160/24958 loss = 1.2606190311908723, ppl = 3.547000782572097\n","Train Epoch #17, Batch 6161/24958 loss = 1.2585015451908113, ppl = 3.540536564597639\n","Train Epoch #17, Batch 6162/24958 loss = 1.261225004196167, ppl = 3.549808027019897\n","Train Epoch #17, Batch 6163/24958 loss = 1.2583371269702912, ppl = 3.5400760056744414\n","Train Epoch #17, Batch 6164/24958 loss = 1.2546854364871978, ppl = 3.5253125858446803\n","Train Epoch #17, Batch 6165/24958 loss = 1.2553895115852356, ppl = 3.527846856536231\n","Train Epoch #17, Batch 6166/24958 loss = 1.2533497440814971, ppl = 3.5215242540031118\n","Train Epoch #17, Batch 6167/24958 loss = 1.255025725364685, ppl = 3.527119120589815\n","Train Epoch #17, Batch 6168/24958 loss = 1.253023363351822, ppl = 3.5202371189751576\n","Train Epoch #17, Batch 6169/24958 loss = 1.2517578852176667, ppl = 3.5155537649406563\n","Train Epoch #17, Batch 6170/24958 loss = 1.2507022869586946, ppl = 3.511866484657469\n","Train Epoch #17, Batch 6171/24958 loss = 1.2495086514949798, ppl = 3.5078049937170834\n","Train Epoch #17, Batch 6172/24958 loss = 1.251536681652069, ppl = 3.5144339558837374\n","Train Epoch #17, Batch 6173/24958 loss = 1.2542366230487823, ppl = 3.524704922591841\n","Train Epoch #17, Batch 6174/24958 loss = 1.2533680772781373, ppl = 3.521766057423493\n","Train Epoch #17, Batch 6175/24958 loss = 1.2540889728069304, ppl = 3.5243973970554827\n","Train Epoch #17, Batch 6176/24958 loss = 1.2528432488441468, ppl = 3.5204090195185387\n","Train Epoch #17, Batch 6177/24958 loss = 1.2539429616928102, ppl = 3.524389883845529\n","Train Epoch #17, Batch 6178/24958 loss = 1.2547521424293517, ppl = 3.5271495730422027\n","Train Epoch #17, Batch 6179/24958 loss = 1.2544216203689575, ppl = 3.5259937908990326\n","Train Epoch #17, Batch 6180/24958 loss = 1.2571279108524323, ppl = 3.535294677204583\n","Train Epoch #17, Batch 6181/24958 loss = 1.2527389967441558, ppl = 3.5195329561586353\n","Train Epoch #17, Batch 6182/24958 loss = 1.2518004298210144, ppl = 3.516216326457886\n","Train Epoch #17, Batch 6183/24958 loss = 1.251241956949234, ppl = 3.5142317596497707\n","Train Epoch #17, Batch 6184/24958 loss = 1.249288557767868, ppl = 3.5065445020849415\n","Train Epoch #17, Batch 6185/24958 loss = 1.2481380486488343, ppl = 3.5022753885812237\n","Train Epoch #17, Batch 6186/24958 loss = 1.2494847679138184, ppl = 3.5076508537772537\n","Train Epoch #17, Batch 6187/24958 loss = 1.249517183303833, ppl = 3.5077668982739003\n","Train Epoch #17, Batch 6188/24958 loss = 1.2498087441921235, ppl = 3.508789110626766\n","Train Epoch #17, Batch 6189/24958 loss = 1.2508053982257843, ppl = 3.5122551944269755\n","Train Epoch #17, Batch 6190/24958 loss = 1.2512575018405914, ppl = 3.5138160966573873\n","Train Epoch #17, Batch 6191/24958 loss = 1.2521003520488738, ppl = 3.5171225188356137\n","Train Epoch #17, Batch 6192/24958 loss = 1.2541521203517914, ppl = 3.5238932157504377\n","Train Epoch #17, Batch 6193/24958 loss = 1.2554990208148957, ppl = 3.5286794035736864\n","Train Epoch #17, Batch 6194/24958 loss = 1.253284705877304, ppl = 3.5212693918541733\n","Train Epoch #17, Batch 6195/24958 loss = 1.2506088602542877, ppl = 3.5121715077930538\n","Train Epoch #17, Batch 6196/24958 loss = 1.250109932422638, ppl = 3.510472079619449\n","Train Epoch #17, Batch 6197/24958 loss = 1.2507689034938811, ppl = 3.512721477934482\n","Train Epoch #17, Batch 6198/24958 loss = 1.2534302365779877, ppl = 3.5218606203941425\n","Train Epoch #17, Batch 6199/24958 loss = 1.252693337202072, ppl = 3.5194405475566772\n","Train Epoch #17, Batch 6200/24958 loss = 1.2521699738502503, ppl = 3.5175639216335894\n","Train Epoch #17, Batch 6201/24958 loss = 1.254807721376419, ppl = 3.5269800207551407\n","Train Epoch #17, Batch 6202/24958 loss = 1.2558334243297578, ppl = 3.531047971219909\n","Train Epoch #17, Batch 6203/24958 loss = 1.2558328306674957, ppl = 3.531045897107291\n","Train Epoch #17, Batch 6204/24958 loss = 1.2555061948299409, ppl = 3.529918155362834\n","Train Epoch #17, Batch 6205/24958 loss = 1.2540083408355713, ppl = 3.524613107322634\n","Train Epoch #17, Batch 6206/24958 loss = 1.2547025084495544, ppl = 3.5270300979507625\n","Train Epoch #17, Batch 6207/24958 loss = 1.2538866090774536, ppl = 3.52443020647724\n","Train Epoch #17, Batch 6208/24958 loss = 1.255165605545044, ppl = 3.5286835560792964\n","Train Epoch #17, Batch 6209/24958 loss = 1.2556620061397552, ppl = 3.530369809474037\n","Train Epoch #17, Batch 6210/24958 loss = 1.2555643153190612, ppl = 3.529997627149592\n","Train Epoch #17, Batch 6211/24958 loss = 1.2535865998268128, ppl = 3.52357078963051\n","Train Epoch #17, Batch 6212/24958 loss = 1.2545485615730285, ppl = 3.526817969287026\n","Train Epoch #17, Batch 6213/24958 loss = 1.2546862363815308, ppl = 3.52727517733894\n","Train Epoch #17, Batch 6214/24958 loss = 1.253942254781723, ppl = 3.5245964929336338\n","Train Epoch #17, Batch 6215/24958 loss = 1.2555262124538422, ppl = 3.5301964412190374\n","Train Epoch #17, Batch 6216/24958 loss = 1.2552686369419097, ppl = 3.529347522679842\n","Train Epoch #17, Batch 6217/24958 loss = 1.2542184174060822, ppl = 3.525744044792213\n","Train Epoch #17, Batch 6218/24958 loss = 1.2518212866783143, ppl = 3.516471737351286\n","Train Epoch #17, Batch 6219/24958 loss = 1.2508843755722046, ppl = 3.5131179085245923\n","Train Epoch #17, Batch 6220/24958 loss = 1.252348004579544, ppl = 3.5179424112195705\n","Train Epoch #17, Batch 6221/24958 loss = 1.2489740002155303, ppl = 3.50826430806756\n","Train Epoch #17, Batch 6222/24958 loss = 1.2502973639965058, ppl = 3.5130173579145816\n","Train Epoch #17, Batch 6223/24958 loss = 1.2530130386352538, ppl = 3.523550067861444\n","Train Epoch #17, Batch 6224/24958 loss = 1.2539198541641234, ppl = 3.52633892902786\n","Train Epoch #17, Batch 6225/24958 loss = 1.2519662380218506, ppl = 3.518938072260123\n","Train Epoch #17, Batch 6226/24958 loss = 1.2494648385047913, ppl = 3.5089299781031436\n","Train Epoch #17, Batch 6227/24958 loss = 1.2526553678512573, ppl = 3.5214910200139373\n","Train Epoch #17, Batch 6228/24958 loss = 1.2534304308891295, ppl = 3.524774563220139\n","Train Epoch #17, Batch 6229/24958 loss = 1.2536735022068024, ppl = 3.525580086652409\n","Train Epoch #17, Batch 6230/24958 loss = 1.2547346901893617, ppl = 3.529039110812109\n","Train Epoch #17, Batch 6231/24958 loss = 1.254882711172104, ppl = 3.5295235052903426\n","Train Epoch #17, Batch 6232/24958 loss = 1.2534532618522645, ppl = 3.524466933871847\n","Train Epoch #17, Batch 6233/24958 loss = 1.2531823348999023, ppl = 3.5236181025670645\n","Train Epoch #17, Batch 6234/24958 loss = 1.2543023991584779, ppl = 3.5276196691458352\n","Train Epoch #17, Batch 6235/24958 loss = 1.2530001378059388, ppl = 3.5231965152023164\n","Train Epoch #17, Batch 6236/24958 loss = 1.2555493521690368, ppl = 3.5310910516155762\n","Train Epoch #17, Batch 6237/24958 loss = 1.2594230949878693, ppl = 3.548842330711435\n","Train Epoch #17, Batch 6238/24958 loss = 1.2606922340393067, ppl = 3.553246420888463\n","Train Epoch #17, Batch 6239/24958 loss = 1.2594771027565002, ppl = 3.5490353313512966\n","Train Epoch #17, Batch 6240/24958 loss = 1.259554411172867, ppl = 3.549317965717408\n","Train Epoch #17, Batch 6241/24958 loss = 1.2577385818958282, ppl = 3.542255406454599\n","Train Epoch #17, Batch 6242/24958 loss = 1.258437501192093, ppl = 3.545310376206611\n","Train Epoch #17, Batch 6243/24958 loss = 1.259253396987915, ppl = 3.5481018652167546\n","Train Epoch #17, Batch 6244/24958 loss = 1.2608694589138032, ppl = 3.5540328957275626\n","Train Epoch #17, Batch 6245/24958 loss = 1.2622821533679962, ppl = 3.5591668039197906\n","Train Epoch #17, Batch 6246/24958 loss = 1.2596598482131958, ppl = 3.5495977412820623\n","Train Epoch #17, Batch 6247/24958 loss = 1.2598368680477143, ppl = 3.550312894988313\n","Train Epoch #17, Batch 6248/24958 loss = 1.2595658457279206, ppl = 3.549360213385336\n","Train Epoch #17, Batch 6249/24958 loss = 1.2594021260738373, ppl = 3.5487931632134306\n","Train Epoch #17, Batch 6250/24958 loss = 1.2606106662750245, ppl = 3.552729617902143\n","Train Epoch #17, Batch 6251/24958 loss = 1.2602400887012482, ppl = 3.551405895972488\n","Train Epoch #17, Batch 6252/24958 loss = 1.2575828170776366, ppl = 3.5424389696493885\n","Train Epoch #17, Batch 6253/24958 loss = 1.2592070007324219, ppl = 3.548540614918518\n","Train Epoch #17, Batch 6254/24958 loss = 1.2628993117809295, ppl = 3.5652385753130136\n","Train Epoch #17, Batch 6255/24958 loss = 1.2639930188655852, ppl = 3.569268111711404\n","Train Epoch #17, Batch 6256/24958 loss = 1.263446319103241, ppl = 3.567385217185385\n","Train Epoch #17, Batch 6257/24958 loss = 1.2634262001514436, ppl = 3.567317130362879\n","Train Epoch #17, Batch 6258/24958 loss = 1.263008303642273, ppl = 3.5657233715600607\n","Train Epoch #17, Batch 6259/24958 loss = 1.2643372201919556, ppl = 3.570221359334375\n","Train Epoch #17, Batch 6260/24958 loss = 1.2632517898082734, ppl = 3.566035266706936\n","Train Epoch #17, Batch 6261/24958 loss = 1.2640801119804381, ppl = 3.5684023524323236\n","Train Epoch #17, Batch 6262/24958 loss = 1.264573484659195, ppl = 3.5703691415274035\n","Train Epoch #17, Batch 6263/24958 loss = 1.2676269483566285, ppl = 3.580748978121175\n","Train Epoch #17, Batch 6264/24958 loss = 1.2669804537296294, ppl = 3.578652022155636\n","Train Epoch #17, Batch 6265/24958 loss = 1.2663926041126252, ppl = 3.5765238983438454\n","Train Epoch #17, Batch 6266/24958 loss = 1.26803067445755, ppl = 3.581497349184097\n","Train Epoch #17, Batch 6267/24958 loss = 1.2677425301074983, ppl = 3.5804674990535177\n","Train Epoch #17, Batch 6268/24958 loss = 1.2690496551990509, ppl = 3.584802371138258\n","Train Epoch #17, Batch 6269/24958 loss = 1.2684990501403808, ppl = 3.582942546901527\n","Train Epoch #17, Batch 6270/24958 loss = 1.2688752830028533, ppl = 3.5842123488126987\n","Train Epoch #17, Batch 6271/24958 loss = 1.2705270147323608, ppl = 3.5899659069640153\n","Train Epoch #17, Batch 6272/24958 loss = 1.2694974613189698, ppl = 3.586432859645354\n","Train Epoch #17, Batch 6273/24958 loss = 1.2669305002689362, ppl = 3.5766054898161137\n","Train Epoch #17, Batch 6274/24958 loss = 1.2672877717018127, ppl = 3.5777835559198934\n","Train Epoch #17, Batch 6275/24958 loss = 1.2653884410858154, ppl = 3.5712390885156053\n","Train Epoch #17, Batch 6276/24958 loss = 1.266623876094818, ppl = 3.575192447996587\n","Train Epoch #17, Batch 6277/24958 loss = 1.2652895033359528, ppl = 3.5704173421525134\n","Train Epoch #17, Batch 6278/24958 loss = 1.2666585767269134, ppl = 3.57562643622518\n","Train Epoch #17, Batch 6279/24958 loss = 1.2665887141227723, ppl = 3.5753869904540623\n","Train Epoch #17, Batch 6280/24958 loss = 1.2646458780765533, ppl = 3.5684603508972774\n","Train Epoch #17, Batch 6281/24958 loss = 1.265802652835846, ppl = 3.571968454096306\n","Train Epoch #17, Batch 6282/24958 loss = 1.2656531572341918, ppl = 3.5714683299432903\n","Train Epoch #17, Batch 6283/24958 loss = 1.2657370066642761, ppl = 3.57175926916633\n","Train Epoch #17, Batch 6284/24958 loss = 1.266770018339157, ppl = 3.575637221947907\n","Train Epoch #17, Batch 6285/24958 loss = 1.2661844539642333, ppl = 3.5736458771133908\n","Train Epoch #17, Batch 6286/24958 loss = 1.2640596961975097, ppl = 3.5654792634705164\n","Train Epoch #17, Batch 6287/24958 loss = 1.2633360481262208, ppl = 3.562976122284195\n","Train Epoch #17, Batch 6288/24958 loss = 1.2660432648658753, ppl = 3.574036311451093\n","Train Epoch #17, Batch 6289/24958 loss = 1.2652557349205018, ppl = 3.571269145088991\n","Train Epoch #17, Batch 6290/24958 loss = 1.2651432347297669, ppl = 3.570874114543014\n","Train Epoch #17, Batch 6291/24958 loss = 1.2638306140899658, ppl = 3.5658422447435414\n","Train Epoch #17, Batch 6292/24958 loss = 1.26462060213089, ppl = 3.568842684705805\n","Train Epoch #17, Batch 6293/24958 loss = 1.2637961328029632, ppl = 3.5658368302055696\n","Train Epoch #17, Batch 6294/24958 loss = 1.2648404157161712, ppl = 3.5691276278238906\n","Train Epoch #17, Batch 6295/24958 loss = 1.2665894103050233, ppl = 3.5747952383136017\n","Train Epoch #17, Batch 6296/24958 loss = 1.26769562125206, ppl = 3.5786809125675108\n","Train Epoch #17, Batch 6297/24958 loss = 1.267358696460724, ppl = 3.5775123066106773\n","Train Epoch #17, Batch 6298/24958 loss = 1.2649986910820008, ppl = 3.569290089423093\n","Train Epoch #17, Batch 6299/24958 loss = 1.26532937169075, ppl = 3.570354059900209\n","Train Epoch #17, Batch 6300/24958 loss = 1.2659198498725892, ppl = 3.5724785228665024\n","Train Epoch #17, Batch 6301/24958 loss = 1.26701024889946, ppl = 3.577157336486174\n","Train Epoch #17, Batch 6302/24958 loss = 1.2641211473941802, ppl = 3.566686709746964\n","Train Epoch #17, Batch 6303/24958 loss = 1.265083646774292, ppl = 3.5702164966918417\n","Train Epoch #17, Batch 6304/24958 loss = 1.2658658933639526, ppl = 3.572980091582695\n","Train Epoch #17, Batch 6305/24958 loss = 1.266494573354721, ppl = 3.5751103937587074\n","Train Epoch #17, Batch 6306/24958 loss = 1.2662441003322602, ppl = 3.5742188750949513\n","Train Epoch #17, Batch 6307/24958 loss = 1.2658346283435822, ppl = 3.5729918763930835\n","Train Epoch #17, Batch 6308/24958 loss = 1.2652731692790986, ppl = 3.5710575844212142\n","Train Epoch #17, Batch 6309/24958 loss = 1.2657108175754548, ppl = 3.5726153010999333\n","Train Epoch #17, Batch 6310/24958 loss = 1.2671371233463287, ppl = 3.578427379587958\n","Train Epoch #17, Batch 6311/24958 loss = 1.2682206726074219, ppl = 3.5817907172823804\n","Train Epoch #17, Batch 6312/24958 loss = 1.2668102133274077, ppl = 3.577133113263805\n","Train Epoch #17, Batch 6313/24958 loss = 1.2683899354934693, ppl = 3.582855549453788\n","Train Epoch #17, Batch 6314/24958 loss = 1.2689833331108094, ppl = 3.584975856826994\n","Train Epoch #17, Batch 6315/24958 loss = 1.2675679922103882, ppl = 3.5799307369793216\n","Train Epoch #17, Batch 6316/24958 loss = 1.2697898483276366, ppl = 3.5880256489859557\n","Train Epoch #17, Batch 6317/24958 loss = 1.2706016623973846, ppl = 3.590777602640735\n","Train Epoch #17, Batch 6318/24958 loss = 1.2703470516204833, ppl = 3.5899170776978626\n","Train Epoch #17, Batch 6319/24958 loss = 1.2708954226970672, ppl = 3.591841833284473\n","Train Epoch #17, Batch 6320/24958 loss = 1.2721698820590972, ppl = 3.5966581015769292\n","Train Epoch #17, Batch 6321/24958 loss = 1.2766979706287385, ppl = 3.6104704025417567\n","Train Epoch #17, Batch 6322/24958 loss = 1.27468599319458, ppl = 3.6034819891584204\n","Train Epoch #17, Batch 6323/24958 loss = 1.2742314267158508, ppl = 3.601513818227376\n","Train Epoch #17, Batch 6324/24958 loss = 1.2754201793670654, ppl = 3.6055746128188613\n","Train Epoch #17, Batch 6325/24958 loss = 1.276091696023941, ppl = 3.60795720818808\n","Train Epoch #17, Batch 6326/24958 loss = 1.275358066558838, ppl = 3.605466269366336\n","Train Epoch #17, Batch 6327/24958 loss = 1.2734368896484376, ppl = 3.5974287667245757\n","Train Epoch #17, Batch 6328/24958 loss = 1.2699351131916046, ppl = 3.5844213127405067\n","Train Epoch #17, Batch 6329/24958 loss = 1.2698587548732758, ppl = 3.5841661534953952\n","Train Epoch #17, Batch 6330/24958 loss = 1.267073442339897, ppl = 3.5758140570267694\n","Train Epoch #17, Batch 6331/24958 loss = 1.2676084142923356, ppl = 3.5776257547552706\n","Train Epoch #17, Batch 6332/24958 loss = 1.2675034433603287, ppl = 3.5772821420380785\n","Train Epoch #17, Batch 6333/24958 loss = 1.269222622513771, ppl = 3.5830799005875154\n","Train Epoch #17, Batch 6334/24958 loss = 1.2657482421398163, ppl = 3.5719959051680172\n","Train Epoch #17, Batch 6335/24958 loss = 1.2666562902927399, ppl = 3.5750188130383447\n","Train Epoch #17, Batch 6336/24958 loss = 1.2679351234436036, ppl = 3.579804890784903\n","Train Epoch #17, Batch 6337/24958 loss = 1.2636138558387757, ppl = 3.560411491081422\n","Train Epoch #17, Batch 6338/24958 loss = 1.2635362040996552, ppl = 3.5601256789476583\n","Train Epoch #17, Batch 6339/24958 loss = 1.2613671559095383, ppl = 3.5537703531704086\n","Train Epoch #17, Batch 6340/24958 loss = 1.2621339136362075, ppl = 3.5566951137156586\n","Train Epoch #17, Batch 6341/24958 loss = 1.2631012731790543, ppl = 3.5602977760318244\n","Train Epoch #17, Batch 6342/24958 loss = 1.260086560845375, ppl = 3.548519168895959\n","Train Epoch #17, Batch 6343/24958 loss = 1.2593398350477218, ppl = 3.5459556009474875\n","Train Epoch #17, Batch 6344/24958 loss = 1.2569166034460069, ppl = 3.537402389895505\n","Train Epoch #17, Batch 6345/24958 loss = 1.2592882281541824, ppl = 3.5478322269867717\n","Train Epoch #17, Batch 6346/24958 loss = 1.2625278919935226, ppl = 3.5600430746485134\n","Train Epoch #17, Batch 6347/24958 loss = 1.2606470209360123, ppl = 3.553054765122774\n","Train Epoch #17, Batch 6348/24958 loss = 1.2600361233949662, ppl = 3.5509997515752256\n","Train Epoch #17, Batch 6349/24958 loss = 1.2599896901845933, ppl = 3.5508406107858135\n","Train Epoch #17, Batch 6350/24958 loss = 1.2604103928804398, ppl = 3.5523264293172634\n","Train Epoch #17, Batch 6351/24958 loss = 1.2616677814722062, ppl = 3.557024344924812\n","Train Epoch #17, Batch 6352/24958 loss = 1.2635307532548905, ppl = 3.5630571151784602\n","Train Epoch #17, Batch 6353/24958 loss = 1.2622117954492569, ppl = 3.55802780849109\n","Train Epoch #17, Batch 6354/24958 loss = 1.2603177744150162, ppl = 3.5486956079564203\n","Train Epoch #17, Batch 6355/24958 loss = 1.2603995698690413, ppl = 3.549015051203668\n","Train Epoch #17, Batch 6356/24958 loss = 1.2607953077554703, ppl = 3.5503676870676433\n","Train Epoch #17, Batch 6357/24958 loss = 1.2615418916940688, ppl = 3.55298835582277\n","Train Epoch #17, Batch 6358/24958 loss = 1.2629238837957382, ppl = 3.5585232387095598\n","Train Epoch #17, Batch 6359/24958 loss = 1.2617881780862807, ppl = 3.5546426667422923\n","Train Epoch #17, Batch 6360/24958 loss = 1.2614701336622238, ppl = 3.553499726018486\n","Train Epoch #17, Batch 6361/24958 loss = 1.261635634303093, ppl = 3.553996633773202\n","Train Epoch #17, Batch 6362/24958 loss = 1.2603379386663436, ppl = 3.549024411533229\n","Train Epoch #17, Batch 6363/24958 loss = 1.2599888724088668, ppl = 3.547671195738445\n","Train Epoch #17, Batch 6364/24958 loss = 1.2610739105939865, ppl = 3.5512697632665176\n","Train Epoch #17, Batch 6365/24958 loss = 1.2605905503034591, ppl = 3.5496112446930543\n","Train Epoch #17, Batch 6366/24958 loss = 1.2610954767465592, ppl = 3.5513159474697664\n","Train Epoch #17, Batch 6367/24958 loss = 1.2599027425050735, ppl = 3.5473550544427344\n","Train Epoch #17, Batch 6368/24958 loss = 1.2593271714448928, ppl = 3.545376288662597\n","Train Epoch #17, Batch 6369/24958 loss = 1.2591678482294082, ppl = 3.544856957232367\n","Train Epoch #17, Batch 6370/24958 loss = 1.260545832514763, ppl = 3.5499377770527007\n","Train Epoch #17, Batch 6371/24958 loss = 1.2590317648649216, ppl = 3.5446282873566117\n","Train Epoch #17, Batch 6372/24958 loss = 1.2591416078805924, ppl = 3.5449881296051164\n","Train Epoch #17, Batch 6373/24958 loss = 1.2585674279928207, ppl = 3.543114322302431\n","Train Epoch #17, Batch 6374/24958 loss = 1.260238112807274, ppl = 3.5492178971044437\n","Train Epoch #17, Batch 6375/24958 loss = 1.2584975546598434, ppl = 3.5442196401706663\n","Train Epoch #17, Batch 6376/24958 loss = 1.2575335007905961, ppl = 3.5410933255556505\n","Train Epoch #17, Batch 6377/24958 loss = 1.2583284538984298, ppl = 3.5438610713116394\n","Train Epoch #17, Batch 6378/24958 loss = 1.2574737399816514, ppl = 3.5405258974153084\n","Train Epoch #17, Batch 6379/24958 loss = 1.258535506129265, ppl = 3.5443517945186693\n","Train Epoch #17, Batch 6380/24958 loss = 1.25836441218853, ppl = 3.5438038455268526\n","Train Epoch #17, Batch 6381/24958 loss = 1.2594535249471663, ppl = 3.5474990437283167\n","Train Epoch #17, Batch 6382/24958 loss = 1.260359954237938, ppl = 3.550649435558047\n","Train Epoch #17, Batch 6383/24958 loss = 1.260283038020134, ppl = 3.5503824606588155\n","Train Epoch #17, Batch 6384/24958 loss = 1.2588997000455857, ppl = 3.545277745774739\n","Train Epoch #17, Batch 6385/24958 loss = 1.2577686446905136, ppl = 3.5417463272903276\n","Train Epoch #17, Batch 6386/24958 loss = 1.2573169678449632, ppl = 3.5402228565210243\n","Train Epoch #17, Batch 6387/24958 loss = 1.2570892137289047, ppl = 3.539471788336328\n","Train Epoch #17, Batch 6388/24958 loss = 1.2539554864168168, ppl = 3.5269262491682936\n","Train Epoch #17, Batch 6389/24958 loss = 1.2528795844316483, ppl = 3.5234813682321673\n","Train Epoch #17, Batch 6390/24958 loss = 1.2527948468923569, ppl = 3.523186743422637\n","Train Epoch #17, Batch 6391/24958 loss = 1.253141011595726, ppl = 3.5244503054658325\n","Train Epoch #17, Batch 6392/24958 loss = 1.2519108194112778, ppl = 3.5198779564830636\n","Train Epoch #17, Batch 6393/24958 loss = 1.2517070943117141, ppl = 3.5191726213059713\n","Train Epoch #17, Batch 6394/24958 loss = 1.2522958344221116, ppl = 3.521185106400327\n","Train Epoch #17, Batch 6395/24958 loss = 1.2512746864557267, ppl = 3.517756319701033\n","Train Epoch #17, Batch 6396/24958 loss = 1.2503942269086838, ppl = 3.514629096855839\n","Train Epoch #17, Batch 6397/24958 loss = 1.2513046377897263, ppl = 3.517879633696822\n","Train Epoch #17, Batch 6398/24958 loss = 1.2526050800085067, ppl = 3.5221696355622147\n","Train Epoch #17, Batch 6399/24958 loss = 1.2534673780202865, ppl = 3.525115401193781\n","Train Epoch #17, Batch 6400/24958 loss = 1.2548240953683854, ppl = 3.5304991828956775\n","Train Epoch #17, Batch 6401/24958 loss = 1.2513764268159866, ppl = 3.5172916408189816\n","Train Epoch #17, Batch 6402/24958 loss = 1.2545970267057418, ppl = 3.529168756244037\n","Train Epoch #17, Batch 6403/24958 loss = 1.255197324156761, ppl = 3.5315485965545563\n","Train Epoch #17, Batch 6404/24958 loss = 1.253611211180687, ppl = 3.5261615155446413\n","Train Epoch #17, Batch 6405/24958 loss = 1.2521229213476182, ppl = 3.521326898000565\n","Train Epoch #17, Batch 6406/24958 loss = 1.2500772792100907, ppl = 3.5148243246714554\n","Train Epoch #17, Batch 6407/24958 loss = 1.25109789788723, ppl = 3.5179786932472954\n","Train Epoch #17, Batch 6408/24958 loss = 1.2514233034849167, ppl = 3.519086503126648\n","Train Epoch #17, Batch 6409/24958 loss = 1.2532701426744461, ppl = 3.526465234467636\n","Train Epoch #17, Batch 6410/24958 loss = 1.2512522345781327, ppl = 3.5184753175732055\n","Train Epoch #17, Batch 6411/24958 loss = 1.2536643224954604, ppl = 3.527409640198794\n","Train Epoch #17, Batch 6412/24958 loss = 1.254524477124214, ppl = 3.530171507248992\n","Train Epoch #17, Batch 6413/24958 loss = 1.2525490671396255, ppl = 3.5231517893642\n","Train Epoch #17, Batch 6414/24958 loss = 1.25334292948246, ppl = 3.5261924819373007\n","Train Epoch #17, Batch 6415/24958 loss = 1.2527293008565903, ppl = 3.5242174995158617\n","Train Epoch #17, Batch 6416/24958 loss = 1.2537756913900375, ppl = 3.5286994210117864\n","Train Epoch #17, Batch 6417/24958 loss = 1.2537822264432907, ppl = 3.528722492980537\n","Train Epoch #17, Batch 6418/24958 loss = 1.2551302582025528, ppl = 3.5335380573357473\n","Train Epoch #17, Batch 6419/24958 loss = 1.2562989908456803, ppl = 3.538009991369112\n","Train Epoch #17, Batch 6420/24958 loss = 1.255829979777336, ppl = 3.5361658093390127\n","Train Epoch #17, Batch 6421/24958 loss = 1.2574272292852402, ppl = 3.542734692517858\n","Train Epoch #17, Batch 6422/24958 loss = 1.2574111491441726, ppl = 3.5426843106343893\n","Train Epoch #17, Batch 6423/24958 loss = 1.2553840798139573, ppl = 3.5349191243612985\n","Train Epoch #17, Batch 6424/24958 loss = 1.2566508215665817, ppl = 3.5398119826447623\n","Train Epoch #17, Batch 6425/24958 loss = 1.2566051822900772, ppl = 3.539644934448719\n","Train Epoch #17, Batch 6426/24958 loss = 1.2565445703268052, ppl = 3.539447191416315\n","Train Epoch #17, Batch 6427/24958 loss = 1.2561481434106827, ppl = 3.537972328944057\n","Train Epoch #17, Batch 6428/24958 loss = 1.2583020812273025, ppl = 3.5454280836160637\n","Train Epoch #17, Batch 6429/24958 loss = 1.2583077973127366, ppl = 3.5454471171152955\n","Train Epoch #17, Batch 6430/24958 loss = 1.2624759459495545, ppl = 3.558894229053934\n","Train Epoch #17, Batch 6431/24958 loss = 1.2623562872409821, ppl = 3.5584805455019013\n","Train Epoch #17, Batch 6432/24958 loss = 1.2614340722560882, ppl = 3.5556118847850415\n","Train Epoch #17, Batch 6433/24958 loss = 1.2625463688373566, ppl = 3.5599303901552326\n","Train Epoch #17, Batch 6434/24958 loss = 1.2650698333978654, ppl = 3.567588768524792\n","Train Epoch #17, Batch 6435/24958 loss = 1.2664446693658828, ppl = 3.57272130333422\n","Train Epoch #17, Batch 6436/24958 loss = 1.264653473496437, ppl = 3.5661829610753197\n","Train Epoch #17, Batch 6437/24958 loss = 1.266284881234169, ppl = 3.5725407108670506\n","Train Epoch #17, Batch 6438/24958 loss = 1.2655284875631332, ppl = 3.5698697425877066\n","Train Epoch #17, Batch 6439/24958 loss = 1.2696397268772126, ppl = 3.583211676047385\n","Train Epoch #17, Batch 6440/24958 loss = 1.2678422617912293, ppl = 3.5766925526764424\n","Train Epoch #17, Batch 6441/24958 loss = 1.2661101567745208, ppl = 3.570478469487351\n","Train Epoch #17, Batch 6442/24958 loss = 1.2667449665069581, ppl = 3.5726724979300126\n","Train Epoch #17, Batch 6443/24958 loss = 1.2683549618721008, ppl = 3.5784484292399816\n","Train Epoch #17, Batch 6444/24958 loss = 1.2686731040477752, ppl = 3.579456753756071\n","Train Epoch #17, Batch 6445/24958 loss = 1.2641093266010284, ppl = 3.5613558966827146\n","Train Epoch #17, Batch 6446/24958 loss = 1.2618019437789918, ppl = 3.5522635669080334\n","Train Epoch #17, Batch 6447/24958 loss = 1.2613430500030518, ppl = 3.5507489037609266\n","Train Epoch #17, Batch 6448/24958 loss = 1.26069002866745, ppl = 3.548686671070257\n","Train Epoch #17, Batch 6449/24958 loss = 1.2611693811416627, ppl = 3.5503656671458077\n","Train Epoch #17, Batch 6450/24958 loss = 1.2608807516098022, ppl = 3.5493395847875804\n","Train Epoch #17, Batch 6451/24958 loss = 1.2609361898899079, ppl = 3.5495606231297394\n","Train Epoch #17, Batch 6452/24958 loss = 1.2626044046878815, ppl = 3.556004049025732\n","Train Epoch #17, Batch 6453/24958 loss = 1.2616747534275055, ppl = 3.5528373194362763\n","Train Epoch #17, Batch 6454/24958 loss = 1.2578410148620605, ppl = 3.5385860862185026\n","Train Epoch #17, Batch 6455/24958 loss = 1.2583365225791932, ppl = 3.540578108374305\n","Train Epoch #17, Batch 6456/24958 loss = 1.2581070482730865, ppl = 3.539787249683912\n","Train Epoch #17, Batch 6457/24958 loss = 1.2571218287944794, ppl = 3.536369349723373\n","Train Epoch #17, Batch 6458/24958 loss = 1.2570371687412263, ppl = 3.536007849671874\n","Train Epoch #17, Batch 6459/24958 loss = 1.2603029894828797, ppl = 3.5484693992220855\n","Train Epoch #17, Batch 6460/24958 loss = 1.2599092423915863, ppl = 3.547103852154415\n","Train Epoch #17, Batch 6461/24958 loss = 1.2611252665519714, ppl = 3.5510183884220576\n","Train Epoch #17, Batch 6462/24958 loss = 1.262001942396164, ppl = 3.5543062140469646\n","Train Epoch #17, Batch 6463/24958 loss = 1.2605552911758422, ppl = 3.549175401990192\n","Train Epoch #17, Batch 6464/24958 loss = 1.2609600019454956, ppl = 3.550620826790078\n","Train Epoch #17, Batch 6465/24958 loss = 1.2613583672046662, ppl = 3.5519818690912395\n","Train Epoch #17, Batch 6466/24958 loss = 1.2645868623256684, ppl = 3.5651744350673744\n","Train Epoch #17, Batch 6467/24958 loss = 1.2645445799827575, ppl = 3.565042508169968\n","Train Epoch #17, Batch 6468/24958 loss = 1.266907114982605, ppl = 3.573943260686418\n","Train Epoch #17, Batch 6469/24958 loss = 1.2682527327537536, ppl = 3.5786009479983742\n","Train Epoch #17, Batch 6470/24958 loss = 1.267829922437668, ppl = 3.5769668983804506\n","Train Epoch #17, Batch 6471/24958 loss = 1.268567361831665, ppl = 3.579452624212515\n","Train Epoch #17, Batch 6472/24958 loss = 1.2692709147930146, ppl = 3.5818535932117634\n","Train Epoch #17, Batch 6473/24958 loss = 1.2690588247776031, ppl = 3.5811882097164234\n","Train Epoch #17, Batch 6474/24958 loss = 1.2687274658679961, ppl = 3.579895245829749\n","Train Epoch #17, Batch 6475/24958 loss = 1.2719143640995025, ppl = 3.589762432184362\n","Train Epoch #17, Batch 6476/24958 loss = 1.2735446679592133, ppl = 3.5952323406356252\n","Train Epoch #17, Batch 6477/24958 loss = 1.27391704082489, ppl = 3.5966064509911093\n","Train Epoch #17, Batch 6478/24958 loss = 1.2728146302700043, ppl = 3.592704962224549\n","Train Epoch #17, Batch 6479/24958 loss = 1.2733688533306122, ppl = 3.5948693315169065\n","Train Epoch #17, Batch 6480/24958 loss = 1.2751535665988922, ppl = 3.6010735085986316\n","Train Epoch #17, Batch 6481/24958 loss = 1.2776518476009369, ppl = 3.6112364554436818\n","Train Epoch #17, Batch 6482/24958 loss = 1.2769299161434173, ppl = 3.608704368762661\n","Train Epoch #17, Batch 6483/24958 loss = 1.2775981390476228, ppl = 3.6110937951588995\n","Train Epoch #17, Batch 6484/24958 loss = 1.2769534981250763, ppl = 3.608945702406837\n","Train Epoch #17, Batch 6485/24958 loss = 1.2794644343852997, ppl = 3.6173630172156175\n","Train Epoch #17, Batch 6486/24958 loss = 1.2794421923160553, ppl = 3.6172897594546187\n","Train Epoch #17, Batch 6487/24958 loss = 1.2804096138477326, ppl = 3.620601455824601\n","Train Epoch #17, Batch 6488/24958 loss = 1.2810427331924439, ppl = 3.6228294325535417\n","Train Epoch #17, Batch 6489/24958 loss = 1.2828998398780822, ppl = 3.6290183753309115\n","Train Epoch #17, Batch 6490/24958 loss = 1.2846107745170594, ppl = 3.6354788970434773\n","Train Epoch #17, Batch 6491/24958 loss = 1.2841711819171906, ppl = 3.6338817360901627\n","Train Epoch #17, Batch 6492/24958 loss = 1.2843188905715943, ppl = 3.634401488660889\n","Train Epoch #17, Batch 6493/24958 loss = 1.284661420583725, ppl = 3.635595689758242\n","Train Epoch #17, Batch 6494/24958 loss = 1.2830425155162812, ppl = 3.630334643533663\n","Train Epoch #17, Batch 6495/24958 loss = 1.2811697566509246, ppl = 3.6248878732490835\n","Train Epoch #17, Batch 6496/24958 loss = 1.2834607446193695, ppl = 3.6336359090715913\n","Train Epoch #17, Batch 6497/24958 loss = 1.2818308329582215, ppl = 3.6280178201627313\n","Train Epoch #17, Batch 6498/24958 loss = 1.2807352340221405, ppl = 3.6243671100935524\n","Train Epoch #17, Batch 6499/24958 loss = 1.2790370392799377, ppl = 3.618798276818419\n","Train Epoch #17, Batch 6500/24958 loss = 1.2777282965183259, ppl = 3.613592674602174\n","Train Epoch #17, Batch 6501/24958 loss = 1.2788676834106445, ppl = 3.6174646279376863\n","Train Epoch #17, Batch 6502/24958 loss = 1.2762198567390441, ppl = 3.6074301679843184\n","Train Epoch #17, Batch 6503/24958 loss = 1.2751706373691558, ppl = 3.6033616767595715\n","Train Epoch #17, Batch 6504/24958 loss = 1.274485764503479, ppl = 3.6012870248215103\n","Train Epoch #17, Batch 6505/24958 loss = 1.2760044300556184, ppl = 3.606228002285554\n","Train Epoch #17, Batch 6506/24958 loss = 1.27908243060112, ppl = 3.616553184759322\n","Train Epoch #17, Batch 6507/24958 loss = 1.2799393391609193, ppl = 3.61946187705622\n","Train Epoch #17, Batch 6508/24958 loss = 1.278948550224304, ppl = 3.6161980194040666\n","Train Epoch #17, Batch 6509/24958 loss = 1.2755310976505279, ppl = 3.603531888462758\n","Train Epoch #17, Batch 6510/24958 loss = 1.2750913870334626, ppl = 3.6019946554205666\n","Train Epoch #17, Batch 6511/24958 loss = 1.27403781414032, ppl = 3.5978261402337024\n","Train Epoch #17, Batch 6512/24958 loss = 1.2742734360694885, ppl = 3.5986250773587343\n","Train Epoch #17, Batch 6513/24958 loss = 1.2761470639705659, ppl = 3.6052482296485766\n","Train Epoch #17, Batch 6514/24958 loss = 1.2734162354469298, ppl = 3.5957269428141654\n","Train Epoch #17, Batch 6515/24958 loss = 1.2731211495399475, ppl = 3.594819495900245\n","Train Epoch #17, Batch 6516/24958 loss = 1.268556410074234, ppl = 3.5782864689845244\n","Train Epoch #17, Batch 6517/24958 loss = 1.2689750957489014, ppl = 3.5797965105066902\n","Train Epoch #17, Batch 6518/24958 loss = 1.2682598423957825, ppl = 3.577160717100759\n","Train Epoch #17, Batch 6519/24958 loss = 1.2640817111730576, ppl = 3.56331481644891\n","Train Epoch #17, Batch 6520/24958 loss = 1.261510813832283, ppl = 3.5546081837114127\n","Train Epoch #17, Batch 6521/24958 loss = 1.25831541121006, ppl = 3.5424372064673206\n","Train Epoch #17, Batch 6522/24958 loss = 1.2607007700204849, ppl = 3.550870856723107\n","Train Epoch #17, Batch 6523/24958 loss = 1.2600568169355393, ppl = 3.5487157502647233\n","Train Epoch #17, Batch 6524/24958 loss = 1.2587830501794814, ppl = 3.543797448807831\n","Train Epoch #17, Batch 6525/24958 loss = 1.2591558533906937, ppl = 3.545184561451866\n","Train Epoch #17, Batch 6526/24958 loss = 1.2613453108072281, ppl = 3.553145661377944\n","Train Epoch #17, Batch 6527/24958 loss = 1.261446332335472, ppl = 3.5535159676670167\n","Train Epoch #17, Batch 6528/24958 loss = 1.260918805003166, ppl = 3.551538854111574\n","Train Epoch #17, Batch 6529/24958 loss = 1.262405212521553, ppl = 3.5568766086624892\n","Train Epoch #17, Batch 6530/24958 loss = 1.2607665926218032, ppl = 3.5509139692847014\n","Train Epoch #17, Batch 6531/24958 loss = 1.2599404495954514, ppl = 3.5481889958882853\n","Train Epoch #17, Batch 6532/24958 loss = 1.2647384721040726, ppl = 3.566473169011914\n","Train Epoch #17, Batch 6533/24958 loss = 1.2644917613267899, ppl = 3.5654734358511035\n","Train Epoch #17, Batch 6534/24958 loss = 1.2661123067140578, ppl = 3.5715144557136838\n","Train Epoch #17, Batch 6535/24958 loss = 1.263162278532982, ppl = 3.561306612442359\n","Train Epoch #17, Batch 6536/24958 loss = 1.2650861316919326, ppl = 3.5683773747426972\n","Train Epoch #17, Batch 6537/24958 loss = 1.2636618369817734, ppl = 3.5627704632569044\n","Train Epoch #17, Batch 6538/24958 loss = 1.263552320599556, ppl = 3.5624002128200756\n","Train Epoch #17, Batch 6539/24958 loss = 1.261299619078636, ppl = 3.5544171245960787\n","Train Epoch #17, Batch 6540/24958 loss = 1.2621795696020126, ppl = 3.557462347113102\n","Train Epoch #17, Batch 6541/24958 loss = 1.2618500977754592, ppl = 3.5563973916859397\n","Train Epoch #17, Batch 6542/24958 loss = 1.2631646984815597, ppl = 3.5614088394368526\n","Train Epoch #17, Batch 6543/24958 loss = 1.2637175053358078, ppl = 3.5636164466907347\n","Train Epoch #17, Batch 6544/24958 loss = 1.2640498262643813, ppl = 3.564704532304566\n","Train Epoch #17, Batch 6545/24958 loss = 1.266052718758583, ppl = 3.571644966536076\n","Train Epoch #17, Batch 6546/24958 loss = 1.2673636656999587, ppl = 3.576552364358948\n","Train Epoch #17, Batch 6547/24958 loss = 1.2697249549627303, ppl = 3.585143161364036\n","Train Epoch #17, Batch 6548/24958 loss = 1.2707181340456009, ppl = 3.5883341525886667\n","Train Epoch #17, Batch 6549/24958 loss = 1.271279940009117, ppl = 3.590407180047168\n","Train Epoch #17, Batch 6550/24958 loss = 1.272635471224785, ppl = 3.5954938765844973\n","Train Epoch #17, Batch 6551/24958 loss = 1.2708931928873062, ppl = 3.5891010232674603\n","Train Epoch #17, Batch 6552/24958 loss = 1.2687438982725143, ppl = 3.580990545657611\n","Train Epoch #17, Batch 6553/24958 loss = 1.2706452423334123, ppl = 3.5877974440799547\n","Train Epoch #17, Batch 6554/24958 loss = 1.2729651540517808, ppl = 3.59576171796044\n","Train Epoch #17, Batch 6555/24958 loss = 1.2719958263635636, ppl = 3.591954996735826\n","Train Epoch #17, Batch 6556/24958 loss = 1.27126529276371, ppl = 3.589554806006199\n","Train Epoch #17, Batch 6557/24958 loss = 1.272328389286995, ppl = 3.593257509998386\n","Train Epoch #17, Batch 6558/24958 loss = 1.2717400759458541, ppl = 3.590828180498434\n","Train Epoch #17, Batch 6559/24958 loss = 1.269199884533882, ppl = 3.5807949288524084\n","Train Epoch #17, Batch 6560/24958 loss = 1.2708802789449691, ppl = 3.587016821748764\n","Train Epoch #17, Batch 6561/24958 loss = 1.2713244432210922, ppl = 3.5885695677737948\n","Train Epoch #17, Batch 6562/24958 loss = 1.2697108393907548, ppl = 3.5827324769163647\n","Train Epoch #17, Batch 6563/24958 loss = 1.2713706630468369, ppl = 3.5886840666072173\n","Train Epoch #17, Batch 6564/24958 loss = 1.2710532289743424, ppl = 3.5875454223347147\n","Train Epoch #17, Batch 6565/24958 loss = 1.2714353436231614, ppl = 3.5889028899077977\n","Train Epoch #17, Batch 6566/24958 loss = 1.2676490837335586, ppl = 3.5738321559944173\n","Train Epoch #17, Batch 6567/24958 loss = 1.2683756226301193, ppl = 3.5761784736509274\n","Train Epoch #17, Batch 6568/24958 loss = 1.2655710619688034, ppl = 3.5658335405484314\n","Train Epoch #17, Batch 6569/24958 loss = 1.2636389416456222, ppl = 3.559333818987404\n","Train Epoch #17, Batch 6570/24958 loss = 1.2648933535814286, ppl = 3.56439055403864\n","Train Epoch #17, Batch 6571/24958 loss = 1.2648171669244765, ppl = 3.5641251745349236\n","Train Epoch #17, Batch 6572/24958 loss = 1.2648541086912155, ppl = 3.564255971521204\n","Train Epoch #17, Batch 6573/24958 loss = 1.2638233000040053, ppl = 3.5612156130694164\n","Train Epoch #17, Batch 6574/24958 loss = 1.2616231793165207, ppl = 3.5536364793777926\n","Train Epoch #17, Batch 6575/24958 loss = 1.2604947394132615, ppl = 3.5497781745954597\n","Train Epoch #17, Batch 6576/24958 loss = 1.2591607135534286, ppl = 3.545237185326209\n","Train Epoch #17, Batch 6577/24958 loss = 1.2576388949155808, ppl = 3.539930290312947\n","Train Epoch #17, Batch 6578/24958 loss = 1.2578329557180405, ppl = 3.540586265143832\n","Train Epoch #17, Batch 6579/24958 loss = 1.2570130509138107, ppl = 3.5374261198191252\n","Train Epoch #17, Batch 6580/24958 loss = 1.2579224532842637, ppl = 3.541039779136995\n","Train Epoch #17, Batch 6581/24958 loss = 1.255647709965706, ppl = 3.531686326787123\n","Train Epoch #17, Batch 6582/24958 loss = 1.2562713557481766, ppl = 3.5338628455539545\n","Train Epoch #17, Batch 6583/24958 loss = 1.257654224038124, ppl = 3.539345074782297\n","Train Epoch #17, Batch 6584/24958 loss = 1.2578485721349717, ppl = 3.539978170104953\n","Train Epoch #17, Batch 6585/24958 loss = 1.257027820944786, ppl = 3.536991186055025\n","Train Epoch #17, Batch 6586/24958 loss = 1.258557259440422, ppl = 3.542428218709345\n","Train Epoch #17, Batch 6587/24958 loss = 1.2590165382623673, ppl = 3.5441161719535175\n","Train Epoch #17, Batch 6588/24958 loss = 1.2578751415014267, ppl = 3.5401988633324426\n","Train Epoch #17, Batch 6589/24958 loss = 1.256054978966713, ppl = 3.534122168219477\n","Train Epoch #17, Batch 6590/24958 loss = 1.2543738931417465, ppl = 3.5277651434481343\n","Train Epoch #17, Batch 6591/24958 loss = 1.252361610531807, ppl = 3.5212871124950387\n","Train Epoch #17, Batch 6592/24958 loss = 1.254888466000557, ppl = 3.531477703456704\n","Train Epoch #17, Batch 6593/24958 loss = 1.2552357321977616, ppl = 3.5327309042836537\n","Train Epoch #17, Batch 6594/24958 loss = 1.2578688937425613, ppl = 3.541749363063392\n","Train Epoch #17, Batch 6595/24958 loss = 1.2593983167409897, ppl = 3.546119731998429\n","Train Epoch #17, Batch 6596/24958 loss = 1.2578007572889327, ppl = 3.5398113967683953\n","Train Epoch #17, Batch 6597/24958 loss = 1.258621615767479, ppl = 3.5425263713121886\n","Train Epoch #17, Batch 6598/24958 loss = 1.258650638461113, ppl = 3.542618011509652\n","Train Epoch #17, Batch 6599/24958 loss = 1.2613342195749282, ppl = 3.551879259413709\n","Train Epoch #17, Batch 6600/24958 loss = 1.261509479880333, ppl = 3.5525374969596766\n","Train Epoch #17, Batch 6601/24958 loss = 1.2614408892393112, ppl = 3.5522917196638444\n","Train Epoch #17, Batch 6602/24958 loss = 1.262568594813347, ppl = 3.5562431409002158\n","Train Epoch #17, Batch 6603/24958 loss = 1.2628974467515945, ppl = 3.557472688339743\n","Train Epoch #17, Batch 6604/24958 loss = 1.2638186126947404, ppl = 3.5602967414674622\n","Train Epoch #17, Batch 6605/24958 loss = 1.2642649108171462, ppl = 3.561897269225784\n","Train Epoch #17, Batch 6606/24958 loss = 1.2638764399290086, ppl = 3.5604123453784497\n","Train Epoch #17, Batch 6607/24958 loss = 1.2643832570314408, ppl = 3.562253715539951\n","Train Epoch #17, Batch 6608/24958 loss = 1.2655315726995469, ppl = 3.5660669452263405\n","Train Epoch #17, Batch 6609/24958 loss = 1.2668934017419815, ppl = 3.5706027148383117\n","Train Epoch #17, Batch 6610/24958 loss = 1.2655478531122208, ppl = 3.5662974652845567\n","Train Epoch #17, Batch 6611/24958 loss = 1.2642485159635544, ppl = 3.5617260520832303\n","Train Epoch #17, Batch 6612/24958 loss = 1.264994301199913, ppl = 3.564382566998392\n","Train Epoch #17, Batch 6613/24958 loss = 1.26323426425457, ppl = 3.5581265902219745\n","Train Epoch #17, Batch 6614/24958 loss = 1.264977120757103, ppl = 3.5638997051722128\n","Train Epoch #17, Batch 6615/24958 loss = 1.264932424426079, ppl = 3.5637645754258864\n","Train Epoch #17, Batch 6616/24958 loss = 1.2666324549913406, ppl = 3.5690605461108253\n","Train Epoch #17, Batch 6617/24958 loss = 1.2650690466165542, ppl = 3.5637305563547583\n","Train Epoch #17, Batch 6618/24958 loss = 1.264288098216057, ppl = 3.561059998559663\n","Train Epoch #17, Batch 6619/24958 loss = 1.2663029098510743, ppl = 3.5670190578555587\n","Train Epoch #17, Batch 6620/24958 loss = 1.268804303407669, ppl = 3.575459681481317\n","Train Epoch #17, Batch 6621/24958 loss = 1.268573795557022, ppl = 3.5747230396134397\n","Train Epoch #17, Batch 6622/24958 loss = 1.2679241824150085, ppl = 3.572223528158753\n","Train Epoch #17, Batch 6623/24958 loss = 1.2662101936340333, ppl = 3.5671199254699815\n","Train Epoch #17, Batch 6624/24958 loss = 1.2678379678726197, ppl = 3.5735201083838244\n","Train Epoch #17, Batch 6625/24958 loss = 1.2668950426578522, ppl = 3.570109239529197\n","Train Epoch #17, Batch 6626/24958 loss = 1.2668274343013763, ppl = 3.5698364384789882\n","Train Epoch #17, Batch 6627/24958 loss = 1.2666949939727783, ppl = 3.5693517234561396\n","Train Epoch #17, Batch 6628/24958 loss = 1.2662380409240723, ppl = 3.5677214219316\n","Train Epoch #17, Batch 6629/24958 loss = 1.264988316297531, ppl = 3.5631814058812097\n","Train Epoch #17, Batch 6630/24958 loss = 1.2640891444683076, ppl = 3.560301647260064\n","Train Epoch #17, Batch 6631/24958 loss = 1.266295281648636, ppl = 3.568111855213664\n","Train Epoch #17, Batch 6632/24958 loss = 1.262207772731781, ppl = 3.5520142341593197\n","Train Epoch #17, Batch 6633/24958 loss = 1.2641940915584564, ppl = 3.5608089690087947\n","Train Epoch #17, Batch 6634/24958 loss = 1.2627387762069702, ppl = 3.5553400414609264\n","Train Epoch #17, Batch 6635/24958 loss = 1.2652666985988616, ppl = 3.5638963760695375\n","Train Epoch #17, Batch 6636/24958 loss = 1.26323792219162, ppl = 3.556477721989919\n","Train Epoch #17, Batch 6637/24958 loss = 1.261807506084442, ppl = 3.551595695473102\n","Train Epoch #17, Batch 6638/24958 loss = 1.2615512526035308, ppl = 3.550745040618492\n","Train Epoch #17, Batch 6639/24958 loss = 1.262334065437317, ppl = 3.5533178047167824\n","Train Epoch #17, Batch 6640/24958 loss = 1.261898112297058, ppl = 3.5517756208590696\n","Train Epoch #17, Batch 6641/24958 loss = 1.2622263145446777, ppl = 3.552836404903551\n","Train Epoch #17, Batch 6642/24958 loss = 1.2635015070438385, ppl = 3.5583694381136617\n","Train Epoch #17, Batch 6643/24958 loss = 1.260783270597458, ppl = 3.548599431724658\n","Train Epoch #17, Batch 6644/24958 loss = 1.2614306128025055, ppl = 3.5508256526280837\n","Train Epoch #17, Batch 6645/24958 loss = 1.259051342010498, ppl = 3.5427291372297502\n","Train Epoch #17, Batch 6646/24958 loss = 1.257470715045929, ppl = 3.5368895712422512\n","Train Epoch #17, Batch 6647/24958 loss = 1.2560279655456543, ppl = 3.531401886570261\n","Train Epoch #17, Batch 6648/24958 loss = 1.257143143415451, ppl = 3.5353836102117753\n","Train Epoch #17, Batch 6649/24958 loss = 1.2553065621852875, ppl = 3.529017113136324\n","Train Epoch #17, Batch 6650/24958 loss = 1.2535658717155456, ppl = 3.522606494521729\n","Train Epoch #17, Batch 6651/24958 loss = 1.2542708027362823, ppl = 3.525059727947635\n","Train Epoch #17, Batch 6652/24958 loss = 1.255991061925888, ppl = 3.531409055767519\n","Train Epoch #17, Batch 6653/24958 loss = 1.255442249774933, ppl = 3.529309716372189\n","Train Epoch #17, Batch 6654/24958 loss = 1.2539237844944, ppl = 3.523890625022375\n","Train Epoch #17, Batch 6655/24958 loss = 1.2522030341625214, ppl = 3.517978417381911\n","Train Epoch #17, Batch 6656/24958 loss = 1.2533670008182525, ppl = 3.521887785291111\n","Train Epoch #17, Batch 6657/24958 loss = 1.2550642788410187, ppl = 3.5286791449073696\n","Train Epoch #17, Batch 6658/24958 loss = 1.2513071405887604, ppl = 3.5161227957261136\n","Train Epoch #17, Batch 6659/24958 loss = 1.2521421217918396, ppl = 3.5191440198277917\n","Train Epoch #17, Batch 6660/24958 loss = 1.2498567509651184, ppl = 3.510926042408491\n","Train Epoch #17, Batch 6661/24958 loss = 1.2506282484531404, ppl = 3.5137926026906126\n","Train Epoch #17, Batch 6662/24958 loss = 1.2520603942871094, ppl = 3.518925310002568\n","Train Epoch #17, Batch 6663/24958 loss = 1.2519003522396088, ppl = 3.5183074662089844\n","Train Epoch #17, Batch 6664/24958 loss = 1.252074509859085, ppl = 3.5189276966118666\n","Train Epoch #17, Batch 6665/24958 loss = 1.2507451045513154, ppl = 3.514420397615102\n","Train Epoch #17, Batch 6666/24958 loss = 1.2510346961021424, ppl = 3.5153824634769215\n","Train Epoch #17, Batch 6667/24958 loss = 1.2528150069713593, ppl = 3.521906812834713\n","Train Epoch #17, Batch 6668/24958 loss = 1.2527096283435821, ppl = 3.5215718423981315\n","Train Epoch #17, Batch 6669/24958 loss = 1.2547936475276946, ppl = 3.5286378004617207\n","Train Epoch #17, Batch 6670/24958 loss = 1.2542600846290588, ppl = 3.5264091831903874\n","Train Epoch #17, Batch 6671/24958 loss = 1.254426395893097, ppl = 3.5269911136777137\n","Train Epoch #17, Batch 6672/24958 loss = 1.2534778761863707, ppl = 3.5237811928869336\n","Train Epoch #17, Batch 6673/24958 loss = 1.2555821251869201, ppl = 3.5303390507789\n","Train Epoch #17, Batch 6674/24958 loss = 1.2566656374931335, ppl = 3.533863545948427\n","Train Epoch #17, Batch 6675/24958 loss = 1.2571185255050659, ppl = 3.5353599408241063\n","Train Epoch #17, Batch 6676/24958 loss = 1.258155983686447, ppl = 3.5388384223783733\n","Train Epoch #17, Batch 6677/24958 loss = 1.2597282612323761, ppl = 3.5443354858467835\n","Train Epoch #17, Batch 6678/24958 loss = 1.2605243802070618, ppl = 3.54716385882336\n","Train Epoch #17, Batch 6679/24958 loss = 1.259510062932968, ppl = 3.5435964544695167\n","Train Epoch #17, Batch 6680/24958 loss = 1.2591786801815033, ppl = 3.5422414435672267\n","Train Epoch #17, Batch 6681/24958 loss = 1.2603017485141754, ppl = 3.5465938524090963\n","Train Epoch #17, Batch 6682/24958 loss = 1.2606154847145081, ppl = 3.5477411906894876\n","Train Epoch #17, Batch 6683/24958 loss = 1.2591798615455627, ppl = 3.5420644615734407\n","Train Epoch #17, Batch 6684/24958 loss = 1.2589026188850403, ppl = 3.5411650553010774\n","Train Epoch #17, Batch 6685/24958 loss = 1.260577416419983, ppl = 3.5475317589985336\n","Train Epoch #17, Batch 6686/24958 loss = 1.2603689777851104, ppl = 3.546740938446732\n","Train Epoch #17, Batch 6687/24958 loss = 1.2620579671859742, ppl = 3.5536598517211933\n","Train Epoch #17, Batch 6688/24958 loss = 1.262625153064728, ppl = 3.5555505847976474\n","Train Epoch #17, Batch 6689/24958 loss = 1.2641800618171692, ppl = 3.5606714146735685\n","Train Epoch #17, Batch 6690/24958 loss = 1.262328987121582, ppl = 3.5548033260406093\n","Train Epoch #17, Batch 6691/24958 loss = 1.266129366159439, ppl = 3.5682398481953728\n","Train Epoch #17, Batch 6692/24958 loss = 1.2652119839191436, ppl = 3.5642393318081997\n","Train Epoch #17, Batch 6693/24958 loss = 1.2632314383983612, ppl = 3.557642057568732\n","Train Epoch #17, Batch 6694/24958 loss = 1.2601719498634338, ppl = 3.547374086169329\n","Train Epoch #17, Batch 6695/24958 loss = 1.2610138428211213, ppl = 3.5500808158516874\n","Train Epoch #17, Batch 6696/24958 loss = 1.2612604820728301, ppl = 3.5509901726965585\n","Train Epoch #17, Batch 6697/24958 loss = 1.26158949136734, ppl = 3.55214249075212\n","Train Epoch #17, Batch 6698/24958 loss = 1.264194015264511, ppl = 3.561550333744253\n","Train Epoch #17, Batch 6699/24958 loss = 1.2638831448554992, ppl = 3.5603459302135407\n","Train Epoch #17, Batch 6700/24958 loss = 1.2642166483402253, ppl = 3.5616308076320333\n","Train Epoch #17, Batch 6701/24958 loss = 1.2636187958717346, ppl = 3.559558457544024\n","Train Epoch #17, Batch 6702/24958 loss = 1.2648118555545806, ppl = 3.5642535266533546\n","Train Epoch #17, Batch 6703/24958 loss = 1.2641798961162567, ppl = 3.5619259451894845\n","Train Epoch #17, Batch 6704/24958 loss = 1.2656649672985076, ppl = 3.567063760758907\n","Train Epoch #17, Batch 6705/24958 loss = 1.2647063899040223, ppl = 3.56371201127821\n","Train Epoch #17, Batch 6706/24958 loss = 1.2632611989974976, ppl = 3.558667675000684\n","Train Epoch #17, Batch 6707/24958 loss = 1.261907126903534, ppl = 3.553949011874646\n","Train Epoch #17, Batch 6708/24958 loss = 1.2631485080718994, ppl = 3.558594899168853\n","Train Epoch #17, Batch 6709/24958 loss = 1.2611160588264465, ppl = 3.5520425433757765\n","Train Epoch #17, Batch 6710/24958 loss = 1.2610881209373475, ppl = 3.5519591483379718\n","Train Epoch #17, Batch 6711/24958 loss = 1.26219966173172, ppl = 3.555832564625504\n","Train Epoch #17, Batch 6712/24958 loss = 1.260670506954193, ppl = 3.5505909911661417\n","Train Epoch #17, Batch 6713/24958 loss = 1.2615745508670806, ppl = 3.553666823751475\n","Train Epoch #17, Batch 6714/24958 loss = 1.2608885896205901, ppl = 3.551273871878918\n","Train Epoch #17, Batch 6715/24958 loss = 1.2624719715118409, ppl = 3.5564491073061997\n","Train Epoch #17, Batch 6716/24958 loss = 1.2651407277584077, ppl = 3.5668107818670234\n","Train Epoch #17, Batch 6717/24958 loss = 1.2663036847114564, ppl = 3.5706951858128506\n","Train Epoch #17, Batch 6718/24958 loss = 1.2667813718318939, ppl = 3.5723038628887385\n","Train Epoch #17, Batch 6719/24958 loss = 1.2688461804389954, ppl = 3.579793275720093\n","Train Epoch #17, Batch 6720/24958 loss = 1.2687337362766267, ppl = 3.57936681853079\n","Train Epoch #17, Batch 6721/24958 loss = 1.2674396312236786, ppl = 3.5755321568521317\n","Train Epoch #17, Batch 6722/24958 loss = 1.2672108459472655, ppl = 3.5746898170295407\n","Train Epoch #17, Batch 6723/24958 loss = 1.2680515956878662, ppl = 3.5770840693005574\n","Train Epoch #17, Batch 6724/24958 loss = 1.2639976143836975, ppl = 3.562884143247734\n","Train Epoch #17, Batch 6725/24958 loss = 1.2649649679660797, ppl = 3.566387722248486\n","Train Epoch #17, Batch 6726/24958 loss = 1.2663349997997284, ppl = 3.572292408907905\n","Train Epoch #17, Batch 6727/24958 loss = 1.2666395127773284, ppl = 3.573416553439143\n","Train Epoch #17, Batch 6728/24958 loss = 1.2678848731517791, ppl = 3.5780409415340073\n","Train Epoch #17, Batch 6729/24958 loss = 1.2682488429546357, ppl = 3.579305141811636\n","Train Epoch #17, Batch 6730/24958 loss = 1.2692434358596802, ppl = 3.5825059782980992\n","Train Epoch #17, Batch 6731/24958 loss = 1.2677383160591125, ppl = 3.576993421896175\n","Train Epoch #17, Batch 6732/24958 loss = 1.26716784119606, ppl = 3.575225624907801\n","Train Epoch #17, Batch 6733/24958 loss = 1.2646609032154084, ppl = 3.5644004424284748\n","Train Epoch #17, Batch 6734/24958 loss = 1.2626443660259248, ppl = 3.5580249551625474\n","Train Epoch #17, Batch 6735/24958 loss = 1.2604955089092256, ppl = 3.5506179549988364\n","Train Epoch #17, Batch 6736/24958 loss = 1.26320960521698, ppl = 3.560902506015327\n","Train Epoch #17, Batch 6737/24958 loss = 1.2639615726470947, ppl = 3.563381848801673\n","Train Epoch #17, Batch 6738/24958 loss = 1.2665894412994385, ppl = 3.573231554645885\n","Train Epoch #17, Batch 6739/24958 loss = 1.2667741656303406, ppl = 3.5738686012804224\n","Train Epoch #17, Batch 6740/24958 loss = 1.2649746572971343, ppl = 3.5681688067027473\n","Train Epoch #17, Batch 6741/24958 loss = 1.2648393428325653, ppl = 3.5677272342444932\n","Train Epoch #17, Batch 6742/24958 loss = 1.2634066152572632, ppl = 3.5615583376959847\n","Train Epoch #17, Batch 6743/24958 loss = 1.2638150358200073, ppl = 3.562862261333491\n","Train Epoch #17, Batch 6744/24958 loss = 1.2637567400932312, ppl = 3.562655824673473\n","Train Epoch #17, Batch 6745/24958 loss = 1.2653568422794341, ppl = 3.567886067729035\n","Train Epoch #17, Batch 6746/24958 loss = 1.2656249117851257, ppl = 3.568812594078754\n","Train Epoch #17, Batch 6747/24958 loss = 1.2672778511047362, ppl = 3.5751679084491026\n","Train Epoch #17, Batch 6748/24958 loss = 1.2661372220516205, ppl = 3.5711003938323183\n","Train Epoch #17, Batch 6749/24958 loss = 1.2690680718421936, ppl = 3.5818548581751566\n","Train Epoch #17, Batch 6750/24958 loss = 1.2716514790058135, ppl = 3.591793555803495\n","Train Epoch #17, Batch 6751/24958 loss = 1.2718058037757873, ppl = 3.592354088283996\n","Train Epoch #17, Batch 6752/24958 loss = 1.2709910988807678, ppl = 3.589210810351529\n","Train Epoch #17, Batch 6753/24958 loss = 1.2706559491157532, ppl = 3.587984307134727\n","Train Epoch #17, Batch 6754/24958 loss = 1.2726759397983551, ppl = 3.5953817635679592\n","Train Epoch #17, Batch 6755/24958 loss = 1.2750866556167602, ppl = 3.603965486583633\n","Train Epoch #17, Batch 6756/24958 loss = 1.276319558620453, ppl = 3.608633930769269\n","Train Epoch #17, Batch 6757/24958 loss = 1.2735804498195649, ppl = 3.5982101419292314\n","Train Epoch #17, Batch 6758/24958 loss = 1.2755612087249757, ppl = 3.6042416036650184\n","Train Epoch #17, Batch 6759/24958 loss = 1.275590444803238, ppl = 3.604352028204813\n","Train Epoch #17, Batch 6760/24958 loss = 1.2772982907295227, ppl = 3.610312753725178\n","Train Epoch #17, Batch 6761/24958 loss = 1.274836869239807, ppl = 3.601889024417206\n","Train Epoch #17, Batch 6762/24958 loss = 1.2737579607963563, ppl = 3.5979548479582486\n","Train Epoch #17, Batch 6763/24958 loss = 1.2710683977603912, ppl = 3.588923522432866\n","Train Epoch #17, Batch 6764/24958 loss = 1.271534321308136, ppl = 3.5906369202563404\n","Train Epoch #17, Batch 6765/24958 loss = 1.2734604716300963, ppl = 3.597370696490911\n","Train Epoch #17, Batch 6766/24958 loss = 1.2743771636486054, ppl = 3.6006064345578244\n","Train Epoch #17, Batch 6767/24958 loss = 1.2749312329292297, ppl = 3.602885611373866\n","Train Epoch #17, Batch 6768/24958 loss = 1.275390909910202, ppl = 3.604373040954404\n","Train Epoch #17, Batch 6769/24958 loss = 1.2755097842216492, ppl = 3.6048222096766556\n","Train Epoch #17, Batch 6770/24958 loss = 1.274544872045517, ppl = 3.6010818304649854\n","Train Epoch #17, Batch 6771/24958 loss = 1.2755808985233308, ppl = 3.604933224381453\n","Train Epoch #17, Batch 6772/24958 loss = 1.2763646972179412, ppl = 3.60756363768731\n","Train Epoch #17, Batch 6773/24958 loss = 1.276506700515747, ppl = 3.6080578832133137\n","Train Epoch #17, Batch 6774/24958 loss = 1.2751823139190674, ppl = 3.6038004067218714\n","Train Epoch #17, Batch 6775/24958 loss = 1.2733072829246521, ppl = 3.598022356805038\n","Train Epoch #17, Batch 6776/24958 loss = 1.274055471420288, ppl = 3.60076463492625\n","Train Epoch #17, Batch 6777/24958 loss = 1.271958020925522, ppl = 3.5936157580215093\n","Train Epoch #17, Batch 6778/24958 loss = 1.273645088672638, ppl = 3.600408000337544\n","Train Epoch #17, Batch 6779/24958 loss = 1.2741809797286987, ppl = 3.602247636502164\n","Train Epoch #17, Batch 6780/24958 loss = 1.2721654784679413, ppl = 3.594906741826868\n","Train Epoch #17, Batch 6781/24958 loss = 1.2685530948638917, ppl = 3.582484695413726\n","Train Epoch #17, Batch 6782/24958 loss = 1.2692734289169312, ppl = 3.5852592382026067\n","Train Epoch #17, Batch 6783/24958 loss = 1.2676526021957397, ppl = 3.5797571604023437\n","Train Epoch #17, Batch 6784/24958 loss = 1.271341358423233, ppl = 3.59402970621255\n","Train Epoch #17, Batch 6785/24958 loss = 1.2688027536869049, ppl = 3.584773177106409\n","Train Epoch #17, Batch 6786/24958 loss = 1.268533127307892, ppl = 3.583774359130771\n","Train Epoch #17, Batch 6787/24958 loss = 1.2642230236530303, ppl = 3.5681852159101375\n","Train Epoch #17, Batch 6788/24958 loss = 1.2653619134426117, ppl = 3.5723214960931697\n","Train Epoch #17, Batch 6789/24958 loss = 1.266191474199295, ppl = 3.575397230572569\n","Train Epoch #17, Batch 6790/24958 loss = 1.2680533528327942, ppl = 3.5813028566875964\n","Train Epoch #17, Batch 6791/24958 loss = 1.266598116159439, ppl = 3.5755472585117913\n","Train Epoch #17, Batch 6792/24958 loss = 1.2661612117290497, ppl = 3.5737672319872984\n","Train Epoch #17, Batch 6793/24958 loss = 1.2662287187576293, ppl = 3.57397125485311\n","Train Epoch #17, Batch 6794/24958 loss = 1.2664198970794678, ppl = 3.5745249924350757\n","Train Epoch #17, Batch 6795/24958 loss = 1.267169816493988, ppl = 3.5771356017444766\n","Train Epoch #17, Batch 6796/24958 loss = 1.2656372940540315, ppl = 3.571832007424084\n","Train Epoch #17, Batch 6797/24958 loss = 1.266405508518219, ppl = 3.574674895682764\n","Train Epoch #17, Batch 6798/24958 loss = 1.2646632850170136, ppl = 3.5681147649880063\n","Train Epoch #17, Batch 6799/24958 loss = 1.263879305124283, ppl = 3.5652385793447787\n","Train Epoch #17, Batch 6800/24958 loss = 1.2613898348808288, ppl = 3.556605757081026\n","Train Epoch #17, Batch 6801/24958 loss = 1.2634454798698425, ppl = 3.564282420317603\n","Train Epoch #17, Batch 6802/24958 loss = 1.2617431557178498, ppl = 3.5577476508776273\n","Train Epoch #17, Batch 6803/24958 loss = 1.2620226335525513, ppl = 3.558758883058926\n","Train Epoch #17, Batch 6804/24958 loss = 1.2591873383522034, ppl = 3.5495678467718377\n","Train Epoch #17, Batch 6805/24958 loss = 1.2581199419498443, ppl = 3.5461948453219234\n","Train Epoch #17, Batch 6806/24958 loss = 1.2584261035919189, ppl = 3.5472034824948975\n","Train Epoch #17, Batch 6807/24958 loss = 1.2589281678199769, ppl = 3.5488790009935385\n","Train Epoch #17, Batch 6808/24958 loss = 1.2582253730297088, ppl = 3.5461781672126564\n","Train Epoch #17, Batch 6809/24958 loss = 1.2589482843875885, ppl = 3.5483577525380112\n","Train Epoch #17, Batch 6810/24958 loss = 1.2610154509544373, ppl = 3.555202796191551\n","Train Epoch #17, Batch 6811/24958 loss = 1.2616909980773925, ppl = 3.557776091121257\n","Train Epoch #17, Batch 6812/24958 loss = 1.2634449446201323, ppl = 3.5638580203537757\n","Train Epoch #17, Batch 6813/24958 loss = 1.2624304115772247, ppl = 3.5604249834170814\n","Train Epoch #17, Batch 6814/24958 loss = 1.2617130839824677, ppl = 3.5580921278277624\n","Train Epoch #17, Batch 6815/24958 loss = 1.2602938401699066, ppl = 3.553416106209945\n","Train Epoch #17, Batch 6816/24958 loss = 1.2568248808383942, ppl = 3.5404493485689903\n","Train Epoch #17, Batch 6817/24958 loss = 1.2551949298381806, ppl = 3.5351278912172237\n","Train Epoch #17, Batch 6818/24958 loss = 1.2574173951148986, ppl = 3.5437110181884943\n","Train Epoch #17, Batch 6819/24958 loss = 1.2568143475055695, ppl = 3.541361623996638\n","Train Epoch #17, Batch 6820/24958 loss = 1.2581166410446167, ppl = 3.5466071522180402\n","Train Epoch #17, Batch 6821/24958 loss = 1.2618287158012391, ppl = 3.5590829233637886\n","Train Epoch #17, Batch 6822/24958 loss = 1.2607049131393433, ppl = 3.5552139362501367\n","Train Epoch #17, Batch 6823/24958 loss = 1.2628834998607636, ppl = 3.562441179876639\n","Train Epoch #17, Batch 6824/24958 loss = 1.2637899661064147, ppl = 3.565136357098514\n","Train Epoch #17, Batch 6825/24958 loss = 1.2640230548381806, ppl = 3.566032455564129\n","Train Epoch #17, Batch 6826/24958 loss = 1.262265580892563, ppl = 3.558599507929212\n","Train Epoch #17, Batch 6827/24958 loss = 1.2609971249103546, ppl = 3.554134375675793\n","Train Epoch #17, Batch 6828/24958 loss = 1.2602461338043214, ppl = 3.551277110440624\n","Train Epoch #17, Batch 6829/24958 loss = 1.261563252210617, ppl = 3.556256425644025\n","Train Epoch #17, Batch 6830/24958 loss = 1.2613815093040466, ppl = 3.5556475152292917\n","Train Epoch #17, Batch 6831/24958 loss = 1.2614221024513244, ppl = 3.555785561077462\n","Train Epoch #17, Batch 6832/24958 loss = 1.2625982511043548, ppl = 3.5595439484039186\n","Train Epoch #17, Batch 6833/24958 loss = 1.2620068895816803, ppl = 3.557362260648188\n","Train Epoch #17, Batch 6834/24958 loss = 1.2644421660900116, ppl = 3.56523063988044\n","Train Epoch #17, Batch 6835/24958 loss = 1.2667067289352416, ppl = 3.573083430942653\n","Train Epoch #17, Batch 6836/24958 loss = 1.2643848299980163, ppl = 3.564118172254413\n","Train Epoch #17, Batch 6837/24958 loss = 1.266783744096756, ppl = 3.573397388841621\n","Train Epoch #17, Batch 6838/24958 loss = 1.2676066517829896, ppl = 3.5770531431891\n","Train Epoch #17, Batch 6839/24958 loss = 1.2673980438709258, ppl = 3.5763345866029614\n","Train Epoch #17, Batch 6840/24958 loss = 1.2695978426933288, ppl = 3.583447868162763\n","Train Epoch #17, Batch 6841/24958 loss = 1.2690981233119965, ppl = 3.581867944013966\n","Train Epoch #17, Batch 6842/24958 loss = 1.269105192422867, ppl = 3.5818962631176148\n","Train Epoch #17, Batch 6843/24958 loss = 1.2703996467590333, ppl = 3.5863990535803207\n","Train Epoch #17, Batch 6844/24958 loss = 1.2702189779281616, ppl = 3.5857668607309767\n","Train Epoch #17, Batch 6845/24958 loss = 1.2700680124759673, ppl = 3.5852368797974994\n","Train Epoch #17, Batch 6846/24958 loss = 1.26890109539032, ppl = 3.5813788506162676\n","Train Epoch #17, Batch 6847/24958 loss = 1.2649831616878509, ppl = 3.567857086589633\n","Train Epoch #17, Batch 6848/24958 loss = 1.264155648946762, ppl = 3.565183401654069\n","Train Epoch #17, Batch 6849/24958 loss = 1.26242822766304, ppl = 3.5584673788279546\n","Train Epoch #17, Batch 6850/24958 loss = 1.261177315711975, ppl = 3.5533343439237854\n","Train Epoch #17, Batch 6851/24958 loss = 1.2617409479618074, ppl = 3.5554566322890593\n","Train Epoch #17, Batch 6852/24958 loss = 1.2628100633621215, ppl = 3.559635111154539\n","Train Epoch #17, Batch 6853/24958 loss = 1.2638142240047454, ppl = 3.563436326539437\n","Train Epoch #17, Batch 6854/24958 loss = 1.2638731920719146, ppl = 3.56367552394916\n","Train Epoch #17, Batch 6855/24958 loss = 1.265050300359726, ppl = 3.5686811024893963\n","Train Epoch #17, Batch 6856/24958 loss = 1.264472883939743, ppl = 3.5664229596816313\n","Train Epoch #17, Batch 6857/24958 loss = 1.26546635389328, ppl = 3.5698782676710668\n","Train Epoch #17, Batch 6858/24958 loss = 1.2667805409431458, ppl = 3.57459237792242\n","Train Epoch #17, Batch 6859/24958 loss = 1.2674171793460847, ppl = 3.577078782410426\n","Train Epoch #17, Batch 6860/24958 loss = 1.2653970122337341, ppl = 3.5701338769981095\n","Train Epoch #17, Batch 6861/24958 loss = 1.266029895544052, ppl = 3.572105902592178\n","Train Epoch #17, Batch 6862/24958 loss = 1.2663728499412537, ppl = 3.573310758865278\n","Train Epoch #17, Batch 6863/24958 loss = 1.2691035997867584, ppl = 3.582500142762637\n","Train Epoch #17, Batch 6864/24958 loss = 1.2685888266563417, ppl = 3.5806116847466463\n","Train Epoch #17, Batch 6865/24958 loss = 1.2651720821857453, ppl = 3.569487902766548\n","Train Epoch #17, Batch 6866/24958 loss = 1.2657995736598968, ppl = 3.5718801631771906\n","Train Epoch #17, Batch 6867/24958 loss = 1.2636966025829315, ppl = 3.563860470957197\n","Train Epoch #17, Batch 6868/24958 loss = 1.264485776424408, ppl = 3.566579095586217\n","Train Epoch #17, Batch 6869/24958 loss = 1.265756618976593, ppl = 3.571729961132047\n","Train Epoch #17, Batch 6870/24958 loss = 1.2664850187301635, ppl = 3.574519865866687\n","Train Epoch #17, Batch 6871/24958 loss = 1.2660745990276336, ppl = 3.5729462583057043\n","Train Epoch #17, Batch 6872/24958 loss = 1.2661149525642394, ppl = 3.5730873451207055\n","Train Epoch #17, Batch 6873/24958 loss = 1.2653482282161712, ppl = 3.5705002008367135\n","Train Epoch #17, Batch 6874/24958 loss = 1.266033124923706, ppl = 3.5726314967066854\n","Train Epoch #17, Batch 6875/24958 loss = 1.270256780385971, ppl = 3.5873562620946213\n","Train Epoch #17, Batch 6876/24958 loss = 1.2689825916290283, ppl = 3.582805283932485\n","Train Epoch #17, Batch 6877/24958 loss = 1.2693788421154022, ppl = 3.5840435313867527\n","Train Epoch #17, Batch 6878/24958 loss = 1.2680254244804383, ppl = 3.5785052617161353\n","Train Epoch #17, Batch 6879/24958 loss = 1.2685727846622468, ppl = 3.5804888584326653\n","Train Epoch #17, Batch 6880/24958 loss = 1.2706151843070983, ppl = 3.5879380728323254\n","Train Epoch #17, Batch 6881/24958 loss = 1.2745301115512848, ppl = 3.6016186291896357\n","Train Epoch #17, Batch 6882/24958 loss = 1.27134361743927, ppl = 3.5907253018436167\n","Train Epoch #17, Batch 6883/24958 loss = 1.2731667733192444, ppl = 3.5969789507369967\n","Train Epoch #17, Batch 6884/24958 loss = 1.2711964344978333, ppl = 3.5887048618520523\n","Train Epoch #17, Batch 6885/24958 loss = 1.2725419700145721, ppl = 3.5933180705190337\n","Train Epoch #17, Batch 6886/24958 loss = 1.2706117594242097, ppl = 3.58690271634537\n","Train Epoch #17, Batch 6887/24958 loss = 1.2734464967250825, ppl = 3.5963848678337325\n","Train Epoch #17, Batch 6888/24958 loss = 1.2743289029598237, ppl = 3.599929693705288\n","Train Epoch #17, Batch 6889/24958 loss = 1.272527220249176, ppl = 3.593559798215963\n","Train Epoch #17, Batch 6890/24958 loss = 1.2727790570259094, ppl = 3.5944463759830723\n","Train Epoch #17, Batch 6891/24958 loss = 1.2708951115608216, ppl = 3.588137170579493\n","Train Epoch #17, Batch 6892/24958 loss = 1.2702830755710601, ppl = 3.585770854391382\n","Train Epoch #17, Batch 6893/24958 loss = 1.2708911156654359, ppl = 3.5876719215679436\n","Train Epoch #17, Batch 6894/24958 loss = 1.2742614591121673, ppl = 3.5993918224495407\n","Train Epoch #17, Batch 6895/24958 loss = 1.2753575313091279, ppl = 3.6035775143561715\n","Train Epoch #17, Batch 6896/24958 loss = 1.274702044725418, ppl = 3.6015457745855226\n","Train Epoch #17, Batch 6897/24958 loss = 1.2758350896835327, ppl = 3.6061582628537434\n","Train Epoch #17, Batch 6898/24958 loss = 1.2771345460414887, ppl = 3.6109413924531792\n","Train Epoch #17, Batch 6899/24958 loss = 1.276887320280075, ppl = 3.610080174226527\n","Train Epoch #17, Batch 6900/24958 loss = 1.2787136471271514, ppl = 3.616199546911348\n","Train Epoch #17, Batch 6901/24958 loss = 1.2776588606834411, ppl = 3.6120637500638333\n","Train Epoch #17, Batch 6902/24958 loss = 1.2754091477394105, ppl = 3.604969786990677\n","Train Epoch #17, Batch 6903/24958 loss = 1.2733833384513855, ppl = 3.598241427261578\n","Train Epoch #17, Batch 6904/24958 loss = 1.2751372480392456, ppl = 3.6036166220887975\n","Train Epoch #17, Batch 6905/24958 loss = 1.2762043499946594, ppl = 3.6069886425511055\n","Train Epoch #17, Batch 6906/24958 loss = 1.275657376050949, ppl = 3.6052080734512\n","Train Epoch #17, Batch 6907/24958 loss = 1.2762967538833618, ppl = 3.6074673114449443\n","Train Epoch #17, Batch 6908/24958 loss = 1.2766373932361603, ppl = 3.6087526918051354\n","Train Epoch #17, Batch 6909/24958 loss = 1.27809903383255, ppl = 3.6136714823290195\n","Train Epoch #17, Batch 6910/24958 loss = 1.2783245635032654, ppl = 3.6145075201483303\n","Train Epoch #17, Batch 6911/24958 loss = 1.2787633097171784, ppl = 3.616274355679018\n","Train Epoch #17, Batch 6912/24958 loss = 1.2776433801651002, ppl = 3.6122688844185307\n","Train Epoch #17, Batch 6913/24958 loss = 1.2777129125595093, ppl = 3.6124932176814766\n","Train Epoch #17, Batch 6914/24958 loss = 1.2786002671718597, ppl = 3.6154039950188097\n","Train Epoch #17, Batch 6915/24958 loss = 1.279179221391678, ppl = 3.6172317302795465\n","Train Epoch #17, Batch 6916/24958 loss = 1.2826309430599212, ppl = 3.63012229959509\n","Train Epoch #17, Batch 6917/24958 loss = 1.2846102905273438, ppl = 3.6367018042596992\n","Train Epoch #17, Batch 6918/24958 loss = 1.281852685213089, ppl = 3.6263216455765956\n","Train Epoch #17, Batch 6919/24958 loss = 1.2813527262210846, ppl = 3.624478470389014\n","Train Epoch #17, Batch 6920/24958 loss = 1.2800120735168456, ppl = 3.619088554201328\n","Train Epoch #17, Batch 6921/24958 loss = 1.2784108781814576, ppl = 3.6131359722871896\n","Train Epoch #17, Batch 6922/24958 loss = 1.279893674850464, ppl = 3.6183353763088792\n","Train Epoch #17, Batch 6923/24958 loss = 1.2803591942787171, ppl = 3.6200946458411396\n","Train Epoch #17, Batch 6924/24958 loss = 1.2812964022159576, ppl = 3.6231503885184315\n","Train Epoch #17, Batch 6925/24958 loss = 1.2797283720970154, ppl = 3.6175057521607794\n","Train Epoch #17, Batch 6926/24958 loss = 1.2787587189674376, ppl = 3.613930710410138\n","Train Epoch #17, Batch 6927/24958 loss = 1.2788544368743897, ppl = 3.614248249340636\n","Train Epoch #17, Batch 6928/24958 loss = 1.2789420509338378, ppl = 3.614570641041752\n","Train Epoch #17, Batch 6929/24958 loss = 1.276854784488678, ppl = 3.6069695953380427\n","Train Epoch #17, Batch 6930/24958 loss = 1.2777809858322144, ppl = 3.6101915267716493\n","Train Epoch #17, Batch 6931/24958 loss = 1.2762677955627442, ppl = 3.605406315791205\n","Train Epoch #17, Batch 6932/24958 loss = 1.2763589525222778, ppl = 3.6057164856224437\n","Train Epoch #17, Batch 6933/24958 loss = 1.275789076089859, ppl = 3.6037326771013802\n","Train Epoch #17, Batch 6934/24958 loss = 1.2765222454071046, ppl = 3.606501963266471\n","Train Epoch #17, Batch 6935/24958 loss = 1.276563892364502, ppl = 3.606663687229948\n","Train Epoch #17, Batch 6936/24958 loss = 1.2751845407485962, ppl = 3.6022439956338475\n","Train Epoch #17, Batch 6937/24958 loss = 1.2714059960842132, ppl = 3.588554024643358\n","Train Epoch #17, Batch 6938/24958 loss = 1.2692221760749818, ppl = 3.5794751711370543\n","Train Epoch #17, Batch 6939/24958 loss = 1.27060795545578, ppl = 3.584541878502656\n","Train Epoch #17, Batch 6940/24958 loss = 1.2697975635528564, ppl = 3.581737760829034\n","Train Epoch #17, Batch 6941/24958 loss = 1.2729522931575774, ppl = 3.5931738952908496\n","Train Epoch #17, Batch 6942/24958 loss = 1.2727773535251616, ppl = 3.5924789298854676\n","Train Epoch #17, Batch 6943/24958 loss = 1.2739917707443238, ppl = 3.5972675021526097\n","Train Epoch #17, Batch 6944/24958 loss = 1.2754135918617249, ppl = 3.602565629986644\n","Train Epoch #17, Batch 6945/24958 loss = 1.2742759037017821, ppl = 3.5988188928708578\n","Train Epoch #17, Batch 6946/24958 loss = 1.2762028539180756, ppl = 3.605442967879095\n","Train Epoch #17, Batch 6947/24958 loss = 1.2788822317123414, ppl = 3.614105392632788\n","Train Epoch #17, Batch 6948/24958 loss = 1.2806321430206298, ppl = 3.6200320699275053\n","Train Epoch #17, Batch 6949/24958 loss = 1.2816294586658479, ppl = 3.6237674312872112\n","Train Epoch #17, Batch 6950/24958 loss = 1.2816509652137755, ppl = 3.623850366496874\n","Train Epoch #17, Batch 6951/24958 loss = 1.2805109429359436, ppl = 3.6196779907161516\n","Train Epoch #17, Batch 6952/24958 loss = 1.2798677778244019, ppl = 3.6171109454140957\n","Train Epoch #17, Batch 6953/24958 loss = 1.2777096807956696, ppl = 3.609387824318963\n","Train Epoch #17, Batch 6954/24958 loss = 1.2777404356002808, ppl = 3.6095131385521784\n","Train Epoch #17, Batch 6955/24958 loss = 1.2744985818862915, ppl = 3.5970322555001553\n","Train Epoch #17, Batch 6956/24958 loss = 1.2749498331546782, ppl = 3.598785803201667\n","Train Epoch #17, Batch 6957/24958 loss = 1.2768991208076477, ppl = 3.606649339724649\n","Train Epoch #17, Batch 6958/24958 loss = 1.277664351463318, ppl = 3.609693604134489\n","Train Epoch #17, Batch 6959/24958 loss = 1.2768280577659608, ppl = 3.6064594886535155\n","Train Epoch #17, Batch 6960/24958 loss = 1.2772188460826874, ppl = 3.6076958018046503\n","Train Epoch #17, Batch 6961/24958 loss = 1.277118785381317, ppl = 3.60737565300596\n","Train Epoch #17, Batch 6962/24958 loss = 1.2755801618099212, ppl = 3.6022791223196164\n","Train Epoch #17, Batch 6963/24958 loss = 1.2742268097400666, ppl = 3.597411600439255\n","Train Epoch #17, Batch 6964/24958 loss = 1.272965774536133, ppl = 3.5931761729003724\n","Train Epoch #17, Batch 6965/24958 loss = 1.2774188172817231, ppl = 3.6084966285157467\n","Train Epoch #17, Batch 6966/24958 loss = 1.2774296629428863, ppl = 3.608539310710575\n","Train Epoch #17, Batch 6967/24958 loss = 1.278965127468109, ppl = 3.614226104845902\n","Train Epoch #17, Batch 6968/24958 loss = 1.2780694818496705, ppl = 3.6111568480714418\n","Train Epoch #17, Batch 6969/24958 loss = 1.2764791023731232, ppl = 3.6048106158932933\n","Train Epoch #17, Batch 6970/24958 loss = 1.2748433172702789, ppl = 3.598817808801747\n","Train Epoch #17, Batch 6971/24958 loss = 1.2734094595909118, ppl = 3.593800535063983\n","Train Epoch #17, Batch 6972/24958 loss = 1.27255939245224, ppl = 3.5909455370782415\n","Train Epoch #17, Batch 6973/24958 loss = 1.2744043350219727, ppl = 3.5975234307801576\n","Train Epoch #17, Batch 6974/24958 loss = 1.2754732704162597, ppl = 3.601155682744492\n","Train Epoch #17, Batch 6975/24958 loss = 1.2726536965370179, ppl = 3.590654289223936\n","Train Epoch #17, Batch 6976/24958 loss = 1.2724269819259644, ppl = 3.589903575528932\n","Train Epoch #17, Batch 6977/24958 loss = 1.2711825346946717, ppl = 3.586174101803347\n","Train Epoch #17, Batch 6978/24958 loss = 1.2714338302612305, ppl = 3.58714656871037\n","Train Epoch #17, Batch 6979/24958 loss = 1.2706203985214233, ppl = 3.5842372644916463\n","Train Epoch #17, Batch 6980/24958 loss = 1.268901697397232, ppl = 3.577869617832277\n","Train Epoch #17, Batch 6981/24958 loss = 1.2677317798137664, ppl = 3.5732071033870083\n","Train Epoch #17, Batch 6982/24958 loss = 1.2715689885616301, ppl = 3.586784555680328\n","Train Epoch #17, Batch 6983/24958 loss = 1.2700313782691957, ppl = 3.5814366598342593\n","Train Epoch #17, Batch 6984/24958 loss = 1.2708519530296325, ppl = 3.584685663227444\n","Train Epoch #17, Batch 6985/24958 loss = 1.2694242680072785, ppl = 3.579810404202629\n","Train Epoch #17, Batch 6986/24958 loss = 1.2694806027412415, ppl = 3.579980631062225\n","Train Epoch #17, Batch 6987/24958 loss = 1.270919407606125, ppl = 3.5859251423836294\n","Train Epoch #17, Batch 6988/24958 loss = 1.2712842476367952, ppl = 3.587484679181847\n","Train Epoch #17, Batch 6989/24958 loss = 1.274294137954712, ppl = 3.5988162847654515\n","Train Epoch #17, Batch 6990/24958 loss = 1.275358020067215, ppl = 3.602818081099974\n","Train Epoch #17, Batch 6991/24958 loss = 1.2783754134178162, ppl = 3.613537099183641\n","Train Epoch #17, Batch 6992/24958 loss = 1.2788817882537842, ppl = 3.615484485633\n","Train Epoch #17, Batch 6993/24958 loss = 1.27989443898201, ppl = 3.6189187713766957\n","Train Epoch #17, Batch 6994/24958 loss = 1.278089212179184, ppl = 3.6121532137095658\n","Train Epoch #17, Batch 6995/24958 loss = 1.2767973446846008, ppl = 3.6072669262589456\n","Train Epoch #17, Batch 6996/24958 loss = 1.2788759684562683, ppl = 3.614196188851667\n","Train Epoch #17, Batch 6997/24958 loss = 1.2754316568374633, ppl = 3.6016499260522763\n","Train Epoch #17, Batch 6998/24958 loss = 1.2738525986671447, ppl = 3.595916388089945\n","Train Epoch #17, Batch 6999/24958 loss = 1.273832745552063, ppl = 3.5958481483101643\n","Train Epoch #17, Batch 7000/24958 loss = 1.2724988675117492, ppl = 3.591270352449016\n","Train Epoch #17, Batch 7001/24958 loss = 1.2720763385295868, ppl = 3.589732188379668\n","Train Epoch #17, Batch 7002/24958 loss = 1.2718107795715332, ppl = 3.5889953001357497\n","Train Epoch #17, Batch 7003/24958 loss = 1.272936874628067, ppl = 3.5925666773423983\n","Train Epoch #17, Batch 7004/24958 loss = 1.2724099600315093, ppl = 3.5908516745940036\n","Train Epoch #17, Batch 7005/24958 loss = 1.2707001650333405, ppl = 3.585615727285817\n","Train Epoch #17, Batch 7006/24958 loss = 1.2710658633708953, ppl = 3.5867953656633063\n","Train Epoch #17, Batch 7007/24958 loss = 1.270288417339325, ppl = 3.5840669411574684\n","Train Epoch #17, Batch 7008/24958 loss = 1.2686749005317688, ppl = 3.57834794031937\n","Train Epoch #17, Batch 7009/24958 loss = 1.2687241756916046, ppl = 3.578526617382819\n","Train Epoch #17, Batch 7010/24958 loss = 1.2673210740089416, ppl = 3.5736188076591917\n","Train Epoch #17, Batch 7011/24958 loss = 1.2663992393016814, ppl = 3.5699941700440716\n","Train Epoch #17, Batch 7012/24958 loss = 1.2671108043193817, ppl = 3.5724868967164762\n","Train Epoch #17, Batch 7013/24958 loss = 1.2669187235832213, ppl = 3.5718709615539144\n","Train Epoch #17, Batch 7014/24958 loss = 1.2660485410690308, ppl = 3.569014097643917\n","Train Epoch #17, Batch 7015/24958 loss = 1.2667010378837587, ppl = 3.5712049064054234\n","Train Epoch #17, Batch 7016/24958 loss = 1.2643440997600555, ppl = 3.56193216037903\n","Train Epoch #17, Batch 7017/24958 loss = 1.2636416792869567, ppl = 3.559446870816797\n","Train Epoch #17, Batch 7018/24958 loss = 1.2644677770137787, ppl = 3.562262072111108\n","Train Epoch #17, Batch 7019/24958 loss = 1.2662507581710816, ppl = 3.5692793607042694\n","Train Epoch #17, Batch 7020/24958 loss = 1.2653605091571807, ppl = 3.5660793456388715\n","Train Epoch #17, Batch 7021/24958 loss = 1.2656050205230713, ppl = 3.566927836317577\n","Train Epoch #17, Batch 7022/24958 loss = 1.2666617047786712, ppl = 3.571132832142873\n","Train Epoch #17, Batch 7023/24958 loss = 1.265250301361084, ppl = 3.5660415481008005\n","Train Epoch #17, Batch 7024/24958 loss = 1.265944973230362, ppl = 3.5684986589047893\n","Train Epoch #17, Batch 7025/24958 loss = 1.2675152027606964, ppl = 3.574151850662289\n","Train Epoch #17, Batch 7026/24958 loss = 1.2669558751583099, ppl = 3.572241926797079\n","Train Epoch #17, Batch 7027/24958 loss = 1.2695815753936768, ppl = 3.5822508870159977\n","Train Epoch #17, Batch 7028/24958 loss = 1.2695097637176513, ppl = 3.5819864344397603\n","Train Epoch #17, Batch 7029/24958 loss = 1.2705537045001984, ppl = 3.585589937506855\n","Train Epoch #17, Batch 7030/24958 loss = 1.2703975045681, ppl = 3.5850254409602615\n","Train Epoch #17, Batch 7031/24958 loss = 1.2719003403186797, ppl = 3.5897753858845727\n","Train Epoch #17, Batch 7032/24958 loss = 1.2711865270137788, ppl = 3.5874205304801525\n","Train Epoch #17, Batch 7033/24958 loss = 1.271760218143463, ppl = 3.589418003003132\n","Train Epoch #17, Batch 7034/24958 loss = 1.271903817653656, ppl = 3.58998458369618\n","Train Epoch #17, Batch 7035/24958 loss = 1.2697860205173492, ppl = 3.5825577549686085\n","Train Epoch #17, Batch 7036/24958 loss = 1.2697918868064881, ppl = 3.582575290194273\n","Train Epoch #17, Batch 7037/24958 loss = 1.2710703599452973, ppl = 3.5866415622184\n","Train Epoch #17, Batch 7038/24958 loss = 1.2692199921607972, ppl = 3.5803576849564975\n","Train Epoch #17, Batch 7039/24958 loss = 1.2675694143772125, ppl = 3.5744001975339814\n","Train Epoch #17, Batch 7040/24958 loss = 1.2679289507865905, ppl = 3.5756162669703544\n","Train Epoch #17, Batch 7041/24958 loss = 1.2658213925361634, ppl = 3.567583969790214\n","Train Epoch #17, Batch 7042/24958 loss = 1.2643327498435974, ppl = 3.5621372301955883\n","Train Epoch #17, Batch 7043/24958 loss = 1.2612077617645263, ppl = 3.550899002369549\n","Train Epoch #17, Batch 7044/24958 loss = 1.2593327403068542, ppl = 3.5440644064719886\n","Train Epoch #17, Batch 7045/24958 loss = 1.260012755393982, ppl = 3.546252469209267\n","Train Epoch #17, Batch 7046/24958 loss = 1.2594270884990693, ppl = 3.544102553759422\n","Train Epoch #17, Batch 7047/24958 loss = 1.2588882339000702, ppl = 3.5421691960756094\n","Train Epoch #17, Batch 7048/24958 loss = 1.257321652173996, ppl = 3.536815924477691\n","Train Epoch #17, Batch 7049/24958 loss = 1.2532411605119704, ppl = 3.5236305939781003\n","Train Epoch #17, Batch 7050/24958 loss = 1.2532475143671036, ppl = 3.5236551303561208\n","Train Epoch #17, Batch 7051/24958 loss = 1.2538980203866958, ppl = 3.525977509394682\n","Train Epoch #17, Batch 7052/24958 loss = 1.2538933449983596, ppl = 3.52595944654706\n","Train Epoch #17, Batch 7053/24958 loss = 1.2524995082616805, ppl = 3.521787741747195\n","Train Epoch #17, Batch 7054/24958 loss = 1.2513041907548905, ppl = 3.5171900389276844\n","Train Epoch #17, Batch 7055/24958 loss = 1.2532831007242202, ppl = 3.5243228669659037\n","Train Epoch #17, Batch 7056/24958 loss = 1.2530096739530563, ppl = 3.5232509077206964\n","Train Epoch #17, Batch 7057/24958 loss = 1.2505659586191178, ppl = 3.5136248391618725\n","Train Epoch #17, Batch 7058/24958 loss = 1.2496667259931564, ppl = 3.510071042244241\n","Train Epoch #17, Batch 7059/24958 loss = 1.250843032002449, ppl = 3.5146993699038664\n","Train Epoch #17, Batch 7060/24958 loss = 1.2512192624807357, ppl = 3.5159361556557105\n","Train Epoch #17, Batch 7061/24958 loss = 1.2519383698701858, ppl = 3.518309803420865\n","Train Epoch #17, Batch 7062/24958 loss = 1.252168238759041, ppl = 3.5190223027655834\n","Train Epoch #17, Batch 7063/24958 loss = 1.251840700507164, ppl = 3.517940004133393\n","Train Epoch #17, Batch 7064/24958 loss = 1.2532817739248276, ppl = 3.5228248811888188\n","Train Epoch #17, Batch 7065/24958 loss = 1.2517493027448654, ppl = 3.5167677211034056\n","Train Epoch #17, Batch 7066/24958 loss = 1.2501067405939101, ppl = 3.5108032994280696\n","Train Epoch #17, Batch 7067/24958 loss = 1.249883090853691, ppl = 3.5099196819092464\n","Train Epoch #17, Batch 7068/24958 loss = 1.2499936252832413, ppl = 3.5102837672388953\n","Train Epoch #17, Batch 7069/24958 loss = 1.2478606754541397, ppl = 3.5032122905851395\n","Train Epoch #17, Batch 7070/24958 loss = 1.2481531709432603, ppl = 3.5042131785037283\n","Train Epoch #17, Batch 7071/24958 loss = 1.2508491414785385, ppl = 3.5142830931728093\n","Train Epoch #17, Batch 7072/24958 loss = 1.2522050577402115, ppl = 3.518955834139702\n","Train Epoch #17, Batch 7073/24958 loss = 1.2498473244905473, ppl = 3.5107550903188183\n","Train Epoch #17, Batch 7074/24958 loss = 1.249056653380394, ppl = 3.5080313281189155\n","Train Epoch #17, Batch 7075/24958 loss = 1.2521937173604964, ppl = 3.519911500811809\n","Train Epoch #17, Batch 7076/24958 loss = 1.2543098610639571, ppl = 3.52762709089373\n","Train Epoch #17, Batch 7077/24958 loss = 1.2559948164224624, ppl = 3.532791949093728\n","Train Epoch #17, Batch 7078/24958 loss = 1.2568240422010422, ppl = 3.5361799148808486\n","Train Epoch #17, Batch 7079/24958 loss = 1.2561183685064317, ppl = 3.533840779399664\n","Train Epoch #17, Batch 7080/24958 loss = 1.255226280093193, ppl = 3.530942745120798\n","Train Epoch #17, Batch 7081/24958 loss = 1.2553512901067734, ppl = 3.531415324780356\n","Train Epoch #17, Batch 7082/24958 loss = 1.2549093931913375, ppl = 3.5295735935239247\n","Train Epoch #17, Batch 7083/24958 loss = 1.2568735021352768, ppl = 3.5365564586036005\n","Train Epoch #17, Batch 7084/24958 loss = 1.2555772000551224, ppl = 3.5315423915459387\n","Train Epoch #17, Batch 7085/24958 loss = 1.256799675822258, ppl = 3.535673352655449\n","Train Epoch #17, Batch 7086/24958 loss = 1.2602239221334457, ppl = 3.548047515945986\n","Train Epoch #17, Batch 7087/24958 loss = 1.2570200377702714, ppl = 3.5358872172996985\n","Train Epoch #17, Batch 7088/24958 loss = 1.2552935093641282, ppl = 3.5289846066796184\n","Train Epoch #17, Batch 7089/24958 loss = 1.2528109210729599, ppl = 3.519400044477997\n","Train Epoch #17, Batch 7090/24958 loss = 1.2505945855379104, ppl = 3.5115176983762257\n","Train Epoch #17, Batch 7091/24958 loss = 1.2474477118253708, ppl = 3.500407163654025\n","Train Epoch #17, Batch 7092/24958 loss = 1.2488723641633988, ppl = 3.5064458359087896\n","Train Epoch #17, Batch 7093/24958 loss = 1.2472418183088303, ppl = 3.5010806127301892\n","Train Epoch #17, Batch 7094/24958 loss = 1.2486825948953628, ppl = 3.5063801817971396\n","Train Epoch #17, Batch 7095/24958 loss = 1.246164122223854, ppl = 3.4984915264262697\n","Train Epoch #17, Batch 7096/24958 loss = 1.2456307274103164, ppl = 3.4965738114915506\n","Train Epoch #17, Batch 7097/24958 loss = 1.2464866250753404, ppl = 3.4993003713037747\n","Train Epoch #17, Batch 7098/24958 loss = 1.2468757802248, ppl = 3.5006304741612344\n","Train Epoch #17, Batch 7099/24958 loss = 1.247021388411522, ppl = 3.501134124641125\n","Train Epoch #17, Batch 7100/24958 loss = 1.2475503724813461, ppl = 3.5028768685053144\n","Train Epoch #17, Batch 7101/24958 loss = 1.248957204222679, ppl = 3.5082606566154526\n","Train Epoch #17, Batch 7102/24958 loss = 1.2505132216215133, ppl = 3.5128706717288867\n","Train Epoch #17, Batch 7103/24958 loss = 1.2507548874616623, ppl = 3.513690943208255\n","Train Epoch #17, Batch 7104/24958 loss = 1.25146846473217, ppl = 3.516035500370187\n","Train Epoch #17, Batch 7105/24958 loss = 1.2528701370954514, ppl = 3.520260566620526\n","Train Epoch #17, Batch 7106/24958 loss = 1.2532011598348618, ppl = 3.5213661931976525\n","Train Epoch #17, Batch 7107/24958 loss = 1.253474559187889, ppl = 3.522301594770829\n","Train Epoch #17, Batch 7108/24958 loss = 1.2548164802789687, ppl = 3.52699222093767\n","Train Epoch #17, Batch 7109/24958 loss = 1.254171195626259, ppl = 3.5247206577309758\n","Train Epoch #17, Batch 7110/24958 loss = 1.2554199701547624, ppl = 3.529054343279464\n","Train Epoch #17, Batch 7111/24958 loss = 1.2539515954256057, ppl = 3.523928302784033\n","Train Epoch #17, Batch 7112/24958 loss = 1.2545239323377608, ppl = 3.5260660633391963\n","Train Epoch #17, Batch 7113/24958 loss = 1.2569023197889329, ppl = 3.5345936334482464\n","Train Epoch #17, Batch 7114/24958 loss = 1.2591983360052108, ppl = 3.5427038462209772\n","Train Epoch #17, Batch 7115/24958 loss = 1.2610551100969314, ppl = 3.549780369068862\n","Train Epoch #17, Batch 7116/24958 loss = 1.2606428152322768, ppl = 3.548371206935688\n","Train Epoch #17, Batch 7117/24958 loss = 1.2580644702911377, ppl = 3.540608861538044\n","Train Epoch #17, Batch 7118/24958 loss = 1.2596135187149047, ppl = 3.546557660690007\n","Train Epoch #17, Batch 7119/24958 loss = 1.2590706765651702, ppl = 3.544287254125688\n","Train Epoch #17, Batch 7120/24958 loss = 1.257372624874115, ppl = 3.538919836027876\n","Train Epoch #17, Batch 7121/24958 loss = 1.2588319754600525, ppl = 3.5444390985139522\n","Train Epoch #17, Batch 7122/24958 loss = 1.2581742095947266, ppl = 3.5417695960702322\n","Train Epoch #17, Batch 7123/24958 loss = 1.2601616704463958, ppl = 3.5491543801082255\n","Train Epoch #17, Batch 7124/24958 loss = 1.2619591689109801, ppl = 3.556364251863109\n","Train Epoch #17, Batch 7125/24958 loss = 1.2606093883514404, ppl = 3.5514521847522933\n","Train Epoch #17, Batch 7126/24958 loss = 1.2596555614471436, ppl = 3.5484317486839587\n","Train Epoch #17, Batch 7127/24958 loss = 1.2578191673755645, ppl = 3.5411604414943314\n","Train Epoch #17, Batch 7128/24958 loss = 1.2579772460460663, ppl = 3.5417451008002003\n","Train Epoch #17, Batch 7129/24958 loss = 1.2581451749801635, ppl = 3.5423606997817516\n","Train Epoch #17, Batch 7130/24958 loss = 1.2580049312114716, ppl = 3.541861325728456\n","Train Epoch #17, Batch 7131/24958 loss = 1.2575442957878114, ppl = 3.540328844152337\n","Train Epoch #17, Batch 7132/24958 loss = 1.2589010739326476, ppl = 3.5449536245202022\n","Train Epoch #17, Batch 7133/24958 loss = 1.2609361743927001, ppl = 3.5530395058136373\n","Train Epoch #17, Batch 7134/24958 loss = 1.2579326224327088, ppl = 3.5427292749512533\n","Train Epoch #17, Batch 7135/24958 loss = 1.2571156692504883, ppl = 3.540259266743239\n","Train Epoch #17, Batch 7136/24958 loss = 1.2592262041568756, ppl = 3.5472851873772813\n","Train Epoch #17, Batch 7137/24958 loss = 1.2595212531089783, ppl = 3.548299770227411\n","Train Epoch #17, Batch 7138/24958 loss = 1.2634931886196137, ppl = 3.563375306070638\n","Train Epoch #17, Batch 7139/24958 loss = 1.2650220489501953, ppl = 3.5688591096519016\n","Train Epoch #17, Batch 7140/24958 loss = 1.26407363653183, ppl = 3.565743343806261\n","Train Epoch #17, Batch 7141/24958 loss = 1.2631787621974946, ppl = 3.5628126755184923\n","Train Epoch #17, Batch 7142/24958 loss = 1.2616856896877289, ppl = 3.5581063462523446\n","Train Epoch #17, Batch 7143/24958 loss = 1.2638362777233123, ppl = 3.5654568781991673\n","Train Epoch #17, Batch 7144/24958 loss = 1.2636000871658326, ppl = 3.564683309591659\n","Train Epoch #17, Batch 7145/24958 loss = 1.26220183134079, ppl = 3.5603401927008407\n","Train Epoch #17, Batch 7146/24958 loss = 1.2620336031913757, ppl = 3.559745569564513\n","Train Epoch #17, Batch 7147/24958 loss = 1.2618928754329681, ppl = 3.559257575563243\n","Train Epoch #17, Batch 7148/24958 loss = 1.263536285161972, ppl = 3.5648955743991304\n","Train Epoch #17, Batch 7149/24958 loss = 1.266287278532982, ppl = 3.5731818269166387\n","Train Epoch #17, Batch 7150/24958 loss = 1.2675009661912917, ppl = 3.5781665319103793\n","Train Epoch #17, Batch 7151/24958 loss = 1.2677622240781785, ppl = 3.579142612498152\n","Train Epoch #17, Batch 7152/24958 loss = 1.2683658236265183, ppl = 3.581545806494593\n","Train Epoch #17, Batch 7153/24958 loss = 1.2717539232969284, ppl = 3.592794095311782\n","Train Epoch #17, Batch 7154/24958 loss = 1.2725655204057693, ppl = 3.595855539849085\n","Train Epoch #17, Batch 7155/24958 loss = 1.2688258773088454, ppl = 3.5834604024175354\n","Train Epoch #17, Batch 7156/24958 loss = 1.2692789763212204, ppl = 3.5852528873336724\n","Train Epoch #17, Batch 7157/24958 loss = 1.2667734277248384, ppl = 3.5775459010210966\n","Train Epoch #17, Batch 7158/24958 loss = 1.2656997549533844, ppl = 3.5737007477096108\n","Train Epoch #17, Batch 7159/24958 loss = 1.264489551782608, ppl = 3.5689469506750697\n","Train Epoch #17, Batch 7160/24958 loss = 1.2649434888362885, ppl = 3.5705024673289687\n","Train Epoch #17, Batch 7161/24958 loss = 1.264597603082657, ppl = 3.569339446002847\n","Train Epoch #17, Batch 7162/24958 loss = 1.2663349628448486, ppl = 3.57528850616881\n","Train Epoch #17, Batch 7163/24958 loss = 1.266836669445038, ppl = 3.5769609172990497\n","Train Epoch #17, Batch 7164/24958 loss = 1.2678722655773162, ppl = 3.5809324347194957\n","Train Epoch #17, Batch 7165/24958 loss = 1.2695251953601838, ppl = 3.5875062314547534\n","Train Epoch #17, Batch 7166/24958 loss = 1.2718396496772766, ppl = 3.596207165520941\n","Train Epoch #17, Batch 7167/24958 loss = 1.2709103751182556, ppl = 3.592740182326923\n","Train Epoch #17, Batch 7168/24958 loss = 1.2730540335178375, ppl = 3.6006586176537976\n","Train Epoch #17, Batch 7169/24958 loss = 1.2747475063800813, ppl = 3.6061472037353677\n","Train Epoch #17, Batch 7170/24958 loss = 1.2764532375335693, ppl = 3.6126049158770797\n","Train Epoch #17, Batch 7171/24958 loss = 1.2741787016391755, ppl = 3.6039357738774735\n","Train Epoch #17, Batch 7172/24958 loss = 1.2756771385669707, ppl = 3.609892839513642\n","Train Epoch #17, Batch 7173/24958 loss = 1.2766081774234772, ppl = 3.612902361385809\n","Train Epoch #17, Batch 7174/24958 loss = 1.2771091544628144, ppl = 3.6146030813396965\n","Train Epoch #17, Batch 7175/24958 loss = 1.274267898797989, ppl = 3.6036908502253895\n","Train Epoch #17, Batch 7176/24958 loss = 1.272361264228821, ppl = 3.5966684031098985\n","Train Epoch #17, Batch 7177/24958 loss = 1.2742351973056794, ppl = 3.603533173230727\n","Train Epoch #17, Batch 7178/24958 loss = 1.2722865998744965, ppl = 3.5959953845519537\n","Train Epoch #17, Batch 7179/24958 loss = 1.2744581079483033, ppl = 3.603754387757218\n","Train Epoch #17, Batch 7180/24958 loss = 1.2755754137039184, ppl = 3.607425858448871\n","Train Epoch #17, Batch 7181/24958 loss = 1.276949803829193, ppl = 3.6130303761368405\n","Train Epoch #17, Batch 7182/24958 loss = 1.2738653600215912, ppl = 3.602211216828024\n","Train Epoch #17, Batch 7183/24958 loss = 1.2729842519760133, ppl = 3.598908609559444\n","Train Epoch #17, Batch 7184/24958 loss = 1.2732694137096405, ppl = 3.5999565321712907\n","Train Epoch #17, Batch 7185/24958 loss = 1.271724784374237, ppl = 3.594818451623974\n","Train Epoch #17, Batch 7186/24958 loss = 1.2689744520187378, ppl = 3.5845567801921665\n","Train Epoch #17, Batch 7187/24958 loss = 1.269307519197464, ppl = 3.5856472770350103\n","Train Epoch #17, Batch 7188/24958 loss = 1.2686569488048554, ppl = 3.583340247232438\n","Train Epoch #17, Batch 7189/24958 loss = 1.2684904956817626, ppl = 3.582778777135037\n","Train Epoch #17, Batch 7190/24958 loss = 1.268704262971878, ppl = 3.5834652063766788\n","Train Epoch #17, Batch 7191/24958 loss = 1.267552000284195, ppl = 3.580195548461187\n","Train Epoch #17, Batch 7192/24958 loss = 1.2648095417022704, ppl = 3.5692874320880588\n","Train Epoch #17, Batch 7193/24958 loss = 1.266848349571228, ppl = 3.5761386424487394\n","Train Epoch #17, Batch 7194/24958 loss = 1.2658443665504455, ppl = 3.5723658583857913\n","Train Epoch #17, Batch 7195/24958 loss = 1.267172986268997, ppl = 3.5762796828500827\n","Train Epoch #17, Batch 7196/24958 loss = 1.2683231592178346, ppl = 3.580546258549321\n","Train Epoch #17, Batch 7197/24958 loss = 1.2669734752178192, ppl = 3.5763496362123863\n","Train Epoch #17, Batch 7198/24958 loss = 1.267260582447052, ppl = 3.5773646663472967\n","Train Epoch #17, Batch 7199/24958 loss = 1.2683145606517792, ppl = 3.581237429518671\n","Train Epoch #17, Batch 7200/24958 loss = 1.2683338570594787, ppl = 3.5813027610183035\n","Train Epoch #17, Batch 7201/24958 loss = 1.268520622253418, ppl = 3.5820761437819737\n","Train Epoch #17, Batch 7202/24958 loss = 1.2689666938781738, ppl = 3.583535513312495\n","Train Epoch #17, Batch 7203/24958 loss = 1.2716767477989197, ppl = 3.5942293534749425\n","Train Epoch #17, Batch 7204/24958 loss = 1.2725691878795624, ppl = 3.5974071426637706\n","Train Epoch #17, Batch 7205/24958 loss = 1.274084689617157, ppl = 3.602693410324579\n","Train Epoch #17, Batch 7206/24958 loss = 1.274162073135376, ppl = 3.602957194535475\n","Train Epoch #17, Batch 7207/24958 loss = 1.2747562003135682, ppl = 3.6050802849015855\n","Train Epoch #17, Batch 7208/24958 loss = 1.2729922556877136, ppl = 3.5990399397287622\n","Train Epoch #17, Batch 7209/24958 loss = 1.2726012694835662, ppl = 3.597733212610966\n","Train Epoch #17, Batch 7210/24958 loss = 1.2718675351142883, ppl = 3.5951215838374027\n","Train Epoch #17, Batch 7211/24958 loss = 1.2739803981781006, ppl = 3.602746389810215\n","Train Epoch #17, Batch 7212/24958 loss = 1.2731333661079407, ppl = 3.5996252532201414\n","Train Epoch #17, Batch 7213/24958 loss = 1.2726278614997864, ppl = 3.597639340992606\n","Train Epoch #17, Batch 7214/24958 loss = 1.2730654752254487, ppl = 3.5994077771269533\n","Train Epoch #17, Batch 7215/24958 loss = 1.271910592317581, ppl = 3.5948530977528543\n","Train Epoch #17, Batch 7216/24958 loss = 1.2734141612052918, ppl = 3.600284992396378\n","Train Epoch #17, Batch 7217/24958 loss = 1.277591968178749, ppl = 3.613971218964139\n","Train Epoch #17, Batch 7218/24958 loss = 1.2778048306703567, ppl = 3.6148630794761063\n","Train Epoch #17, Batch 7219/24958 loss = 1.275737972855568, ppl = 3.607263471540767\n","Train Epoch #17, Batch 7220/24958 loss = 1.2782962661981583, ppl = 3.61571833927999\n","Train Epoch #17, Batch 7221/24958 loss = 1.2760371500253678, ppl = 3.60749910974521\n","Train Epoch #17, Batch 7222/24958 loss = 1.2757262033224106, ppl = 3.6062969869624997\n","Train Epoch #17, Batch 7223/24958 loss = 1.2738168078660965, ppl = 3.5991754250222225\n","Train Epoch #17, Batch 7224/24958 loss = 1.273549820780754, ppl = 3.598020876245662\n","Train Epoch #17, Batch 7225/24958 loss = 1.275268958210945, ppl = 3.604396713724701\n","Train Epoch #17, Batch 7226/24958 loss = 1.2765059679746629, ppl = 3.6083707761817725\n","Train Epoch #17, Batch 7227/24958 loss = 1.28005577981472, ppl = 3.6237426259287036\n","Train Epoch #17, Batch 7228/24958 loss = 1.280471252799034, ppl = 3.625324069176477\n","Train Epoch #17, Batch 7229/24958 loss = 1.2786663669347762, ppl = 3.6192194263571844\n","Train Epoch #17, Batch 7230/24958 loss = 1.2784235614538193, ppl = 3.6183712421421834\n","Train Epoch #17, Batch 7231/24958 loss = 1.2793514102697372, ppl = 3.6215319032751245\n","Train Epoch #17, Batch 7232/24958 loss = 1.2787091439962388, ppl = 3.619264366180979\n","Train Epoch #17, Batch 7233/24958 loss = 1.2760286849737168, ppl = 3.608939437292272\n","Train Epoch #17, Batch 7234/24958 loss = 1.280917026400566, ppl = 3.627492121128783\n","Train Epoch #17, Batch 7235/24958 loss = 1.2833472377061843, ppl = 3.635474349369382\n","Train Epoch #17, Batch 7236/24958 loss = 1.2858670443296432, ppl = 3.6460563337898493\n","Train Epoch #17, Batch 7237/24958 loss = 1.2856848973035813, ppl = 3.6454264543822785\n","Train Epoch #17, Batch 7238/24958 loss = 1.2816968435049056, ppl = 3.630301128900569\n","Train Epoch #17, Batch 7239/24958 loss = 1.2789556747674942, ppl = 3.6210272616747754\n","Train Epoch #17, Batch 7240/24958 loss = 1.2810159641504288, ppl = 3.6281927369287645\n","Train Epoch #17, Batch 7241/24958 loss = 1.2824489361047744, ppl = 3.6330161400236336\n","Train Epoch #17, Batch 7242/24958 loss = 1.2838379317522048, ppl = 3.6373711387581404\n","Train Epoch #17, Batch 7243/24958 loss = 1.283505123257637, ppl = 3.6361277355998336\n","Train Epoch #17, Batch 7244/24958 loss = 1.2833127385377885, ppl = 3.635511002737807\n","Train Epoch #17, Batch 7245/24958 loss = 1.285904797911644, ppl = 3.644074365265289\n","Train Epoch #17, Batch 7246/24958 loss = 1.289120575785637, ppl = 3.6573688177524213\n","Train Epoch #17, Batch 7247/24958 loss = 1.28893308699131, ppl = 3.6567292513004563\n","Train Epoch #17, Batch 7248/24958 loss = 1.2884745162725448, ppl = 3.6550617609196006\n","Train Epoch #17, Batch 7249/24958 loss = 1.2879948860406876, ppl = 3.6534482562947033\n","Train Epoch #17, Batch 7250/24958 loss = 1.286128244996071, ppl = 3.646021854503555\n","Train Epoch #17, Batch 7251/24958 loss = 1.2853667122125625, ppl = 3.643246399923466\n","Train Epoch #17, Batch 7252/24958 loss = 1.285489528775215, ppl = 3.643753399493929\n","Train Epoch #17, Batch 7253/24958 loss = 1.2843839806318282, ppl = 3.6396568442543504\n","Train Epoch #17, Batch 7254/24958 loss = 1.283119847178459, ppl = 3.6349932358621264\n","Train Epoch #17, Batch 7255/24958 loss = 1.2847823721170426, ppl = 3.6399369988493286\n","Train Epoch #17, Batch 7256/24958 loss = 1.282542400956154, ppl = 3.631816666614369\n","Train Epoch #17, Batch 7257/24958 loss = 1.2845329117774964, ppl = 3.6377780043192764\n","Train Epoch #17, Batch 7258/24958 loss = 1.2843395316600799, ppl = 3.637128266685646\n","Train Epoch #17, Batch 7259/24958 loss = 1.2845696032047271, ppl = 3.637988282729994\n","Train Epoch #17, Batch 7260/24958 loss = 1.2867498910427093, ppl = 3.6465274772104914\n","Train Epoch #17, Batch 7261/24958 loss = 1.287859593629837, ppl = 3.6504058436390876\n","Train Epoch #17, Batch 7262/24958 loss = 1.2871418511867523, ppl = 3.6478223042208846\n","Train Epoch #17, Batch 7263/24958 loss = 1.2872829520702362, ppl = 3.648307972132504\n","Train Epoch #17, Batch 7264/24958 loss = 1.284998630285263, ppl = 3.640063603712301\n","Train Epoch #17, Batch 7265/24958 loss = 1.2817578601837158, ppl = 3.62812000699554\n","Train Epoch #17, Batch 7266/24958 loss = 1.281391419172287, ppl = 3.626604781347544\n","Train Epoch #17, Batch 7267/24958 loss = 1.2824113690853118, ppl = 3.630427633505477\n","Train Epoch #17, Batch 7268/24958 loss = 1.279086412191391, ppl = 3.618818876812976\n","Train Epoch #17, Batch 7269/24958 loss = 1.2782997107505798, ppl = 3.61615339556129\n","Train Epoch #17, Batch 7270/24958 loss = 1.2742498898506165, ppl = 3.602440154468402\n","Train Epoch #17, Batch 7271/24958 loss = 1.2736655282974243, ppl = 3.6005134690837304\n","Train Epoch #17, Batch 7272/24958 loss = 1.269566659927368, ppl = 3.5861181943352256\n","Train Epoch #17, Batch 7273/24958 loss = 1.2716291046142578, ppl = 3.5938722209146006\n","Train Epoch #17, Batch 7274/24958 loss = 1.2696946382522583, ppl = 3.587750410402037\n","Train Epoch #17, Batch 7275/24958 loss = 1.268964660167694, ppl = 3.585412642990788\n","Train Epoch #17, Batch 7276/24958 loss = 1.269417097568512, ppl = 3.58695996763148\n","Train Epoch #17, Batch 7277/24958 loss = 1.2676825749874114, ppl = 3.5805627937040385\n","Train Epoch #17, Batch 7278/24958 loss = 1.2685135805606842, ppl = 3.583598750919352\n","Train Epoch #17, Batch 7279/24958 loss = 1.266730191707611, ppl = 3.577105818947778\n","Train Epoch #17, Batch 7280/24958 loss = 1.2666875195503235, ppl = 3.576957934517184\n","Train Epoch #17, Batch 7281/24958 loss = 1.2667126452922821, ppl = 3.577067732804437\n","Train Epoch #17, Batch 7282/24958 loss = 1.26768838763237, ppl = 3.580136853637863\n","Train Epoch #17, Batch 7283/24958 loss = 1.2667614173889161, ppl = 3.576962563347174\n","Train Epoch #17, Batch 7284/24958 loss = 1.2664120650291444, ppl = 3.575682842824159\n","Train Epoch #17, Batch 7285/24958 loss = 1.2693446862697602, ppl = 3.5861660934695028\n","Train Epoch #17, Batch 7286/24958 loss = 1.2695110833644867, ppl = 3.586709977473636\n","Train Epoch #17, Batch 7287/24958 loss = 1.2687502336502074, ppl = 3.5842711170211654\n","Train Epoch #17, Batch 7288/24958 loss = 1.2696177780628204, ppl = 3.5873815565159566\n","Train Epoch #17, Batch 7289/24958 loss = 1.271156212091446, ppl = 3.5929448110792492\n","Train Epoch #17, Batch 7290/24958 loss = 1.2730597054958344, ppl = 3.599749821916197\n","Train Epoch #17, Batch 7291/24958 loss = 1.2756936943531036, ppl = 3.6078176108120066\n","Train Epoch #17, Batch 7292/24958 loss = 1.2773875975608826, ppl = 3.6141986020295183\n","Train Epoch #17, Batch 7293/24958 loss = 1.2765159392356873, ppl = 3.611097849067493\n","Train Epoch #17, Batch 7294/24958 loss = 1.2756745886802674, ppl = 3.6082152293173495\n","Train Epoch #17, Batch 7295/24958 loss = 1.2770779025554657, ppl = 3.612954544236142\n","Train Epoch #17, Batch 7296/24958 loss = 1.2781425976753236, ppl = 3.617366209642285\n","Train Epoch #17, Batch 7297/24958 loss = 1.2805138850212097, ppl = 3.6251380390457046\n","Train Epoch #17, Batch 7298/24958 loss = 1.2796954023838043, ppl = 3.6223195788175415\n","Train Epoch #17, Batch 7299/24958 loss = 1.2762299168109894, ppl = 3.61098101041214\n","Train Epoch #17, Batch 7300/24958 loss = 1.2758293068408966, ppl = 3.609650198226008\n","Train Epoch #17, Batch 7301/24958 loss = 1.2724771177768708, ppl = 3.597745566475039\n","Train Epoch #17, Batch 7302/24958 loss = 1.2736474633216859, ppl = 3.6018988029397843\n","Train Epoch #17, Batch 7303/24958 loss = 1.2688233196735381, ppl = 3.5846585334459804\n","Train Epoch #17, Batch 7304/24958 loss = 1.2668643248081208, ppl = 3.578036833697115\n","Train Epoch #17, Batch 7305/24958 loss = 1.2663197469711305, ppl = 3.576044444624537\n","Train Epoch #17, Batch 7306/24958 loss = 1.2648991537094116, ppl = 3.5715126868658156\n","Train Epoch #17, Batch 7307/24958 loss = 1.264850252866745, ppl = 3.5713331385225953\n","Train Epoch #17, Batch 7308/24958 loss = 1.264961930513382, ppl = 3.5716847830794434\n","Train Epoch #17, Batch 7309/24958 loss = 1.2633683931827546, ppl = 3.566857263052884\n","Train Epoch #17, Batch 7310/24958 loss = 1.2625399649143219, ppl = 3.564129966729504\n","Train Epoch #17, Batch 7311/24958 loss = 1.2614784836769104, ppl = 3.560098188978888\n","Train Epoch #17, Batch 7312/24958 loss = 1.2594424295425415, ppl = 3.553593644373225\n","Train Epoch #17, Batch 7313/24958 loss = 1.2602451622486115, ppl = 3.556794974587609\n","Train Epoch #17, Batch 7314/24958 loss = 1.257868115901947, ppl = 3.5480570321258806\n","Train Epoch #17, Batch 7315/24958 loss = 1.2566990530490876, ppl = 3.5439521580573654\n","Train Epoch #17, Batch 7316/24958 loss = 1.2561985278129577, ppl = 3.5420525188614227\n","Train Epoch #17, Batch 7317/24958 loss = 1.2567744064331055, ppl = 3.544428250891157\n","Train Epoch #17, Batch 7318/24958 loss = 1.2550844073295593, ppl = 3.537843836426916\n","Train Epoch #17, Batch 7319/24958 loss = 1.255634572505951, ppl = 3.539715902363375\n","Train Epoch #17, Batch 7320/24958 loss = 1.2538811552524567, ppl = 3.5336918057312388\n","Train Epoch #17, Batch 7321/24958 loss = 1.2542885613441468, ppl = 3.535040202142684\n","Train Epoch #17, Batch 7322/24958 loss = 1.2523477125167846, ppl = 3.5283255828353224\n","Train Epoch #17, Batch 7323/24958 loss = 1.2522295653820037, ppl = 3.5279280087801914\n","Train Epoch #17, Batch 7324/24958 loss = 1.2485980463027955, ppl = 3.514934504458416\n","Train Epoch #17, Batch 7325/24958 loss = 1.248396463394165, ppl = 3.5141289288489066\n","Train Epoch #17, Batch 7326/24958 loss = 1.2480965650081635, ppl = 3.5131198520594755\n","Train Epoch #17, Batch 7327/24958 loss = 1.2445889818668365, ppl = 3.4979006480746992\n","Train Epoch #17, Batch 7328/24958 loss = 1.2426905643939972, ppl = 3.4911813865357133\n","Train Epoch #17, Batch 7329/24958 loss = 1.24547527551651, ppl = 3.5010915384908863\n","Train Epoch #17, Batch 7330/24958 loss = 1.2441300296783446, ppl = 3.4967477765394728\n","Train Epoch #17, Batch 7331/24958 loss = 1.244640780687332, ppl = 3.498616909428898\n","Train Epoch #17, Batch 7332/24958 loss = 1.2438268756866455, ppl = 3.4959449007410286\n","Train Epoch #17, Batch 7333/24958 loss = 1.2445375800132752, ppl = 3.4984188239066047\n","Train Epoch #17, Batch 7334/24958 loss = 1.2400987100601197, ppl = 3.4812190831967786\n","Train Epoch #17, Batch 7335/24958 loss = 1.2395347237586976, ppl = 3.47919017409302\n","Train Epoch #17, Batch 7336/24958 loss = 1.237569100856781, ppl = 3.470712345623091\n","Train Epoch #17, Batch 7337/24958 loss = 1.2361112892627717, ppl = 3.46606394045828\n","Train Epoch #17, Batch 7338/24958 loss = 1.2380509233474732, ppl = 3.4726707077704293\n","Train Epoch #17, Batch 7339/24958 loss = 1.2376346957683564, ppl = 3.471471853314351\n","Train Epoch #17, Batch 7340/24958 loss = 1.2361901819705963, ppl = 3.466295552117001\n","Train Epoch #17, Batch 7341/24958 loss = 1.2359144437313079, ppl = 3.4653129354615544\n","Train Epoch #17, Batch 7342/24958 loss = 1.240831402540207, ppl = 3.4866400850846104\n","Train Epoch #17, Batch 7343/24958 loss = 1.2412123310565948, ppl = 3.4880667177920652\n","Train Epoch #17, Batch 7344/24958 loss = 1.2439238798618317, ppl = 3.4979561159062365\n","Train Epoch #17, Batch 7345/24958 loss = 1.2445075035095214, ppl = 3.5002100325922054\n","Train Epoch #17, Batch 7346/24958 loss = 1.2390538239479065, ppl = 3.479887503936697\n","Train Epoch #17, Batch 7347/24958 loss = 1.2409809064865112, ppl = 3.4870695950648214\n","Train Epoch #17, Batch 7348/24958 loss = 1.2422174501419068, ppl = 3.491746930753882\n","Train Epoch #17, Batch 7349/24958 loss = 1.2443259251117706, ppl = 3.499455336633925\n","Train Epoch #17, Batch 7350/24958 loss = 1.2432324540615083, ppl = 3.495707048949117\n","Train Epoch #17, Batch 7351/24958 loss = 1.2420393908023835, ppl = 3.491762311679143\n","Train Epoch #17, Batch 7352/24958 loss = 1.240963259935379, ppl = 3.4875246957511052\n","Train Epoch #17, Batch 7353/24958 loss = 1.2407719945907594, ppl = 3.486860795294592\n","Train Epoch #17, Batch 7354/24958 loss = 1.2405742454528808, ppl = 3.4861831267720063\n","Train Epoch #17, Batch 7355/24958 loss = 1.2423948979377746, ppl = 3.492628564037331\n","Train Epoch #17, Batch 7356/24958 loss = 1.2437295234203338, ppl = 3.49724648149434\n","Train Epoch #17, Batch 7357/24958 loss = 1.2425039756298064, ppl = 3.493436916256207\n","Train Epoch #17, Batch 7358/24958 loss = 1.243041718006134, ppl = 3.495275247441113\n","Train Epoch #17, Batch 7359/24958 loss = 1.2425114297866822, ppl = 3.493322357320776\n","Train Epoch #17, Batch 7360/24958 loss = 1.2401848769187926, ppl = 3.4842742221993475\n","Train Epoch #17, Batch 7361/24958 loss = 1.2385120260715485, ppl = 3.4785862912821006\n","Train Epoch #17, Batch 7362/24958 loss = 1.2391194415092468, ppl = 3.480760544465356\n","Train Epoch #17, Batch 7363/24958 loss = 1.2406062757968903, ppl = 3.486317267707706\n","Train Epoch #17, Batch 7364/24958 loss = 1.2410334646701813, ppl = 3.4877193777318656\n","Train Epoch #17, Batch 7365/24958 loss = 1.2397119188308716, ppl = 3.4838564476180665\n","Train Epoch #17, Batch 7366/24958 loss = 1.2370909559726715, ppl = 3.4744963255146732\n","Train Epoch #17, Batch 7367/24958 loss = 1.2345669615268706, ppl = 3.465702029370631\n","Train Epoch #17, Batch 7368/24958 loss = 1.236248461008072, ppl = 3.4710912012448034\n","Train Epoch #17, Batch 7369/24958 loss = 1.2359749925136567, ppl = 3.470212678047379\n","Train Epoch #17, Batch 7370/24958 loss = 1.2391456115245818, ppl = 3.480460002845114\n","Train Epoch #17, Batch 7371/24958 loss = 1.2402055954933167, ppl = 3.4840401261194223\n","Train Epoch #17, Batch 7372/24958 loss = 1.2419706737995149, ppl = 3.4895250427660485\n","Train Epoch #17, Batch 7373/24958 loss = 1.2399075174331664, ppl = 3.481768607063089\n","Train Epoch #17, Batch 7374/24958 loss = 1.2386294609308244, ppl = 3.478327261454954\n","Train Epoch #17, Batch 7375/24958 loss = 1.2425007408857345, ppl = 3.4929211395319273\n","Train Epoch #17, Batch 7376/24958 loss = 1.242367176413536, ppl = 3.492457047277779\n","Train Epoch #17, Batch 7377/24958 loss = 1.2433977395296096, ppl = 3.496123485711975\n","Train Epoch #17, Batch 7378/24958 loss = 1.2425857573747634, ppl = 3.493154243484665\n","Train Epoch #17, Batch 7379/24958 loss = 1.2430413562059401, ppl = 3.494704512256248\n","Train Epoch #17, Batch 7380/24958 loss = 1.2452475982904434, ppl = 3.503241260241022\n","Train Epoch #17, Batch 7381/24958 loss = 1.2418483394384383, ppl = 3.4906322396516636\n","Train Epoch #17, Batch 7382/24958 loss = 1.242332494854927, ppl = 3.4922699423147754\n","Train Epoch #17, Batch 7383/24958 loss = 1.2426110309362413, ppl = 3.493193024350528\n","Train Epoch #17, Batch 7384/24958 loss = 1.2442624527215957, ppl = 3.4996563322690744\n","Train Epoch #17, Batch 7385/24958 loss = 1.2435468250513078, ppl = 3.4968078991066163\n","Train Epoch #17, Batch 7386/24958 loss = 1.2450743395090103, ppl = 3.502247234403084\n","Train Epoch #17, Batch 7387/24958 loss = 1.2467930573225021, ppl = 3.508032484672102\n","Train Epoch #17, Batch 7388/24958 loss = 1.2472742241621018, ppl = 3.509877577974463\n","Train Epoch #17, Batch 7389/24958 loss = 1.244865841269493, ppl = 3.501527206714794\n","Train Epoch #17, Batch 7390/24958 loss = 1.2449222415685655, ppl = 3.501749262718974\n","Train Epoch #17, Batch 7391/24958 loss = 1.2448592704534531, ppl = 3.5015305586286445\n","Train Epoch #17, Batch 7392/24958 loss = 1.2441312927007675, ppl = 3.4986553506318887\n","Train Epoch #17, Batch 7393/24958 loss = 1.2459757977724075, ppl = 3.5055514550944458\n","Train Epoch #17, Batch 7394/24958 loss = 1.2476849156618117, ppl = 3.511672507440706\n","Train Epoch #17, Batch 7395/24958 loss = 1.2478599792718887, ppl = 3.5123117709424836\n","Train Epoch #17, Batch 7396/24958 loss = 1.245179243683815, ppl = 3.5020402693773436\n","Train Epoch #17, Batch 7397/24958 loss = 1.244995453953743, ppl = 3.501369844232158\n","Train Epoch #17, Batch 7398/24958 loss = 1.2457150191068649, ppl = 3.5038352991703903\n","Train Epoch #17, Batch 7399/24958 loss = 1.2486453777551652, ppl = 3.5131565993773624\n","Train Epoch #17, Batch 7400/24958 loss = 1.2487091714143752, ppl = 3.5133649670552107\n","Train Epoch #17, Batch 7401/24958 loss = 1.2510008805990218, ppl = 3.521064020918222\n","Train Epoch #17, Batch 7402/24958 loss = 1.2499603766202927, ppl = 3.5173479513437815\n","Train Epoch #17, Batch 7403/24958 loss = 1.25336161673069, ppl = 3.5286134748919573\n","Train Epoch #17, Batch 7404/24958 loss = 1.2547468501329422, ppl = 3.533159721813507\n","Train Epoch #17, Batch 7405/24958 loss = 1.2549917417764664, ppl = 3.5340422686036037\n","Train Epoch #17, Batch 7406/24958 loss = 1.25744027197361, ppl = 3.5422787740305557\n","Train Epoch #17, Batch 7407/24958 loss = 1.2577489978075027, ppl = 3.543427183787809\n","Train Epoch #17, Batch 7408/24958 loss = 1.2582470053434371, ppl = 3.545043980164648\n","Train Epoch #17, Batch 7409/24958 loss = 1.2617740482091904, ppl = 3.5568620750772286\n","Train Epoch #17, Batch 7410/24958 loss = 1.2631627398729324, ppl = 3.5615661468568796\n","Train Epoch #17, Batch 7411/24958 loss = 1.2620478922128677, ppl = 3.5577680816245367\n","Train Epoch #17, Batch 7412/24958 loss = 1.264134323000908, ppl = 3.5644509518417107\n","Train Epoch #17, Batch 7413/24958 loss = 1.263085781931877, ppl = 3.560319624246339\n","Train Epoch #17, Batch 7414/24958 loss = 1.2645752340555192, ppl = 3.565549647291872\n","Train Epoch #17, Batch 7415/24958 loss = 1.2649598854780197, ppl = 3.5668476497941723\n","Train Epoch #17, Batch 7416/24958 loss = 1.2639117759466172, ppl = 3.5631648588087796\n","Train Epoch #17, Batch 7417/24958 loss = 1.2609874361753464, ppl = 3.5524005902563545\n","Train Epoch #17, Batch 7418/24958 loss = 1.2617527836561202, ppl = 3.55524505184972\n","Train Epoch #17, Batch 7419/24958 loss = 1.2615785151720047, ppl = 3.554640880516774\n","Train Epoch #17, Batch 7420/24958 loss = 1.263936269879341, ppl = 3.5629984032053925\n","Train Epoch #17, Batch 7421/24958 loss = 1.265238944888115, ppl = 3.567697745588629\n","Train Epoch #17, Batch 7422/24958 loss = 1.2661564391851425, ppl = 3.5707099336750328\n","Train Epoch #17, Batch 7423/24958 loss = 1.2655363780260087, ppl = 3.5686986819710125\n","Train Epoch #17, Batch 7424/24958 loss = 1.2671211296319962, ppl = 3.5737946268398093\n","Train Epoch #17, Batch 7425/24958 loss = 1.266960181593895, ppl = 3.5731629959467437\n","Train Epoch #17, Batch 7426/24958 loss = 1.265981553196907, ppl = 3.5700729704649343\n","Train Epoch #17, Batch 7427/24958 loss = 1.2668726116418838, ppl = 3.573448894459126\n","Train Epoch #17, Batch 7428/24958 loss = 1.2669045680761337, ppl = 3.573551768705795\n","Train Epoch #17, Batch 7429/24958 loss = 1.2658121234178543, ppl = 3.5693322753434944\n","Train Epoch #17, Batch 7430/24958 loss = 1.2670331448316574, ppl = 3.573249987006172\n","Train Epoch #17, Batch 7431/24958 loss = 1.2685931712388991, ppl = 3.5795875509205177\n","Train Epoch #17, Batch 7432/24958 loss = 1.270524381995201, ppl = 3.586300457761463\n","Train Epoch #17, Batch 7433/24958 loss = 1.2716376215219498, ppl = 3.5905468992311604\n","Train Epoch #17, Batch 7434/24958 loss = 1.2720360761880876, ppl = 3.5917981978879108\n","Train Epoch #17, Batch 7435/24958 loss = 1.2708967512845992, ppl = 3.5880326168161742\n","Train Epoch #17, Batch 7436/24958 loss = 1.2690946489572525, ppl = 3.581596301169869\n","Train Epoch #17, Batch 7437/24958 loss = 1.2701032930612564, ppl = 3.584739606444573\n","Train Epoch #17, Batch 7438/24958 loss = 1.2702258437871934, ppl = 3.5852016543526135\n","Train Epoch #17, Batch 7439/24958 loss = 1.2731871753931046, ppl = 3.594923377879659\n","Train Epoch #17, Batch 7440/24958 loss = 1.2740913027524947, ppl = 3.598075213101178\n","Train Epoch #17, Batch 7441/24958 loss = 1.2726417928934097, ppl = 3.593332668888347\n","Train Epoch #17, Batch 7442/24958 loss = 1.2680553609132768, ppl = 3.573134024365525\n","Train Epoch #17, Batch 7443/24958 loss = 1.26644209086895, ppl = 3.5674473231765718\n","Train Epoch #17, Batch 7444/24958 loss = 1.2640741282701493, ppl = 3.55866776461484\n","Train Epoch #17, Batch 7445/24958 loss = 1.2622917860746383, ppl = 3.5521772476669105\n","Train Epoch #17, Batch 7446/24958 loss = 1.2647138720750808, ppl = 3.559856867123128\n","Train Epoch #17, Batch 7447/24958 loss = 1.2621908205747605, ppl = 3.5507196293331837\n","Train Epoch #17, Batch 7448/24958 loss = 1.2621515399217607, ppl = 3.5505619809044227\n","Train Epoch #17, Batch 7449/24958 loss = 1.261147624850273, ppl = 3.5466889006163185\n","Train Epoch #17, Batch 7450/24958 loss = 1.2621847516298295, ppl = 3.550233868095138\n","Train Epoch #17, Batch 7451/24958 loss = 1.263294933438301, ppl = 3.5538890957793323\n","Train Epoch #17, Batch 7452/24958 loss = 1.2640317231416702, ppl = 3.55674090220909\n","Train Epoch #17, Batch 7453/24958 loss = 1.2648620098829269, ppl = 3.559717286994612\n","Train Epoch #17, Batch 7454/24958 loss = 1.2675470954179764, ppl = 3.570168565953994\n","Train Epoch #17, Batch 7455/24958 loss = 1.268402926325798, ppl = 3.5736284796199773\n","Train Epoch #17, Batch 7456/24958 loss = 1.2707094568014146, ppl = 3.5832170231975846\n","Train Epoch #17, Batch 7457/24958 loss = 1.2713327032327653, ppl = 3.5850960141460315\n","Train Epoch #17, Batch 7458/24958 loss = 1.270977550148964, ppl = 3.5838708325688424\n","Train Epoch #17, Batch 7459/24958 loss = 1.2707216447591783, ppl = 3.5829648199419353\n","Train Epoch #17, Batch 7460/24958 loss = 1.2720515435934068, ppl = 3.587878010866029\n","Train Epoch #17, Batch 7461/24958 loss = 1.2734436577558517, ppl = 3.592543747091716\n","Train Epoch #17, Batch 7462/24958 loss = 1.272466842532158, ppl = 3.5891103725657048\n","Train Epoch #17, Batch 7463/24958 loss = 1.272203922867775, ppl = 3.5880666891462996\n","Train Epoch #17, Batch 7464/24958 loss = 1.2747858899831772, ppl = 3.5979437680254263\n","Train Epoch #17, Batch 7465/24958 loss = 1.2764340931177138, ppl = 3.602842843234394\n","Train Epoch #17, Batch 7466/24958 loss = 1.2768763333559037, ppl = 3.604255255809359\n","Train Epoch #17, Batch 7467/24958 loss = 1.2799513787031174, ppl = 3.615283026149076\n","Train Epoch #17, Batch 7468/24958 loss = 1.2807568258047104, ppl = 3.6182036225445944\n","Train Epoch #17, Batch 7469/24958 loss = 1.2803070098161697, ppl = 3.6168098305061607\n","Train Epoch #17, Batch 7470/24958 loss = 1.2781957131624222, ppl = 3.609631766573393\n","Train Epoch #17, Batch 7471/24958 loss = 1.2769774562120437, ppl = 3.6055488927074917\n","Train Epoch #17, Batch 7472/24958 loss = 1.277002245783806, ppl = 3.6056330279701916\n","Train Epoch #17, Batch 7473/24958 loss = 1.27746007502079, ppl = 3.6072188055819\n","Train Epoch #17, Batch 7474/24958 loss = 1.2808530485630036, ppl = 3.617415730706881\n","Train Epoch #17, Batch 7475/24958 loss = 1.2787904417514802, ppl = 3.608942121650949\n","Train Epoch #17, Batch 7476/24958 loss = 1.279935302734375, ppl = 3.6131287081960415\n","Train Epoch #17, Batch 7477/24958 loss = 1.2769528722763062, ppl = 3.603473267724528\n","Train Epoch #17, Batch 7478/24958 loss = 1.2775189125537871, ppl = 3.6055175675675937\n","Train Epoch #17, Batch 7479/24958 loss = 1.2776716017723084, ppl = 3.606053127693972\n","Train Epoch #17, Batch 7480/24958 loss = 1.2772922909259796, ppl = 3.6044482148482375\n","Train Epoch #17, Batch 7481/24958 loss = 1.2784763479232788, ppl = 3.6083632166585384\n","Train Epoch #17, Batch 7482/24958 loss = 1.2804474329948425, ppl = 3.6159129376323396\n","Train Epoch #17, Batch 7483/24958 loss = 1.2814932990074157, ppl = 3.6196178487470085\n","Train Epoch #17, Batch 7484/24958 loss = 1.2792592453956604, ppl = 3.611117277258559\n","Train Epoch #17, Batch 7485/24958 loss = 1.2788996422290801, ppl = 3.6097610739254717\n","Train Epoch #17, Batch 7486/24958 loss = 1.2772711420059204, ppl = 3.603990578584172\n","Train Epoch #17, Batch 7487/24958 loss = 1.2758383548259735, ppl = 3.5991001697066953\n","Train Epoch #17, Batch 7488/24958 loss = 1.273506724834442, ppl = 3.5909316867647814\n","Train Epoch #17, Batch 7489/24958 loss = 1.2763152897357941, ppl = 3.6008750181615214\n","Train Epoch #17, Batch 7490/24958 loss = 1.2733151602745056, ppl = 3.590641480500411\n","Train Epoch #17, Batch 7491/24958 loss = 1.2739114201068877, ppl = 3.5927686147857414\n","Train Epoch #17, Batch 7492/24958 loss = 1.2713056874275208, ppl = 3.5840344276520737\n","Train Epoch #17, Batch 7493/24958 loss = 1.2701591372489929, ppl = 3.5795994103059496\n","Train Epoch #17, Batch 7494/24958 loss = 1.2691098296642302, ppl = 3.5757183065966616\n","Train Epoch #17, Batch 7495/24958 loss = 1.2684558522701264, ppl = 3.573386357162128\n","Train Epoch #17, Batch 7496/24958 loss = 1.2683280754089354, ppl = 3.5729621779124145\n","Train Epoch #17, Batch 7497/24958 loss = 1.2694244968891144, ppl = 3.577150456263779\n","Train Epoch #17, Batch 7498/24958 loss = 1.2671160340309142, ppl = 3.569830347082413\n","Train Epoch #17, Batch 7499/24958 loss = 1.2638202863931656, ppl = 3.5595268097989003\n","Train Epoch #17, Batch 7500/24958 loss = 1.2636763209104538, ppl = 3.559058456783677\n","Train Epoch #17, Batch 7501/24958 loss = 1.262850380539894, ppl = 3.5560783707894585\n","Train Epoch #17, Batch 7502/24958 loss = 1.263097546696663, ppl = 3.5569264123659603\n","Train Epoch #17, Batch 7503/24958 loss = 1.2611111778020858, ppl = 3.5498872671516404\n","Train Epoch #17, Batch 7504/24958 loss = 1.261563065648079, ppl = 3.551511854555719\n","Train Epoch #17, Batch 7505/24958 loss = 1.2617853182554244, ppl = 3.5523317389747446\n","Train Epoch #17, Batch 7506/24958 loss = 1.2601048117876053, ppl = 3.54646520338084\n","Train Epoch #17, Batch 7507/24958 loss = 1.2599810892343521, ppl = 3.5460007142098813\n","Train Epoch #17, Batch 7508/24958 loss = 1.2623952358961106, ppl = 3.5550878899805434\n","Train Epoch #17, Batch 7509/24958 loss = 1.2614767223596572, ppl = 3.551598337954872\n","Train Epoch #17, Batch 7510/24958 loss = 1.2609526079893112, ppl = 3.5497457918211284\n","Train Epoch #17, Batch 7511/24958 loss = 1.2603348928689957, ppl = 3.5478166810610166\n","Train Epoch #17, Batch 7512/24958 loss = 1.2602177637815475, ppl = 3.5474034417024614\n","Train Epoch #17, Batch 7513/24958 loss = 1.258651449084282, ppl = 3.5419853386075824\n","Train Epoch #17, Batch 7514/24958 loss = 1.258274740576744, ppl = 3.540588102784889\n","Train Epoch #17, Batch 7515/24958 loss = 1.2566430598497391, ppl = 3.535409419311948\n","Train Epoch #17, Batch 7516/24958 loss = 1.2560655170679091, ppl = 3.5335391008575017\n","Train Epoch #17, Batch 7517/24958 loss = 1.2572702723741531, ppl = 3.537596347985212\n","Train Epoch #17, Batch 7518/24958 loss = 1.2565436631441116, ppl = 3.5348906889865015\n","Train Epoch #17, Batch 7519/24958 loss = 1.2582234567403794, ppl = 3.541176976413486\n","Train Epoch #17, Batch 7520/24958 loss = 1.2563757115602494, ppl = 3.5344641115395365\n","Train Epoch #17, Batch 7521/24958 loss = 1.2539808708429336, ppl = 3.5262701887865493\n","Train Epoch #17, Batch 7522/24958 loss = 1.2555009001493453, ppl = 3.5319108046700625\n","Train Epoch #17, Batch 7523/24958 loss = 1.2552665227651596, ppl = 3.531182464820161\n","Train Epoch #17, Batch 7524/24958 loss = 1.259215903878212, ppl = 3.548021964650927\n","Train Epoch #17, Batch 7525/24958 loss = 1.25888465821743, ppl = 3.5467535676952884\n","Train Epoch #17, Batch 7526/24958 loss = 1.2610856515169144, ppl = 3.5541531849888\n","Train Epoch #17, Batch 7527/24958 loss = 1.2594042164087296, ppl = 3.548024439513158\n","Train Epoch #17, Batch 7528/24958 loss = 1.2625612491369247, ppl = 3.559993976197147\n","Train Epoch #17, Batch 7529/24958 loss = 1.2594819068908691, ppl = 3.550306108088078\n","Train Epoch #17, Batch 7530/24958 loss = 1.259178216457367, ppl = 3.5492865620859066\n","Train Epoch #17, Batch 7531/24958 loss = 1.2568108916282654, ppl = 3.540037635372953\n","Train Epoch #17, Batch 7532/24958 loss = 1.2558466029167175, ppl = 3.5365238272157673\n","Train Epoch #17, Batch 7533/24958 loss = 1.2538741636276245, ppl = 3.5293083936631207\n","Train Epoch #17, Batch 7534/24958 loss = 1.2534644877910615, ppl = 3.5280225730407717\n","Train Epoch #17, Batch 7535/24958 loss = 1.2533437478542329, ppl = 3.5276480822284735\n","Train Epoch #17, Batch 7536/24958 loss = 1.254134486913681, ppl = 3.530330060379723\n","Train Epoch #17, Batch 7537/24958 loss = 1.2550452053546906, ppl = 3.533453816783934\n","Train Epoch #17, Batch 7538/24958 loss = 1.2534600615501403, ppl = 3.527893086195816\n","Train Epoch #17, Batch 7539/24958 loss = 1.2514532959461213, ppl = 3.5209966652488207\n","Train Epoch #17, Batch 7540/24958 loss = 1.2520764112472533, ppl = 3.523340830954605\n","Train Epoch #17, Batch 7541/24958 loss = 1.255704870223999, ppl = 3.536640088049684\n","Train Epoch #17, Batch 7542/24958 loss = 1.256356225013733, ppl = 3.5389761949393663\n","Train Epoch #17, Batch 7543/24958 loss = 1.2590415930747987, ppl = 3.5489824308219102\n","Train Epoch #17, Batch 7544/24958 loss = 1.2588786935806275, ppl = 3.548451483767729\n","Train Epoch #17, Batch 7545/24958 loss = 1.2574686539173126, ppl = 3.5440764354075918\n","Train Epoch #17, Batch 7546/24958 loss = 1.2565299212932586, ppl = 3.540877532554053\n","Train Epoch #17, Batch 7547/24958 loss = 1.2577914953231812, ppl = 3.545158535880467\n","Train Epoch #17, Batch 7548/24958 loss = 1.2568562829494476, ppl = 3.541582364508257\n","Train Epoch #17, Batch 7549/24958 loss = 1.2566061556339263, ppl = 3.5406763848969915\n","Train Epoch #17, Batch 7550/24958 loss = 1.255484677553177, ppl = 3.536858942664143\n","Train Epoch #17, Batch 7551/24958 loss = 1.2545439720153808, ppl = 3.5337358039504023\n","Train Epoch #17, Batch 7552/24958 loss = 1.2538155460357665, ppl = 3.530915205122042\n","Train Epoch #17, Batch 7553/24958 loss = 1.2530076491832733, ppl = 3.528015883175252\n","Train Epoch #17, Batch 7554/24958 loss = 1.2504953229427338, ppl = 3.5181558932344883\n","Train Epoch #17, Batch 7555/24958 loss = 1.250148242712021, ppl = 3.516716949476741\n","Train Epoch #17, Batch 7556/24958 loss = 1.2471415030956268, ppl = 3.504628882843613\n","Train Epoch #17, Batch 7557/24958 loss = 1.247830491065979, ppl = 3.5068470125819347\n","Train Epoch #17, Batch 7558/24958 loss = 1.2495627987384796, ppl = 3.5132566652701773\n","Train Epoch #17, Batch 7559/24958 loss = 1.2513861465454101, ppl = 3.5202478456115136\n","Train Epoch #17, Batch 7560/24958 loss = 1.2498030531406403, ppl = 3.514471050795399\n","Train Epoch #17, Batch 7561/24958 loss = 1.2493069767951965, ppl = 3.5127334701845228\n","Train Epoch #17, Batch 7562/24958 loss = 1.2508856964111328, ppl = 3.5184556594528504\n","Train Epoch #17, Batch 7563/24958 loss = 1.2511441898345947, ppl = 3.5194815444554934\n","Train Epoch #17, Batch 7564/24958 loss = 1.2504741036891938, ppl = 3.516668348482351\n","Train Epoch #17, Batch 7565/24958 loss = 1.2526553630828858, ppl = 3.5245267744632627\n","Train Epoch #17, Batch 7566/24958 loss = 1.2521776139736176, ppl = 3.523003640675739\n","Train Epoch #17, Batch 7567/24958 loss = 1.2505152714252472, ppl = 3.5166236015793944\n","Train Epoch #17, Batch 7568/24958 loss = 1.2524362540245055, ppl = 3.524616637921034\n","Train Epoch #17, Batch 7569/24958 loss = 1.2536643481254577, ppl = 3.5285751420684006\n","Train Epoch #17, Batch 7570/24958 loss = 1.2544054770469666, ppl = 3.530924191057112\n","Train Epoch #17, Batch 7571/24958 loss = 1.2559266555309296, ppl = 3.5361018711410903\n","Train Epoch #17, Batch 7572/24958 loss = 1.2559314358234406, ppl = 3.5361181193501143\n","Train Epoch #17, Batch 7573/24958 loss = 1.2596899390220642, ppl = 3.552284972541614\n","Train Epoch #17, Batch 7574/24958 loss = 1.2597235429286957, ppl = 3.5524042627219377\n","Train Epoch #17, Batch 7575/24958 loss = 1.258826757669449, ppl = 3.54923138016818\n","Train Epoch #17, Batch 7576/24958 loss = 1.2581514453887939, ppl = 3.5467040996271533\n","Train Epoch #17, Batch 7577/24958 loss = 1.2601374304294586, ppl = 3.5528085320204834\n","Train Epoch #17, Batch 7578/24958 loss = 1.2618154096603393, ppl = 3.5595953079599614\n","Train Epoch #17, Batch 7579/24958 loss = 1.26182976603508, ppl = 3.5596460850509484\n","Train Epoch #17, Batch 7580/24958 loss = 1.2595866584777833, ppl = 3.551304563663572\n","Train Epoch #17, Batch 7581/24958 loss = 1.2623316133022309, ppl = 3.562378981536236\n","Train Epoch #17, Batch 7582/24958 loss = 1.2586847960948944, ppl = 3.549483054398002\n","Train Epoch #17, Batch 7583/24958 loss = 1.2583857309818267, ppl = 3.5483837895530725\n","Train Epoch #17, Batch 7584/24958 loss = 1.2574551141262054, ppl = 3.5453662051155685\n","Train Epoch #17, Batch 7585/24958 loss = 1.2590217435359954, ppl = 3.5516482126311826\n","Train Epoch #17, Batch 7586/24958 loss = 1.26157932639122, ppl = 3.561157172096155\n","Train Epoch #17, Batch 7587/24958 loss = 1.265571849346161, ppl = 3.576734899698739\n","Train Epoch #17, Batch 7588/24958 loss = 1.2690189731121064, ppl = 3.5895383223463795\n","Train Epoch #17, Batch 7589/24958 loss = 1.2688710129261016, ppl = 3.588941913431367\n","Train Epoch #17, Batch 7590/24958 loss = 1.269818013906479, ppl = 3.591847192483934\n","Train Epoch #17, Batch 7591/24958 loss = 1.2688767766952516, ppl = 3.5885460571945815\n","Train Epoch #17, Batch 7592/24958 loss = 1.2698628532886505, ppl = 3.5915868082575035\n","Train Epoch #17, Batch 7593/24958 loss = 1.2670552623271942, ppl = 3.58265044908324\n","Train Epoch #17, Batch 7594/24958 loss = 1.2657655358314515, ppl = 3.578405618957093\n","Train Epoch #17, Batch 7595/24958 loss = 1.2696831607818604, ppl = 3.594953591704989\n","Train Epoch #17, Batch 7596/24958 loss = 1.2690875327587128, ppl = 3.5930462652580673\n","Train Epoch #17, Batch 7597/24958 loss = 1.268611603975296, ppl = 3.591171714195678\n","Train Epoch #17, Batch 7598/24958 loss = 1.2724083292484283, ppl = 3.6041902618869073\n","Train Epoch #17, Batch 7599/24958 loss = 1.2746290177106858, ppl = 3.610753281029522\n","Train Epoch #17, Batch 7600/24958 loss = 1.2757942444086074, ppl = 3.614744850482505\n","Train Epoch #17, Batch 7601/24958 loss = 1.2752502340078353, ppl = 3.612912243583833\n","Train Epoch #17, Batch 7602/24958 loss = 1.2770553654432297, ppl = 3.6197842012534163\n","Train Epoch #17, Batch 7603/24958 loss = 1.277823686003685, ppl = 3.622342468731566\n","Train Epoch #17, Batch 7604/24958 loss = 1.2761598652601243, ppl = 3.6167065328844115\n","Train Epoch #17, Batch 7605/24958 loss = 1.274946281313896, ppl = 3.612443618178202\n","Train Epoch #17, Batch 7606/24958 loss = 1.2774090629816055, ppl = 3.621396037237845\n","Train Epoch #17, Batch 7607/24958 loss = 1.2799677819013595, ppl = 3.6322754608028727\n","Train Epoch #17, Batch 7608/24958 loss = 1.2797028404474258, ppl = 3.63116770719118\n","Train Epoch #17, Batch 7609/24958 loss = 1.2772644919157028, ppl = 3.623318798819207\n","Train Epoch #17, Batch 7610/24958 loss = 1.2768480914831162, ppl = 3.6219146511426046\n","Train Epoch #17, Batch 7611/24958 loss = 1.2781596451997757, ppl = 3.626157560101328\n","Train Epoch #17, Batch 7612/24958 loss = 1.279382809996605, ppl = 3.6307211579899636\n","Train Epoch #17, Batch 7613/24958 loss = 1.2805922776460648, ppl = 3.634829196241088\n","Train Epoch #17, Batch 7614/24958 loss = 1.2822579199075699, ppl = 3.641425658749912\n","Train Epoch #17, Batch 7615/24958 loss = 1.2855276077985764, ppl = 3.652726494000815\n","Train Epoch #17, Batch 7616/24958 loss = 1.2863783317804336, ppl = 3.655519827098031\n","Train Epoch #17, Batch 7617/24958 loss = 1.2889101308584214, ppl = 3.665818868280478\n","Train Epoch #17, Batch 7618/24958 loss = 1.2888333410024644, ppl = 3.6655442458875602\n","Train Epoch #17, Batch 7619/24958 loss = 1.2886041218042374, ppl = 3.6646229754237436\n","Train Epoch #17, Batch 7620/24958 loss = 1.2895345824956894, ppl = 3.6678483807077784\n","Train Epoch #17, Batch 7621/24958 loss = 1.2889998310804367, ppl = 3.66627161814545\n","Train Epoch #17, Batch 7622/24958 loss = 1.2873798912763597, ppl = 3.6602894218712603\n","Train Epoch #17, Batch 7623/24958 loss = 1.290493534207344, ppl = 3.6715083820124246\n","Train Epoch #17, Batch 7624/24958 loss = 1.2860081225633622, ppl = 3.6528541047754066\n","Train Epoch #17, Batch 7625/24958 loss = 1.2851086837053298, ppl = 3.6496145957710424\n","Train Epoch #17, Batch 7626/24958 loss = 1.2842479580640793, ppl = 3.6465256050074815\n","Train Epoch #17, Batch 7627/24958 loss = 1.2849418944120408, ppl = 3.6489307623916507\n","Train Epoch #17, Batch 7628/24958 loss = 1.2816096836328505, ppl = 3.6364013090418386\n","Train Epoch #17, Batch 7629/24958 loss = 1.2863007473945618, ppl = 3.6524818258663463\n","Train Epoch #17, Batch 7630/24958 loss = 1.2862612521648407, ppl = 3.6523514936532115\n","Train Epoch #17, Batch 7631/24958 loss = 1.2869491016864776, ppl = 3.6548171329883137\n","Train Epoch #17, Batch 7632/24958 loss = 1.2875917303562163, ppl = 3.6571209754560523\n","Train Epoch #17, Batch 7633/24958 loss = 1.2881964087486266, ppl = 3.6591837181799547\n","Train Epoch #17, Batch 7634/24958 loss = 1.290306270122528, ppl = 3.6664062236351977\n","Train Epoch #17, Batch 7635/24958 loss = 1.292947428226471, ppl = 3.6757253185397536\n","Train Epoch #17, Batch 7636/24958 loss = 1.2924675512313843, ppl = 3.6740724786394945\n","Train Epoch #17, Batch 7637/24958 loss = 1.2929684591293336, ppl = 3.675915792595498\n","Train Epoch #17, Batch 7638/24958 loss = 1.2977329623699188, ppl = 3.695674802769223\n","Train Epoch #17, Batch 7639/24958 loss = 1.299780362844467, ppl = 3.7027256625608986\n","Train Epoch #17, Batch 7640/24958 loss = 1.2997765827178955, ppl = 3.7027109967976104\n","Train Epoch #17, Batch 7641/24958 loss = 1.2991439092159272, ppl = 3.700031642855308\n","Train Epoch #17, Batch 7642/24958 loss = 1.2967227733135223, ppl = 3.692065512359057\n","Train Epoch #17, Batch 7643/24958 loss = 1.293810292482376, ppl = 3.6813298694199665\n","Train Epoch #17, Batch 7644/24958 loss = 1.2936409199237824, ppl = 3.6807869195652767\n","Train Epoch #17, Batch 7645/24958 loss = 1.2944798684120178, ppl = 3.6833153637643976\n","Train Epoch #17, Batch 7646/24958 loss = 1.294757069349289, ppl = 3.6842289368800816\n","Train Epoch #17, Batch 7647/24958 loss = 1.2951053059101105, ppl = 3.685508900898476\n","Train Epoch #17, Batch 7648/24958 loss = 1.294167640209198, ppl = 3.682243865389842\n","Train Epoch #17, Batch 7649/24958 loss = 1.2975149261951446, ppl = 3.6964644793288652\n","Train Epoch #17, Batch 7650/24958 loss = 1.2997899222373963, ppl = 3.7046815919750706\n","Train Epoch #17, Batch 7651/24958 loss = 1.3009197890758515, ppl = 3.708469010364872\n","Train Epoch #17, Batch 7652/24958 loss = 1.2987830853462219, ppl = 3.7012875208489873\n","Train Epoch #17, Batch 7653/24958 loss = 1.3017115890979767, ppl = 3.713011293767601\n","Train Epoch #17, Batch 7654/24958 loss = 1.303556077480316, ppl = 3.7200040494441335\n","Train Epoch #17, Batch 7655/24958 loss = 1.3035307013988495, ppl = 3.7199007901780847\n","Train Epoch #17, Batch 7656/24958 loss = 1.305054739713669, ppl = 3.7255742239025307\n","Train Epoch #17, Batch 7657/24958 loss = 1.3045213544368743, ppl = 3.7238437670229114\n","Train Epoch #17, Batch 7658/24958 loss = 1.3029417276382447, ppl = 3.717955494217934\n","Train Epoch #17, Batch 7659/24958 loss = 1.3011849761009215, ppl = 3.7111978654929176\n","Train Epoch #17, Batch 7660/24958 loss = 1.3020970046520233, ppl = 3.7144138499577575\n","Train Epoch #17, Batch 7661/24958 loss = 1.30127170920372, ppl = 3.7117074537118815\n","Train Epoch #17, Batch 7662/24958 loss = 1.3018000996112824, ppl = 3.713833472307607\n","Train Epoch #17, Batch 7663/24958 loss = 1.2999022436141967, ppl = 3.706883971267489\n","Train Epoch #17, Batch 7664/24958 loss = 1.2982791650295258, ppl = 3.7008024978785956\n","Train Epoch #17, Batch 7665/24958 loss = 1.2981645631790162, ppl = 3.700345579602777\n","Train Epoch #17, Batch 7666/24958 loss = 1.29870055437088, ppl = 3.7020594233065043\n","Train Epoch #17, Batch 7667/24958 loss = 1.2983814358711243, ppl = 3.700951406334279\n","Train Epoch #17, Batch 7668/24958 loss = 1.2950434482097626, ppl = 3.6879721434679325\n","Train Epoch #17, Batch 7669/24958 loss = 1.2940237927436828, ppl = 3.684651713422145\n","Train Epoch #17, Batch 7670/24958 loss = 1.2935299646854401, ppl = 3.683067225681997\n","Train Epoch #17, Batch 7671/24958 loss = 1.292297158241272, ppl = 3.678811553272212\n","Train Epoch #17, Batch 7672/24958 loss = 1.2911979866027832, ppl = 3.675272633364729\n","Train Epoch #17, Batch 7673/24958 loss = 1.290706695318222, ppl = 3.6727987075840645\n","Train Epoch #17, Batch 7674/24958 loss = 1.290433301925659, ppl = 3.671839728139339\n","Train Epoch #17, Batch 7675/24958 loss = 1.290879487991333, ppl = 3.673382804460054\n","Train Epoch #17, Batch 7676/24958 loss = 1.29099982380867, ppl = 3.6738207424860128\n","Train Epoch #17, Batch 7677/24958 loss = 1.2907899808883667, ppl = 3.673116979275213\n","Train Epoch #17, Batch 7678/24958 loss = 1.2886354184150697, ppl = 3.664601335934189\n","Train Epoch #17, Batch 7679/24958 loss = 1.2864782071113587, ppl = 3.6577334046619314\n","Train Epoch #17, Batch 7680/24958 loss = 1.2853709614276887, ppl = 3.65425645108279\n","Train Epoch #17, Batch 7681/24958 loss = 1.284359006881714, ppl = 3.6498162665633656\n","Train Epoch #17, Batch 7682/24958 loss = 1.2860498452186584, ppl = 3.6552148574297725\n","Train Epoch #17, Batch 7683/24958 loss = 1.2868786191940307, ppl = 3.658343696838171\n","Train Epoch #17, Batch 7684/24958 loss = 1.2881902182102203, ppl = 3.6626799743575833\n","Train Epoch #17, Batch 7685/24958 loss = 1.28680069565773, ppl = 3.657059811542496\n","Train Epoch #17, Batch 7686/24958 loss = 1.2869326531887055, ppl = 3.657619517865237\n","Train Epoch #17, Batch 7687/24958 loss = 1.2841018509864808, ppl = 3.6459524665830525\n","Train Epoch #17, Batch 7688/24958 loss = 1.2816060388088226, ppl = 3.6362536875705813\n","Train Epoch #17, Batch 7689/24958 loss = 1.2795696175098419, ppl = 3.6288817804730225\n","Train Epoch #17, Batch 7690/24958 loss = 1.2806008648872376, ppl = 3.632374691729911\n","Train Epoch #17, Batch 7691/24958 loss = 1.2809201610088348, ppl = 3.633459894129034\n","Train Epoch #17, Batch 7692/24958 loss = 1.2810763657093047, ppl = 3.633969690942136\n","Train Epoch #17, Batch 7693/24958 loss = 1.284876775741577, ppl = 3.6467164858032266\n","Train Epoch #17, Batch 7694/24958 loss = 1.2847796022891997, ppl = 3.646418294532997\n","Train Epoch #17, Batch 7695/24958 loss = 1.2808166015148164, ppl = 3.629714108617891\n","Train Epoch #17, Batch 7696/24958 loss = 1.2821219730377198, ppl = 3.634047620931259\n","Train Epoch #17, Batch 7697/24958 loss = 1.279248126745224, ppl = 3.624441857236062\n","Train Epoch #17, Batch 7698/24958 loss = 1.2769486939907073, ppl = 3.615976635088577\n","Train Epoch #17, Batch 7699/24958 loss = 1.2781129729747773, ppl = 3.6200460313632954\n","Train Epoch #17, Batch 7700/24958 loss = 1.2774893712997437, ppl = 3.617852082622623\n","Train Epoch #17, Batch 7701/24958 loss = 1.277442181110382, ppl = 3.617697762369366\n","Train Epoch #17, Batch 7702/24958 loss = 1.2746017467975617, ppl = 3.6074094396078213\n","Train Epoch #17, Batch 7703/24958 loss = 1.2740800666809082, ppl = 3.605651087127969\n","Train Epoch #17, Batch 7704/24958 loss = 1.2744895684719086, ppl = 3.6069524776558537\n","Train Epoch #17, Batch 7705/24958 loss = 1.2741796600818633, ppl = 3.605944295883515\n","Train Epoch #17, Batch 7706/24958 loss = 1.2716908252239227, ppl = 3.596908463742486\n","Train Epoch #17, Batch 7707/24958 loss = 1.270385386943817, ppl = 3.591010819838506\n","Train Epoch #17, Batch 7708/24958 loss = 1.2705442082881928, ppl = 3.591671345387769\n","Train Epoch #17, Batch 7709/24958 loss = 1.2741686165332795, ppl = 3.6040880027939077\n","Train Epoch #17, Batch 7710/24958 loss = 1.2764952790737152, ppl = 3.6127389485521304\n","Train Epoch #17, Batch 7711/24958 loss = 1.274115046262741, ppl = 3.605427482132507\n","Train Epoch #17, Batch 7712/24958 loss = 1.2727760922908784, ppl = 3.6004601021400906\n","Train Epoch #17, Batch 7713/24958 loss = 1.2741900646686555, ppl = 3.6059371366858755\n","Train Epoch #17, Batch 7714/24958 loss = 1.2706946241855621, ppl = 3.593254647920767\n","Train Epoch #17, Batch 7715/24958 loss = 1.2686068201065064, ppl = 3.5856195625027754\n","Train Epoch #17, Batch 7716/24958 loss = 1.2697626769542694, ppl = 3.5898163910413916\n","Train Epoch #17, Batch 7717/24958 loss = 1.2689773952960968, ppl = 3.586338864698312\n","Train Epoch #17, Batch 7718/24958 loss = 1.2696672558784485, ppl = 3.5888832983712153\n","Train Epoch #17, Batch 7719/24958 loss = 1.269913444519043, ppl = 3.5898736151003514\n","Train Epoch #17, Batch 7720/24958 loss = 1.272938870191574, ppl = 3.6026990512817427\n","Train Epoch #17, Batch 7721/24958 loss = 1.2722526001930237, ppl = 3.6007952189255117\n","Train Epoch #17, Batch 7722/24958 loss = 1.274006154537201, ppl = 3.6073154643128174\n","Train Epoch #17, Batch 7723/24958 loss = 1.2730623948574067, ppl = 3.6035391174022235\n","Train Epoch #17, Batch 7724/24958 loss = 1.2735283696651458, ppl = 3.60511115284106\n","Train Epoch #17, Batch 7725/24958 loss = 1.2723240602016448, ppl = 3.601205628328234\n","Train Epoch #17, Batch 7726/24958 loss = 1.273197168111801, ppl = 3.604341025437663\n","Train Epoch #17, Batch 7727/24958 loss = 1.274269493818283, ppl = 3.608401954445086\n","Train Epoch #17, Batch 7728/24958 loss = 1.2752957594394685, ppl = 3.6118262373184056\n","Train Epoch #17, Batch 7729/24958 loss = 1.2734714603424073, ppl = 3.6046647549838324\n","Train Epoch #17, Batch 7730/24958 loss = 1.2740630424022674, ppl = 3.6066718760959224\n","Train Epoch #17, Batch 7731/24958 loss = 1.2740231907367707, ppl = 3.6065243501679847\n","Train Epoch #17, Batch 7732/24958 loss = 1.2726439952850341, ppl = 3.6017557206390425\n","Train Epoch #17, Batch 7733/24958 loss = 1.271718909740448, ppl = 3.5986494904090818\n","Train Epoch #17, Batch 7734/24958 loss = 1.2707008910179138, ppl = 3.594974289593614\n","Train Epoch #17, Batch 7735/24958 loss = 1.2701008331775665, ppl = 3.59263600176787\n","Train Epoch #17, Batch 7736/24958 loss = 1.2701526808738708, ppl = 3.592810782921058\n","Train Epoch #17, Batch 7737/24958 loss = 1.2701176333427429, ppl = 3.5926787842037236\n","Train Epoch #17, Batch 7738/24958 loss = 1.2660276055336, ppl = 3.5751785966921927\n","Train Epoch #17, Batch 7739/24958 loss = 1.2650496196746825, ppl = 3.5716303918450687\n","Train Epoch #17, Batch 7740/24958 loss = 1.2668027532100679, ppl = 3.579063253893622\n","Train Epoch #17, Batch 7741/24958 loss = 1.2662463879585266, ppl = 3.5768431445034805\n","Train Epoch #17, Batch 7742/24958 loss = 1.267743204832077, ppl = 3.581538524086673\n","Train Epoch #17, Batch 7743/24958 loss = 1.2675943624973298, ppl = 3.581069402093622\n","Train Epoch #17, Batch 7744/24958 loss = 1.2697776865959167, ppl = 3.588825161889121\n","Train Epoch #17, Batch 7745/24958 loss = 1.272809008359909, ppl = 3.5999508307073653\n","Train Epoch #17, Batch 7746/24958 loss = 1.2726929354667664, ppl = 3.599565204260992\n","Train Epoch #17, Batch 7747/24958 loss = 1.2714277684688569, ppl = 3.595120651935282\n","Train Epoch #17, Batch 7748/24958 loss = 1.2709629011154175, ppl = 3.593611985166445\n","Train Epoch #17, Batch 7749/24958 loss = 1.2681006467342377, ppl = 3.5811690753150227\n","Train Epoch #17, Batch 7750/24958 loss = 1.266613312959671, ppl = 3.5755880373012747\n","Train Epoch #17, Batch 7751/24958 loss = 1.2673608458042145, ppl = 3.578339626825004\n","Train Epoch #17, Batch 7752/24958 loss = 1.2706496596336365, ppl = 3.590079325160135\n","Train Epoch #17, Batch 7753/24958 loss = 1.2683680856227875, ppl = 3.580658371830972\n","Train Epoch #17, Batch 7754/24958 loss = 1.2659623062610625, ppl = 3.5717812677540643\n","Train Epoch #17, Batch 7755/24958 loss = 1.2633940029144286, ppl = 3.562576292921286\n","Train Epoch #17, Batch 7756/24958 loss = 1.260663229227066, ppl = 3.5529853736702717\n","Train Epoch #17, Batch 7757/24958 loss = 1.2629246485233308, ppl = 3.5610002748356853\n","Train Epoch #17, Batch 7758/24958 loss = 1.2643219721317291, ppl = 3.566160558706877\n","Train Epoch #17, Batch 7759/24958 loss = 1.263284194469452, ppl = 3.5626920529209856\n","Train Epoch #17, Batch 7760/24958 loss = 1.2648996484279633, ppl = 3.5691605786050427\n","Train Epoch #17, Batch 7761/24958 loss = 1.2665663111209868, ppl = 3.574865885318342\n","Train Epoch #17, Batch 7762/24958 loss = 1.263702734708786, ppl = 3.564579913999182\n","Train Epoch #17, Batch 7763/24958 loss = 1.2671996223926545, ppl = 3.5785003718966015\n","Train Epoch #17, Batch 7764/24958 loss = 1.2677740573883056, ppl = 3.5805408044950955\n","Train Epoch #17, Batch 7765/24958 loss = 1.267223926782608, ppl = 3.5784188766532012\n","Train Epoch #17, Batch 7766/24958 loss = 1.26917227268219, ppl = 3.5854830448821917\n","Train Epoch #17, Batch 7767/24958 loss = 1.26932892203331, ppl = 3.5860225319908454\n","Train Epoch #17, Batch 7768/24958 loss = 1.2702868390083313, ppl = 3.5893153084873597\n","Train Epoch #17, Batch 7769/24958 loss = 1.2725474560260772, ppl = 3.5971613617632467\n","Train Epoch #17, Batch 7770/24958 loss = 1.2743000614643096, ppl = 3.6031571024091162\n","Train Epoch #17, Batch 7771/24958 loss = 1.2735346961021423, ppl = 3.60076718243047\n","Train Epoch #17, Batch 7772/24958 loss = 1.2747504758834838, ppl = 3.604704868479839\n","Train Epoch #17, Batch 7773/24958 loss = 1.272282463312149, ppl = 3.5939602130870254\n","Train Epoch #17, Batch 7774/24958 loss = 1.272703722715378, ppl = 3.5954488896413066\n","Train Epoch #17, Batch 7775/24958 loss = 1.2725263452529907, ppl = 3.5948271957291484\n","Train Epoch #17, Batch 7776/24958 loss = 1.2733062529563903, ppl = 3.5977969255203646\n","Train Epoch #17, Batch 7777/24958 loss = 1.2731832265853882, ppl = 3.597391139521509\n","Train Epoch #17, Batch 7778/24958 loss = 1.27317844748497, ppl = 3.597374216600491\n","Train Epoch #17, Batch 7779/24958 loss = 1.276913801431656, ppl = 3.610292776652136\n","Train Epoch #17, Batch 7780/24958 loss = 1.2793100416660308, ppl = 3.618333444685131\n","Train Epoch #17, Batch 7781/24958 loss = 1.2761535012722016, ppl = 3.6070471896613765\n","Train Epoch #17, Batch 7782/24958 loss = 1.2760568678379058, ppl = 3.606713449912377\n","Train Epoch #17, Batch 7783/24958 loss = 1.2753582429885864, ppl = 3.604058958158888\n","Train Epoch #17, Batch 7784/24958 loss = 1.2746194076538087, ppl = 3.601546559388081\n","Train Epoch #17, Batch 7785/24958 loss = 1.2736565780639648, ppl = 3.5980858075360813\n","Train Epoch #17, Batch 7786/24958 loss = 1.2709662115573883, ppl = 3.5880144464401043\n","Train Epoch #17, Batch 7787/24958 loss = 1.2702642393112182, ppl = 3.585597325654025\n","Train Epoch #17, Batch 7788/24958 loss = 1.2709468162059785, ppl = 3.5880141247254613\n","Train Epoch #17, Batch 7789/24958 loss = 1.2738297140598298, ppl = 3.598920368941828\n","Train Epoch #17, Batch 7790/24958 loss = 1.274251811504364, ppl = 3.6004572356916396\n","Train Epoch #17, Batch 7791/24958 loss = 1.2747553610801696, ppl = 3.602240659819776\n","Train Epoch #17, Batch 7792/24958 loss = 1.2736688947677612, ppl = 3.5988543392062513\n","Train Epoch #17, Batch 7793/24958 loss = 1.272138043642044, ppl = 3.5931316534036046\n","Train Epoch #17, Batch 7794/24958 loss = 1.2726988434791564, ppl = 3.5948931341074966\n","Train Epoch #17, Batch 7795/24958 loss = 1.27342942237854, ppl = 3.597496501382894\n","Train Epoch #17, Batch 7796/24958 loss = 1.2725591659545898, ppl = 3.594545086409887\n","Train Epoch #17, Batch 7797/24958 loss = 1.2752059769630433, ppl = 3.6032875688113513\n","Train Epoch #17, Batch 7798/24958 loss = 1.2763177621364594, ppl = 3.6071380621033327\n","Train Epoch #17, Batch 7799/24958 loss = 1.2797740626335143, ppl = 3.6224254510833425\n","Train Epoch #17, Batch 7800/24958 loss = 1.279405379295349, ppl = 3.621191267548822\n","Train Epoch #17, Batch 7801/24958 loss = 1.2804531669616699, ppl = 3.624795148452137\n","Train Epoch #17, Batch 7802/24958 loss = 1.2826224505901336, ppl = 3.6323825756899466\n","Train Epoch #17, Batch 7803/24958 loss = 1.2844904053211212, ppl = 3.6391260538451977\n","Train Epoch #17, Batch 7804/24958 loss = 1.2853875029087067, ppl = 3.6421702963543434\n","Train Epoch #17, Batch 7805/24958 loss = 1.2869002282619477, ppl = 3.6474012522909423\n","Train Epoch #17, Batch 7806/24958 loss = 1.2871123957633972, ppl = 3.6480869008381855\n","Train Epoch #17, Batch 7807/24958 loss = 1.2838134837150574, ppl = 3.6362027012670968\n","Train Epoch #17, Batch 7808/24958 loss = 1.2813904917240142, ppl = 3.6271823348379626\n","Train Epoch #17, Batch 7809/24958 loss = 1.279373230934143, ppl = 3.6197214554483246\n","Train Epoch #17, Batch 7810/24958 loss = 1.279065532684326, ppl = 3.618458655766243\n","Train Epoch #17, Batch 7811/24958 loss = 1.2814974224567413, ppl = 3.6259488933559667\n","Train Epoch #17, Batch 7812/24958 loss = 1.282463527917862, ppl = 3.629465586584636\n","Train Epoch #17, Batch 7813/24958 loss = 1.2808380210399628, ppl = 3.623233747159992\n","Train Epoch #17, Batch 7814/24958 loss = 1.2835045409202577, ppl = 3.632496174637638\n","Train Epoch #17, Batch 7815/24958 loss = 1.2835039341449737, ppl = 3.6324941793096825\n","Train Epoch #17, Batch 7816/24958 loss = 1.28156236410141, ppl = 3.6257091942283832\n","Train Epoch #17, Batch 7817/24958 loss = 1.2810111129283905, ppl = 3.623426144017635\n","Train Epoch #17, Batch 7818/24958 loss = 1.278891258239746, ppl = 3.616134747335422\n","Train Epoch #17, Batch 7819/24958 loss = 1.276166639328003, ppl = 3.606422382657899\n","Train Epoch #17, Batch 7820/24958 loss = 1.2755830073356629, ppl = 3.603637196720648\n","Train Epoch #17, Batch 7821/24958 loss = 1.2782242965698243, ppl = 3.6117389464611267\n","Train Epoch #17, Batch 7822/24958 loss = 1.2783651387691497, ppl = 3.6123139375421944\n","Train Epoch #17, Batch 7823/24958 loss = 1.278889149427414, ppl = 3.6143666323107446\n","Train Epoch #17, Batch 7824/24958 loss = 1.2813463521003723, ppl = 3.6239842965299585\n","Train Epoch #17, Batch 7825/24958 loss = 1.2830918610095978, ppl = 3.6298040436308994\n","Train Epoch #17, Batch 7826/24958 loss = 1.28024223446846, ppl = 3.620505316125715\n","Train Epoch #17, Batch 7827/24958 loss = 1.2791400682926177, ppl = 3.6163374906890446\n","Train Epoch #17, Batch 7828/24958 loss = 1.2784968280792237, ppl = 3.614150310161179\n","Train Epoch #17, Batch 7829/24958 loss = 1.2767756330966948, ppl = 3.608492069533422\n","Train Epoch #17, Batch 7830/24958 loss = 1.2751910603046417, ppl = 3.6033717248903843\n","Train Epoch #17, Batch 7831/24958 loss = 1.2740513145923615, ppl = 3.5993920282641607\n","Train Epoch #17, Batch 7832/24958 loss = 1.2768540382385254, ppl = 3.609823268271317\n","Train Epoch #17, Batch 7833/24958 loss = 1.277684770822525, ppl = 3.6125993622839503\n","Train Epoch #17, Batch 7834/24958 loss = 1.2778296279907226, ppl = 3.6130997666784817\n","Train Epoch #17, Batch 7835/24958 loss = 1.2777044808864593, ppl = 3.612629530853309\n","Train Epoch #17, Batch 7836/24958 loss = 1.2779313051700592, ppl = 3.613404911206379\n","Train Epoch #17, Batch 7837/24958 loss = 1.275914239883423, ppl = 3.6065372805600533\n","Train Epoch #17, Batch 7838/24958 loss = 1.2756221330165862, ppl = 3.6055402834043235\n","Train Epoch #17, Batch 7839/24958 loss = 1.2758664190769196, ppl = 3.606394327790656\n","Train Epoch #17, Batch 7840/24958 loss = 1.27242879986763, ppl = 3.592948084170624\n","Train Epoch #17, Batch 7841/24958 loss = 1.2710721230506896, ppl = 3.5880251208675453\n","Train Epoch #17, Batch 7842/24958 loss = 1.2742259109020233, ppl = 3.6005482866442615\n","Train Epoch #17, Batch 7843/24958 loss = 1.2763198864459993, ppl = 3.6078354432256607\n","Train Epoch #17, Batch 7844/24958 loss = 1.2756966042518616, ppl = 3.605446120689535\n","Train Epoch #17, Batch 7845/24958 loss = 1.273509613275528, ppl = 3.597088567884587\n","Train Epoch #17, Batch 7846/24958 loss = 1.2753903782367706, ppl = 3.603923399072299\n","Train Epoch #17, Batch 7847/24958 loss = 1.2758228635787965, ppl = 3.605379912011249\n","Train Epoch #17, Batch 7848/24958 loss = 1.2766273534297943, ppl = 3.608035970656751\n","Train Epoch #17, Batch 7849/24958 loss = 1.2758077430725097, ppl = 3.605081289872958\n","Train Epoch #17, Batch 7850/24958 loss = 1.276297274827957, ppl = 3.6068273675003777\n","Train Epoch #17, Batch 7851/24958 loss = 1.2754414224624633, ppl = 3.6036938543641885\n","Train Epoch #17, Batch 7852/24958 loss = 1.2716437911987304, ppl = 3.5904585870423005\n","Train Epoch #17, Batch 7853/24958 loss = 1.272996129989624, ppl = 3.5957815938692708\n","Train Epoch #17, Batch 7854/24958 loss = 1.272632097005844, ppl = 3.5946148173160055\n","Train Epoch #17, Batch 7855/24958 loss = 1.274808521270752, ppl = 3.6022579985183008\n","Train Epoch #17, Batch 7856/24958 loss = 1.2736450707912446, ppl = 3.5989032747322933\n","Train Epoch #17, Batch 7857/24958 loss = 1.2728687310218811, ppl = 3.5959452551602338\n","Train Epoch #17, Batch 7858/24958 loss = 1.2700799465179444, ppl = 3.586315182946362\n","Train Epoch #17, Batch 7859/24958 loss = 1.271206600666046, ppl = 3.5900978094083054\n","Train Epoch #17, Batch 7860/24958 loss = 1.2691443467140198, ppl = 3.5820171294778387\n","Train Epoch #17, Batch 7861/24958 loss = 1.2685277187824249, ppl = 3.57979473086814\n","Train Epoch #17, Batch 7862/24958 loss = 1.2683741223812104, ppl = 3.5793218824643827\n","Train Epoch #17, Batch 7863/24958 loss = 1.2661364603042602, ppl = 3.5698637531283683\n","Train Epoch #17, Batch 7864/24958 loss = 1.2680124199390412, ppl = 3.5774058381657823\n","Train Epoch #17, Batch 7865/24958 loss = 1.2676958656311035, ppl = 3.576236724928944\n","Train Epoch #17, Batch 7866/24958 loss = 1.2677196145057679, ppl = 3.576331604978196\n","Train Epoch #17, Batch 7867/24958 loss = 1.2674422979354858, ppl = 3.5753822743079007\n","Train Epoch #17, Batch 7868/24958 loss = 1.2668539452552796, ppl = 3.573322622957434\n","Train Epoch #17, Batch 7869/24958 loss = 1.26974422454834, ppl = 3.5863183507367764\n","Train Epoch #17, Batch 7870/24958 loss = 1.2692510974407196, ppl = 3.5845238026477055\n","Train Epoch #17, Batch 7871/24958 loss = 1.271550316810608, ppl = 3.5922907859754734\n","Train Epoch #17, Batch 7872/24958 loss = 1.273727127313614, ppl = 3.600655780040873\n","Train Epoch #17, Batch 7873/24958 loss = 1.273781694173813, ppl = 3.600865802461601\n","Train Epoch #17, Batch 7874/24958 loss = 1.2730880510807037, ppl = 3.5984474086668894\n","Train Epoch #17, Batch 7875/24958 loss = 1.2739695644378661, ppl = 3.6016487508960062\n","Train Epoch #17, Batch 7876/24958 loss = 1.2745881414413451, ppl = 3.6041745242772287\n","Train Epoch #17, Batch 7877/24958 loss = 1.2721737670898436, ppl = 3.5971428932199725\n","Train Epoch #17, Batch 7878/24958 loss = 1.2716469073295593, ppl = 3.595325997361292\n","Train Epoch #17, Batch 7879/24958 loss = 1.2692209815979003, ppl = 3.5863983665868293\n","Train Epoch #17, Batch 7880/24958 loss = 1.269569869041443, ppl = 3.5877381675483577\n","Train Epoch #17, Batch 7881/24958 loss = 1.271622087955475, ppl = 3.5946651246773196\n","Train Epoch #17, Batch 7882/24958 loss = 1.272857494354248, ppl = 3.5991846514480335\n","Train Epoch #17, Batch 7883/24958 loss = 1.271358698606491, ppl = 3.594078643029365\n","Train Epoch #17, Batch 7884/24958 loss = 1.2712677228450775, ppl = 3.593781920708488\n","Train Epoch #17, Batch 7885/24958 loss = 1.2715703821182252, ppl = 3.59483409681439\n","Train Epoch #17, Batch 7886/24958 loss = 1.2746877777576446, ppl = 3.606768195266949\n","Train Epoch #17, Batch 7887/24958 loss = 1.2753993964195252, ppl = 3.609219727888653\n","Train Epoch #17, Batch 7888/24958 loss = 1.2755996155738831, ppl = 3.609960504403734\n","Train Epoch #17, Batch 7889/24958 loss = 1.272365721464157, ppl = 3.5979285030249524\n","Train Epoch #17, Batch 7890/24958 loss = 1.2702247166633607, ppl = 3.590761914625543\n","Train Epoch #17, Batch 7891/24958 loss = 1.2688953828811647, ppl = 3.5862413923702636\n","Train Epoch #17, Batch 7892/24958 loss = 1.270324056148529, ppl = 3.5907727815601835\n","Train Epoch #17, Batch 7893/24958 loss = 1.271316727399826, ppl = 3.594383056455021\n","Train Epoch #17, Batch 7894/24958 loss = 1.271228541135788, ppl = 3.5940994748033406\n","Train Epoch #17, Batch 7895/24958 loss = 1.2702071523666383, ppl = 3.590511604612632\n","Train Epoch #17, Batch 7896/24958 loss = 1.2719153428077699, ppl = 3.5965581272041773\n","Train Epoch #17, Batch 7897/24958 loss = 1.2714587509632111, ppl = 3.5948802091544483\n","Train Epoch #17, Batch 7898/24958 loss = 1.2712930381298064, ppl = 3.59427879083253\n","Train Epoch #17, Batch 7899/24958 loss = 1.2672420620918274, ppl = 3.5768537326145116\n","Train Epoch #17, Batch 7900/24958 loss = 1.2698415398597718, ppl = 3.5866092636995974\n","Train Epoch #17, Batch 7901/24958 loss = 1.2692255318164825, ppl = 3.584444903569389\n","Train Epoch #17, Batch 7902/24958 loss = 1.2680155420303345, ppl = 3.5800108146365615\n","Train Epoch #17, Batch 7903/24958 loss = 1.2651112389564514, ppl = 3.570034971897533\n","Train Epoch #17, Batch 7904/24958 loss = 1.2648434388637542, ppl = 3.5690974473269903\n","Train Epoch #17, Batch 7905/24958 loss = 1.2633471035957335, ppl = 3.5639190320740086\n","Train Epoch #17, Batch 7906/24958 loss = 1.2631603050231934, ppl = 3.563314603065906\n","Train Epoch #17, Batch 7907/24958 loss = 1.2657762372493744, ppl = 3.572406720465711\n","Train Epoch #17, Batch 7908/24958 loss = 1.265377916097641, ppl = 3.57112200074633\n","Train Epoch #17, Batch 7909/24958 loss = 1.2653229999542237, ppl = 3.5709391925448775\n","Train Epoch #17, Batch 7910/24958 loss = 1.2645421993732453, ppl = 3.567903859879991\n","Train Epoch #17, Batch 7911/24958 loss = 1.2656797289848327, ppl = 3.5720839711223062\n","Train Epoch #17, Batch 7912/24958 loss = 1.264912464618683, ppl = 3.5692635731408764\n","Train Epoch #17, Batch 7913/24958 loss = 1.2642904901504517, ppl = 3.567134510035452\n","Train Epoch #17, Batch 7914/24958 loss = 1.2629318594932557, ppl = 3.5621072663834337\n","Train Epoch #17, Batch 7915/24958 loss = 1.2624110746383668, ppl = 3.5604385906398153\n","Train Epoch #17, Batch 7916/24958 loss = 1.265800141096115, ppl = 3.5732118698074355\n","Train Epoch #17, Batch 7917/24958 loss = 1.2658374857902528, ppl = 3.5733625932382047\n","Train Epoch #17, Batch 7918/24958 loss = 1.269454253911972, ppl = 3.5868175405865816\n","Train Epoch #17, Batch 7919/24958 loss = 1.2710782015323638, ppl = 3.5922854972705993\n","Train Epoch #17, Batch 7920/24958 loss = 1.2675363326072693, ppl = 3.5784635404117857\n","Train Epoch #17, Batch 7921/24958 loss = 1.2673526465892793, ppl = 3.577828283274266\n","Train Epoch #17, Batch 7922/24958 loss = 1.2673052859306335, ppl = 3.5776340280149883\n","Train Epoch #17, Batch 7923/24958 loss = 1.265879864692688, ppl = 3.5722924260869457\n","Train Epoch #17, Batch 7924/24958 loss = 1.2675056922435761, ppl = 3.5800862603854866\n","Train Epoch #17, Batch 7925/24958 loss = 1.2667335486412048, ppl = 3.577386201947329\n","Train Epoch #17, Batch 7926/24958 loss = 1.2692397582530974, ppl = 3.585418934924553\n","Train Epoch #17, Batch 7927/24958 loss = 1.268415241241455, ppl = 3.5825880130581966\n","Train Epoch #17, Batch 7928/24958 loss = 1.2704220974445344, ppl = 3.5899043201327503\n","Train Epoch #17, Batch 7929/24958 loss = 1.273127679824829, ppl = 3.599264316384341\n","Train Epoch #17, Batch 7930/24958 loss = 1.2774077105522155, ppl = 3.6151944924625288\n","Train Epoch #17, Batch 7931/24958 loss = 1.2758060002326965, ppl = 3.6103155565755585\n","Train Epoch #17, Batch 7932/24958 loss = 1.2742068004608154, ppl = 3.604008383819531\n","Train Epoch #17, Batch 7933/24958 loss = 1.2746620392799377, ppl = 3.6056303782330743\n","Train Epoch #17, Batch 7934/24958 loss = 1.2733408629894256, ppl = 3.6013240169012795\n","Train Epoch #17, Batch 7935/24958 loss = 1.2726915776729584, ppl = 3.5989766155396192\n","Train Epoch #17, Batch 7936/24958 loss = 1.273571581840515, ppl = 3.602156968069653\n","Train Epoch #17, Batch 7937/24958 loss = 1.2761285638809203, ppl = 3.611110312482806\n","Train Epoch #17, Batch 7938/24958 loss = 1.275958114862442, ppl = 3.6105418625739167\n","Train Epoch #17, Batch 7939/24958 loss = 1.275954030752182, ppl = 3.610527412025194\n","Train Epoch #17, Batch 7940/24958 loss = 1.2788710415363311, ppl = 3.6216288371442436\n","Train Epoch #17, Batch 7941/24958 loss = 1.2801540958881379, ppl = 3.6262671645373685\n","Train Epoch #17, Batch 7942/24958 loss = 1.27716956615448, ppl = 3.614320539150272\n","Train Epoch #17, Batch 7943/24958 loss = 1.2750493276119232, ppl = 3.606951329017594\n","Train Epoch #17, Batch 7944/24958 loss = 1.2747123789787294, ppl = 3.605720343737819\n","Train Epoch #17, Batch 7945/24958 loss = 1.276436961889267, ppl = 3.612155336475991\n","Train Epoch #17, Batch 7946/24958 loss = 1.2756851291656495, ppl = 3.609268040392192\n","Train Epoch #17, Batch 7947/24958 loss = 1.2760996854305267, ppl = 3.6107245621068773\n","Train Epoch #17, Batch 7948/24958 loss = 1.2759017908573151, ppl = 3.61005125530505\n","Train Epoch #17, Batch 7949/24958 loss = 1.2760362386703492, ppl = 3.6105194866409294\n","Train Epoch #17, Batch 7950/24958 loss = 1.2771476686000824, ppl = 3.6148159325793063\n","Train Epoch #17, Batch 7951/24958 loss = 1.2793786859512328, ppl = 3.6235811910173084\n","Train Epoch #17, Batch 7952/24958 loss = 1.281754982471466, ppl = 3.6312666778697134\n","Train Epoch #17, Batch 7953/24958 loss = 1.2820709991455077, ppl = 3.632617806136159\n","Train Epoch #17, Batch 7954/24958 loss = 1.2845078456401824, ppl = 3.6413021247638744\n","Train Epoch #17, Batch 7955/24958 loss = 1.283165726661682, ppl = 3.6363940924996045\n","Train Epoch #17, Batch 7956/24958 loss = 1.2845737290382386, ppl = 3.640504987583692\n","Train Epoch #17, Batch 7957/24958 loss = 1.2828543531894683, ppl = 3.6347166744433785\n","Train Epoch #17, Batch 7958/24958 loss = 1.2842943251132966, ppl = 3.639353793301231\n","Train Epoch #17, Batch 7959/24958 loss = 1.2841313087940216, ppl = 3.6387797638359096\n","Train Epoch #17, Batch 7960/24958 loss = 1.2842348611354828, ppl = 3.6391470170839035\n","Train Epoch #17, Batch 7961/24958 loss = 1.2844531393051148, ppl = 3.639918096004284\n","Train Epoch #17, Batch 7962/24958 loss = 1.2854010844230652, ppl = 3.6429557022026633\n","Train Epoch #17, Batch 7963/24958 loss = 1.2842433667182922, ppl = 3.638832634142218\n","Train Epoch #17, Batch 7964/24958 loss = 1.2819429969787597, ppl = 3.6297717591628613\n","Train Epoch #17, Batch 7965/24958 loss = 1.2826019084453584, ppl = 3.6322476416909546\n","Train Epoch #17, Batch 7966/24958 loss = 1.2811107242107391, ppl = 3.62670648516474\n","Train Epoch #17, Batch 7967/24958 loss = 1.2808301281929015, ppl = 3.625772352393986\n","Train Epoch #17, Batch 7968/24958 loss = 1.2821192133426667, ppl = 3.630448538799413\n","Train Epoch #17, Batch 7969/24958 loss = 1.2778629016876222, ppl = 3.612501454889734\n","Train Epoch #17, Batch 7970/24958 loss = 1.2788331043720245, ppl = 3.6161184221429443\n","Train Epoch #17, Batch 7971/24958 loss = 1.2763514065742492, ppl = 3.607808133504773\n","Train Epoch #17, Batch 7972/24958 loss = 1.2743838357925414, ppl = 3.600170441284052\n","Train Epoch #17, Batch 7973/24958 loss = 1.2743351197242736, ppl = 3.5999828831669327\n","Train Epoch #17, Batch 7974/24958 loss = 1.2732206737995149, ppl = 3.596432089305698\n","Train Epoch #17, Batch 7975/24958 loss = 1.2718314146995544, ppl = 3.5915109066087676\n","Train Epoch #17, Batch 7976/24958 loss = 1.2721464586257936, ppl = 3.592858608275701\n","Train Epoch #17, Batch 7977/24958 loss = 1.2754564595222473, ppl = 3.602961700338075\n","Train Epoch #17, Batch 7978/24958 loss = 1.2771588611602782, ppl = 3.6091947083804876\n","Train Epoch #17, Batch 7979/24958 loss = 1.2790567433834077, ppl = 3.615990637385093\n","Train Epoch #17, Batch 7980/24958 loss = 1.2773623621463777, ppl = 3.609900229009743\n","Train Epoch #17, Batch 7981/24958 loss = 1.2768505227565765, ppl = 3.6080373399449224\n","Train Epoch #17, Batch 7982/24958 loss = 1.2777710235118866, ppl = 3.6117870645013195\n","Train Epoch #17, Batch 7983/24958 loss = 1.277635247707367, ppl = 3.611361207194528\n","Train Epoch #17, Batch 7984/24958 loss = 1.2778413224220275, ppl = 3.6120372197378354\n","Train Epoch #17, Batch 7985/24958 loss = 1.2787451505661012, ppl = 3.6153757098190606\n","Train Epoch #17, Batch 7986/24958 loss = 1.2761513543128968, ppl = 3.6051953534503722\n","Train Epoch #17, Batch 7987/24958 loss = 1.2741598331928252, ppl = 3.5987505694555635\n","Train Epoch #17, Batch 7988/24958 loss = 1.2747986721992492, ppl = 3.601215811233308\n","Train Epoch #17, Batch 7989/24958 loss = 1.2780707013607024, ppl = 3.6134141910669086\n","Train Epoch #17, Batch 7990/24958 loss = 1.2786368250846862, ppl = 3.615162575350801\n","Train Epoch #17, Batch 7991/24958 loss = 1.278356614112854, ppl = 3.614283991190976\n","Train Epoch #17, Batch 7992/24958 loss = 1.2781117963790893, ppl = 3.6134608203591343\n","Train Epoch #17, Batch 7993/24958 loss = 1.2784137201309205, ppl = 3.614631888258422\n","Train Epoch #17, Batch 7994/24958 loss = 1.2791328132152557, ppl = 3.617018899273327\n","Train Epoch #17, Batch 7995/24958 loss = 1.2786322116851807, ppl = 3.615389810313006\n","Train Epoch #17, Batch 7996/24958 loss = 1.2792070508003235, ppl = 3.61766817357566\n","Train Epoch #17, Batch 7997/24958 loss = 1.2777103996276855, ppl = 3.612675690652349\n","Train Epoch #17, Batch 7998/24958 loss = 1.2776084697246552, ppl = 3.6123106785659047\n","Train Epoch #17, Batch 7999/24958 loss = 1.277269982099533, ppl = 3.6111495064778243\n","Train Epoch #17, Batch 8000/24958 loss = 1.274572937488556, ppl = 3.601074908956384\n","Train Epoch #17, Batch 8001/24958 loss = 1.2731923508644103, ppl = 3.5966822499829396\n","Train Epoch #17, Batch 8002/24958 loss = 1.2724529314041138, ppl = 3.5942251845731352\n","Train Epoch #17, Batch 8003/24958 loss = 1.2750099074840546, ppl = 3.602849991787679\n","Train Epoch #17, Batch 8004/24958 loss = 1.2744212579727172, ppl = 3.600875383843666\n","Train Epoch #17, Batch 8005/24958 loss = 1.2761994695663452, ppl = 3.60711904341364\n","Train Epoch #17, Batch 8006/24958 loss = 1.277064106464386, ppl = 3.6100140765741857\n","Train Epoch #17, Batch 8007/24958 loss = 1.2768753743171692, ppl = 3.609275561680444\n","Train Epoch #17, Batch 8008/24958 loss = 1.279103035926819, ppl = 3.6171644675474517\n","Train Epoch #17, Batch 8009/24958 loss = 1.2811013984680175, ppl = 3.624507799848313\n","Train Epoch #17, Batch 8010/24958 loss = 1.2820116829872132, ppl = 3.628069805889004\n","Train Epoch #17, Batch 8011/24958 loss = 1.2795635509490966, ppl = 3.6196277065013702\n","Train Epoch #17, Batch 8012/24958 loss = 1.2808709132671356, ppl = 3.624567310462739\n","Train Epoch #17, Batch 8013/24958 loss = 1.2807308781147002, ppl = 3.6241059506480275\n","Train Epoch #17, Batch 8014/24958 loss = 1.2802588427066803, ppl = 3.6225131660745817\n","Train Epoch #17, Batch 8015/24958 loss = 1.2819726300239562, ppl = 3.628348403396169\n","Train Epoch #17, Batch 8016/24958 loss = 1.2786075568199158, ppl = 3.6156511854857047\n","Train Epoch #17, Batch 8017/24958 loss = 1.2763284993171693, ppl = 3.6074104074346853\n","Train Epoch #17, Batch 8018/24958 loss = 1.27281747341156, ppl = 3.594283711266282\n","Train Epoch #17, Batch 8019/24958 loss = 1.27376761674881, ppl = 3.597919713043985\n","Train Epoch #17, Batch 8020/24958 loss = 1.2751237106323243, ppl = 3.6026428260140593\n","Train Epoch #17, Batch 8021/24958 loss = 1.2762329745292664, ppl = 3.6066628026814573\n","Train Epoch #17, Batch 8022/24958 loss = 1.2736456763744355, ppl = 3.5973345371301577\n","Train Epoch #17, Batch 8023/24958 loss = 1.2737829959392548, ppl = 3.597816624489419\n","Train Epoch #17, Batch 8024/24958 loss = 1.2680081939697265, ppl = 3.575031068356404\n","Train Epoch #17, Batch 8025/24958 loss = 1.267699043750763, ppl = 3.574007129413267\n","Train Epoch #17, Batch 8026/24958 loss = 1.2667831420898437, ppl = 3.570835783121106\n","Train Epoch #17, Batch 8027/24958 loss = 1.2693129408359527, ppl = 3.580317313173386\n","Train Epoch #17, Batch 8028/24958 loss = 1.2683486664295196, ppl = 3.576618559755661\n","Train Epoch #17, Batch 8029/24958 loss = 1.2673035991191863, ppl = 3.5727003237085544\n","Train Epoch #17, Batch 8030/24958 loss = 1.2644839453697205, ppl = 3.561459217386519\n","Train Epoch #17, Batch 8031/24958 loss = 1.2684075498580933, ppl = 3.5749539320462493\n","Train Epoch #17, Batch 8032/24958 loss = 1.2667272114753723, ppl = 3.5693284127411844\n","Train Epoch #17, Batch 8033/24958 loss = 1.2676922249794007, ppl = 3.5730208646301445\n","Train Epoch #17, Batch 8034/24958 loss = 1.2706704771518706, ppl = 3.583598344008647\n","Train Epoch #17, Batch 8035/24958 loss = 1.2698909938335419, ppl = 3.5809743252319337\n","Train Epoch #17, Batch 8036/24958 loss = 1.2678452694416047, ppl = 3.5739897294978435\n","Train Epoch #17, Batch 8037/24958 loss = 1.2659535920619964, ppl = 3.567150353749745\n","Train Epoch #17, Batch 8038/24958 loss = 1.2658936166763306, ppl = 3.566952628315913\n","Train Epoch #17, Batch 8039/24958 loss = 1.2662624859809875, ppl = 3.5682818738981035\n","Train Epoch #17, Batch 8040/24958 loss = 1.2660214185714722, ppl = 3.5672367724912606\n","Train Epoch #17, Batch 8041/24958 loss = 1.2656047892570497, ppl = 3.5656649123326245\n","Train Epoch #17, Batch 8042/24958 loss = 1.2655400812625885, ppl = 3.565443345871671\n","Train Epoch #17, Batch 8043/24958 loss = 1.2666585385799407, ppl = 3.569135802504289\n","Train Epoch #17, Batch 8044/24958 loss = 1.2673979270458222, ppl = 3.5718924363291973\n","Train Epoch #17, Batch 8045/24958 loss = 1.2652333331108094, ppl = 3.563985737960645\n","Train Epoch #17, Batch 8046/24958 loss = 1.263127328157425, ppl = 3.5569635518097136\n","Train Epoch #17, Batch 8047/24958 loss = 1.2625952446460724, ppl = 3.5551049714571064\n","Train Epoch #17, Batch 8048/24958 loss = 1.263008623123169, ppl = 3.556526743553101\n","Train Epoch #17, Batch 8049/24958 loss = 1.2627393555641175, ppl = 3.555595264609982\n","Train Epoch #17, Batch 8050/24958 loss = 1.2618575537204741, ppl = 3.5521477845196943\n","Train Epoch #17, Batch 8051/24958 loss = 1.2601092457771301, ppl = 3.5451168305991803\n","Train Epoch #17, Batch 8052/24958 loss = 1.2605791461467744, ppl = 3.5468650644888298\n","Train Epoch #17, Batch 8053/24958 loss = 1.2586918127536775, ppl = 3.539394716985417\n","Train Epoch #17, Batch 8054/24958 loss = 1.2572692477703094, ppl = 3.534069998569318\n","Train Epoch #17, Batch 8055/24958 loss = 1.2571026110649108, ppl = 3.533505316537044\n","Train Epoch #17, Batch 8056/24958 loss = 1.260440468788147, ppl = 3.545907878455708\n","Train Epoch #17, Batch 8057/24958 loss = 1.2628451800346374, ppl = 3.554295466235903\n","Train Epoch #17, Batch 8058/24958 loss = 1.2654229807853699, ppl = 3.564462985906106\n","Train Epoch #17, Batch 8059/24958 loss = 1.2664453864097596, ppl = 3.5682228492873374\n","Train Epoch #17, Batch 8060/24958 loss = 1.2662144923210144, ppl = 3.5674091554022804\n","Train Epoch #17, Batch 8061/24958 loss = 1.2672957718372344, ppl = 3.5714871717731467\n","Train Epoch #17, Batch 8062/24958 loss = 1.2685085070133209, ppl = 3.5758176547586156\n","Train Epoch #17, Batch 8063/24958 loss = 1.2704028975963593, ppl = 3.5828239865343843\n","Train Epoch #17, Batch 8064/24958 loss = 1.2702325522899627, ppl = 3.582232288841488\n","Train Epoch #17, Batch 8065/24958 loss = 1.267190111875534, ppl = 3.5720472536234316\n","Train Epoch #17, Batch 8066/24958 loss = 1.2680484390258788, ppl = 3.575135490822522\n","Train Epoch #17, Batch 8067/24958 loss = 1.2697880136966706, ppl = 3.581372619563258\n","Train Epoch #17, Batch 8068/24958 loss = 1.2691778588294982, ppl = 3.579084072864327\n","Train Epoch #17, Batch 8069/24958 loss = 1.269621104001999, ppl = 3.5806171607541053\n","Train Epoch #17, Batch 8070/24958 loss = 1.2696260130405426, ppl = 3.5806363687703326\n","Train Epoch #17, Batch 8071/24958 loss = 1.2722690188884735, ppl = 3.5895615598265715\n","Train Epoch #17, Batch 8072/24958 loss = 1.2729435861110687, ppl = 3.592012664352296\n","Train Epoch #17, Batch 8073/24958 loss = 1.2722516655921936, ppl = 3.589445088249048\n","Train Epoch #17, Batch 8074/24958 loss = 1.2735969948768615, ppl = 3.5937823074016375\n","Train Epoch #17, Batch 8075/24958 loss = 1.2745809650421143, ppl = 3.5971965424943333\n","Train Epoch #17, Batch 8076/24958 loss = 1.2729019165039062, ppl = 3.5904797954416905\n","Train Epoch #17, Batch 8077/24958 loss = 1.2747570252418519, ppl = 3.5977877578202513\n","Train Epoch #17, Batch 8078/24958 loss = 1.274927533864975, ppl = 3.5984725088306355\n","Train Epoch #17, Batch 8079/24958 loss = 1.273444367647171, ppl = 3.593053482833406\n","Train Epoch #17, Batch 8080/24958 loss = 1.2720958554744721, ppl = 3.588892229182398\n","Train Epoch #17, Batch 8081/24958 loss = 1.271900576353073, ppl = 3.5882062456151984\n","Train Epoch #17, Batch 8082/24958 loss = 1.2700034129619597, ppl = 3.5808379034767035\n","Train Epoch #17, Batch 8083/24958 loss = 1.2720498394966127, ppl = 3.587912168875222\n","Train Epoch #17, Batch 8084/24958 loss = 1.2718491387367248, ppl = 3.587253608854681\n","Train Epoch #17, Batch 8085/24958 loss = 1.2717582404613494, ppl = 3.586904045336122\n","Train Epoch #17, Batch 8086/24958 loss = 1.2709896504878997, ppl = 3.5843607389109455\n","Train Epoch #17, Batch 8087/24958 loss = 1.2732013595104217, ppl = 3.5916000978487035\n","Train Epoch #17, Batch 8088/24958 loss = 1.2724013137817383, ppl = 3.5885372578125736\n","Train Epoch #17, Batch 8089/24958 loss = 1.272110300064087, ppl = 3.587283510315339\n","Train Epoch #17, Batch 8090/24958 loss = 1.2740442442893982, ppl = 3.5940611170530916\n","Train Epoch #17, Batch 8091/24958 loss = 1.2756086921691894, ppl = 3.5992968172782738\n","Train Epoch #17, Batch 8092/24958 loss = 1.275969922542572, ppl = 3.600518538153909\n","Train Epoch #17, Batch 8093/24958 loss = 1.2760385072231293, ppl = 3.60078952097593\n","Train Epoch #17, Batch 8094/24958 loss = 1.276321052312851, ppl = 3.601775410496472\n","Train Epoch #17, Batch 8095/24958 loss = 1.2768327176570893, ppl = 3.603441433159351\n","Train Epoch #17, Batch 8096/24958 loss = 1.2749633932113646, ppl = 3.5964875994459646\n","Train Epoch #17, Batch 8097/24958 loss = 1.2767297172546386, ppl = 3.6024618221638707\n","Train Epoch #17, Batch 8098/24958 loss = 1.2766866862773896, ppl = 3.602308841157751\n","Train Epoch #17, Batch 8099/24958 loss = 1.2781370174884796, ppl = 3.6075729419526454\n","Train Epoch #17, Batch 8100/24958 loss = 1.278826092481613, ppl = 3.6098944703000115\n","Train Epoch #17, Batch 8101/24958 loss = 1.2806299030780792, ppl = 3.6157597499574283\n","Train Epoch #17, Batch 8102/24958 loss = 1.2805600798130035, ppl = 3.6155369805942916\n","Train Epoch #17, Batch 8103/24958 loss = 1.2795427465438842, ppl = 3.611839348524194\n","Train Epoch #17, Batch 8104/24958 loss = 1.2789283525943755, ppl = 3.6098986732637046\n","Train Epoch #17, Batch 8105/24958 loss = 1.2776526367664338, ppl = 3.6053083454947137\n","Train Epoch #17, Batch 8106/24958 loss = 1.2770077276229859, ppl = 3.6031254666885157\n","Train Epoch #17, Batch 8107/24958 loss = 1.276070922613144, ppl = 3.599659102386509\n","Train Epoch #17, Batch 8108/24958 loss = 1.2754549145698548, ppl = 3.5972990502655864\n","Train Epoch #17, Batch 8109/24958 loss = 1.2720783936977387, ppl = 3.5856818703161686\n","Train Epoch #17, Batch 8110/24958 loss = 1.2709207105636597, ppl = 3.581206514489914\n","Train Epoch #17, Batch 8111/24958 loss = 1.2746430206298829, ppl = 3.594931660303827\n","Train Epoch #17, Batch 8112/24958 loss = 1.2730937719345092, ppl = 3.589146840922745\n","Train Epoch #17, Batch 8113/24958 loss = 1.274162746667862, ppl = 3.5928378491558366\n","Train Epoch #17, Batch 8114/24958 loss = 1.2750155210494996, ppl = 3.595771277736457\n","Train Epoch #17, Batch 8115/24958 loss = 1.2752385008335114, ppl = 3.5966066904879934\n","Train Epoch #17, Batch 8116/24958 loss = 1.277929652929306, ppl = 3.60640792706605\n","Train Epoch #17, Batch 8117/24958 loss = 1.2775847268104554, ppl = 3.6053163812561757\n","Train Epoch #17, Batch 8118/24958 loss = 1.278387084007263, ppl = 3.607923490529158\n","Train Epoch #17, Batch 8119/24958 loss = 1.277624990940094, ppl = 3.604979962524929\n","Train Epoch #17, Batch 8120/24958 loss = 1.2774383163452148, ppl = 3.6042911659303023\n","Train Epoch #17, Batch 8121/24958 loss = 1.2750683963298797, ppl = 3.5962124790878813\n","Train Epoch #17, Batch 8122/24958 loss = 1.2747898554801942, ppl = 3.595344686793814\n","Train Epoch #17, Batch 8123/24958 loss = 1.2750309658050538, ppl = 3.5962073350364716\n","Train Epoch #17, Batch 8124/24958 loss = 1.2766364479064942, ppl = 3.601284728282883\n","Train Epoch #17, Batch 8125/24958 loss = 1.276707682609558, ppl = 3.6015178665019043\n","Train Epoch #17, Batch 8126/24958 loss = 1.2797731852531433, ppl = 3.613378882405671\n","Train Epoch #17, Batch 8127/24958 loss = 1.278097859621048, ppl = 3.6068355854976706\n","Train Epoch #17, Batch 8128/24958 loss = 1.277791886329651, ppl = 3.6057345435224226\n","Train Epoch #17, Batch 8129/24958 loss = 1.2787429654598237, ppl = 3.6092833973584253\n","Train Epoch #17, Batch 8130/24958 loss = 1.2791258656978608, ppl = 3.6106304180956106\n","Train Epoch #17, Batch 8131/24958 loss = 1.2782052612304688, ppl = 3.606973358511786\n","Train Epoch #17, Batch 8132/24958 loss = 1.2812727677822113, ppl = 3.6180106857502783\n","Train Epoch #17, Batch 8133/24958 loss = 1.2811016476154327, ppl = 3.6173296677037627\n","Train Epoch #17, Batch 8134/24958 loss = 1.2804941880702971, ppl = 3.6149092959959694\n","Train Epoch #17, Batch 8135/24958 loss = 1.2812417256832123, ppl = 3.617421706750763\n","Train Epoch #17, Batch 8136/24958 loss = 1.283359980583191, ppl = 3.62468112740353\n","Train Epoch #17, Batch 8137/24958 loss = 1.281369343996048, ppl = 3.6187528642069196\n","Train Epoch #17, Batch 8138/24958 loss = 1.2800375366210937, ppl = 3.6146543259811863\n","Train Epoch #17, Batch 8139/24958 loss = 1.2791431856155395, ppl = 3.611514177911908\n","Train Epoch #17, Batch 8140/24958 loss = 1.2773747718334199, ppl = 3.6045715525454933\n","Train Epoch #17, Batch 8141/24958 loss = 1.2768050134181976, ppl = 3.602525282134585\n","Train Epoch #17, Batch 8142/24958 loss = 1.2771995711326598, ppl = 3.603898838950995\n","Train Epoch #17, Batch 8143/24958 loss = 1.2769770991802216, ppl = 3.603131106420964\n","Train Epoch #17, Batch 8144/24958 loss = 1.2767021012306214, ppl = 3.6020819632981356\n","Train Epoch #17, Batch 8145/24958 loss = 1.2792129075527192, ppl = 3.611419718757629\n","Train Epoch #17, Batch 8146/24958 loss = 1.2804145586490632, ppl = 3.6152445520854473\n","Train Epoch #17, Batch 8147/24958 loss = 1.279037926197052, ppl = 3.6108707014045716\n","Train Epoch #17, Batch 8148/24958 loss = 1.2784246933460235, ppl = 3.608782343740366\n","Train Epoch #17, Batch 8149/24958 loss = 1.278496767282486, ppl = 3.6090292164396733\n","Train Epoch #17, Batch 8150/24958 loss = 1.2772064054012298, ppl = 3.6045019619121716\n","Train Epoch #17, Batch 8151/24958 loss = 1.2770119380950928, ppl = 3.603793184338034\n","Train Epoch #17, Batch 8152/24958 loss = 1.2761436247825622, ppl = 3.6006256943453185\n","Train Epoch #17, Batch 8153/24958 loss = 1.2767414629459382, ppl = 3.6028413133263575\n","Train Epoch #17, Batch 8154/24958 loss = 1.2762668192386628, ppl = 3.601226696310911\n","Train Epoch #17, Batch 8155/24958 loss = 1.2763768923282623, ppl = 3.6015986452802786\n","Train Epoch #17, Batch 8156/24958 loss = 1.275256712436676, ppl = 3.5969673716401127\n","Train Epoch #17, Batch 8157/24958 loss = 1.2744436085224151, ppl = 3.5939029025808287\n","Train Epoch #17, Batch 8158/24958 loss = 1.2737304699420928, ppl = 3.5908231171620644\n","Train Epoch #17, Batch 8159/24958 loss = 1.2698841714859008, ppl = 3.5784705735645796\n","Train Epoch #17, Batch 8160/24958 loss = 1.2687590205669403, ppl = 3.574763490763283\n","Train Epoch #17, Batch 8161/24958 loss = 1.2662274289131163, ppl = 3.5658641243152065\n","Train Epoch #17, Batch 8162/24958 loss = 1.2644461631774901, ppl = 3.5596773896241682\n","Train Epoch #17, Batch 8163/24958 loss = 1.2644575798511506, ppl = 3.559723765877164\n","Train Epoch #17, Batch 8164/24958 loss = 1.2647233378887177, ppl = 3.560651311975529\n","Train Epoch #17, Batch 8165/24958 loss = 1.2656685256958007, ppl = 3.563490572431411\n","Train Epoch #17, Batch 8166/24958 loss = 1.2651726710796356, ppl = 3.5616742441896094\n","Train Epoch #17, Batch 8167/24958 loss = 1.2653065264225005, ppl = 3.562200642086192\n","Train Epoch #17, Batch 8168/24958 loss = 1.2638161146640778, ppl = 3.557163928390904\n","Train Epoch #17, Batch 8169/24958 loss = 1.263814299106598, ppl = 3.557157509159767\n","Train Epoch #17, Batch 8170/24958 loss = 1.2630059492588044, ppl = 3.5541183239395555\n","Train Epoch #17, Batch 8171/24958 loss = 1.261035271883011, ppl = 3.5472448933111957\n","Train Epoch #17, Batch 8172/24958 loss = 1.2596495044231415, ppl = 3.542382517262144\n","Train Epoch #17, Batch 8173/24958 loss = 1.2599128019809722, ppl = 3.5433386813575622\n","Train Epoch #17, Batch 8174/24958 loss = 1.2599772679805756, ppl = 3.5435615249212074\n","Train Epoch #17, Batch 8175/24958 loss = 1.258634502887726, ppl = 3.538983570841042\n","Train Epoch #17, Batch 8176/24958 loss = 1.2569836020469665, ppl = 3.5333925534147546\n","Train Epoch #17, Batch 8177/24958 loss = 1.2559368431568145, ppl = 3.5291030958938836\n","Train Epoch #17, Batch 8178/24958 loss = 1.2551305675506592, ppl = 3.5259656465776703\n","Train Epoch #17, Batch 8179/24958 loss = 1.2558944606781006, ppl = 3.5286562692250167\n","Train Epoch #17, Batch 8180/24958 loss = 1.2586057579517365, ppl = 3.537633437373118\n","Train Epoch #17, Batch 8181/24958 loss = 1.2578363466262816, ppl = 3.535057301847874\n","Train Epoch #17, Batch 8182/24958 loss = 1.2595128428936004, ppl = 3.5414950397169993\n","Train Epoch #17, Batch 8183/24958 loss = 1.2606243336200713, ppl = 3.545989011215286\n","Train Epoch #17, Batch 8184/24958 loss = 1.2629951119422913, ppl = 3.5546800010746904\n","Train Epoch #17, Batch 8185/24958 loss = 1.2617889630794525, ppl = 3.550330213217012\n","Train Epoch #17, Batch 8186/24958 loss = 1.2621027743816375, ppl = 3.5513450777854354\n","Train Epoch #17, Batch 8187/24958 loss = 1.2612017643451692, ppl = 3.548201492151709\n","Train Epoch #17, Batch 8188/24958 loss = 1.260132817029953, ppl = 3.544473525081475\n","Train Epoch #17, Batch 8189/24958 loss = 1.2585187292098998, ppl = 3.538144875665888\n","Train Epoch #17, Batch 8190/24958 loss = 1.2584682083129883, ppl = 3.5379506416172872\n","Train Epoch #17, Batch 8191/24958 loss = 1.258693858385086, ppl = 3.5387757044967976\n","Train Epoch #17, Batch 8192/24958 loss = 1.260378234386444, ppl = 3.54509307311535\n","Train Epoch #17, Batch 8193/24958 loss = 1.2586388349533082, ppl = 3.53876343065287\n","Train Epoch #17, Batch 8194/24958 loss = 1.2580586421489715, ppl = 3.53676864630039\n","Train Epoch #17, Batch 8195/24958 loss = 1.2584211730957031, ppl = 3.5380017492246\n","Train Epoch #17, Batch 8196/24958 loss = 1.2581401777267456, ppl = 3.537064344105965\n","Train Epoch #17, Batch 8197/24958 loss = 1.2571787750720977, ppl = 3.5336821555401694\n","Train Epoch #17, Batch 8198/24958 loss = 1.2571136164665222, ppl = 3.533451757271335\n","Train Epoch #17, Batch 8199/24958 loss = 1.25745148897171, ppl = 3.534791681671453\n","Train Epoch #17, Batch 8200/24958 loss = 1.2577083170413972, ppl = 3.535698699931322\n","Train Epoch #17, Batch 8201/24958 loss = 1.2577157461643218, ppl = 3.535725110472016\n","Train Epoch #17, Batch 8202/24958 loss = 1.2595165085792541, ppl = 3.541998241331172\n","Train Epoch #17, Batch 8203/24958 loss = 1.2584801065921782, ppl = 3.5385988632046117\n","Train Epoch #17, Batch 8204/24958 loss = 1.2591873240470886, ppl = 3.540843245037556\n","Train Epoch #17, Batch 8205/24958 loss = 1.2603716111183167, ppl = 3.5450847570537065\n","Train Epoch #17, Batch 8206/24958 loss = 1.2609698593616485, ppl = 3.5471049311468255\n","Train Epoch #17, Batch 8207/24958 loss = 1.2617506456375123, ppl = 3.549971225448037\n","Train Epoch #17, Batch 8208/24958 loss = 1.263284217119217, ppl = 3.556127538619222\n","Train Epoch #17, Batch 8209/24958 loss = 1.2651673138141633, ppl = 3.5621206864637247\n","Train Epoch #17, Batch 8210/24958 loss = 1.2652699184417724, ppl = 3.5624967432963586\n","Train Epoch #17, Batch 8211/24958 loss = 1.2631559908390044, ppl = 3.5540823252987455\n","Train Epoch #17, Batch 8212/24958 loss = 1.2648760843276978, ppl = 3.5605616775601407\n","Train Epoch #17, Batch 8213/24958 loss = 1.2642282104492188, ppl = 3.558277755262205\n","Train Epoch #17, Batch 8214/24958 loss = 1.2664584088325501, ppl = 3.5672437576362404\n","Train Epoch #17, Batch 8215/24958 loss = 1.2674956512451172, ppl = 3.571384392403421\n","Train Epoch #17, Batch 8216/24958 loss = 1.2676935911178588, ppl = 3.572214833995636\n","Train Epoch #17, Batch 8217/24958 loss = 1.2703213334083556, ppl = 3.581562359069131\n","Train Epoch #17, Batch 8218/24958 loss = 1.269104518890381, ppl = 3.5776882892230173\n","Train Epoch #17, Batch 8219/24958 loss = 1.2708364260196685, ppl = 3.584717095224056\n","Train Epoch #17, Batch 8220/24958 loss = 1.2693346107006074, ppl = 3.5796195749021718\n","Train Epoch #17, Batch 8221/24958 loss = 1.269978860616684, ppl = 3.5816298164371734\n","Train Epoch #17, Batch 8222/24958 loss = 1.270307230949402, ppl = 3.5826554171455007\n","Train Epoch #17, Batch 8223/24958 loss = 1.2711604821681977, ppl = 3.5858807892473035\n","Train Epoch #17, Batch 8224/24958 loss = 1.2708424317836762, ppl = 3.584809172580103\n","Train Epoch #17, Batch 8225/24958 loss = 1.27068674325943, ppl = 3.5843017754169972\n","Train Epoch #17, Batch 8226/24958 loss = 1.2675107872486115, ppl = 3.572077566752965\n","Train Epoch #17, Batch 8227/24958 loss = 1.266864765882492, ppl = 3.569833144266899\n","Train Epoch #17, Batch 8228/24958 loss = 1.267004588842392, ppl = 3.57033211783135\n","Train Epoch #17, Batch 8229/24958 loss = 1.268720784187317, ppl = 3.577655749296592\n","Train Epoch #17, Batch 8230/24958 loss = 1.2696586215496064, ppl = 3.5811813103875716\n","Train Epoch #17, Batch 8231/24958 loss = 1.2664632272720338, ppl = 3.5708084538216087\n","Train Epoch #17, Batch 8232/24958 loss = 1.2643031668663025, ppl = 3.562691522779337\n","Train Epoch #17, Batch 8233/24958 loss = 1.264867479801178, ppl = 3.5649822207350543\n","Train Epoch #17, Batch 8234/24958 loss = 1.2645123887062073, ppl = 3.563634006180805\n","Train Epoch #17, Batch 8235/24958 loss = 1.2632665812969208, ppl = 3.5595482879645615\n","Train Epoch #17, Batch 8236/24958 loss = 1.2622401416301727, ppl = 3.555838538130161\n","Train Epoch #17, Batch 8237/24958 loss = 1.2641387748718262, ppl = 3.5614660191366174\n","Train Epoch #17, Batch 8238/24958 loss = 1.2664182496070862, ppl = 3.5688318139754163\n","Train Epoch #17, Batch 8239/24958 loss = 1.2668216514587403, ppl = 3.5702134826331293\n","Train Epoch #17, Batch 8240/24958 loss = 1.2671366405487061, ppl = 3.5713619716206777\n","Train Epoch #17, Batch 8241/24958 loss = 1.2647651708126069, ppl = 3.56399345003315\n","Train Epoch #17, Batch 8242/24958 loss = 1.2645501458644868, ppl = 3.5632381775856885\n","Train Epoch #17, Batch 8243/24958 loss = 1.2657450568675994, ppl = 3.5675696531310384\n","Train Epoch #17, Batch 8244/24958 loss = 1.265173236131668, ppl = 3.565478324750403\n","Train Epoch #17, Batch 8245/24958 loss = 1.2633460021018983, ppl = 3.5584551920977066\n","Train Epoch #17, Batch 8246/24958 loss = 1.2640478014945984, ppl = 3.560911076249852\n","Train Epoch #17, Batch 8247/24958 loss = 1.2662440764904022, ppl = 3.568189890101296\n","Train Epoch #17, Batch 8248/24958 loss = 1.2670016086101532, ppl = 3.5707885517040983\n","Train Epoch #17, Batch 8249/24958 loss = 1.2676171743869782, ppl = 3.5729711249249476\n","Train Epoch #17, Batch 8250/24958 loss = 1.2688431322574616, ppl = 3.5772582988169233\n","Train Epoch #17, Batch 8251/24958 loss = 1.2714805376529694, ppl = 3.5881510887395813\n","Train Epoch #17, Batch 8252/24958 loss = 1.2707514679431915, ppl = 3.5856959226856686\n","Train Epoch #17, Batch 8253/24958 loss = 1.2716683983802795, ppl = 3.589362223286173\n","Train Epoch #17, Batch 8254/24958 loss = 1.2687242662906646, ppl = 3.5808909648947465\n","Train Epoch #17, Batch 8255/24958 loss = 1.2702419531345368, ppl = 3.586459555201973\n","Train Epoch #17, Batch 8256/24958 loss = 1.2691515719890594, ppl = 3.5824233116659827\n","Train Epoch #17, Batch 8257/24958 loss = 1.2687161898612975, ppl = 3.580882023203916\n","Train Epoch #17, Batch 8258/24958 loss = 1.267719019651413, ppl = 3.5769277667454396\n","Train Epoch #17, Batch 8259/24958 loss = 1.2714059662818908, ppl = 3.5886687176201586\n","Train Epoch #17, Batch 8260/24958 loss = 1.2739696538448333, ppl = 3.5977654130065515\n","Train Epoch #17, Batch 8261/24958 loss = 1.2755217027664185, ppl = 3.602951944627275\n","Train Epoch #17, Batch 8262/24958 loss = 1.2771085941791533, ppl = 3.608408779235661\n","Train Epoch #17, Batch 8263/24958 loss = 1.2786668622493744, ppl = 3.6152624430440614\n","Train Epoch #17, Batch 8264/24958 loss = 1.277708238363266, ppl = 3.612029444951403\n","Train Epoch #17, Batch 8265/24958 loss = 1.2778043496608733, ppl = 3.612333472619028\n","Train Epoch #17, Batch 8266/24958 loss = 1.2781748270988464, ppl = 3.6136819993338816\n","Train Epoch #17, Batch 8267/24958 loss = 1.276544588804245, ppl = 3.6077265634141282\n","Train Epoch #17, Batch 8268/24958 loss = 1.2777248227596283, ppl = 3.611652324103673\n","Train Epoch #17, Batch 8269/24958 loss = 1.2766805493831634, ppl = 3.6081466705146914\n","Train Epoch #17, Batch 8270/24958 loss = 1.2758295965194701, ppl = 3.605201945118877\n","Train Epoch #17, Batch 8271/24958 loss = 1.2776581180095672, ppl = 3.6115329630627593\n","Train Epoch #17, Batch 8272/24958 loss = 1.2799023354053498, ppl = 3.6197634906260516\n","Train Epoch #17, Batch 8273/24958 loss = 1.2782146143913269, ppl = 3.6140492560499013\n","Train Epoch #17, Batch 8274/24958 loss = 1.2786108100414275, ppl = 3.6154508101617933\n","Train Epoch #17, Batch 8275/24958 loss = 1.2782826852798461, ppl = 3.614422508004007\n","Train Epoch #17, Batch 8276/24958 loss = 1.2810173046588897, ppl = 3.6242187315562098\n","Train Epoch #17, Batch 8277/24958 loss = 1.2780897545814514, ppl = 3.614353425718451\n","Train Epoch #17, Batch 8278/24958 loss = 1.276761462688446, ppl = 3.6097057398066155\n","Train Epoch #17, Batch 8279/24958 loss = 1.2754216337203979, ppl = 3.6051181722733565\n","Train Epoch #17, Batch 8280/24958 loss = 1.2749418914318085, ppl = 3.603347492384322\n","Train Epoch #17, Batch 8281/24958 loss = 1.273045433163643, ppl = 3.597783221002666\n","Train Epoch #17, Batch 8282/24958 loss = 1.2698995155096053, ppl = 3.5865254892440355\n","Train Epoch #17, Batch 8283/24958 loss = 1.2673546701669693, ppl = 3.5769268711033395\n","Train Epoch #17, Batch 8284/24958 loss = 1.2676329284906387, ppl = 3.578088712823227\n","Train Epoch #17, Batch 8285/24958 loss = 1.2681110888719558, ppl = 3.579750635583202\n","Train Epoch #17, Batch 8286/24958 loss = 1.26797946870327, ppl = 3.579321095697196\n","Train Epoch #17, Batch 8287/24958 loss = 1.2683542555570602, ppl = 3.580594398656791\n","Train Epoch #17, Batch 8288/24958 loss = 1.2691356736421584, ppl = 3.5832801100797957\n","Train Epoch #17, Batch 8289/24958 loss = 1.2685399430990218, ppl = 3.581190616561352\n","Train Epoch #17, Batch 8290/24958 loss = 1.2671765047311783, ppl = 3.5763027204899434\n","Train Epoch #17, Batch 8291/24958 loss = 1.2662524408102036, ppl = 3.5730388492760863\n","Train Epoch #17, Batch 8292/24958 loss = 1.2648245233297348, ppl = 3.5676160337083718\n","Train Epoch #17, Batch 8293/24958 loss = 1.2665380889177322, ppl = 3.5738433866168413\n","Train Epoch #17, Batch 8294/24958 loss = 1.2660323923826218, ppl = 3.5721966688642524\n","Train Epoch #17, Batch 8295/24958 loss = 1.2664477246999741, ppl = 3.5736654209148737\n","Train Epoch #17, Batch 8296/24958 loss = 1.2679805022478103, ppl = 3.579114212057949\n","Train Epoch #17, Batch 8297/24958 loss = 1.2682729488611222, ppl = 3.5801088410926205\n","Train Epoch #17, Batch 8298/24958 loss = 1.2690938216447831, ppl = 3.5831240303031944\n","Train Epoch #17, Batch 8299/24958 loss = 1.2699604576826096, ppl = 3.58677522508188\n","Train Epoch #17, Batch 8300/24958 loss = 1.2709876602888108, ppl = 3.590645047260283\n","Train Epoch #17, Batch 8301/24958 loss = 1.2705703455209731, ppl = 3.589191482279483\n","Train Epoch #17, Batch 8302/24958 loss = 1.2688450306653976, ppl = 3.5831591327359456\n","Train Epoch #17, Batch 8303/24958 loss = 1.2697861510515214, ppl = 3.58623107688486\n","Train Epoch #17, Batch 8304/24958 loss = 1.2688650530576706, ppl = 3.5833386108576373\n","Train Epoch #17, Batch 8305/24958 loss = 1.2678825503587723, ppl = 3.579784752989463\n","Train Epoch #17, Batch 8306/24958 loss = 1.2686331087350846, ppl = 3.582496305238065\n","Train Epoch #17, Batch 8307/24958 loss = 1.2668056124448777, ppl = 3.5761223360105925\n","Train Epoch #17, Batch 8308/24958 loss = 1.2652978378534316, ppl = 3.570061966824069\n","Train Epoch #17, Batch 8309/24958 loss = 1.2654235631227493, ppl = 3.5705037277806597\n","Train Epoch #17, Batch 8310/24958 loss = 1.2657090300321578, ppl = 3.571570525346601\n","Train Epoch #17, Batch 8311/24958 loss = 1.2666598337888717, ppl = 3.5751360479159207\n","Train Epoch #17, Batch 8312/24958 loss = 1.2662806886434554, ppl = 3.573610611504492\n","Train Epoch #17, Batch 8313/24958 loss = 1.267986769080162, ppl = 3.5799583591339945\n","Train Epoch #17, Batch 8314/24958 loss = 1.2647968095541, ppl = 3.5677082562934017\n","Train Epoch #17, Batch 8315/24958 loss = 1.2639175766706467, ppl = 3.5641709967695596\n","Train Epoch #17, Batch 8316/24958 loss = 1.263997648358345, ppl = 3.5645116290505787\n","Train Epoch #17, Batch 8317/24958 loss = 1.2630631893873214, ppl = 3.560902914761909\n","Train Epoch #17, Batch 8318/24958 loss = 1.2647185510396957, ppl = 3.566292889544114\n","Train Epoch #17, Batch 8319/24958 loss = 1.2621978706121444, ppl = 3.5564447710682106\n","Train Epoch #17, Batch 8320/24958 loss = 1.2630495554208756, ppl = 3.55924135026855\n","Train Epoch #17, Batch 8321/24958 loss = 1.2648255735635758, ppl = 3.5655030501255753\n","Train Epoch #17, Batch 8322/24958 loss = 1.267490320801735, ppl = 3.5751976484014563\n","Train Epoch #17, Batch 8323/24958 loss = 1.265407935976982, ppl = 3.567784097611767\n","Train Epoch #17, Batch 8324/24958 loss = 1.2697220546007157, ppl = 3.5856717566753504\n","Train Epoch #17, Batch 8325/24958 loss = 1.2701886266469955, ppl = 3.587216285093132\n","Train Epoch #17, Batch 8326/24958 loss = 1.2696984428167344, ppl = 3.5856520003684738\n","Train Epoch #17, Batch 8327/24958 loss = 1.271530881524086, ppl = 3.5924156615386598\n","Train Epoch #17, Batch 8328/24958 loss = 1.2711172038316727, ppl = 3.5909593915590103\n","Train Epoch #17, Batch 8329/24958 loss = 1.2686724168062211, ppl = 3.5808871109561045\n","Train Epoch #17, Batch 8330/24958 loss = 1.266260080933571, ppl = 3.5724457289659237\n","Train Epoch #17, Batch 8331/24958 loss = 1.267909707427025, ppl = 3.577387013351219\n","Train Epoch #17, Batch 8332/24958 loss = 1.2670373350381852, ppl = 3.5745746388783908\n","Train Epoch #17, Batch 8333/24958 loss = 1.267079731822014, ppl = 3.5747520161505166\n","Train Epoch #17, Batch 8334/24958 loss = 1.269003215432167, ppl = 3.5826626522577967\n","Train Epoch #17, Batch 8335/24958 loss = 1.2708998173475266, ppl = 3.589093902628784\n","Train Epoch #17, Batch 8336/24958 loss = 1.2717430049180984, ppl = 3.592113118290045\n","Train Epoch #17, Batch 8337/24958 loss = 1.2710998445749282, ppl = 3.5900860088398385\n","Train Epoch #17, Batch 8338/24958 loss = 1.270229578614235, ppl = 3.5870741500173735\n","Train Epoch #17, Batch 8339/24958 loss = 1.2708980172872544, ppl = 3.5894899096014115\n","Train Epoch #17, Batch 8340/24958 loss = 1.2704891592264176, ppl = 3.5880061011365156\n","Train Epoch #17, Batch 8341/24958 loss = 1.2725334507226944, ppl = 3.5942512067759647\n","Train Epoch #17, Batch 8342/24958 loss = 1.274936597943306, ppl = 3.603690637683856\n","Train Epoch #17, Batch 8343/24958 loss = 1.2745115965604783, ppl = 3.6020904041428086\n","Train Epoch #17, Batch 8344/24958 loss = 1.2757851988077165, ppl = 3.6069173169603\n","Train Epoch #17, Batch 8345/24958 loss = 1.2735533756017685, ppl = 3.599909993793012\n","Train Epoch #17, Batch 8346/24958 loss = 1.273532595038414, ppl = 3.5998347706806557\n","Train Epoch #17, Batch 8347/24958 loss = 1.2733730894327164, ppl = 3.599250640262744\n","Train Epoch #17, Batch 8348/24958 loss = 1.2723033732175828, ppl = 3.595637028639179\n","Train Epoch #17, Batch 8349/24958 loss = 1.2715385049581527, ppl = 3.5929450213916523\n","Train Epoch #17, Batch 8350/24958 loss = 1.273630092740059, ppl = 3.6015893376424954\n","Train Epoch #17, Batch 8351/24958 loss = 1.2693189471960067, ppl = 3.585133871734409\n","Train Epoch #17, Batch 8352/24958 loss = 1.2693393272161484, ppl = 3.58520009816018\n","Train Epoch #17, Batch 8353/24958 loss = 1.2674624508619308, ppl = 3.5780391997395293\n","Train Epoch #17, Batch 8354/24958 loss = 1.2705799061059952, ppl = 3.5870911957493066\n","Train Epoch #17, Batch 8355/24958 loss = 1.269895970225334, ppl = 3.584476921946324\n","Train Epoch #17, Batch 8356/24958 loss = 1.2705494052171706, ppl = 3.5868427075792226\n","Train Epoch #17, Batch 8357/24958 loss = 1.2710331505537034, ppl = 3.588559383669863\n","Train Epoch #17, Batch 8358/24958 loss = 1.270292140841484, ppl = 3.5858660213571114\n","Train Epoch #17, Batch 8359/24958 loss = 1.268280056118965, ppl = 3.5789265379871606\n","Train Epoch #17, Batch 8360/24958 loss = 1.26699660718441, ppl = 3.5740813957215574\n","Train Epoch #17, Batch 8361/24958 loss = 1.2662119263410567, ppl = 3.571358672699056\n","Train Epoch #17, Batch 8362/24958 loss = 1.2658055716753005, ppl = 3.5698778326585447\n","Train Epoch #17, Batch 8363/24958 loss = 1.2636929541826247, ppl = 3.560832345156486\n","Train Epoch #17, Batch 8364/24958 loss = 1.2648967534303666, ppl = 3.564943190178103\n","Train Epoch #17, Batch 8365/24958 loss = 1.26673976957798, ppl = 3.5713758151783197\n","Train Epoch #17, Batch 8366/24958 loss = 1.2666447013616562, ppl = 3.571024990310974\n","Train Epoch #17, Batch 8367/24958 loss = 1.2667157632112502, ppl = 3.571264852605479\n","Train Epoch #17, Batch 8368/24958 loss = 1.2662177079916, ppl = 3.5695515290385997\n","Train Epoch #17, Batch 8369/24958 loss = 1.2660353153944015, ppl = 3.5689759115351283\n","Train Epoch #17, Batch 8370/24958 loss = 1.2682127743959426, ppl = 3.577041213017841\n","Train Epoch #17, Batch 8371/24958 loss = 1.2680354064702988, ppl = 3.576375167756266\n","Train Epoch #17, Batch 8372/24958 loss = 1.2671171182394028, ppl = 3.5727828435098052\n","Train Epoch #17, Batch 8373/24958 loss = 1.2682139760255813, ppl = 3.576385971338442\n","Train Epoch #17, Batch 8374/24958 loss = 1.2672145611047745, ppl = 3.5729543482543322\n","Train Epoch #17, Batch 8375/24958 loss = 1.267268083691597, ppl = 3.5731197868986375\n","Train Epoch #17, Batch 8376/24958 loss = 1.2643634289503098, ppl = 3.562798417259458\n","Train Epoch #17, Batch 8377/24958 loss = 1.2681540423631668, ppl = 3.5761675771493766\n","Train Epoch #17, Batch 8378/24958 loss = 1.2682136338949204, ppl = 3.576363128012637\n","Train Epoch #17, Batch 8379/24958 loss = 1.2708108621835708, ppl = 3.5858526096237053\n","Train Epoch #17, Batch 8380/24958 loss = 1.2717856055498122, ppl = 3.589541548188747\n","Train Epoch #17, Batch 8381/24958 loss = 1.2754942524433135, ppl = 3.6015052914632837\n","Train Epoch #17, Batch 8382/24958 loss = 1.2773989677429198, ppl = 3.607894515813537\n","Train Epoch #17, Batch 8383/24958 loss = 1.2778927075862885, ppl = 3.6095709215382845\n","Train Epoch #17, Batch 8384/24958 loss = 1.2755428087711334, ppl = 3.6007045150775143\n","Train Epoch #17, Batch 8385/24958 loss = 1.27532949924469, ppl = 3.5999532978788693\n","Train Epoch #17, Batch 8386/24958 loss = 1.2756698369979858, ppl = 3.6010756813228038\n","Train Epoch #17, Batch 8387/24958 loss = 1.2764350295066833, ppl = 3.6038283438891763\n","Train Epoch #17, Batch 8388/24958 loss = 1.2771207726001739, ppl = 3.6063644705051767\n","Train Epoch #17, Batch 8389/24958 loss = 1.2786266839504241, ppl = 3.6118967098826973\n","Train Epoch #17, Batch 8390/24958 loss = 1.2792920970916748, ppl = 3.614199021905789\n","Train Epoch #17, Batch 8391/24958 loss = 1.2802083492279053, ppl = 3.6174340180570272\n","Train Epoch #17, Batch 8392/24958 loss = 1.2797078275680542, ppl = 3.6157091911783623\n","Train Epoch #17, Batch 8393/24958 loss = 1.2793306720256805, ppl = 3.6142455401465843\n","Train Epoch #17, Batch 8394/24958 loss = 1.2794401955604553, ppl = 3.614595154898932\n","Train Epoch #17, Batch 8395/24958 loss = 1.280546599626541, ppl = 3.6188189309759577\n","Train Epoch #17, Batch 8396/24958 loss = 1.2807295060157775, ppl = 3.619526691781386\n","Train Epoch #17, Batch 8397/24958 loss = 1.2815156733989717, ppl = 3.6223492812905813\n","Train Epoch #17, Batch 8398/24958 loss = 1.2818399965763092, ppl = 3.62361047391046\n","Train Epoch #17, Batch 8399/24958 loss = 1.2790972018241882, ppl = 3.6130599053490253\n","Train Epoch #17, Batch 8400/24958 loss = 1.2756088638305665, ppl = 3.60138591322166\n","Train Epoch #17, Batch 8401/24958 loss = 1.2765951645374298, ppl = 3.604921649944755\n","Train Epoch #17, Batch 8402/24958 loss = 1.277798148393631, ppl = 3.6090166978337193\n","Train Epoch #17, Batch 8403/24958 loss = 1.2765418088436127, ppl = 3.6049787975646357\n","Train Epoch #17, Batch 8404/24958 loss = 1.2772139370441438, ppl = 3.6070629835261716\n","Train Epoch #17, Batch 8405/24958 loss = 1.2779494535923004, ppl = 3.6096903384215375\n","Train Epoch #17, Batch 8406/24958 loss = 1.278065950870514, ppl = 3.610129756252027\n","Train Epoch #17, Batch 8407/24958 loss = 1.2801739609241485, ppl = 3.6175893822632617\n","Train Epoch #17, Batch 8408/24958 loss = 1.276842449903488, ppl = 3.60703785248101\n","Train Epoch #17, Batch 8409/24958 loss = 1.2770712327957154, ppl = 3.607856115566422\n","Train Epoch #17, Batch 8410/24958 loss = 1.2766494619846345, ppl = 3.6062905891300407\n","Train Epoch #17, Batch 8411/24958 loss = 1.274712483882904, ppl = 3.5993681739211896\n","Train Epoch #17, Batch 8412/24958 loss = 1.2750905334949494, ppl = 3.6008891187700796\n","Train Epoch #17, Batch 8413/24958 loss = 1.2737400496006013, ppl = 3.5957766033048797\n","Train Epoch #17, Batch 8414/24958 loss = 1.275931715965271, ppl = 3.603765381800652\n","Train Epoch #17, Batch 8415/24958 loss = 1.2748021852970124, ppl = 3.5996545259323796\n","Train Epoch #17, Batch 8416/24958 loss = 1.272934341430664, ppl = 3.5923774585799673\n","Train Epoch #17, Batch 8417/24958 loss = 1.2717372226715087, ppl = 3.588220801762514\n","Train Epoch #17, Batch 8418/24958 loss = 1.2730594277381897, ppl = 3.5932150515443437\n","Train Epoch #17, Batch 8419/24958 loss = 1.2735623359680175, ppl = 3.594986813865962\n","Train Epoch #17, Batch 8420/24958 loss = 1.2724491453170776, ppl = 3.5913782681624213\n","Train Epoch #17, Batch 8421/24958 loss = 1.2726372575759888, ppl = 3.592108983581326\n","Train Epoch #17, Batch 8422/24958 loss = 1.2713325560092925, ppl = 3.5870397558969427\n","Train Epoch #17, Batch 8423/24958 loss = 1.272587617635727, ppl = 3.591321944911268\n","Train Epoch #17, Batch 8424/24958 loss = 1.2693038129806518, ppl = 3.5770330509591077\n","Train Epoch #17, Batch 8425/24958 loss = 1.2689800226688386, ppl = 3.5759535548440833\n","Train Epoch #17, Batch 8426/24958 loss = 1.2699964916706086, ppl = 3.579284922536735\n","Train Epoch #17, Batch 8427/24958 loss = 1.270411537885666, ppl = 3.580996813426216\n","Train Epoch #17, Batch 8428/24958 loss = 1.2699680614471436, ppl = 3.579501121662411\n","Train Epoch #17, Batch 8429/24958 loss = 1.2687577164173127, ppl = 3.5753553076543323\n","Train Epoch #17, Batch 8430/24958 loss = 1.271406693458557, ppl = 3.584739763010294\n","Train Epoch #17, Batch 8431/24958 loss = 1.2707353019714356, ppl = 3.5826298652655337\n","Train Epoch #17, Batch 8432/24958 loss = 1.2704287469387054, ppl = 3.581698416646706\n","Train Epoch #17, Batch 8433/24958 loss = 1.2710605823993684, ppl = 3.5844329406202546\n","Train Epoch #17, Batch 8434/24958 loss = 1.2678582203388213, ppl = 3.572044754929974\n","Train Epoch #17, Batch 8435/24958 loss = 1.2677310717105865, ppl = 3.571574421005272\n","Train Epoch #17, Batch 8436/24958 loss = 1.2663084530830384, ppl = 3.5666231834455324\n","Train Epoch #17, Batch 8437/24958 loss = 1.2696349656581878, ppl = 3.5786663605067446\n","Train Epoch #17, Batch 8438/24958 loss = 1.2707612466812135, ppl = 3.5826153061555988\n","Train Epoch #17, Batch 8439/24958 loss = 1.2694931137561798, ppl = 3.578165461566471\n","Train Epoch #17, Batch 8440/24958 loss = 1.2690452194213868, ppl = 3.5766081240030885\n","Train Epoch #17, Batch 8441/24958 loss = 1.2703133177757264, ppl = 3.581174929489076\n","Train Epoch #17, Batch 8442/24958 loss = 1.2695975983142853, ppl = 3.5781228317207354\n","Train Epoch #17, Batch 8443/24958 loss = 1.2696313738822937, ppl = 3.578247532121192\n","Train Epoch #17, Batch 8444/24958 loss = 1.266534422636032, ppl = 3.5674973161960937\n","Train Epoch #17, Batch 8445/24958 loss = 1.269834864139557, ppl = 3.578455473418019\n","Train Epoch #17, Batch 8446/24958 loss = 1.2686420845985413, ppl = 3.5743895482476464\n","Train Epoch #17, Batch 8447/24958 loss = 1.2701058828830718, ppl = 3.5801164604288505\n","Train Epoch #17, Batch 8448/24958 loss = 1.2721687150001526, ppl = 3.5874491739135355\n","Train Epoch #17, Batch 8449/24958 loss = 1.2724067795276641, ppl = 3.5882650970986933\n","Train Epoch #17, Batch 8450/24958 loss = 1.2715801346302031, ppl = 3.584631190783741\n","Train Epoch #17, Batch 8451/24958 loss = 1.2725121784210205, ppl = 3.5876136649392123\n","Train Epoch #17, Batch 8452/24958 loss = 1.274170937538147, ppl = 3.593482741596367\n","Train Epoch #17, Batch 8453/24958 loss = 1.2727947199344636, ppl = 3.5890232604418846\n","Train Epoch #17, Batch 8454/24958 loss = 1.2715143191814422, ppl = 3.5849614411461115\n","Train Epoch #17, Batch 8455/24958 loss = 1.2694384491443633, ppl = 3.578038314452662\n","Train Epoch #17, Batch 8456/24958 loss = 1.2684629881381988, ppl = 3.5745622716240986\n","Train Epoch #17, Batch 8457/24958 loss = 1.2691232323646546, ppl = 3.5770434279751977\n","Train Epoch #17, Batch 8458/24958 loss = 1.2663700371980666, ppl = 3.568615833666687\n","Train Epoch #17, Batch 8459/24958 loss = 1.2672918826341628, ppl = 3.5716225063715608\n","Train Epoch #17, Batch 8460/24958 loss = 1.268230327963829, ppl = 3.5751035268185363\n","Train Epoch #17, Batch 8461/24958 loss = 1.2684184354543686, ppl = 3.5757368962035248\n","Train Epoch #17, Batch 8462/24958 loss = 1.2687562066316604, ppl = 3.576963564043487\n","Train Epoch #17, Batch 8463/24958 loss = 1.2677465504407883, ppl = 3.573270707600417\n","Train Epoch #17, Batch 8464/24958 loss = 1.2672376698255539, ppl = 3.5714723851243546\n","Train Epoch #17, Batch 8465/24958 loss = 1.2672590905427932, ppl = 3.571554338045169\n","Train Epoch #17, Batch 8466/24958 loss = 1.267743871808052, ppl = 3.5733786716321636\n","Train Epoch #17, Batch 8467/24958 loss = 1.2689520889520645, ppl = 3.577728908178716\n","Train Epoch #17, Batch 8468/24958 loss = 1.2676829022169114, ppl = 3.573729839983608\n","Train Epoch #17, Batch 8469/24958 loss = 1.269702143073082, ppl = 3.580727182127423\n","Train Epoch #17, Batch 8470/24958 loss = 1.2688167268037795, ppl = 3.5772345029991572\n","Train Epoch #17, Batch 8471/24958 loss = 1.2683503204584121, ppl = 3.575538418846018\n","Train Epoch #17, Batch 8472/24958 loss = 1.2675791579484939, ppl = 3.5727663022720604\n","Train Epoch #17, Batch 8473/24958 loss = 1.2672545725107194, ppl = 3.571658583695714\n","Train Epoch #17, Batch 8474/24958 loss = 1.2692076534032821, ppl = 3.5787005167015757\n","Train Epoch #17, Batch 8475/24958 loss = 1.2706102401018142, ppl = 3.583367153523521\n","Train Epoch #17, Batch 8476/24958 loss = 1.2728504246473313, ppl = 3.5910563312868273\n","Train Epoch #17, Batch 8477/24958 loss = 1.2707343524694443, ppl = 3.5829746769635444\n","Train Epoch #17, Batch 8478/24958 loss = 1.2735982519388198, ppl = 3.5938890373392116\n","Train Epoch #17, Batch 8479/24958 loss = 1.2712035590410233, ppl = 3.5850542230195104\n","Train Epoch #17, Batch 8480/24958 loss = 1.2716043430566788, ppl = 3.5866784543120254\n","Train Epoch #17, Batch 8481/24958 loss = 1.2725045198202134, ppl = 3.5903152534889955\n","Train Epoch #17, Batch 8482/24958 loss = 1.2714053827524185, ppl = 3.586480608851242\n","Train Epoch #17, Batch 8483/24958 loss = 1.2749748402833938, ppl = 3.601407638646611\n","Train Epoch #17, Batch 8484/24958 loss = 1.2758651119470596, ppl = 3.6045241610493877\n","Train Epoch #17, Batch 8485/24958 loss = 1.275757240653038, ppl = 3.6041503254305254\n","Train Epoch #17, Batch 8486/24958 loss = 1.2754002517461778, ppl = 3.6029740030195727\n","Train Epoch #17, Batch 8487/24958 loss = 1.2764814215898515, ppl = 3.607240534908401\n","Train Epoch #17, Batch 8488/24958 loss = 1.274311781525612, ppl = 3.5997770584821414\n","Train Epoch #17, Batch 8489/24958 loss = 1.2734948271512985, ppl = 3.5966727108610286\n","Train Epoch #17, Batch 8490/24958 loss = 1.2734251922369004, ppl = 3.5964245360090583\n","Train Epoch #17, Batch 8491/24958 loss = 1.272023051381111, ppl = 3.5915905736030975\n","Train Epoch #17, Batch 8492/24958 loss = 1.2722357541322709, ppl = 3.5923130250889574\n","Train Epoch #17, Batch 8493/24958 loss = 1.2713093382120133, ppl = 3.5889436767096954\n","Train Epoch #17, Batch 8494/24958 loss = 1.2728410786390305, ppl = 3.5942565490119502\n","Train Epoch #17, Batch 8495/24958 loss = 1.2717780393362046, ppl = 3.5901896716354726\n","Train Epoch #17, Batch 8496/24958 loss = 1.2708067613840104, ppl = 3.586575185736531\n","Train Epoch #17, Batch 8497/24958 loss = 1.2720558720827102, ppl = 3.591542247961398\n","Train Epoch #17, Batch 8498/24958 loss = 1.2697620075941085, ppl = 3.583441299807439\n","Train Epoch #17, Batch 8499/24958 loss = 1.2694099742174147, ppl = 3.5822848547190826\n","Train Epoch #17, Batch 8500/24958 loss = 1.2717787998914718, ppl = 3.589760337293965\n","Train Epoch #17, Batch 8501/24958 loss = 1.271058855652809, ppl = 3.5871453410828087\n","Train Epoch #17, Batch 8502/24958 loss = 1.272819146513939, ppl = 3.594099250676832\n","Train Epoch #17, Batch 8503/24958 loss = 1.2741641706228257, ppl = 3.598441813610263\n","Train Epoch #17, Batch 8504/24958 loss = 1.2750197058916093, ppl = 3.601305633844575\n","Train Epoch #17, Batch 8505/24958 loss = 1.275250373482704, ppl = 3.6021702135403864\n","Train Epoch #17, Batch 8506/24958 loss = 1.2749359840154648, ppl = 3.60099599714518\n","Train Epoch #17, Batch 8507/24958 loss = 1.2745651096105575, ppl = 3.5995670580038603\n","Train Epoch #17, Batch 8508/24958 loss = 1.2765217572450638, ppl = 3.605334961842948\n","Train Epoch #17, Batch 8509/24958 loss = 1.2754328471422196, ppl = 3.6016025540566843\n","Train Epoch #17, Batch 8510/24958 loss = 1.2761209911108018, ppl = 3.604191368418972\n","Train Epoch #17, Batch 8511/24958 loss = 1.2759239047765731, ppl = 3.6035592810087143\n","Train Epoch #17, Batch 8512/24958 loss = 1.2732747250795364, ppl = 3.594018092037781\n","Train Epoch #17, Batch 8513/24958 loss = 1.2739665991067886, ppl = 3.596551046378491\n","Train Epoch #17, Batch 8514/24958 loss = 1.2721186941862106, ppl = 3.5897024884841926\n","Train Epoch #17, Batch 8515/24958 loss = 1.2731903272867202, ppl = 3.5935911492306327\n","Train Epoch #17, Batch 8516/24958 loss = 1.2729902952909469, ppl = 3.59288939015916\n","Train Epoch #17, Batch 8517/24958 loss = 1.2749383801221847, ppl = 3.5999192884320363\n","Train Epoch #17, Batch 8518/24958 loss = 1.2747694367170335, ppl = 3.5992437589568027\n","Train Epoch #17, Batch 8519/24958 loss = 1.2757234483957292, ppl = 3.602859738299643\n","Train Epoch #17, Batch 8520/24958 loss = 1.278444029688835, ppl = 3.612441441795826\n","Train Epoch #17, Batch 8521/24958 loss = 1.2765111130476, ppl = 3.605549750422038\n","Train Epoch #17, Batch 8522/24958 loss = 1.2755534213781357, ppl = 3.602227846661882\n","Train Epoch #17, Batch 8523/24958 loss = 1.2751419311761856, ppl = 3.6007642418114485\n","Train Epoch #17, Batch 8524/24958 loss = 1.2744250851869583, ppl = 3.5982214104957517\n","Train Epoch #17, Batch 8525/24958 loss = 1.276765519976616, ppl = 3.6068714172181076\n","Train Epoch #17, Batch 8526/24958 loss = 1.2789642506837844, ppl = 3.615347694640995\n","Train Epoch #17, Batch 8527/24958 loss = 1.2764627879858017, ppl = 3.6060287177836603\n","Train Epoch #17, Batch 8528/24958 loss = 1.2759729820489882, ppl = 3.6044520599587764\n","Train Epoch #17, Batch 8529/24958 loss = 1.2744253665208816, ppl = 3.5998320424989005\n","Train Epoch #17, Batch 8530/24958 loss = 1.2713954359292985, ppl = 3.589291032871843\n","Train Epoch #17, Batch 8531/24958 loss = 1.2733092898130416, ppl = 3.5956995142676687\n","Train Epoch #17, Batch 8532/24958 loss = 1.275577214360237, ppl = 3.6033164973726715\n","Train Epoch #17, Batch 8533/24958 loss = 1.2730285435914994, ppl = 3.593268708673374\n","Train Epoch #17, Batch 8534/24958 loss = 1.272665702700615, ppl = 3.5920991937148132\n","Train Epoch #17, Batch 8535/24958 loss = 1.2713283902406693, ppl = 3.5874982407082556\n","Train Epoch #17, Batch 8536/24958 loss = 1.2722392302751542, ppl = 3.5905866738519654\n","Train Epoch #17, Batch 8537/24958 loss = 1.2711102753877639, ppl = 3.5860433060020127\n","Train Epoch #17, Batch 8538/24958 loss = 1.2697659987211227, ppl = 3.5813800767397903\n","Train Epoch #17, Batch 8539/24958 loss = 1.2696621507406234, ppl = 3.5810400626472285\n","Train Epoch #17, Batch 8540/24958 loss = 1.271828401684761, ppl = 3.589263286708659\n","Train Epoch #17, Batch 8541/24958 loss = 1.274542641043663, ppl = 3.601220347436696\n","Train Epoch #17, Batch 8542/24958 loss = 1.2725751441717148, ppl = 3.593873315385717\n","Train Epoch #17, Batch 8543/24958 loss = 1.2723365718126296, ppl = 3.5930014522824267\n","Train Epoch #17, Batch 8544/24958 loss = 1.2757799869775772, ppl = 3.605174656018221\n","Train Epoch #17, Batch 8545/24958 loss = 1.2744899255037307, ppl = 3.6004566063954138\n","Train Epoch #17, Batch 8546/24958 loss = 1.274854490160942, ppl = 3.6016482762040467\n","Train Epoch #17, Batch 8547/24958 loss = 1.2725545197725296, ppl = 3.5930070886265724\n","Train Epoch #17, Batch 8548/24958 loss = 1.2726891058683396, ppl = 3.593540117689506\n","Train Epoch #17, Batch 8549/24958 loss = 1.2715697771310805, ppl = 3.58986736005602\n","Train Epoch #17, Batch 8550/24958 loss = 1.2674639159440995, ppl = 3.5756678407252114\n","Train Epoch #17, Batch 8551/24958 loss = 1.2682772797346116, ppl = 3.5785076473672297\n","Train Epoch #17, Batch 8552/24958 loss = 1.265350279211998, ppl = 3.5687640087322476\n","Train Epoch #17, Batch 8553/24958 loss = 1.264043242931366, ppl = 3.565060740511564\n","Train Epoch #17, Batch 8554/24958 loss = 1.2640660429000854, ppl = 3.565128614589873\n","Train Epoch #17, Batch 8555/24958 loss = 1.2657200765609742, ppl = 3.5705262289314437\n","Train Epoch #17, Batch 8556/24958 loss = 1.2681724798679352, ppl = 3.579954978448263\n","Train Epoch #17, Batch 8557/24958 loss = 1.266733499765396, ppl = 3.574750346433603\n","Train Epoch #17, Batch 8558/24958 loss = 1.268087996840477, ppl = 3.5786072030803013\n","Train Epoch #17, Batch 8559/24958 loss = 1.2688823467493058, ppl = 3.5814299179686446\n","Train Epoch #17, Batch 8560/24958 loss = 1.2675519126653672, ppl = 3.576588863891373\n","Train Epoch #17, Batch 8561/24958 loss = 1.2676135152578354, ppl = 3.5767988867841423\n","Train Epoch #17, Batch 8562/24958 loss = 1.2679061967134475, ppl = 3.5778958310419773\n","Train Epoch #17, Batch 8563/24958 loss = 1.2689848691225052, ppl = 3.5818549926283545\n","Train Epoch #17, Batch 8564/24958 loss = 1.268359027504921, ppl = 3.579765215657202\n","Train Epoch #17, Batch 8565/24958 loss = 1.2662714046239854, ppl = 3.572549095864984\n","Train Epoch #17, Batch 8566/24958 loss = 1.266896087527275, ppl = 3.575034161365057\n","Train Epoch #17, Batch 8567/24958 loss = 1.2658486992120743, ppl = 3.5712331223606304\n","Train Epoch #17, Batch 8568/24958 loss = 1.2685312336683274, ppl = 3.5803255316579152\n","Train Epoch #17, Batch 8569/24958 loss = 1.2669356697797776, ppl = 3.5746815937277017\n","Train Epoch #17, Batch 8570/24958 loss = 1.2652038353681565, ppl = 3.568682503096746\n","Train Epoch #17, Batch 8571/24958 loss = 1.2670148450136185, ppl = 3.5757352023580777\n","Train Epoch #17, Batch 8572/24958 loss = 1.2676010650396348, ppl = 3.5778228866974904\n","Train Epoch #17, Batch 8573/24958 loss = 1.2692116218805314, ppl = 3.5836903609546518\n","Train Epoch #17, Batch 8574/24958 loss = 1.2683367723226546, ppl = 3.580365549849945\n","Train Epoch #17, Batch 8575/24958 loss = 1.2704281550645828, ppl = 3.588660497596554\n","Train Epoch #17, Batch 8576/24958 loss = 1.2686273437738418, ppl = 3.582346795143268\n","Train Epoch #17, Batch 8577/24958 loss = 1.267824530005455, ppl = 3.5797012909863146\n","Train Epoch #17, Batch 8578/24958 loss = 1.2644970327615739, ppl = 3.5672959160129905\n","Train Epoch #17, Batch 8579/24958 loss = 1.2634558552503585, ppl = 3.5640672557961706\n","Train Epoch #17, Batch 8580/24958 loss = 1.261196259856224, ppl = 3.5557054698323523\n","Train Epoch #17, Batch 8581/24958 loss = 1.2594491761922837, ppl = 3.5489334153263417\n","Train Epoch #17, Batch 8582/24958 loss = 1.2604535287618637, ppl = 3.5524205215159537\n","Train Epoch #17, Batch 8583/24958 loss = 1.25473102748394, ppl = 3.530752917560946\n","Train Epoch #17, Batch 8584/24958 loss = 1.2558342462778092, ppl = 3.535020424677041\n","Train Epoch #17, Batch 8585/24958 loss = 1.2568705922365189, ppl = 3.5387842836731425\n","Train Epoch #17, Batch 8586/24958 loss = 1.2571823459863662, ppl = 3.5398092169488513\n","Train Epoch #17, Batch 8587/24958 loss = 1.2543982118368149, ppl = 3.529691510292738\n","Train Epoch #17, Batch 8588/24958 loss = 1.2540768533945084, ppl = 3.5287173755295784\n","Train Epoch #17, Batch 8589/24958 loss = 1.253728259205818, ppl = 3.527468024885104\n","Train Epoch #17, Batch 8590/24958 loss = 1.254020830988884, ppl = 3.528522457397492\n","Train Epoch #17, Batch 8591/24958 loss = 1.2551566404104233, ppl = 3.532385339880804\n","Train Epoch #17, Batch 8592/24958 loss = 1.2537665039300918, ppl = 3.527930143789839\n","Train Epoch #17, Batch 8593/24958 loss = 1.2524048727750778, ppl = 3.5235114365236426\n","Train Epoch #17, Batch 8594/24958 loss = 1.2549064165353776, ppl = 3.5341440802462643\n","Train Epoch #17, Batch 8595/24958 loss = 1.2551212507486342, ppl = 3.534931489553192\n","Train Epoch #17, Batch 8596/24958 loss = 1.2556709736585616, ppl = 3.536934009613267\n","Train Epoch #17, Batch 8597/24958 loss = 1.2524547177553176, ppl = 3.5253002201131114\n","Train Epoch #17, Batch 8598/24958 loss = 1.2534525233507157, ppl = 3.528597067745559\n","Train Epoch #17, Batch 8599/24958 loss = 1.2533068174123765, ppl = 3.5281302024721333\n","Train Epoch #17, Batch 8600/24958 loss = 1.2542296677827836, ppl = 3.5315567316182785\n","Train Epoch #17, Batch 8601/24958 loss = 1.255849444270134, ppl = 3.5377162645286604\n","Train Epoch #17, Batch 8602/24958 loss = 1.2546532601118088, ppl = 3.532859015219312\n","Train Epoch #17, Batch 8603/24958 loss = 1.2557152670621872, ppl = 3.5367252496471293\n","Train Epoch #17, Batch 8604/24958 loss = 1.2566779321432113, ppl = 3.540254642612327\n","Train Epoch #17, Batch 8605/24958 loss = 1.2566357940435409, ppl = 3.540095209708205\n","Train Epoch #17, Batch 8606/24958 loss = 1.2568183571100235, ppl = 3.5407725683027804\n","Train Epoch #17, Batch 8607/24958 loss = 1.2557167249917984, ppl = 3.5368276039653104\n","Train Epoch #17, Batch 8608/24958 loss = 1.2592737203836442, ppl = 3.5506923031287028\n","Train Epoch #17, Batch 8609/24958 loss = 1.2611673134565353, ppl = 3.557456111592426\n","Train Epoch #17, Batch 8610/24958 loss = 1.2610917621850968, ppl = 3.557163102561318\n","Train Epoch #17, Batch 8611/24958 loss = 1.2624982339143753, ppl = 3.561958934751164\n","Train Epoch #17, Batch 8612/24958 loss = 1.2626697117090224, ppl = 3.562502976767393\n","Train Epoch #17, Batch 8613/24958 loss = 1.260522329211235, ppl = 3.5551806134636155\n","Train Epoch #17, Batch 8614/24958 loss = 1.2604323154687882, ppl = 3.5548782490467694\n","Train Epoch #17, Batch 8615/24958 loss = 1.2594552689790726, ppl = 3.55131629732807\n","Train Epoch #17, Batch 8616/24958 loss = 1.2597076100111009, ppl = 3.5522038959115734\n","Train Epoch #17, Batch 8617/24958 loss = 1.258140577673912, ppl = 3.546443513311439\n","Train Epoch #17, Batch 8618/24958 loss = 1.258171382546425, ppl = 3.546565839048837\n","Train Epoch #17, Batch 8619/24958 loss = 1.2568710106611252, ppl = 3.5417201005956214\n","Train Epoch #17, Batch 8620/24958 loss = 1.2552138060331344, ppl = 3.535576734353205\n","Train Epoch #17, Batch 8621/24958 loss = 1.2581679517030715, ppl = 3.546684392092538\n","Train Epoch #17, Batch 8622/24958 loss = 1.2577675622701645, ppl = 3.5453871631169314\n","Train Epoch #17, Batch 8623/24958 loss = 1.2586505657434464, ppl = 3.54860360697615\n","Train Epoch #17, Batch 8624/24958 loss = 1.2592266207933427, ppl = 3.5506325297008217\n","Train Epoch #17, Batch 8625/24958 loss = 1.2557436805963516, ppl = 3.5384409801414596\n","Train Epoch #17, Batch 8626/24958 loss = 1.2535539203882218, ppl = 3.5299956359460833\n","Train Epoch #17, Batch 8627/24958 loss = 1.2539385944604873, ppl = 3.5312815048785167\n","Train Epoch #17, Batch 8628/24958 loss = 1.2564712744951247, ppl = 3.5403340538845613\n","Train Epoch #17, Batch 8629/24958 loss = 1.259539619088173, ppl = 3.5502463867455174\n","Train Epoch #17, Batch 8630/24958 loss = 1.2606365579366683, ppl = 3.553699535514074\n","Train Epoch #17, Batch 8631/24958 loss = 1.2583985179662704, ppl = 3.5463218869151456\n","Train Epoch #17, Batch 8632/24958 loss = 1.258229073882103, ppl = 3.545691185833582\n","Train Epoch #17, Batch 8633/24958 loss = 1.2591739815473557, ppl = 3.5491212923324484\n","Train Epoch #17, Batch 8634/24958 loss = 1.2609519630670547, ppl = 3.555280066152223\n","Train Epoch #17, Batch 8635/24958 loss = 1.2626553958654403, ppl = 3.5612516768779905\n","Train Epoch #17, Batch 8636/24958 loss = 1.264234533905983, ppl = 3.5673202475222645\n","Train Epoch #17, Batch 8637/24958 loss = 1.2623658412694931, ppl = 3.560840662338369\n","Train Epoch #17, Batch 8638/24958 loss = 1.2623201483488082, ppl = 3.5606929088833423\n","Train Epoch #17, Batch 8639/24958 loss = 1.2652212959527969, ppl = 3.5716559565835717\n","Train Epoch #17, Batch 8640/24958 loss = 1.2626303642988206, ppl = 3.562019159224669\n","Train Epoch #17, Batch 8641/24958 loss = 1.2604411560297013, ppl = 3.5521291002090423\n","Train Epoch #17, Batch 8642/24958 loss = 1.260647984147072, ppl = 3.5528352266995307\n","Train Epoch #17, Batch 8643/24958 loss = 1.2613183897733689, ppl = 3.555339109469875\n","Train Epoch #17, Batch 8644/24958 loss = 1.2598541706800461, ppl = 3.549647387791951\n","Train Epoch #17, Batch 8645/24958 loss = 1.2614789658784866, ppl = 3.5556923817581496\n","Train Epoch #17, Batch 8646/24958 loss = 1.2617277199029922, ppl = 3.5565307922061837\n","Train Epoch #17, Batch 8647/24958 loss = 1.2630295318365097, ppl = 3.5611767420312073\n","Train Epoch #17, Batch 8648/24958 loss = 1.2623382836580277, ppl = 3.558513687162411\n","Train Epoch #17, Batch 8649/24958 loss = 1.2639888280630112, ppl = 3.5640786619507367\n","Train Epoch #17, Batch 8650/24958 loss = 1.2660135799646377, ppl = 3.570355570193891\n","Train Epoch #17, Batch 8651/24958 loss = 1.2652799063920974, ppl = 3.567783901865706\n","Train Epoch #17, Batch 8652/24958 loss = 1.2663673919439316, ppl = 3.571075767358026\n","Train Epoch #17, Batch 8653/24958 loss = 1.2675527250766754, ppl = 3.574413413757126\n","Train Epoch #17, Batch 8654/24958 loss = 1.2692441499233247, ppl = 3.5799058345401953\n","Train Epoch #17, Batch 8655/24958 loss = 1.2689606070518493, ppl = 3.5789160158123745\n","Train Epoch #17, Batch 8656/24958 loss = 1.2660493278503417, ppl = 3.567965702549312\n","Train Epoch #17, Batch 8657/24958 loss = 1.2651323354244233, ppl = 3.5650191159361073\n","Train Epoch #17, Batch 8658/24958 loss = 1.2660973525047303, ppl = 3.568103685698128\n","Train Epoch #17, Batch 8659/24958 loss = 1.2672344088554381, ppl = 3.572555088170533\n","Train Epoch #17, Batch 8660/24958 loss = 1.2688486301898956, ppl = 3.5785147714208034\n","Train Epoch #17, Batch 8661/24958 loss = 1.2703116714954377, ppl = 3.5839026529118336\n","Train Epoch #17, Batch 8662/24958 loss = 1.2699241852760315, ppl = 3.582457217721615\n","Train Epoch #17, Batch 8663/24958 loss = 1.2712391316890717, ppl = 3.587898494267437\n","Train Epoch #17, Batch 8664/24958 loss = 1.2711870884895324, ppl = 3.587730533046856\n","Train Epoch #17, Batch 8665/24958 loss = 1.2716367101669313, ppl = 3.5891600141342472\n","Train Epoch #17, Batch 8666/24958 loss = 1.2704568159580232, ppl = 3.5845928532955447\n","Train Epoch #17, Batch 8667/24958 loss = 1.2704915857315064, ppl = 3.5847127506097944\n","Train Epoch #17, Batch 8668/24958 loss = 1.2684626686573028, ppl = 3.5776164115239517\n","Train Epoch #17, Batch 8669/24958 loss = 1.2688944339752197, ppl = 3.579055930415018\n","Train Epoch #17, Batch 8670/24958 loss = 1.269476820230484, ppl = 3.580958537029858\n","Train Epoch #17, Batch 8671/24958 loss = 1.2680127131938934, ppl = 3.5751597811693934\n","Train Epoch #17, Batch 8672/24958 loss = 1.2662150502204894, ppl = 3.5691268448493747\n","Train Epoch #17, Batch 8673/24958 loss = 1.2638738226890565, ppl = 3.5608935324015523\n","Train Epoch #17, Batch 8674/24958 loss = 1.2632443857192994, ppl = 3.5586750607523783\n","Train Epoch #17, Batch 8675/24958 loss = 1.2587772190570832, ppl = 3.5428393813064556\n","Train Epoch #17, Batch 8676/24958 loss = 1.2605591654777526, ppl = 3.549080877043315\n","Train Epoch #17, Batch 8677/24958 loss = 1.2602574622631073, ppl = 3.548140311332895\n","Train Epoch #17, Batch 8678/24958 loss = 1.2613644301891327, ppl = 3.551818457821696\n","Train Epoch #17, Batch 8679/24958 loss = 1.2641481423377992, ppl = 3.5612626699397576\n","Train Epoch #17, Batch 8680/24958 loss = 1.2656959772109986, ppl = 3.5667840447442245\n","Train Epoch #17, Batch 8681/24958 loss = 1.2665853130817413, ppl = 3.5700834655988296\n","Train Epoch #17, Batch 8682/24958 loss = 1.266733341217041, ppl = 3.5706276778583765\n","Train Epoch #17, Batch 8683/24958 loss = 1.2685130202770234, ppl = 3.576092961219544\n","Train Epoch #17, Batch 8684/24958 loss = 1.267008774280548, ppl = 3.5703872151996263\n","Train Epoch #17, Batch 8685/24958 loss = 1.2670157837867737, ppl = 3.5704140240299544\n","Train Epoch #17, Batch 8686/24958 loss = 1.2672952604293823, ppl = 3.571360401464332\n","Train Epoch #17, Batch 8687/24958 loss = 1.2673968720436095, ppl = 3.5716822749110158\n","Train Epoch #17, Batch 8688/24958 loss = 1.2700569868087768, ppl = 3.5807725325383415\n","Train Epoch #17, Batch 8689/24958 loss = 1.270704025030136, ppl = 3.5831266522015053\n","Train Epoch #17, Batch 8690/24958 loss = 1.2696275317668915, ppl = 3.579394415178262\n","Train Epoch #17, Batch 8691/24958 loss = 1.2708554124832154, ppl = 3.5840947463635633\n","Train Epoch #17, Batch 8692/24958 loss = 1.2746124935150147, ppl = 3.5977173202239494\n","Train Epoch #17, Batch 8693/24958 loss = 1.2734307169914245, ppl = 3.594340880829068\n","Train Epoch #17, Batch 8694/24958 loss = 1.2705596125125884, ppl = 3.582350965856529\n","Train Epoch #17, Batch 8695/24958 loss = 1.2676778745651245, ppl = 3.5730755402178387\n","Train Epoch #17, Batch 8696/24958 loss = 1.267698550224304, ppl = 3.5731530263254485\n","Train Epoch #17, Batch 8697/24958 loss = 1.2694748151302337, ppl = 3.579113899309594\n","Train Epoch #17, Batch 8698/24958 loss = 1.2708149778842925, ppl = 3.584092687260338\n","Train Epoch #17, Batch 8699/24958 loss = 1.2702726888656617, ppl = 3.5824136710829926\n","Train Epoch #17, Batch 8700/24958 loss = 1.268795508146286, ppl = 3.577075895334379\n","Train Epoch #17, Batch 8701/24958 loss = 1.2675542151927948, ppl = 3.5722676152054733\n","Train Epoch #17, Batch 8702/24958 loss = 1.2685335743427277, ppl = 3.576200766897908\n","Train Epoch #17, Batch 8703/24958 loss = 1.2676236617565155, ppl = 3.5728633618292185\n","Train Epoch #17, Batch 8704/24958 loss = 1.2661242735385896, ppl = 3.567508809645724\n","Train Epoch #17, Batch 8705/24958 loss = 1.2669846725463867, ppl = 3.570901192436523\n","Train Epoch #17, Batch 8706/24958 loss = 1.2658768916130065, ppl = 3.5669748807689374\n","Train Epoch #17, Batch 8707/24958 loss = 1.2662207770347595, ppl = 3.56816001573405\n","Train Epoch #17, Batch 8708/24958 loss = 1.2630950915813446, ppl = 3.555725822930654\n","Train Epoch #17, Batch 8709/24958 loss = 1.2606598591804505, ppl = 3.5472514522992213\n","Train Epoch #17, Batch 8710/24958 loss = 1.258655730485916, ppl = 3.540234788012715\n","Train Epoch #17, Batch 8711/24958 loss = 1.257468467950821, ppl = 3.536142775577614\n","Train Epoch #17, Batch 8712/24958 loss = 1.2566980731487274, ppl = 3.53377012026357\n","Train Epoch #17, Batch 8713/24958 loss = 1.2608452486991881, ppl = 3.5494807267371904\n","Train Epoch #17, Batch 8714/24958 loss = 1.2626122832298279, ppl = 3.555943908182913\n","Train Epoch #17, Batch 8715/24958 loss = 1.2640053403377534, ppl = 3.561131354955151\n","Train Epoch #17, Batch 8716/24958 loss = 1.2655216181278228, ppl = 3.566963348068565\n","Train Epoch #17, Batch 8717/24958 loss = 1.268299503326416, ppl = 3.5778359181234647\n","Train Epoch #17, Batch 8718/24958 loss = 1.268519229888916, ppl = 3.578719465362006\n","Train Epoch #17, Batch 8719/24958 loss = 1.2692138290405273, ppl = 3.5812293503064256\n","Train Epoch #17, Batch 8720/24958 loss = 1.2701705503463745, ppl = 3.5846513004798752\n","Train Epoch #17, Batch 8721/24958 loss = 1.2668638634681701, ppl = 3.57242409887196\n","Train Epoch #17, Batch 8722/24958 loss = 1.267374107837677, ppl = 3.574086423450071\n","Train Epoch #17, Batch 8723/24958 loss = 1.266392204761505, ppl = 3.5705270957286204\n","Train Epoch #17, Batch 8724/24958 loss = 1.2647610354423522, ppl = 3.5650718996415502\n","Train Epoch #17, Batch 8725/24958 loss = 1.2664180755615235, ppl = 3.570345422226292\n","Train Epoch #17, Batch 8726/24958 loss = 1.2667901086807252, ppl = 3.571653063604596\n","Train Epoch #17, Batch 8727/24958 loss = 1.2664872574806214, ppl = 3.5706365816594796\n","Train Epoch #17, Batch 8728/24958 loss = 1.2652449560165406, ppl = 3.5659098941801055\n","Train Epoch #17, Batch 8729/24958 loss = 1.2665951669216156, ppl = 3.571333006465986\n","Train Epoch #17, Batch 8730/24958 loss = 1.2676320803165435, ppl = 3.5749645244199764\n","Train Epoch #17, Batch 8731/24958 loss = 1.269336737394333, ppl = 3.5804312163076095\n","Train Epoch #17, Batch 8732/24958 loss = 1.2697059047222137, ppl = 3.581819175903625\n","Train Epoch #17, Batch 8733/24958 loss = 1.2691721653938293, ppl = 3.5798419065346008\n","Train Epoch #17, Batch 8734/24958 loss = 1.2680568742752074, ppl = 3.575851670670671\n","Train Epoch #17, Batch 8735/24958 loss = 1.268049088716507, ppl = 3.5758219983276702\n","Train Epoch #17, Batch 8736/24958 loss = 1.2663441705703735, ppl = 3.5693100149557586\n","Train Epoch #17, Batch 8737/24958 loss = 1.266674679517746, ppl = 3.5703697062485236\n","Train Epoch #17, Batch 8738/24958 loss = 1.2685464560985564, ppl = 3.577010638709376\n","Train Epoch #17, Batch 8739/24958 loss = 1.2681273770332337, ppl = 3.5752238850477984\n","Train Epoch #17, Batch 8740/24958 loss = 1.2687274432182312, ppl = 3.577238981880276\n","Train Epoch #17, Batch 8741/24958 loss = 1.267728064060211, ppl = 3.573395572890301\n","Train Epoch #17, Batch 8742/24958 loss = 1.2679132652282714, ppl = 3.574040377183797\n","Train Epoch #17, Batch 8743/24958 loss = 1.2665467357635498, ppl = 3.5691082332366046\n","Train Epoch #17, Batch 8744/24958 loss = 1.2656541919708253, ppl = 3.5660261318227344\n","Train Epoch #17, Batch 8745/24958 loss = 1.2660986948013306, ppl = 3.567858295010613\n","Train Epoch #17, Batch 8746/24958 loss = 1.267878656387329, ppl = 3.574506618812012\n","Train Epoch #17, Batch 8747/24958 loss = 1.267508215904236, ppl = 3.5731224553242384\n","Train Epoch #17, Batch 8748/24958 loss = 1.265799355506897, ppl = 3.56727755858953\n","Train Epoch #17, Batch 8749/24958 loss = 1.2677743172645568, ppl = 3.5752636497607506\n","Train Epoch #17, Batch 8750/24958 loss = 1.2672956705093383, ppl = 3.573663125765997\n","Train Epoch #17, Batch 8751/24958 loss = 1.2677897703647614, ppl = 3.5753742096734356\n","Train Epoch #17, Batch 8752/24958 loss = 1.2692851555347442, ppl = 3.5805270723940392\n","Train Epoch #17, Batch 8753/24958 loss = 1.2734804403781892, ppl = 3.596091244155813\n","Train Epoch #17, Batch 8754/24958 loss = 1.2728629875183106, ppl = 3.5939778168335645\n","Train Epoch #17, Batch 8755/24958 loss = 1.2742613852024078, ppl = 3.599143355904017\n","Train Epoch #17, Batch 8756/24958 loss = 1.2745799911022186, ppl = 3.60019237420072\n","Train Epoch #17, Batch 8757/24958 loss = 1.2759704506397247, ppl = 3.6047694770914434\n","Train Epoch #17, Batch 8758/24958 loss = 1.2758113622665406, ppl = 3.604240259059761\n","Train Epoch #17, Batch 8759/24958 loss = 1.273844804763794, ppl = 3.5968463381971776\n","Train Epoch #17, Batch 8760/24958 loss = 1.2744008016586303, ppl = 3.599132161588896\n","Train Epoch #17, Batch 8761/24958 loss = 1.2712967538833617, ppl = 3.5885685917039445\n","Train Epoch #17, Batch 8762/24958 loss = 1.269460210800171, ppl = 3.5824305151011635\n","Train Epoch #17, Batch 8763/24958 loss = 1.268895115852356, ppl = 3.5800042294667014\n","Train Epoch #17, Batch 8764/24958 loss = 1.2707698702812196, ppl = 3.5866417277816414\n","Train Epoch #17, Batch 8765/24958 loss = 1.2718727266788483, ppl = 3.590432653406566\n","Train Epoch #17, Batch 8766/24958 loss = 1.2698962950706483, ppl = 3.5838923028065817\n","Train Epoch #17, Batch 8767/24958 loss = 1.2704912161827087, ppl = 3.586009709900227\n","Train Epoch #17, Batch 8768/24958 loss = 1.2700305032730101, ppl = 3.584589238240336\n","Train Epoch #17, Batch 8769/24958 loss = 1.2704518127441407, ppl = 3.5860551016570157\n","Train Epoch #17, Batch 8770/24958 loss = 1.2728604423999785, ppl = 3.5952140357747555\n","Train Epoch #17, Batch 8771/24958 loss = 1.2719110190868377, ppl = 3.591882933131119\n","Train Epoch #17, Batch 8772/24958 loss = 1.2710441267490387, ppl = 3.589339168582274\n","Train Epoch #17, Batch 8773/24958 loss = 1.2718250095844268, ppl = 3.5918740246457066\n","Train Epoch #17, Batch 8774/24958 loss = 1.2724026322364808, ppl = 3.593904554603552\n","Train Epoch #17, Batch 8775/24958 loss = 1.2738952147960663, ppl = 3.5984309094677953\n","Train Epoch #17, Batch 8776/24958 loss = 1.2720045936107636, ppl = 3.591843557088609\n","Train Epoch #17, Batch 8777/24958 loss = 1.2740869772434236, ppl = 3.598952497251582\n","Train Epoch #17, Batch 8778/24958 loss = 1.2728492534160614, ppl = 3.5948661631430188\n","Train Epoch #17, Batch 8779/24958 loss = 1.2697599673271178, ppl = 3.584536447508008\n","Train Epoch #17, Batch 8780/24958 loss = 1.2684768283367156, ppl = 3.579899752298943\n","Train Epoch #17, Batch 8781/24958 loss = 1.2650834619998932, ppl = 3.5687422518974086\n","Train Epoch #17, Batch 8782/24958 loss = 1.2659264039993285, ppl = 3.5719996061628354\n","Train Epoch #17, Batch 8783/24958 loss = 1.2656794166564942, ppl = 3.571181771102492\n","Train Epoch #17, Batch 8784/24958 loss = 1.2647983527183533, ppl = 3.5682173784326867\n","Train Epoch #17, Batch 8785/24958 loss = 1.2648986411094665, ppl = 3.568603010250685\n","Train Epoch #17, Batch 8786/24958 loss = 1.265033221244812, ppl = 3.569068253512549\n","Train Epoch #17, Batch 8787/24958 loss = 1.2659589540958405, ppl = 3.5721563379983947\n","Train Epoch #17, Batch 8788/24958 loss = 1.265017763376236, ppl = 3.568660430174595\n","Train Epoch #17, Batch 8789/24958 loss = 1.2646730995178224, ppl = 3.5673874956650105\n","Train Epoch #17, Batch 8790/24958 loss = 1.2660506939888, ppl = 3.5722376024507376\n","Train Epoch #17, Batch 8791/24958 loss = 1.2635447299480438, ppl = 3.5632207101850844\n","Train Epoch #17, Batch 8792/24958 loss = 1.2628782784938812, ppl = 3.5604164497003654\n","Train Epoch #17, Batch 8793/24958 loss = 1.265913829803467, ppl = 3.5699626127393236\n","Train Epoch #17, Batch 8794/24958 loss = 1.2678650856018066, ppl = 3.5777305402738557\n","Train Epoch #17, Batch 8795/24958 loss = 1.2707244312763215, ppl = 3.586923101922817\n","Train Epoch #17, Batch 8796/24958 loss = 1.2705392813682557, ppl = 3.5862348893625717\n","Train Epoch #17, Batch 8797/24958 loss = 1.271162359714508, ppl = 3.588589642205865\n","Train Epoch #17, Batch 8798/24958 loss = 1.2684391939640045, ppl = 3.579126731241493\n","Train Epoch #17, Batch 8799/24958 loss = 1.2690752303600312, ppl = 3.581105348191493\n","Train Epoch #17, Batch 8800/24958 loss = 1.2705997705459595, ppl = 3.586627644211786\n","Train Epoch #17, Batch 8801/24958 loss = 1.2709761893749236, ppl = 3.58802321915935\n","Train Epoch #17, Batch 8802/24958 loss = 1.2679450500011444, ppl = 3.5769992359144878\n","Train Epoch #17, Batch 8803/24958 loss = 1.268924629688263, ppl = 3.5806049031063707\n","Train Epoch #17, Batch 8804/24958 loss = 1.2686354255676269, ppl = 3.579661313516285\n","Train Epoch #17, Batch 8805/24958 loss = 1.2678181982040406, ppl = 3.5764322825762234\n","Train Epoch #17, Batch 8806/24958 loss = 1.2688088989257813, ppl = 3.5799227737844843\n","Train Epoch #17, Batch 8807/24958 loss = 1.2697579419612885, ppl = 3.5834130283982266\n","Train Epoch #17, Batch 8808/24958 loss = 1.2689178895950317, ppl = 3.5806826365003808\n","Train Epoch #17, Batch 8809/24958 loss = 1.2719737362861634, ppl = 3.5916674062349925\n","Train Epoch #17, Batch 8810/24958 loss = 1.2750577867031097, ppl = 3.603090137718768\n","Train Epoch #17, Batch 8811/24958 loss = 1.2766399276256561, ppl = 3.6086544032320496\n","Train Epoch #17, Batch 8812/24958 loss = 1.2774371528625488, ppl = 3.6111130298038434\n","Train Epoch #17, Batch 8813/24958 loss = 1.2738197219371796, ppl = 3.597065447379498\n","Train Epoch #17, Batch 8814/24958 loss = 1.2728493130207061, ppl = 3.5933751606174265\n","Train Epoch #17, Batch 8815/24958 loss = 1.2723274397850037, ppl = 3.5913467052812775\n","Train Epoch #17, Batch 8816/24958 loss = 1.2701279997825623, ppl = 3.5831625333910155\n","Train Epoch #17, Batch 8817/24958 loss = 1.2663164782524108, ppl = 3.568955565705732\n","Train Epoch #17, Batch 8818/24958 loss = 1.2643784022331237, ppl = 3.5617928900976734\n","Train Epoch #17, Batch 8819/24958 loss = 1.2660336315631866, ppl = 3.568525942285441\n","Train Epoch #17, Batch 8820/24958 loss = 1.2646495139598846, ppl = 3.563677955437975\n","Train Epoch #17, Batch 8821/24958 loss = 1.2644176256656647, ppl = 3.5629627899175786\n","Train Epoch #17, Batch 8822/24958 loss = 1.2647424721717835, ppl = 3.5640661608985016\n","Train Epoch #17, Batch 8823/24958 loss = 1.2641846454143524, ppl = 3.562194419934321\n","Train Epoch #17, Batch 8824/24958 loss = 1.2654827082157134, ppl = 3.566462152598358\n","Train Epoch #17, Batch 8825/24958 loss = 1.2672642242908478, ppl = 3.5731966043466485\n","Train Epoch #17, Batch 8826/24958 loss = 1.2682158386707305, ppl = 3.576771385815485\n","Train Epoch #17, Batch 8827/24958 loss = 1.269259821176529, ppl = 3.5804091761280596\n","Train Epoch #17, Batch 8828/24958 loss = 1.2695434141159057, ppl = 3.58143705640223\n","Train Epoch #17, Batch 8829/24958 loss = 1.267168185710907, ppl = 3.572359165313476\n","Train Epoch #17, Batch 8830/24958 loss = 1.2673845064640046, ppl = 3.573165418518383\n","Train Epoch #17, Batch 8831/24958 loss = 1.2683600437641145, ppl = 3.5767396084274434\n","Train Epoch #17, Batch 8832/24958 loss = 1.2671570682525635, ppl = 3.572399089887705\n","Train Epoch #17, Batch 8833/24958 loss = 1.2665097081661225, ppl = 3.5701383031998155\n","Train Epoch #17, Batch 8834/24958 loss = 1.2666665244102477, ppl = 3.5706728278538673\n","Train Epoch #17, Batch 8835/24958 loss = 1.2676210463047028, ppl = 3.574488498822329\n","Train Epoch #17, Batch 8836/24958 loss = 1.2678239285945891, ppl = 3.575206490112747\n","Train Epoch #17, Batch 8837/24958 loss = 1.2704823100566864, ppl = 3.5851324992593696\n","Train Epoch #17, Batch 8838/24958 loss = 1.2692824852466584, ppl = 3.5807339363687545\n","Train Epoch #17, Batch 8839/24958 loss = 1.2670444083213805, ppl = 3.5723621418003777\n","Train Epoch #17, Batch 8840/24958 loss = 1.2668400835990905, ppl = 3.571662374735254\n","Train Epoch #17, Batch 8841/24958 loss = 1.2660704624652863, ppl = 3.568953578065059\n","Train Epoch #17, Batch 8842/24958 loss = 1.265530446767807, ppl = 3.567106299266738\n","Train Epoch #17, Batch 8843/24958 loss = 1.2669893789291382, ppl = 3.572396907074438\n","Train Epoch #17, Batch 8844/24958 loss = 1.2669249475002289, ppl = 3.572184880007465\n","Train Epoch #17, Batch 8845/24958 loss = 1.266695920228958, ppl = 3.571230701671914\n","Train Epoch #17, Batch 8846/24958 loss = 1.2640726923942567, ppl = 3.5618226955719074\n","Train Epoch #17, Batch 8847/24958 loss = 1.261031066775322, ppl = 3.5522036801173864\n","Train Epoch #17, Batch 8848/24958 loss = 1.2625043946504593, ppl = 3.5571824215122825\n","Train Epoch #17, Batch 8849/24958 loss = 1.2581963807344436, ppl = 3.5415855073031235\n","Train Epoch #17, Batch 8850/24958 loss = 1.2572110456228256, ppl = 3.538522307796892\n","Train Epoch #17, Batch 8851/24958 loss = 1.2559998744726182, ppl = 3.534473638223797\n","Train Epoch #17, Batch 8852/24958 loss = 1.2552421289682387, ppl = 3.5317663416412866\n","Train Epoch #17, Batch 8853/24958 loss = 1.2532767778635026, ppl = 3.523661480123355\n","Train Epoch #17, Batch 8854/24958 loss = 1.2546501857042314, ppl = 3.5285465488155427\n","Train Epoch #17, Batch 8855/24958 loss = 1.2533973914384842, ppl = 3.5238857901358536\n","Train Epoch #17, Batch 8856/24958 loss = 1.253525796532631, ppl = 3.5243181076582646\n","Train Epoch #17, Batch 8857/24958 loss = 1.2535558706521988, ppl = 3.524424307067775\n","Train Epoch #17, Batch 8858/24958 loss = 1.2538517969846725, ppl = 3.525415509752085\n","Train Epoch #17, Batch 8859/24958 loss = 1.2539968425035477, ppl = 3.525912586039877\n","Train Epoch #17, Batch 8860/24958 loss = 1.2536142772436143, ppl = 3.524326187131255\n","Train Epoch #17, Batch 8861/24958 loss = 1.255815311074257, ppl = 3.5314717179213506\n","Train Epoch #17, Batch 8862/24958 loss = 1.2573979634046555, ppl = 3.536692631756299\n","Train Epoch #17, Batch 8863/24958 loss = 1.2551332515478135, ppl = 3.528234880444202\n","Train Epoch #17, Batch 8864/24958 loss = 1.254902451634407, ppl = 3.5273490155032694\n","Train Epoch #17, Batch 8865/24958 loss = 1.2537543469667434, ppl = 3.5234113061894403\n","Train Epoch #17, Batch 8866/24958 loss = 1.257246006131172, ppl = 3.5359182476555127\n","Train Epoch #17, Batch 8867/24958 loss = 1.257177807688713, ppl = 3.5356690787332075\n","Train Epoch #17, Batch 8868/24958 loss = 1.2582746011018753, ppl = 3.5391614353911702\n","Train Epoch #17, Batch 8869/24958 loss = 1.2585621947050094, ppl = 3.5401981231917903\n","Train Epoch #17, Batch 8870/24958 loss = 1.2567914670705795, ppl = 3.53325433502064\n","Train Epoch #17, Batch 8871/24958 loss = 1.2576154059171676, ppl = 3.536126821408841\n","Train Epoch #17, Batch 8872/24958 loss = 1.260077218413353, ppl = 3.543967616842183\n","Train Epoch #17, Batch 8873/24958 loss = 1.2605025726556778, ppl = 3.545433953537331\n","Train Epoch #17, Batch 8874/24958 loss = 1.2592151600122452, ppl = 3.5410636704643803\n","Train Epoch #17, Batch 8875/24958 loss = 1.2610302287340165, ppl = 3.547560791786385\n","Train Epoch #17, Batch 8876/24958 loss = 1.2620360440015792, ppl = 3.5509100428885527\n","Train Epoch #17, Batch 8877/24958 loss = 1.2623507744073867, ppl = 3.5521191617978265\n","Train Epoch #17, Batch 8878/24958 loss = 1.2629956191778182, ppl = 3.5541849660138825\n","Train Epoch #17, Batch 8879/24958 loss = 1.2643466264009475, ppl = 3.5583130286668445\n","Train Epoch #17, Batch 8880/24958 loss = 1.2651087135076522, ppl = 3.560994864316238\n","Train Epoch #17, Batch 8881/24958 loss = 1.266878189444542, ppl = 3.5663405476132017\n","Train Epoch #17, Batch 8882/24958 loss = 1.2659924930334092, ppl = 3.562925182340005\n","Train Epoch #17, Batch 8883/24958 loss = 1.2663378816843034, ppl = 3.5640745167120946\n","Train Epoch #17, Batch 8884/24958 loss = 1.26912546813488, ppl = 3.5744216735523806\n","Train Epoch #17, Batch 8885/24958 loss = 1.270488561987877, ppl = 3.580065312804741\n","Train Epoch #17, Batch 8886/24958 loss = 1.2708864217996598, ppl = 3.5814779035505313\n","Train Epoch #17, Batch 8887/24958 loss = 1.2699547868967056, ppl = 3.5783710336290624\n","Train Epoch #17, Batch 8888/24958 loss = 1.269542365670204, ppl = 3.576939832966129\n","Train Epoch #17, Batch 8889/24958 loss = 1.2669607764482498, ppl = 3.568680622925429\n","Train Epoch #17, Batch 8890/24958 loss = 1.2681174296140671, ppl = 3.5733019026295154\n","Train Epoch #17, Batch 8891/24958 loss = 1.2688949531316758, ppl = 3.5758618826581543\n","Train Epoch #17, Batch 8892/24958 loss = 1.2672484797239303, ppl = 3.5696847049385543\n","Train Epoch #17, Batch 8893/24958 loss = 1.2663504964113235, ppl = 3.566553179172804\n","Train Epoch #17, Batch 8894/24958 loss = 1.2623620051145554, ppl = 3.5521404010540643\n","Train Epoch #17, Batch 8895/24958 loss = 1.264714850783348, ppl = 3.5619458493326537\n","Train Epoch #17, Batch 8896/24958 loss = 1.2634078484773636, ppl = 3.5574337708436836\n","Train Epoch #17, Batch 8897/24958 loss = 1.261966306567192, ppl = 3.552200623608603\n","Train Epoch #17, Batch 8898/24958 loss = 1.2659383028745652, ppl = 3.5669436826426706\n","Train Epoch #17, Batch 8899/24958 loss = 1.2698238295316697, ppl = 3.5821901582761004\n","Train Epoch #17, Batch 8900/24958 loss = 1.2683950263261794, ppl = 3.576990426052758\n","Train Epoch #17, Batch 8901/24958 loss = 1.2675883346796035, ppl = 3.5740626473918953\n","Train Epoch #17, Batch 8902/24958 loss = 1.2671573323011398, ppl = 3.572749222783477\n","Train Epoch #17, Batch 8903/24958 loss = 1.2651373273134232, ppl = 3.565681650493762\n","Train Epoch #17, Batch 8904/24958 loss = 1.266241905093193, ppl = 3.5694373099573413\n","Train Epoch #17, Batch 8905/24958 loss = 1.265270661711693, ppl = 3.565927601289417\n","Train Epoch #17, Batch 8906/24958 loss = 1.2640426868200303, ppl = 3.561651219666493\n","Train Epoch #17, Batch 8907/24958 loss = 1.2627048391103743, ppl = 3.556824012269593\n","Train Epoch #17, Batch 8908/24958 loss = 1.2654947465658188, ppl = 3.566850039337642\n","Train Epoch #17, Batch 8909/24958 loss = 1.2641813510656357, ppl = 3.5617153357100686\n","Train Epoch #17, Batch 8910/24958 loss = 1.261827842593193, ppl = 3.552689033748779\n","Train Epoch #17, Batch 8911/24958 loss = 1.262271745800972, ppl = 3.554414985860845\n","Train Epoch #17, Batch 8912/24958 loss = 1.266061732172966, ppl = 3.569200633745284\n","Train Epoch #17, Batch 8913/24958 loss = 1.2661958223581313, ppl = 3.569635741099857\n","Train Epoch #17, Batch 8914/24958 loss = 1.2663647931814195, ppl = 3.5702528315489688\n","Train Epoch #17, Batch 8915/24958 loss = 1.266061742901802, ppl = 3.569122594696722\n","Train Epoch #17, Batch 8916/24958 loss = 1.2679198163747787, ppl = 3.5759156063036728\n","Train Epoch #17, Batch 8917/24958 loss = 1.268847786784172, ppl = 3.5788931061142035\n","Train Epoch #17, Batch 8918/24958 loss = 1.2694562488794328, ppl = 3.580994237998942\n","Train Epoch #17, Batch 8919/24958 loss = 1.2668996888399124, ppl = 3.5710373396413884\n","Train Epoch #17, Batch 8920/24958 loss = 1.2691566222906112, ppl = 3.579305994915336\n","Train Epoch #17, Batch 8921/24958 loss = 1.2720740741491319, ppl = 3.58963306448998\n","Train Epoch #17, Batch 8922/24958 loss = 1.2737958997488021, ppl = 3.596119299615929\n","Train Epoch #17, Batch 8923/24958 loss = 1.2735702198743821, ppl = 3.595391220601295\n","Train Epoch #17, Batch 8924/24958 loss = 1.2741350454092026, ppl = 3.597428360229641\n","Train Epoch #17, Batch 8925/24958 loss = 1.2727719074487687, ppl = 3.592169407081285\n","Train Epoch #17, Batch 8926/24958 loss = 1.2725540727376938, ppl = 3.591320824447608\n","Train Epoch #17, Batch 8927/24958 loss = 1.2724513345956803, ppl = 3.5909457480691778\n","Train Epoch #17, Batch 8928/24958 loss = 1.2698538333177567, ppl = 3.5825363931940215\n","Train Epoch #17, Batch 8929/24958 loss = 1.269345456957817, ppl = 3.5808580738524114\n","Train Epoch #17, Batch 8930/24958 loss = 1.2689455193281174, ppl = 3.5793810115230964\n","Train Epoch #17, Batch 8931/24958 loss = 1.26698346555233, ppl = 3.5725301227643587\n","Train Epoch #17, Batch 8932/24958 loss = 1.2671020013093948, ppl = 3.5729350030215854\n","Train Epoch #17, Batch 8933/24958 loss = 1.267079456448555, ppl = 3.5728588760266775\n","Train Epoch #17, Batch 8934/24958 loss = 1.2678094667196274, ppl = 3.575460561768133\n","Train Epoch #17, Batch 8935/24958 loss = 1.2654304271936416, ppl = 3.5665867030018092\n","Train Epoch #17, Batch 8936/24958 loss = 1.266256303191185, ppl = 3.569664536020074\n","Train Epoch #17, Batch 8937/24958 loss = 1.2644431287050246, ppl = 3.562613270108131\n","Train Epoch #17, Batch 8938/24958 loss = 1.262851089835167, ppl = 3.557534948887652\n","Train Epoch #17, Batch 8939/24958 loss = 1.2633763736486434, ppl = 3.55933501577003\n","Train Epoch #17, Batch 8940/24958 loss = 1.2651817172765731, ppl = 3.5660421996263367\n","Train Epoch #17, Batch 8941/24958 loss = 1.2657196301221847, ppl = 3.567913420426689\n","Train Epoch #17, Batch 8942/24958 loss = 1.2640856558084488, ppl = 3.562894689100473\n","Train Epoch #17, Batch 8943/24958 loss = 1.2619888752698898, ppl = 3.5555227297444163\n","Train Epoch #17, Batch 8944/24958 loss = 1.2626826184988023, ppl = 3.557879102365466\n","Train Epoch #17, Batch 8945/24958 loss = 1.2626250022649765, ppl = 3.557642481006707\n","Train Epoch #17, Batch 8946/24958 loss = 1.2637353307008743, ppl = 3.561325800647747\n","Train Epoch #17, Batch 8947/24958 loss = 1.2645113277435303, ppl = 3.563509151697466\n","Train Epoch #17, Batch 8948/24958 loss = 1.266010159254074, ppl = 3.569385754130002\n","Train Epoch #17, Batch 8949/24958 loss = 1.2666328632831574, ppl = 3.5712467043588196\n","Train Epoch #17, Batch 8950/24958 loss = 1.2683584225177764, ppl = 3.5768180225005755\n","Train Epoch #17, Batch 8951/24958 loss = 1.2674108409881593, ppl = 3.5739752393273765\n","Train Epoch #17, Batch 8952/24958 loss = 1.267025374174118, ppl = 3.572674776592821\n","Train Epoch #17, Batch 8953/24958 loss = 1.2665691184997558, ppl = 3.571010336612108\n","Train Epoch #17, Batch 8954/24958 loss = 1.266287430524826, ppl = 3.5699529861978174\n","Train Epoch #17, Batch 8955/24958 loss = 1.2664961862564086, ppl = 3.570689648037718\n","Train Epoch #17, Batch 8956/24958 loss = 1.266401400566101, ppl = 3.570369985281003\n","Train Epoch #17, Batch 8957/24958 loss = 1.2667928004264832, ppl = 3.571781643609931\n","Train Epoch #17, Batch 8958/24958 loss = 1.2664342176914216, ppl = 3.570584310237722\n","Train Epoch #17, Batch 8959/24958 loss = 1.2672481918334961, ppl = 3.5735116306821184\n","Train Epoch #17, Batch 8960/24958 loss = 1.2647325098514557, ppl = 3.5644637660602827\n","Train Epoch #17, Batch 8961/24958 loss = 1.2656787037849426, ppl = 3.5680531078616777\n","Train Epoch #17, Batch 8962/24958 loss = 1.2661944472789763, ppl = 3.569940907151542\n","Train Epoch #17, Batch 8963/24958 loss = 1.2668837201595307, ppl = 3.5723154564027415\n","Train Epoch #17, Batch 8964/24958 loss = 1.2662964975833892, ppl = 3.5701516208995963\n","Train Epoch #17, Batch 8965/24958 loss = 1.2649818229675294, ppl = 3.5661643468242756\n","Train Epoch #17, Batch 8966/24958 loss = 1.264666382074356, ppl = 3.5648466301103547\n","Train Epoch #17, Batch 8967/24958 loss = 1.263831148147583, ppl = 3.5619289669715988\n","Train Epoch #17, Batch 8968/24958 loss = 1.264522808790207, ppl = 3.5643366067553313\n","Train Epoch #17, Batch 8969/24958 loss = 1.2634122788906097, ppl = 3.560493013997633\n","Train Epoch #17, Batch 8970/24958 loss = 1.2623646891117095, ppl = 3.556927942025465\n","Train Epoch #17, Batch 8971/24958 loss = 1.2645550274848938, ppl = 3.565821455658067\n","Train Epoch #17, Batch 8972/24958 loss = 1.2651444470882416, ppl = 3.5680029451284723\n","Train Epoch #17, Batch 8973/24958 loss = 1.2656679105758668, ppl = 3.569895242944125\n","Train Epoch #17, Batch 8974/24958 loss = 1.2676063215732574, ppl = 3.576699077588001\n","Train Epoch #17, Batch 8975/24958 loss = 1.2684403109550475, ppl = 3.580103487559544\n","Train Epoch #17, Batch 8976/24958 loss = 1.2688208389282227, ppl = 3.581461060851277\n","Train Epoch #17, Batch 8977/24958 loss = 1.2667830204963684, ppl = 3.5742663608656913\n","Train Epoch #17, Batch 8978/24958 loss = 1.268494757413864, ppl = 3.580442233799532\n","Train Epoch #17, Batch 8979/24958 loss = 1.2698750817775726, ppl = 3.5852772102166415\n","Train Epoch #17, Batch 8980/24958 loss = 1.2712925243377686, ppl = 3.59084290408908\n","Train Epoch #17, Batch 8981/24958 loss = 1.2730902338027954, ppl = 3.597334578527028\n","Train Epoch #17, Batch 8982/24958 loss = 1.272618362903595, ppl = 3.5956347910837034\n","Train Epoch #17, Batch 8983/24958 loss = 1.2721829771995545, ppl = 3.594192440115017\n","Train Epoch #17, Batch 8984/24958 loss = 1.2709470689296722, ppl = 3.5892476902852866\n","Train Epoch #17, Batch 8985/24958 loss = 1.2677764618396759, ppl = 3.577213754861134\n","Train Epoch #17, Batch 8986/24958 loss = 1.2696682047843932, ppl = 3.5847557326346076\n","Train Epoch #17, Batch 8987/24958 loss = 1.2692007315158844, ppl = 3.5833024993067357\n","Train Epoch #17, Batch 8988/24958 loss = 1.268885966539383, ppl = 3.582249222734703\n","Train Epoch #17, Batch 8989/24958 loss = 1.2711191165447235, ppl = 3.589265386561587\n","Train Epoch #17, Batch 8990/24958 loss = 1.2689697098731996, ppl = 3.5810823602064703\n","Train Epoch #17, Batch 8991/24958 loss = 1.268324201107025, ppl = 3.578943128336852\n","Train Epoch #17, Batch 8992/24958 loss = 1.2690475380420685, ppl = 3.5815321435358367\n","Train Epoch #17, Batch 8993/24958 loss = 1.270442510843277, ppl = 3.586521581399414\n","Train Epoch #17, Batch 8994/24958 loss = 1.2740639173984527, ppl = 3.5993549572424026\n","Train Epoch #17, Batch 8995/24958 loss = 1.271576325893402, ppl = 3.5890547724110013\n","Train Epoch #17, Batch 8996/24958 loss = 1.2707515025138856, ppl = 3.586496285047988\n","Train Epoch #17, Batch 8997/24958 loss = 1.2721280002593993, ppl = 3.591476700951142\n","Train Epoch #17, Batch 8998/24958 loss = 1.2681546556949614, ppl = 3.576729566047884\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"yUg0ghVu0qbW","executionInfo":{"status":"ok","timestamp":1622366081214,"user_tz":-540,"elapsed":6122,"user":{"displayName":"최석웅","photoUrl":"","userId":"05234760535644650462"}}},"source":["  SAVE_PATH = f'./model_checkpoints/cur_epoch_{cur_epoch+1}_train_loss_{int(train_loss_sum/len(train_dl.data_iter))}_train_ppl_{int(train_ppl_sum/len(train_dl.data_iter))}_valid_loss_{int(valid_loss_sum/len(test_valid_dl.data_iter))}_valid_ppl_{int(valid_ppl_sum/len(test_valid_dl.data_iter))}.pt'\n","  torch.save({'hyper_params' : hyper_params, 'train_loss_sum' : train_loss_sum, 'train_ppl_sum' : train_ppl_sum, 'valid_loss_sum' : valid_loss_sum, 'valid_ppl_sum' : valid_ppl_sum,\n","              'model_state_dict' : tl_model.state_dict(), 'optim_state_dict' : optimizer.state_dict(), 'grad_scaler_state_dict' : scaler.state_dict()}, SAVE_PATH)"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"fgKcF_WrjbWA"},"source":[""],"execution_count":null,"outputs":[]}]}